{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b1b3fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 13:23:59,060 - INFO - Using device: cuda\n",
      "2025-05-30 13:23:59,060 - INFO - Loading DataFrames...\n",
      "2025-05-30 13:23:59,142 - INFO - Data loaded: 9429 training, 607 validation samples\n",
      "2025-05-30 13:23:59,142 - INFO - Medical material: 2305/9429 train positive, 152/607 valid positive\n",
      "2025-05-30 13:23:59,142 - INFO - Arterial wall calcification: 4492/9429 train positive, 274/607 valid positive\n",
      "2025-05-30 13:23:59,142 - INFO - Cardiomegaly: 2343/9429 train positive, 171/607 valid positive\n",
      "2025-05-30 13:23:59,142 - INFO - Pericardial effusion: 2301/9429 train positive, 151/607 valid positive\n",
      "2025-05-30 13:23:59,148 - INFO - Coronary artery wall calcification: 4039/9429 train positive, 257/607 valid positive\n",
      "2025-05-30 13:23:59,149 - INFO - Hiatal hernia: 2305/9429 train positive, 152/607 valid positive\n",
      "2025-05-30 13:23:59,149 - INFO - Lymphadenopathy: 3757/9429 train positive, 236/607 valid positive\n",
      "2025-05-30 13:23:59,149 - INFO - Emphysema: 2368/9429 train positive, 158/607 valid positive\n",
      "2025-05-30 13:23:59,149 - INFO - Atelectasis: 3486/9429 train positive, 213/607 valid positive\n",
      "2025-05-30 13:23:59,149 - INFO - Lung nodule: 4438/9429 train positive, 276/607 valid positive\n",
      "2025-05-30 13:23:59,149 - INFO - Lung opacity: 4284/9429 train positive, 275/607 valid positive\n",
      "2025-05-30 13:23:59,149 - INFO - Pulmonary fibrotic sequela: 3103/9429 train positive, 188/607 valid positive\n",
      "2025-05-30 13:23:59,149 - INFO - Pleural effusion: 2440/9429 train positive, 178/607 valid positive\n",
      "2025-05-30 13:23:59,149 - INFO - Mosaic attenuation pattern: 2299/9429 train positive, 152/607 valid positive\n",
      "2025-05-30 13:23:59,149 - INFO - Peribronchial thickening: 2301/9429 train positive, 151/607 valid positive\n",
      "2025-05-30 13:23:59,156 - INFO - Consolidation: 2362/9429 train positive, 167/607 valid positive\n",
      "2025-05-30 13:23:59,156 - INFO - Bronchiectasis: 2299/9429 train positive, 151/607 valid positive\n",
      "2025-05-30 13:23:59,156 - INFO - Interlobular septal thickening: 2299/9429 train positive, 150/607 valid positive\n",
      "2025-05-30 13:23:59,159 - INFO - Dataset initialized with 9429 samples\n",
      "2025-05-30 13:23:59,160 - INFO - Dataset initialized with 607 samples\n",
      "2025-05-30 13:23:59,420 - INFO - Created ResNet3D-18 model with gradient checkpointing\n",
      "2025-05-30 13:24:01,086 - INFO - Starting training from epoch 1...\n",
      "2025-05-30 13:24:02,638 - INFO - Epoch [1/30] Batch [0/4715] Loss: 0.9723\n",
      "2025-05-30 13:24:04,354 - INFO - Epoch [1/30] Batch [10/4715] Loss: 0.9686\n",
      "2025-05-30 13:24:06,082 - INFO - Epoch [1/30] Batch [20/4715] Loss: 0.9316\n",
      "2025-05-30 13:24:07,806 - INFO - Epoch [1/30] Batch [30/4715] Loss: 0.9274\n",
      "2025-05-30 13:24:09,486 - INFO - Epoch [1/30] Batch [40/4715] Loss: 1.1041\n",
      "2025-05-30 13:24:11,136 - INFO - Epoch [1/30] Batch [50/4715] Loss: 0.9126\n",
      "2025-05-30 13:24:12,838 - INFO - Epoch [1/30] Batch [60/4715] Loss: 0.9599\n",
      "2025-05-30 13:24:14,547 - INFO - Epoch [1/30] Batch [70/4715] Loss: 0.8198\n",
      "2025-05-30 13:24:16,436 - INFO - Epoch [1/30] Batch [80/4715] Loss: 0.9186\n",
      "2025-05-30 13:24:18,179 - INFO - Epoch [1/30] Batch [90/4715] Loss: 0.9431\n",
      "2025-05-30 13:24:19,813 - INFO - Epoch [1/30] Batch [100/4715] Loss: 1.0012\n",
      "2025-05-30 13:24:21,659 - INFO - Epoch [1/30] Batch [110/4715] Loss: 0.9743\n",
      "2025-05-30 13:24:23,506 - INFO - Epoch [1/30] Batch [120/4715] Loss: 0.9223\n",
      "2025-05-30 13:24:25,273 - INFO - Epoch [1/30] Batch [130/4715] Loss: 1.0449\n",
      "2025-05-30 13:24:26,972 - INFO - Epoch [1/30] Batch [140/4715] Loss: 0.9130\n",
      "2025-05-30 13:24:28,701 - INFO - Epoch [1/30] Batch [150/4715] Loss: 0.9191\n",
      "2025-05-30 13:24:30,722 - INFO - Epoch [1/30] Batch [160/4715] Loss: 0.9114\n",
      "2025-05-30 13:24:32,570 - INFO - Epoch [1/30] Batch [170/4715] Loss: 1.0829\n",
      "2025-05-30 13:24:34,244 - INFO - Epoch [1/30] Batch [180/4715] Loss: 1.0358\n",
      "2025-05-30 13:24:35,994 - INFO - Epoch [1/30] Batch [190/4715] Loss: 0.8970\n",
      "2025-05-30 13:24:37,793 - INFO - Epoch [1/30] Batch [200/4715] Loss: 0.8315\n",
      "2025-05-30 13:24:40,356 - INFO - Epoch [1/30] Batch [210/4715] Loss: 0.8207\n",
      "2025-05-30 13:24:42,127 - INFO - Epoch [1/30] Batch [220/4715] Loss: 0.8669\n",
      "2025-05-30 13:24:43,856 - INFO - Epoch [1/30] Batch [230/4715] Loss: 0.9586\n",
      "2025-05-30 13:24:45,634 - INFO - Epoch [1/30] Batch [240/4715] Loss: 0.9648\n",
      "2025-05-30 13:24:47,385 - INFO - Epoch [1/30] Batch [250/4715] Loss: 0.9536\n",
      "2025-05-30 13:24:49,246 - INFO - Epoch [1/30] Batch [260/4715] Loss: 0.8828\n",
      "2025-05-30 13:24:50,970 - INFO - Epoch [1/30] Batch [270/4715] Loss: 0.9803\n",
      "2025-05-30 13:24:52,802 - INFO - Epoch [1/30] Batch [280/4715] Loss: 0.8759\n",
      "2025-05-30 13:24:54,505 - INFO - Epoch [1/30] Batch [290/4715] Loss: 1.0499\n",
      "2025-05-30 13:24:56,219 - INFO - Epoch [1/30] Batch [300/4715] Loss: 1.0088\n",
      "2025-05-30 13:24:57,959 - INFO - Epoch [1/30] Batch [310/4715] Loss: 0.9076\n",
      "2025-05-30 13:24:59,657 - INFO - Epoch [1/30] Batch [320/4715] Loss: 1.1167\n",
      "2025-05-30 13:25:01,373 - INFO - Epoch [1/30] Batch [330/4715] Loss: 1.0094\n",
      "2025-05-30 13:25:03,345 - INFO - Epoch [1/30] Batch [340/4715] Loss: 1.0049\n",
      "2025-05-30 13:25:05,260 - INFO - Epoch [1/30] Batch [350/4715] Loss: 0.9683\n",
      "2025-05-30 13:25:06,943 - INFO - Epoch [1/30] Batch [360/4715] Loss: 0.9863\n",
      "2025-05-30 13:25:08,655 - INFO - Epoch [1/30] Batch [370/4715] Loss: 1.1349\n",
      "2025-05-30 13:25:10,355 - INFO - Epoch [1/30] Batch [380/4715] Loss: 1.0346\n",
      "2025-05-30 13:25:12,107 - INFO - Epoch [1/30] Batch [390/4715] Loss: 0.9367\n",
      "2025-05-30 13:25:13,883 - INFO - Epoch [1/30] Batch [400/4715] Loss: 0.8965\n",
      "2025-05-30 13:25:15,654 - INFO - Epoch [1/30] Batch [410/4715] Loss: 0.9992\n",
      "2025-05-30 13:25:17,456 - INFO - Epoch [1/30] Batch [420/4715] Loss: 0.8907\n",
      "2025-05-30 13:25:19,404 - INFO - Epoch [1/30] Batch [430/4715] Loss: 0.9111\n",
      "2025-05-30 13:25:21,221 - INFO - Epoch [1/30] Batch [440/4715] Loss: 0.9021\n",
      "2025-05-30 13:25:22,938 - INFO - Epoch [1/30] Batch [450/4715] Loss: 0.8945\n",
      "2025-05-30 13:25:24,640 - INFO - Epoch [1/30] Batch [460/4715] Loss: 0.9318\n",
      "2025-05-30 13:25:26,320 - INFO - Epoch [1/30] Batch [470/4715] Loss: 1.0460\n",
      "2025-05-30 13:25:28,022 - INFO - Epoch [1/30] Batch [480/4715] Loss: 0.9090\n",
      "2025-05-30 13:25:29,689 - INFO - Epoch [1/30] Batch [490/4715] Loss: 0.7888\n",
      "2025-05-30 13:25:31,481 - INFO - Epoch [1/30] Batch [500/4715] Loss: 0.8835\n",
      "2025-05-30 13:25:33,294 - INFO - Epoch [1/30] Batch [510/4715] Loss: 0.8987\n",
      "2025-05-30 13:25:34,995 - INFO - Epoch [1/30] Batch [520/4715] Loss: 0.9081\n",
      "2025-05-30 13:25:36,760 - INFO - Epoch [1/30] Batch [530/4715] Loss: 0.8795\n",
      "2025-05-30 13:25:38,509 - INFO - Epoch [1/30] Batch [540/4715] Loss: 0.9012\n",
      "2025-05-30 13:25:40,246 - INFO - Epoch [1/30] Batch [550/4715] Loss: 0.8673\n",
      "2025-05-30 13:25:41,991 - INFO - Epoch [1/30] Batch [560/4715] Loss: 1.0148\n",
      "2025-05-30 13:25:43,809 - INFO - Epoch [1/30] Batch [570/4715] Loss: 0.9969\n",
      "2025-05-30 13:25:45,546 - INFO - Epoch [1/30] Batch [580/4715] Loss: 0.9008\n",
      "2025-05-30 13:25:47,240 - INFO - Epoch [1/30] Batch [590/4715] Loss: 0.9819\n",
      "2025-05-30 13:25:49,227 - INFO - Epoch [1/30] Batch [600/4715] Loss: 1.0238\n",
      "2025-05-30 13:25:50,977 - INFO - Epoch [1/30] Batch [610/4715] Loss: 0.9600\n",
      "2025-05-30 13:25:52,888 - INFO - Epoch [1/30] Batch [620/4715] Loss: 0.8440\n",
      "2025-05-30 13:25:54,846 - INFO - Epoch [1/30] Batch [630/4715] Loss: 1.1264\n",
      "2025-05-30 13:25:56,595 - INFO - Epoch [1/30] Batch [640/4715] Loss: 1.0342\n",
      "2025-05-30 13:25:58,318 - INFO - Epoch [1/30] Batch [650/4715] Loss: 0.8543\n",
      "2025-05-30 13:26:00,221 - INFO - Epoch [1/30] Batch [660/4715] Loss: 1.2540\n",
      "2025-05-30 13:26:01,992 - INFO - Epoch [1/30] Batch [670/4715] Loss: 0.9226\n",
      "2025-05-30 13:26:03,777 - INFO - Epoch [1/30] Batch [680/4715] Loss: 0.9594\n",
      "2025-05-30 13:26:05,472 - INFO - Epoch [1/30] Batch [690/4715] Loss: 0.8958\n",
      "2025-05-30 13:26:07,171 - INFO - Epoch [1/30] Batch [700/4715] Loss: 0.7397\n",
      "2025-05-30 13:26:08,896 - INFO - Epoch [1/30] Batch [710/4715] Loss: 1.0010\n",
      "2025-05-30 13:26:10,480 - INFO - Epoch [1/30] Batch [720/4715] Loss: 1.0577\n",
      "2025-05-30 13:26:12,289 - INFO - Epoch [1/30] Batch [730/4715] Loss: 1.0221\n",
      "2025-05-30 13:26:14,112 - INFO - Epoch [1/30] Batch [740/4715] Loss: 0.8255\n",
      "2025-05-30 13:26:15,971 - INFO - Epoch [1/30] Batch [750/4715] Loss: 0.8819\n",
      "2025-05-30 13:26:17,734 - INFO - Epoch [1/30] Batch [760/4715] Loss: 1.0018\n",
      "2025-05-30 13:26:19,446 - INFO - Epoch [1/30] Batch [770/4715] Loss: 0.9528\n",
      "2025-05-30 13:26:21,238 - INFO - Epoch [1/30] Batch [780/4715] Loss: 0.8638\n",
      "2025-05-30 13:26:23,035 - INFO - Epoch [1/30] Batch [790/4715] Loss: 0.9088\n",
      "2025-05-30 13:26:24,890 - INFO - Epoch [1/30] Batch [800/4715] Loss: 0.9070\n",
      "2025-05-30 13:26:26,692 - INFO - Epoch [1/30] Batch [810/4715] Loss: 0.8530\n",
      "2025-05-30 13:26:28,475 - INFO - Epoch [1/30] Batch [820/4715] Loss: 0.8711\n",
      "2025-05-30 13:26:30,206 - INFO - Epoch [1/30] Batch [830/4715] Loss: 0.9197\n",
      "2025-05-30 13:26:32,012 - INFO - Epoch [1/30] Batch [840/4715] Loss: 0.8763\n",
      "2025-05-30 13:26:33,707 - INFO - Epoch [1/30] Batch [850/4715] Loss: 0.8728\n",
      "2025-05-30 13:26:35,436 - INFO - Epoch [1/30] Batch [860/4715] Loss: 1.0237\n",
      "2025-05-30 13:26:37,192 - INFO - Epoch [1/30] Batch [870/4715] Loss: 0.9024\n",
      "2025-05-30 13:26:38,965 - INFO - Epoch [1/30] Batch [880/4715] Loss: 0.9348\n",
      "2025-05-30 13:26:40,692 - INFO - Epoch [1/30] Batch [890/4715] Loss: 0.9277\n",
      "2025-05-30 13:26:42,419 - INFO - Epoch [1/30] Batch [900/4715] Loss: 1.0119\n",
      "2025-05-30 13:26:44,137 - INFO - Epoch [1/30] Batch [910/4715] Loss: 0.9267\n",
      "2025-05-30 13:26:45,889 - INFO - Epoch [1/30] Batch [920/4715] Loss: 0.8750\n",
      "2025-05-30 13:26:47,672 - INFO - Epoch [1/30] Batch [930/4715] Loss: 1.1715\n",
      "2025-05-30 13:26:49,346 - INFO - Epoch [1/30] Batch [940/4715] Loss: 0.7673\n",
      "2025-05-30 13:26:51,027 - INFO - Epoch [1/30] Batch [950/4715] Loss: 0.8917\n",
      "2025-05-30 13:26:52,722 - INFO - Epoch [1/30] Batch [960/4715] Loss: 0.9796\n",
      "2025-05-30 13:26:54,479 - INFO - Epoch [1/30] Batch [970/4715] Loss: 1.1679\n",
      "2025-05-30 13:26:56,306 - INFO - Epoch [1/30] Batch [980/4715] Loss: 1.1107\n",
      "2025-05-30 13:26:58,021 - INFO - Epoch [1/30] Batch [990/4715] Loss: 1.0705\n",
      "2025-05-30 13:26:59,744 - INFO - Epoch [1/30] Batch [1000/4715] Loss: 0.9381\n",
      "2025-05-30 13:27:01,598 - INFO - Epoch [1/30] Batch [1010/4715] Loss: 0.8417\n",
      "2025-05-30 13:27:03,371 - INFO - Epoch [1/30] Batch [1020/4715] Loss: 0.9288\n",
      "2025-05-30 13:27:05,175 - INFO - Epoch [1/30] Batch [1030/4715] Loss: 0.9269\n",
      "2025-05-30 13:27:06,936 - INFO - Epoch [1/30] Batch [1040/4715] Loss: 0.7998\n",
      "2025-05-30 13:27:08,641 - INFO - Epoch [1/30] Batch [1050/4715] Loss: 1.0371\n",
      "2025-05-30 13:27:10,495 - INFO - Epoch [1/30] Batch [1060/4715] Loss: 0.9346\n",
      "2025-05-30 13:27:12,319 - INFO - Epoch [1/30] Batch [1070/4715] Loss: 0.8576\n",
      "2025-05-30 13:27:14,093 - INFO - Epoch [1/30] Batch [1080/4715] Loss: 1.0583\n",
      "2025-05-30 13:27:15,868 - INFO - Epoch [1/30] Batch [1090/4715] Loss: 1.0485\n",
      "2025-05-30 13:27:17,545 - INFO - Epoch [1/30] Batch [1100/4715] Loss: 0.9188\n",
      "2025-05-30 13:27:19,246 - INFO - Epoch [1/30] Batch [1110/4715] Loss: 0.8814\n",
      "2025-05-30 13:27:20,971 - INFO - Epoch [1/30] Batch [1120/4715] Loss: 0.8524\n",
      "2025-05-30 13:27:22,726 - INFO - Epoch [1/30] Batch [1130/4715] Loss: 0.8924\n",
      "2025-05-30 13:27:24,515 - INFO - Epoch [1/30] Batch [1140/4715] Loss: 0.8996\n",
      "2025-05-30 13:27:26,372 - INFO - Epoch [1/30] Batch [1150/4715] Loss: 1.1989\n",
      "2025-05-30 13:27:28,018 - INFO - Epoch [1/30] Batch [1160/4715] Loss: 0.9831\n",
      "2025-05-30 13:27:29,742 - INFO - Epoch [1/30] Batch [1170/4715] Loss: 0.8606\n",
      "2025-05-30 13:27:31,401 - INFO - Epoch [1/30] Batch [1180/4715] Loss: 0.7201\n",
      "2025-05-30 13:27:33,132 - INFO - Epoch [1/30] Batch [1190/4715] Loss: 1.0172\n",
      "2025-05-30 13:27:35,019 - INFO - Epoch [1/30] Batch [1200/4715] Loss: 1.1013\n",
      "2025-05-30 13:27:36,835 - INFO - Epoch [1/30] Batch [1210/4715] Loss: 1.0941\n",
      "2025-05-30 13:27:38,680 - INFO - Epoch [1/30] Batch [1220/4715] Loss: 0.9531\n",
      "2025-05-30 13:27:40,492 - INFO - Epoch [1/30] Batch [1230/4715] Loss: 0.9121\n",
      "2025-05-30 13:27:42,208 - INFO - Epoch [1/30] Batch [1240/4715] Loss: 0.7743\n",
      "2025-05-30 13:27:43,861 - INFO - Epoch [1/30] Batch [1250/4715] Loss: 0.9109\n",
      "2025-05-30 13:27:45,668 - INFO - Epoch [1/30] Batch [1260/4715] Loss: 0.9828\n",
      "2025-05-30 13:27:47,459 - INFO - Epoch [1/30] Batch [1270/4715] Loss: 1.1341\n",
      "2025-05-30 13:27:49,236 - INFO - Epoch [1/30] Batch [1280/4715] Loss: 0.9172\n",
      "2025-05-30 13:27:51,064 - INFO - Epoch [1/30] Batch [1290/4715] Loss: 0.8066\n",
      "2025-05-30 13:27:52,925 - INFO - Epoch [1/30] Batch [1300/4715] Loss: 1.0114\n",
      "2025-05-30 13:27:54,647 - INFO - Epoch [1/30] Batch [1310/4715] Loss: 0.8991\n",
      "2025-05-30 13:27:56,376 - INFO - Epoch [1/30] Batch [1320/4715] Loss: 0.9515\n",
      "2025-05-30 13:27:58,087 - INFO - Epoch [1/30] Batch [1330/4715] Loss: 0.9508\n",
      "2025-05-30 13:28:00,255 - INFO - Epoch [1/30] Batch [1340/4715] Loss: 1.1393\n",
      "2025-05-30 13:28:01,961 - INFO - Epoch [1/30] Batch [1350/4715] Loss: 1.0128\n",
      "2025-05-30 13:28:03,774 - INFO - Epoch [1/30] Batch [1360/4715] Loss: 0.8260\n",
      "2025-05-30 13:28:05,621 - INFO - Epoch [1/30] Batch [1370/4715] Loss: 1.0250\n",
      "2025-05-30 13:28:07,378 - INFO - Epoch [1/30] Batch [1380/4715] Loss: 0.8642\n",
      "2025-05-30 13:28:09,274 - INFO - Epoch [1/30] Batch [1390/4715] Loss: 0.8064\n",
      "2025-05-30 13:28:11,275 - INFO - Epoch [1/30] Batch [1400/4715] Loss: 0.9963\n",
      "2025-05-30 13:28:13,236 - INFO - Epoch [1/30] Batch [1410/4715] Loss: 1.0037\n",
      "2025-05-30 13:28:15,039 - INFO - Epoch [1/30] Batch [1420/4715] Loss: 0.9621\n",
      "2025-05-30 13:28:16,759 - INFO - Epoch [1/30] Batch [1430/4715] Loss: 0.9960\n",
      "2025-05-30 13:28:18,475 - INFO - Epoch [1/30] Batch [1440/4715] Loss: 0.9936\n",
      "2025-05-30 13:28:20,154 - INFO - Epoch [1/30] Batch [1450/4715] Loss: 0.8887\n",
      "2025-05-30 13:28:21,890 - INFO - Epoch [1/30] Batch [1460/4715] Loss: 0.8718\n",
      "2025-05-30 13:28:23,611 - INFO - Epoch [1/30] Batch [1470/4715] Loss: 0.9986\n",
      "2025-05-30 13:28:25,457 - INFO - Epoch [1/30] Batch [1480/4715] Loss: 1.0239\n",
      "2025-05-30 13:28:27,287 - INFO - Epoch [1/30] Batch [1490/4715] Loss: 0.9603\n",
      "2025-05-30 13:28:29,041 - INFO - Epoch [1/30] Batch [1500/4715] Loss: 0.7925\n",
      "2025-05-30 13:28:30,861 - INFO - Epoch [1/30] Batch [1510/4715] Loss: 0.8119\n",
      "2025-05-30 13:28:32,582 - INFO - Epoch [1/30] Batch [1520/4715] Loss: 0.8251\n",
      "2025-05-30 13:28:34,398 - INFO - Epoch [1/30] Batch [1530/4715] Loss: 0.9120\n",
      "2025-05-30 13:28:36,301 - INFO - Epoch [1/30] Batch [1540/4715] Loss: 0.8557\n",
      "2025-05-30 13:28:37,952 - INFO - Epoch [1/30] Batch [1550/4715] Loss: 0.8356\n",
      "2025-05-30 13:28:39,613 - INFO - Epoch [1/30] Batch [1560/4715] Loss: 0.9619\n",
      "2025-05-30 13:28:41,366 - INFO - Epoch [1/30] Batch [1570/4715] Loss: 1.1255\n",
      "2025-05-30 13:28:43,092 - INFO - Epoch [1/30] Batch [1580/4715] Loss: 0.9864\n",
      "2025-05-30 13:28:44,753 - INFO - Epoch [1/30] Batch [1590/4715] Loss: 1.0234\n",
      "2025-05-30 13:28:46,474 - INFO - Epoch [1/30] Batch [1600/4715] Loss: 0.8308\n",
      "2025-05-30 13:28:48,261 - INFO - Epoch [1/30] Batch [1610/4715] Loss: 0.9212\n",
      "2025-05-30 13:28:50,160 - INFO - Epoch [1/30] Batch [1620/4715] Loss: 1.1638\n",
      "2025-05-30 13:28:51,944 - INFO - Epoch [1/30] Batch [1630/4715] Loss: 1.1218\n",
      "2025-05-30 13:28:53,774 - INFO - Epoch [1/30] Batch [1640/4715] Loss: 1.0979\n",
      "2025-05-30 13:28:55,604 - INFO - Epoch [1/30] Batch [1650/4715] Loss: 0.7783\n",
      "2025-05-30 13:28:57,282 - INFO - Epoch [1/30] Batch [1660/4715] Loss: 1.0681\n",
      "2025-05-30 13:28:59,059 - INFO - Epoch [1/30] Batch [1670/4715] Loss: 0.9189\n",
      "2025-05-30 13:29:01,053 - INFO - Epoch [1/30] Batch [1680/4715] Loss: 0.9917\n",
      "2025-05-30 13:29:02,989 - INFO - Epoch [1/30] Batch [1690/4715] Loss: 0.9726\n",
      "2025-05-30 13:29:04,845 - INFO - Epoch [1/30] Batch [1700/4715] Loss: 0.8917\n",
      "2025-05-30 13:29:06,650 - INFO - Epoch [1/30] Batch [1710/4715] Loss: 0.8880\n",
      "2025-05-30 13:29:08,449 - INFO - Epoch [1/30] Batch [1720/4715] Loss: 0.9258\n",
      "2025-05-30 13:29:10,223 - INFO - Epoch [1/30] Batch [1730/4715] Loss: 1.0736\n",
      "2025-05-30 13:29:11,940 - INFO - Epoch [1/30] Batch [1740/4715] Loss: 0.8371\n",
      "2025-05-30 13:29:13,683 - INFO - Epoch [1/30] Batch [1750/4715] Loss: 0.9691\n",
      "2025-05-30 13:29:15,506 - INFO - Epoch [1/30] Batch [1760/4715] Loss: 0.7739\n",
      "2025-05-30 13:29:17,341 - INFO - Epoch [1/30] Batch [1770/4715] Loss: 0.9434\n",
      "2025-05-30 13:29:19,125 - INFO - Epoch [1/30] Batch [1780/4715] Loss: 1.1312\n",
      "2025-05-30 13:29:20,836 - INFO - Epoch [1/30] Batch [1790/4715] Loss: 0.8664\n",
      "2025-05-30 13:29:22,666 - INFO - Epoch [1/30] Batch [1800/4715] Loss: 0.7867\n",
      "2025-05-30 13:29:24,475 - INFO - Epoch [1/30] Batch [1810/4715] Loss: 1.0116\n",
      "2025-05-30 13:29:26,292 - INFO - Epoch [1/30] Batch [1820/4715] Loss: 0.9604\n",
      "2025-05-30 13:29:28,184 - INFO - Epoch [1/30] Batch [1830/4715] Loss: 0.8908\n",
      "2025-05-30 13:29:30,186 - INFO - Epoch [1/30] Batch [1840/4715] Loss: 1.0100\n",
      "2025-05-30 13:29:32,002 - INFO - Epoch [1/30] Batch [1850/4715] Loss: 0.8372\n",
      "2025-05-30 13:29:33,807 - INFO - Epoch [1/30] Batch [1860/4715] Loss: 0.8957\n",
      "2025-05-30 13:29:35,689 - INFO - Epoch [1/30] Batch [1870/4715] Loss: 0.8629\n",
      "2025-05-30 13:29:37,446 - INFO - Epoch [1/30] Batch [1880/4715] Loss: 0.8105\n",
      "2025-05-30 13:29:39,079 - INFO - Epoch [1/30] Batch [1890/4715] Loss: 0.8104\n",
      "2025-05-30 13:29:40,727 - INFO - Epoch [1/30] Batch [1900/4715] Loss: 0.8777\n",
      "2025-05-30 13:29:42,468 - INFO - Epoch [1/30] Batch [1910/4715] Loss: 1.0421\n",
      "2025-05-30 13:29:44,234 - INFO - Epoch [1/30] Batch [1920/4715] Loss: 0.7761\n",
      "2025-05-30 13:29:45,936 - INFO - Epoch [1/30] Batch [1930/4715] Loss: 0.8109\n",
      "2025-05-30 13:29:47,564 - INFO - Epoch [1/30] Batch [1940/4715] Loss: 0.8585\n",
      "2025-05-30 13:29:49,266 - INFO - Epoch [1/30] Batch [1950/4715] Loss: 0.8444\n",
      "2025-05-30 13:29:51,083 - INFO - Epoch [1/30] Batch [1960/4715] Loss: 0.7544\n",
      "2025-05-30 13:29:52,747 - INFO - Epoch [1/30] Batch [1970/4715] Loss: 0.9212\n",
      "2025-05-30 13:29:54,560 - INFO - Epoch [1/30] Batch [1980/4715] Loss: 0.8485\n",
      "2025-05-30 13:29:56,296 - INFO - Epoch [1/30] Batch [1990/4715] Loss: 0.7867\n",
      "2025-05-30 13:29:58,064 - INFO - Epoch [1/30] Batch [2000/4715] Loss: 0.7136\n",
      "2025-05-30 13:29:59,845 - INFO - Epoch [1/30] Batch [2010/4715] Loss: 1.0138\n",
      "2025-05-30 13:30:01,630 - INFO - Epoch [1/30] Batch [2020/4715] Loss: 0.7866\n",
      "2025-05-30 13:30:03,374 - INFO - Epoch [1/30] Batch [2030/4715] Loss: 1.0571\n",
      "2025-05-30 13:30:05,163 - INFO - Epoch [1/30] Batch [2040/4715] Loss: 0.8750\n",
      "2025-05-30 13:30:06,846 - INFO - Epoch [1/30] Batch [2050/4715] Loss: 0.8977\n",
      "2025-05-30 13:30:08,567 - INFO - Epoch [1/30] Batch [2060/4715] Loss: 0.8001\n",
      "2025-05-30 13:30:10,237 - INFO - Epoch [1/30] Batch [2070/4715] Loss: 0.8862\n",
      "2025-05-30 13:30:12,058 - INFO - Epoch [1/30] Batch [2080/4715] Loss: 1.0787\n",
      "2025-05-30 13:30:13,758 - INFO - Epoch [1/30] Batch [2090/4715] Loss: 0.9383\n",
      "2025-05-30 13:30:16,638 - INFO - Epoch [1/30] Batch [2100/4715] Loss: 0.9783\n",
      "2025-05-30 13:30:18,584 - INFO - Epoch [1/30] Batch [2110/4715] Loss: 0.9813\n",
      "2025-05-30 13:30:20,445 - INFO - Epoch [1/30] Batch [2120/4715] Loss: 0.9628\n",
      "2025-05-30 13:30:22,210 - INFO - Epoch [1/30] Batch [2130/4715] Loss: 1.0532\n",
      "2025-05-30 13:30:23,911 - INFO - Epoch [1/30] Batch [2140/4715] Loss: 1.2081\n",
      "2025-05-30 13:30:25,703 - INFO - Epoch [1/30] Batch [2150/4715] Loss: 0.9445\n",
      "2025-05-30 13:30:27,365 - INFO - Epoch [1/30] Batch [2160/4715] Loss: 1.0137\n",
      "2025-05-30 13:30:29,030 - INFO - Epoch [1/30] Batch [2170/4715] Loss: 0.9267\n",
      "2025-05-30 13:30:31,246 - INFO - Epoch [1/30] Batch [2180/4715] Loss: 1.0444\n",
      "2025-05-30 13:30:32,989 - INFO - Epoch [1/30] Batch [2190/4715] Loss: 0.8366\n",
      "2025-05-30 13:30:34,665 - INFO - Epoch [1/30] Batch [2200/4715] Loss: 0.8094\n",
      "2025-05-30 13:30:36,419 - INFO - Epoch [1/30] Batch [2210/4715] Loss: 1.0360\n",
      "2025-05-30 13:30:38,166 - INFO - Epoch [1/30] Batch [2220/4715] Loss: 1.0100\n",
      "2025-05-30 13:30:39,872 - INFO - Epoch [1/30] Batch [2230/4715] Loss: 0.8869\n",
      "2025-05-30 13:30:41,566 - INFO - Epoch [1/30] Batch [2240/4715] Loss: 0.7476\n",
      "2025-05-30 13:30:43,268 - INFO - Epoch [1/30] Batch [2250/4715] Loss: 0.9858\n",
      "2025-05-30 13:30:45,074 - INFO - Epoch [1/30] Batch [2260/4715] Loss: 1.0412\n",
      "2025-05-30 13:30:46,797 - INFO - Epoch [1/30] Batch [2270/4715] Loss: 1.0221\n",
      "2025-05-30 13:30:48,686 - INFO - Epoch [1/30] Batch [2280/4715] Loss: 0.9206\n",
      "2025-05-30 13:30:50,355 - INFO - Epoch [1/30] Batch [2290/4715] Loss: 0.9288\n",
      "2025-05-30 13:30:52,124 - INFO - Epoch [1/30] Batch [2300/4715] Loss: 0.8412\n",
      "2025-05-30 13:30:53,964 - INFO - Epoch [1/30] Batch [2310/4715] Loss: 0.8475\n",
      "2025-05-30 13:30:55,740 - INFO - Epoch [1/30] Batch [2320/4715] Loss: 0.9649\n",
      "2025-05-30 13:30:58,113 - INFO - Epoch [1/30] Batch [2330/4715] Loss: 0.9062\n",
      "2025-05-30 13:30:59,940 - INFO - Epoch [1/30] Batch [2340/4715] Loss: 1.0277\n",
      "2025-05-30 13:31:01,611 - INFO - Epoch [1/30] Batch [2350/4715] Loss: 0.9623\n",
      "2025-05-30 13:31:03,424 - INFO - Epoch [1/30] Batch [2360/4715] Loss: 0.8680\n",
      "2025-05-30 13:31:05,139 - INFO - Epoch [1/30] Batch [2370/4715] Loss: 0.9450\n",
      "2025-05-30 13:31:06,909 - INFO - Epoch [1/30] Batch [2380/4715] Loss: 0.8485\n",
      "2025-05-30 13:31:08,634 - INFO - Epoch [1/30] Batch [2390/4715] Loss: 0.8413\n",
      "2025-05-30 13:31:10,355 - INFO - Epoch [1/30] Batch [2400/4715] Loss: 1.0317\n",
      "2025-05-30 13:31:12,020 - INFO - Epoch [1/30] Batch [2410/4715] Loss: 0.9706\n",
      "2025-05-30 13:31:13,696 - INFO - Epoch [1/30] Batch [2420/4715] Loss: 1.1358\n",
      "2025-05-30 13:31:15,592 - INFO - Epoch [1/30] Batch [2430/4715] Loss: 0.7856\n",
      "2025-05-30 13:31:17,498 - INFO - Epoch [1/30] Batch [2440/4715] Loss: 0.9516\n",
      "2025-05-30 13:31:19,419 - INFO - Epoch [1/30] Batch [2450/4715] Loss: 0.9478\n",
      "2025-05-30 13:31:21,308 - INFO - Epoch [1/30] Batch [2460/4715] Loss: 0.8629\n",
      "2025-05-30 13:31:23,056 - INFO - Epoch [1/30] Batch [2470/4715] Loss: 0.9731\n",
      "2025-05-30 13:31:24,878 - INFO - Epoch [1/30] Batch [2480/4715] Loss: 1.0077\n",
      "2025-05-30 13:31:26,623 - INFO - Epoch [1/30] Batch [2490/4715] Loss: 0.9273\n",
      "2025-05-30 13:31:28,415 - INFO - Epoch [1/30] Batch [2500/4715] Loss: 1.0969\n",
      "2025-05-30 13:31:30,129 - INFO - Epoch [1/30] Batch [2510/4715] Loss: 0.9009\n",
      "2025-05-30 13:31:31,907 - INFO - Epoch [1/30] Batch [2520/4715] Loss: 0.9167\n",
      "2025-05-30 13:31:33,704 - INFO - Epoch [1/30] Batch [2530/4715] Loss: 0.8787\n",
      "2025-05-30 13:31:35,442 - INFO - Epoch [1/30] Batch [2540/4715] Loss: 0.8523\n",
      "2025-05-30 13:31:37,200 - INFO - Epoch [1/30] Batch [2550/4715] Loss: 0.9827\n",
      "2025-05-30 13:31:39,162 - INFO - Epoch [1/30] Batch [2560/4715] Loss: 0.8745\n",
      "2025-05-30 13:31:40,938 - INFO - Epoch [1/30] Batch [2570/4715] Loss: 0.8471\n",
      "2025-05-30 13:31:42,705 - INFO - Epoch [1/30] Batch [2580/4715] Loss: 0.8959\n",
      "2025-05-30 13:31:44,383 - INFO - Epoch [1/30] Batch [2590/4715] Loss: 0.7678\n",
      "2025-05-30 13:31:46,069 - INFO - Epoch [1/30] Batch [2600/4715] Loss: 1.0873\n",
      "2025-05-30 13:31:47,887 - INFO - Epoch [1/30] Batch [2610/4715] Loss: 0.9111\n",
      "2025-05-30 13:31:49,611 - INFO - Epoch [1/30] Batch [2620/4715] Loss: 0.7820\n",
      "2025-05-30 13:31:51,326 - INFO - Epoch [1/30] Batch [2630/4715] Loss: 1.0231\n",
      "2025-05-30 13:31:53,042 - INFO - Epoch [1/30] Batch [2640/4715] Loss: 0.8717\n",
      "2025-05-30 13:31:54,792 - INFO - Epoch [1/30] Batch [2650/4715] Loss: 0.8922\n",
      "2025-05-30 13:31:56,705 - INFO - Epoch [1/30] Batch [2660/4715] Loss: 0.9172\n",
      "2025-05-30 13:31:58,482 - INFO - Epoch [1/30] Batch [2670/4715] Loss: 1.0607\n",
      "2025-05-30 13:32:00,254 - INFO - Epoch [1/30] Batch [2680/4715] Loss: 1.0438\n",
      "2025-05-30 13:32:01,921 - INFO - Epoch [1/30] Batch [2690/4715] Loss: 0.9245\n",
      "2025-05-30 13:32:03,614 - INFO - Epoch [1/30] Batch [2700/4715] Loss: 0.7172\n",
      "2025-05-30 13:32:05,245 - INFO - Epoch [1/30] Batch [2710/4715] Loss: 0.9688\n",
      "2025-05-30 13:32:07,065 - INFO - Epoch [1/30] Batch [2720/4715] Loss: 1.0538\n",
      "2025-05-30 13:32:08,839 - INFO - Epoch [1/30] Batch [2730/4715] Loss: 0.8115\n",
      "2025-05-30 13:32:10,593 - INFO - Epoch [1/30] Batch [2740/4715] Loss: 0.8051\n",
      "2025-05-30 13:32:12,408 - INFO - Epoch [1/30] Batch [2750/4715] Loss: 0.8399\n",
      "2025-05-30 13:32:15,010 - INFO - Epoch [1/30] Batch [2760/4715] Loss: 0.8567\n",
      "2025-05-30 13:32:16,961 - INFO - Epoch [1/30] Batch [2770/4715] Loss: 0.8276\n",
      "2025-05-30 13:32:19,330 - INFO - Epoch [1/30] Batch [2780/4715] Loss: 0.9029\n",
      "2025-05-30 13:32:21,025 - INFO - Epoch [1/30] Batch [2790/4715] Loss: 0.9828\n",
      "2025-05-30 13:32:22,748 - INFO - Epoch [1/30] Batch [2800/4715] Loss: 0.8844\n",
      "2025-05-30 13:32:24,505 - INFO - Epoch [1/30] Batch [2810/4715] Loss: 0.9954\n",
      "2025-05-30 13:32:26,269 - INFO - Epoch [1/30] Batch [2820/4715] Loss: 0.8675\n",
      "2025-05-30 13:32:27,991 - INFO - Epoch [1/30] Batch [2830/4715] Loss: 0.9446\n",
      "2025-05-30 13:32:29,693 - INFO - Epoch [1/30] Batch [2840/4715] Loss: 0.9385\n",
      "2025-05-30 13:32:32,235 - INFO - Epoch [1/30] Batch [2850/4715] Loss: 0.7508\n",
      "2025-05-30 13:32:33,951 - INFO - Epoch [1/30] Batch [2860/4715] Loss: 0.8211\n",
      "2025-05-30 13:32:35,641 - INFO - Epoch [1/30] Batch [2870/4715] Loss: 0.8741\n",
      "2025-05-30 13:32:37,347 - INFO - Epoch [1/30] Batch [2880/4715] Loss: 0.9274\n",
      "2025-05-30 13:32:39,097 - INFO - Epoch [1/30] Batch [2890/4715] Loss: 0.7633\n",
      "2025-05-30 13:32:40,776 - INFO - Epoch [1/30] Batch [2900/4715] Loss: 0.9154\n",
      "2025-05-30 13:32:42,459 - INFO - Epoch [1/30] Batch [2910/4715] Loss: 0.9050\n",
      "2025-05-30 13:32:44,166 - INFO - Epoch [1/30] Batch [2920/4715] Loss: 0.9508\n",
      "2025-05-30 13:32:45,911 - INFO - Epoch [1/30] Batch [2930/4715] Loss: 0.9115\n",
      "2025-05-30 13:32:47,620 - INFO - Epoch [1/30] Batch [2940/4715] Loss: 0.8836\n",
      "2025-05-30 13:32:49,327 - INFO - Epoch [1/30] Batch [2950/4715] Loss: 0.7945\n",
      "2025-05-30 13:32:51,078 - INFO - Epoch [1/30] Batch [2960/4715] Loss: 0.7650\n",
      "2025-05-30 13:32:52,785 - INFO - Epoch [1/30] Batch [2970/4715] Loss: 0.9200\n",
      "2025-05-30 13:32:54,544 - INFO - Epoch [1/30] Batch [2980/4715] Loss: 0.8293\n",
      "2025-05-30 13:32:56,398 - INFO - Epoch [1/30] Batch [2990/4715] Loss: 0.9694\n",
      "2025-05-30 13:32:58,114 - INFO - Epoch [1/30] Batch [3000/4715] Loss: 0.9232\n",
      "2025-05-30 13:32:59,781 - INFO - Epoch [1/30] Batch [3010/4715] Loss: 1.1928\n",
      "2025-05-30 13:33:01,509 - INFO - Epoch [1/30] Batch [3020/4715] Loss: 0.9562\n",
      "2025-05-30 13:33:03,267 - INFO - Epoch [1/30] Batch [3030/4715] Loss: 0.8818\n",
      "2025-05-30 13:33:05,038 - INFO - Epoch [1/30] Batch [3040/4715] Loss: 1.1356\n",
      "2025-05-30 13:33:06,786 - INFO - Epoch [1/30] Batch [3050/4715] Loss: 0.8773\n",
      "2025-05-30 13:33:08,448 - INFO - Epoch [1/30] Batch [3060/4715] Loss: 0.9068\n",
      "2025-05-30 13:33:10,258 - INFO - Epoch [1/30] Batch [3070/4715] Loss: 0.9083\n",
      "2025-05-30 13:33:12,123 - INFO - Epoch [1/30] Batch [3080/4715] Loss: 0.8872\n",
      "2025-05-30 13:33:14,025 - INFO - Epoch [1/30] Batch [3090/4715] Loss: 0.7525\n",
      "2025-05-30 13:33:15,757 - INFO - Epoch [1/30] Batch [3100/4715] Loss: 0.9734\n",
      "2025-05-30 13:33:17,735 - INFO - Epoch [1/30] Batch [3110/4715] Loss: 0.8929\n",
      "2025-05-30 13:33:19,742 - INFO - Epoch [1/30] Batch [3120/4715] Loss: 0.7110\n",
      "2025-05-30 13:33:21,557 - INFO - Epoch [1/30] Batch [3130/4715] Loss: 1.0362\n",
      "2025-05-30 13:33:23,194 - INFO - Epoch [1/30] Batch [3140/4715] Loss: 0.7877\n",
      "2025-05-30 13:33:24,923 - INFO - Epoch [1/30] Batch [3150/4715] Loss: 1.1110\n",
      "2025-05-30 13:33:26,666 - INFO - Epoch [1/30] Batch [3160/4715] Loss: 0.8167\n",
      "2025-05-30 13:33:28,358 - INFO - Epoch [1/30] Batch [3170/4715] Loss: 0.7636\n",
      "2025-05-30 13:33:30,142 - INFO - Epoch [1/30] Batch [3180/4715] Loss: 1.0211\n",
      "2025-05-30 13:33:31,923 - INFO - Epoch [1/30] Batch [3190/4715] Loss: 0.9000\n",
      "2025-05-30 13:33:33,717 - INFO - Epoch [1/30] Batch [3200/4715] Loss: 0.9514\n",
      "2025-05-30 13:33:35,562 - INFO - Epoch [1/30] Batch [3210/4715] Loss: 0.8472\n",
      "2025-05-30 13:33:37,390 - INFO - Epoch [1/30] Batch [3220/4715] Loss: 0.9348\n",
      "2025-05-30 13:33:39,189 - INFO - Epoch [1/30] Batch [3230/4715] Loss: 0.7591\n",
      "2025-05-30 13:33:40,995 - INFO - Epoch [1/30] Batch [3240/4715] Loss: 0.8167\n",
      "2025-05-30 13:33:42,696 - INFO - Epoch [1/30] Batch [3250/4715] Loss: 0.7880\n",
      "2025-05-30 13:33:44,439 - INFO - Epoch [1/30] Batch [3260/4715] Loss: 0.9343\n",
      "2025-05-30 13:33:46,116 - INFO - Epoch [1/30] Batch [3270/4715] Loss: 0.8182\n",
      "2025-05-30 13:33:47,806 - INFO - Epoch [1/30] Batch [3280/4715] Loss: 0.7531\n",
      "2025-05-30 13:33:49,766 - INFO - Epoch [1/30] Batch [3290/4715] Loss: 0.8324\n",
      "2025-05-30 13:33:51,713 - INFO - Epoch [1/30] Batch [3300/4715] Loss: 0.7305\n",
      "2025-05-30 13:33:53,504 - INFO - Epoch [1/30] Batch [3310/4715] Loss: 0.7015\n",
      "2025-05-30 13:33:55,177 - INFO - Epoch [1/30] Batch [3320/4715] Loss: 0.9611\n",
      "2025-05-30 13:33:56,927 - INFO - Epoch [1/30] Batch [3330/4715] Loss: 0.8692\n",
      "2025-05-30 13:33:58,518 - INFO - Epoch [1/30] Batch [3340/4715] Loss: 0.9156\n",
      "2025-05-30 13:34:00,201 - INFO - Epoch [1/30] Batch [3350/4715] Loss: 0.8367\n",
      "2025-05-30 13:34:01,866 - INFO - Epoch [1/30] Batch [3360/4715] Loss: 1.0392\n",
      "2025-05-30 13:34:03,665 - INFO - Epoch [1/30] Batch [3370/4715] Loss: 1.1329\n",
      "2025-05-30 13:34:05,423 - INFO - Epoch [1/30] Batch [3380/4715] Loss: 0.8139\n",
      "2025-05-30 13:34:07,123 - INFO - Epoch [1/30] Batch [3390/4715] Loss: 0.8690\n",
      "2025-05-30 13:34:08,939 - INFO - Epoch [1/30] Batch [3400/4715] Loss: 0.9176\n",
      "2025-05-30 13:34:10,895 - INFO - Epoch [1/30] Batch [3410/4715] Loss: 1.1307\n",
      "2025-05-30 13:34:12,607 - INFO - Epoch [1/30] Batch [3420/4715] Loss: 0.8949\n",
      "2025-05-30 13:34:14,576 - INFO - Epoch [1/30] Batch [3430/4715] Loss: 0.9313\n",
      "2025-05-30 13:34:16,541 - INFO - Epoch [1/30] Batch [3440/4715] Loss: 0.8013\n",
      "2025-05-30 13:34:18,389 - INFO - Epoch [1/30] Batch [3450/4715] Loss: 0.8756\n",
      "2025-05-30 13:34:20,166 - INFO - Epoch [1/30] Batch [3460/4715] Loss: 0.9393\n",
      "2025-05-30 13:34:21,889 - INFO - Epoch [1/30] Batch [3470/4715] Loss: 0.9751\n",
      "2025-05-30 13:34:23,486 - INFO - Epoch [1/30] Batch [3480/4715] Loss: 0.7693\n",
      "2025-05-30 13:34:25,279 - INFO - Epoch [1/30] Batch [3490/4715] Loss: 1.0300\n",
      "2025-05-30 13:34:27,018 - INFO - Epoch [1/30] Batch [3500/4715] Loss: 1.0363\n",
      "2025-05-30 13:34:28,675 - INFO - Epoch [1/30] Batch [3510/4715] Loss: 0.8586\n",
      "2025-05-30 13:34:30,488 - INFO - Epoch [1/30] Batch [3520/4715] Loss: 0.8902\n",
      "2025-05-30 13:34:32,307 - INFO - Epoch [1/30] Batch [3530/4715] Loss: 0.9285\n",
      "2025-05-30 13:34:34,103 - INFO - Epoch [1/30] Batch [3540/4715] Loss: 0.6541\n",
      "2025-05-30 13:34:35,773 - INFO - Epoch [1/30] Batch [3550/4715] Loss: 1.2293\n",
      "2025-05-30 13:34:37,581 - INFO - Epoch [1/30] Batch [3560/4715] Loss: 0.8259\n",
      "2025-05-30 13:34:39,521 - INFO - Epoch [1/30] Batch [3570/4715] Loss: 0.9096\n",
      "2025-05-30 13:34:41,522 - INFO - Epoch [1/30] Batch [3580/4715] Loss: 0.8539\n",
      "2025-05-30 13:34:43,351 - INFO - Epoch [1/30] Batch [3590/4715] Loss: 0.9021\n",
      "2025-05-30 13:34:45,108 - INFO - Epoch [1/30] Batch [3600/4715] Loss: 0.7997\n",
      "2025-05-30 13:34:46,830 - INFO - Epoch [1/30] Batch [3610/4715] Loss: 0.9245\n",
      "2025-05-30 13:34:48,712 - INFO - Epoch [1/30] Batch [3620/4715] Loss: 0.9979\n",
      "2025-05-30 13:34:50,865 - INFO - Epoch [1/30] Batch [3630/4715] Loss: 0.9396\n",
      "2025-05-30 13:34:52,664 - INFO - Epoch [1/30] Batch [3640/4715] Loss: 0.8267\n",
      "2025-05-30 13:34:54,406 - INFO - Epoch [1/30] Batch [3650/4715] Loss: 0.8959\n",
      "2025-05-30 13:34:57,005 - INFO - Epoch [1/30] Batch [3660/4715] Loss: 0.9133\n",
      "2025-05-30 13:34:58,887 - INFO - Epoch [1/30] Batch [3670/4715] Loss: 0.9718\n",
      "2025-05-30 13:35:00,760 - INFO - Epoch [1/30] Batch [3680/4715] Loss: 0.9138\n",
      "2025-05-30 13:35:02,541 - INFO - Epoch [1/30] Batch [3690/4715] Loss: 0.8776\n",
      "2025-05-30 13:35:04,506 - INFO - Epoch [1/30] Batch [3700/4715] Loss: 0.7635\n",
      "2025-05-30 13:35:06,486 - INFO - Epoch [1/30] Batch [3710/4715] Loss: 0.8987\n",
      "2025-05-30 13:35:08,264 - INFO - Epoch [1/30] Batch [3720/4715] Loss: 1.1765\n",
      "2025-05-30 13:35:09,896 - INFO - Epoch [1/30] Batch [3730/4715] Loss: 0.9413\n",
      "2025-05-30 13:35:11,577 - INFO - Epoch [1/30] Batch [3740/4715] Loss: 1.0629\n",
      "2025-05-30 13:35:13,285 - INFO - Epoch [1/30] Batch [3750/4715] Loss: 0.8709\n",
      "2025-05-30 13:35:15,019 - INFO - Epoch [1/30] Batch [3760/4715] Loss: 0.9043\n",
      "2025-05-30 13:35:16,876 - INFO - Epoch [1/30] Batch [3770/4715] Loss: 0.9678\n",
      "2025-05-30 13:35:18,564 - INFO - Epoch [1/30] Batch [3780/4715] Loss: 0.8055\n",
      "2025-05-30 13:35:20,304 - INFO - Epoch [1/30] Batch [3790/4715] Loss: 1.0050\n",
      "2025-05-30 13:35:21,995 - INFO - Epoch [1/30] Batch [3800/4715] Loss: 0.8794\n",
      "2025-05-30 13:35:23,676 - INFO - Epoch [1/30] Batch [3810/4715] Loss: 0.8709\n",
      "2025-05-30 13:35:25,725 - INFO - Epoch [1/30] Batch [3820/4715] Loss: 0.9347\n",
      "2025-05-30 13:35:27,662 - INFO - Epoch [1/30] Batch [3830/4715] Loss: 0.8647\n",
      "2025-05-30 13:35:29,447 - INFO - Epoch [1/30] Batch [3840/4715] Loss: 0.8780\n",
      "2025-05-30 13:35:31,170 - INFO - Epoch [1/30] Batch [3850/4715] Loss: 0.8466\n",
      "2025-05-30 13:35:32,927 - INFO - Epoch [1/30] Batch [3860/4715] Loss: 0.9098\n",
      "2025-05-30 13:35:34,865 - INFO - Epoch [1/30] Batch [3870/4715] Loss: 1.1804\n",
      "2025-05-30 13:35:36,661 - INFO - Epoch [1/30] Batch [3880/4715] Loss: 1.0156\n",
      "2025-05-30 13:35:38,317 - INFO - Epoch [1/30] Batch [3890/4715] Loss: 0.7586\n",
      "2025-05-30 13:35:40,025 - INFO - Epoch [1/30] Batch [3900/4715] Loss: 0.9524\n",
      "2025-05-30 13:35:41,741 - INFO - Epoch [1/30] Batch [3910/4715] Loss: 0.7829\n",
      "2025-05-30 13:35:43,491 - INFO - Epoch [1/30] Batch [3920/4715] Loss: 0.7687\n",
      "2025-05-30 13:35:45,478 - INFO - Epoch [1/30] Batch [3930/4715] Loss: 0.9134\n",
      "2025-05-30 13:35:47,314 - INFO - Epoch [1/30] Batch [3940/4715] Loss: 0.8559\n",
      "2025-05-30 13:35:49,047 - INFO - Epoch [1/30] Batch [3950/4715] Loss: 1.0115\n",
      "2025-05-30 13:35:50,657 - INFO - Epoch [1/30] Batch [3960/4715] Loss: 0.6444\n",
      "2025-05-30 13:35:52,444 - INFO - Epoch [1/30] Batch [3970/4715] Loss: 0.9234\n",
      "2025-05-30 13:35:54,298 - INFO - Epoch [1/30] Batch [3980/4715] Loss: 0.8657\n",
      "2025-05-30 13:35:56,145 - INFO - Epoch [1/30] Batch [3990/4715] Loss: 0.9362\n",
      "2025-05-30 13:35:57,955 - INFO - Epoch [1/30] Batch [4000/4715] Loss: 0.9439\n",
      "2025-05-30 13:35:59,684 - INFO - Epoch [1/30] Batch [4010/4715] Loss: 0.8718\n",
      "2025-05-30 13:36:01,436 - INFO - Epoch [1/30] Batch [4020/4715] Loss: 0.9234\n",
      "2025-05-30 13:36:03,306 - INFO - Epoch [1/30] Batch [4030/4715] Loss: 0.9266\n",
      "2025-05-30 13:36:05,155 - INFO - Epoch [1/30] Batch [4040/4715] Loss: 0.8942\n",
      "2025-05-30 13:36:06,801 - INFO - Epoch [1/30] Batch [4050/4715] Loss: 1.0118\n",
      "2025-05-30 13:36:08,647 - INFO - Epoch [1/30] Batch [4060/4715] Loss: 0.8677\n",
      "2025-05-30 13:36:10,339 - INFO - Epoch [1/30] Batch [4070/4715] Loss: 0.8969\n",
      "2025-05-30 13:36:12,038 - INFO - Epoch [1/30] Batch [4080/4715] Loss: 0.8468\n",
      "2025-05-30 13:36:13,808 - INFO - Epoch [1/30] Batch [4090/4715] Loss: 0.7515\n",
      "2025-05-30 13:36:15,662 - INFO - Epoch [1/30] Batch [4100/4715] Loss: 0.9083\n",
      "2025-05-30 13:36:17,426 - INFO - Epoch [1/30] Batch [4110/4715] Loss: 0.8382\n",
      "2025-05-30 13:36:19,149 - INFO - Epoch [1/30] Batch [4120/4715] Loss: 0.8136\n",
      "2025-05-30 13:36:20,927 - INFO - Epoch [1/30] Batch [4130/4715] Loss: 1.1023\n",
      "2025-05-30 13:36:22,875 - INFO - Epoch [1/30] Batch [4140/4715] Loss: 0.8105\n",
      "2025-05-30 13:36:24,863 - INFO - Epoch [1/30] Batch [4150/4715] Loss: 0.9037\n",
      "2025-05-30 13:36:26,622 - INFO - Epoch [1/30] Batch [4160/4715] Loss: 0.7585\n",
      "2025-05-30 13:36:28,356 - INFO - Epoch [1/30] Batch [4170/4715] Loss: 0.7779\n",
      "2025-05-30 13:36:30,268 - INFO - Epoch [1/30] Batch [4180/4715] Loss: 0.7395\n",
      "2025-05-30 13:36:32,067 - INFO - Epoch [1/30] Batch [4190/4715] Loss: 0.9506\n",
      "2025-05-30 13:36:33,762 - INFO - Epoch [1/30] Batch [4200/4715] Loss: 0.9259\n",
      "2025-05-30 13:36:35,443 - INFO - Epoch [1/30] Batch [4210/4715] Loss: 0.8931\n",
      "2025-05-30 13:36:37,180 - INFO - Epoch [1/30] Batch [4220/4715] Loss: 0.7009\n",
      "2025-05-30 13:36:38,943 - INFO - Epoch [1/30] Batch [4230/4715] Loss: 0.8831\n",
      "2025-05-30 13:36:40,972 - INFO - Epoch [1/30] Batch [4240/4715] Loss: 0.7383\n",
      "2025-05-30 13:36:42,905 - INFO - Epoch [1/30] Batch [4250/4715] Loss: 0.7808\n",
      "2025-05-30 13:36:44,777 - INFO - Epoch [1/30] Batch [4260/4715] Loss: 0.8715\n",
      "2025-05-30 13:36:46,556 - INFO - Epoch [1/30] Batch [4270/4715] Loss: 0.9185\n",
      "2025-05-30 13:36:48,418 - INFO - Epoch [1/30] Batch [4280/4715] Loss: 0.9003\n",
      "2025-05-30 13:36:50,316 - INFO - Epoch [1/30] Batch [4290/4715] Loss: 0.7941\n",
      "2025-05-30 13:36:52,258 - INFO - Epoch [1/30] Batch [4300/4715] Loss: 1.0229\n",
      "2025-05-30 13:36:54,059 - INFO - Epoch [1/30] Batch [4310/4715] Loss: 0.9614\n",
      "2025-05-30 13:36:55,837 - INFO - Epoch [1/30] Batch [4320/4715] Loss: 0.8514\n",
      "2025-05-30 13:36:57,592 - INFO - Epoch [1/30] Batch [4330/4715] Loss: 0.9282\n",
      "2025-05-30 13:36:59,369 - INFO - Epoch [1/30] Batch [4340/4715] Loss: 0.7776\n",
      "2025-05-30 13:37:01,196 - INFO - Epoch [1/30] Batch [4350/4715] Loss: 1.0702\n",
      "2025-05-30 13:37:02,926 - INFO - Epoch [1/30] Batch [4360/4715] Loss: 0.9147\n",
      "2025-05-30 13:37:04,843 - INFO - Epoch [1/30] Batch [4370/4715] Loss: 1.0632\n",
      "2025-05-30 13:37:06,522 - INFO - Epoch [1/30] Batch [4380/4715] Loss: 0.7908\n",
      "2025-05-30 13:37:08,235 - INFO - Epoch [1/30] Batch [4390/4715] Loss: 0.9347\n",
      "2025-05-30 13:37:10,065 - INFO - Epoch [1/30] Batch [4400/4715] Loss: 1.0282\n",
      "2025-05-30 13:37:12,066 - INFO - Epoch [1/30] Batch [4410/4715] Loss: 0.9753\n",
      "2025-05-30 13:37:13,989 - INFO - Epoch [1/30] Batch [4420/4715] Loss: 0.9975\n",
      "2025-05-30 13:37:15,755 - INFO - Epoch [1/30] Batch [4430/4715] Loss: 0.9233\n",
      "2025-05-30 13:37:17,525 - INFO - Epoch [1/30] Batch [4440/4715] Loss: 0.8642\n",
      "2025-05-30 13:37:19,185 - INFO - Epoch [1/30] Batch [4450/4715] Loss: 0.8683\n",
      "2025-05-30 13:37:20,936 - INFO - Epoch [1/30] Batch [4460/4715] Loss: 1.0240\n",
      "2025-05-30 13:37:22,835 - INFO - Epoch [1/30] Batch [4470/4715] Loss: 0.8833\n",
      "2025-05-30 13:37:24,623 - INFO - Epoch [1/30] Batch [4480/4715] Loss: 1.1249\n",
      "2025-05-30 13:37:26,478 - INFO - Epoch [1/30] Batch [4490/4715] Loss: 0.7365\n",
      "2025-05-30 13:37:28,236 - INFO - Epoch [1/30] Batch [4500/4715] Loss: 1.2770\n",
      "2025-05-30 13:37:29,944 - INFO - Epoch [1/30] Batch [4510/4715] Loss: 1.1970\n",
      "2025-05-30 13:37:31,682 - INFO - Epoch [1/30] Batch [4520/4715] Loss: 0.8835\n",
      "2025-05-30 13:37:33,459 - INFO - Epoch [1/30] Batch [4530/4715] Loss: 0.8253\n",
      "2025-05-30 13:37:35,285 - INFO - Epoch [1/30] Batch [4540/4715] Loss: 0.7124\n",
      "2025-05-30 13:37:37,090 - INFO - Epoch [1/30] Batch [4550/4715] Loss: 0.9555\n",
      "2025-05-30 13:37:38,859 - INFO - Epoch [1/30] Batch [4560/4715] Loss: 0.7680\n",
      "2025-05-30 13:37:40,636 - INFO - Epoch [1/30] Batch [4570/4715] Loss: 0.7163\n",
      "2025-05-30 13:37:42,464 - INFO - Epoch [1/30] Batch [4580/4715] Loss: 0.9366\n",
      "2025-05-30 13:37:44,244 - INFO - Epoch [1/30] Batch [4590/4715] Loss: 1.1240\n",
      "2025-05-30 13:37:46,050 - INFO - Epoch [1/30] Batch [4600/4715] Loss: 0.7186\n",
      "2025-05-30 13:37:47,865 - INFO - Epoch [1/30] Batch [4610/4715] Loss: 0.9450\n",
      "2025-05-30 13:37:49,585 - INFO - Epoch [1/30] Batch [4620/4715] Loss: 0.9544\n",
      "2025-05-30 13:37:51,370 - INFO - Epoch [1/30] Batch [4630/4715] Loss: 1.0115\n",
      "2025-05-30 13:37:53,092 - INFO - Epoch [1/30] Batch [4640/4715] Loss: 0.9327\n",
      "2025-05-30 13:37:55,057 - INFO - Epoch [1/30] Batch [4650/4715] Loss: 0.9746\n",
      "2025-05-30 13:37:56,878 - INFO - Epoch [1/30] Batch [4660/4715] Loss: 0.9955\n",
      "2025-05-30 13:37:58,559 - INFO - Epoch [1/30] Batch [4670/4715] Loss: 0.8205\n",
      "2025-05-30 13:38:00,218 - INFO - Epoch [1/30] Batch [4680/4715] Loss: 1.0340\n",
      "2025-05-30 13:38:01,997 - INFO - Epoch [1/30] Batch [4690/4715] Loss: 0.8310\n",
      "2025-05-30 13:38:03,832 - INFO - Epoch [1/30] Batch [4700/4715] Loss: 0.8467\n",
      "2025-05-30 13:38:05,560 - INFO - Epoch [1/30] Batch [4710/4715] Loss: 0.8678\n",
      "2025-05-30 13:38:48,191 - INFO - \n",
      "Epoch [1/30] Time: 887.10s\n",
      "2025-05-30 13:38:48,191 - INFO - Train Loss: 0.9293, Valid Loss: 0.8842\n",
      "2025-05-30 13:38:48,191 - INFO - Valid AUC (macro): 0.6754, F1 (macro): 0.5223\n",
      "2025-05-30 13:38:48,725 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\best_model.pth\n",
      "2025-05-30 13:38:48,725 - INFO - New best model saved with AUC: 0.6754\n",
      "2025-05-30 13:38:49,344 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 13:38:49,344 - INFO - Saved checkpoint at epoch 1\n",
      "2025-05-30 13:38:49,545 - INFO - Epoch [2/30] Batch [0/4715] Loss: 0.8077\n",
      "2025-05-30 13:38:51,205 - INFO - Epoch [2/30] Batch [10/4715] Loss: 0.7297\n",
      "2025-05-30 13:38:52,767 - INFO - Epoch [2/30] Batch [20/4715] Loss: 0.6963\n",
      "2025-05-30 13:38:54,353 - INFO - Epoch [2/30] Batch [30/4715] Loss: 0.8630\n",
      "2025-05-30 13:38:55,928 - INFO - Epoch [2/30] Batch [40/4715] Loss: 0.8853\n",
      "2025-05-30 13:38:57,567 - INFO - Epoch [2/30] Batch [50/4715] Loss: 0.8089\n",
      "2025-05-30 13:38:59,250 - INFO - Epoch [2/30] Batch [60/4715] Loss: 0.8419\n",
      "2025-05-30 13:39:00,790 - INFO - Epoch [2/30] Batch [70/4715] Loss: 0.8067\n",
      "2025-05-30 13:39:02,387 - INFO - Epoch [2/30] Batch [80/4715] Loss: 0.9052\n",
      "2025-05-30 13:39:03,965 - INFO - Epoch [2/30] Batch [90/4715] Loss: 1.0297\n",
      "2025-05-30 13:39:05,535 - INFO - Epoch [2/30] Batch [100/4715] Loss: 0.9504\n",
      "2025-05-30 13:39:07,015 - INFO - Epoch [2/30] Batch [110/4715] Loss: 0.7470\n",
      "2025-05-30 13:39:08,541 - INFO - Epoch [2/30] Batch [120/4715] Loss: 0.7347\n",
      "2025-05-30 13:39:10,208 - INFO - Epoch [2/30] Batch [130/4715] Loss: 0.9020\n",
      "2025-05-30 13:39:11,805 - INFO - Epoch [2/30] Batch [140/4715] Loss: 1.0227\n",
      "2025-05-30 13:39:13,444 - INFO - Epoch [2/30] Batch [150/4715] Loss: 0.8162\n",
      "2025-05-30 13:39:14,924 - INFO - Epoch [2/30] Batch [160/4715] Loss: 1.0835\n",
      "2025-05-30 13:39:16,501 - INFO - Epoch [2/30] Batch [170/4715] Loss: 0.8223\n",
      "2025-05-30 13:39:18,125 - INFO - Epoch [2/30] Batch [180/4715] Loss: 0.9111\n",
      "2025-05-30 13:39:19,695 - INFO - Epoch [2/30] Batch [190/4715] Loss: 0.8203\n",
      "2025-05-30 13:39:21,209 - INFO - Epoch [2/30] Batch [200/4715] Loss: 0.7622\n",
      "2025-05-30 13:39:22,841 - INFO - Epoch [2/30] Batch [210/4715] Loss: 0.8914\n",
      "2025-05-30 13:39:24,397 - INFO - Epoch [2/30] Batch [220/4715] Loss: 0.9372\n",
      "2025-05-30 13:39:25,974 - INFO - Epoch [2/30] Batch [230/4715] Loss: 0.8121\n",
      "2025-05-30 13:39:27,573 - INFO - Epoch [2/30] Batch [240/4715] Loss: 1.0601\n",
      "2025-05-30 13:39:29,176 - INFO - Epoch [2/30] Batch [250/4715] Loss: 0.8373\n",
      "2025-05-30 13:39:30,758 - INFO - Epoch [2/30] Batch [260/4715] Loss: 1.0023\n",
      "2025-05-30 13:39:32,343 - INFO - Epoch [2/30] Batch [270/4715] Loss: 1.0330\n",
      "2025-05-30 13:39:34,041 - INFO - Epoch [2/30] Batch [280/4715] Loss: 0.8349\n",
      "2025-05-30 13:39:35,664 - INFO - Epoch [2/30] Batch [290/4715] Loss: 0.7693\n",
      "2025-05-30 13:39:37,283 - INFO - Epoch [2/30] Batch [300/4715] Loss: 0.8502\n",
      "2025-05-30 13:39:38,844 - INFO - Epoch [2/30] Batch [310/4715] Loss: 1.0317\n",
      "2025-05-30 13:39:40,519 - INFO - Epoch [2/30] Batch [320/4715] Loss: 0.9898\n",
      "2025-05-30 13:39:42,059 - INFO - Epoch [2/30] Batch [330/4715] Loss: 0.9060\n",
      "2025-05-30 13:39:43,605 - INFO - Epoch [2/30] Batch [340/4715] Loss: 1.0925\n",
      "2025-05-30 13:39:45,163 - INFO - Epoch [2/30] Batch [350/4715] Loss: 0.8964\n",
      "2025-05-30 13:39:46,754 - INFO - Epoch [2/30] Batch [360/4715] Loss: 1.2287\n",
      "2025-05-30 13:39:48,354 - INFO - Epoch [2/30] Batch [370/4715] Loss: 1.0597\n",
      "2025-05-30 13:39:49,902 - INFO - Epoch [2/30] Batch [380/4715] Loss: 0.7348\n",
      "2025-05-30 13:39:51,563 - INFO - Epoch [2/30] Batch [390/4715] Loss: 0.8138\n",
      "2025-05-30 13:39:53,123 - INFO - Epoch [2/30] Batch [400/4715] Loss: 0.7707\n",
      "2025-05-30 13:39:54,702 - INFO - Epoch [2/30] Batch [410/4715] Loss: 0.8219\n",
      "2025-05-30 13:39:56,249 - INFO - Epoch [2/30] Batch [420/4715] Loss: 0.7686\n",
      "2025-05-30 13:39:57,837 - INFO - Epoch [2/30] Batch [430/4715] Loss: 1.0289\n",
      "2025-05-30 13:39:59,465 - INFO - Epoch [2/30] Batch [440/4715] Loss: 0.9230\n",
      "2025-05-30 13:40:00,956 - INFO - Epoch [2/30] Batch [450/4715] Loss: 0.9677\n",
      "2025-05-30 13:40:02,586 - INFO - Epoch [2/30] Batch [460/4715] Loss: 0.9083\n",
      "2025-05-30 13:40:04,229 - INFO - Epoch [2/30] Batch [470/4715] Loss: 1.0403\n",
      "2025-05-30 13:40:05,759 - INFO - Epoch [2/30] Batch [480/4715] Loss: 0.8727\n",
      "2025-05-30 13:40:07,285 - INFO - Epoch [2/30] Batch [490/4715] Loss: 0.7302\n",
      "2025-05-30 13:40:08,843 - INFO - Epoch [2/30] Batch [500/4715] Loss: 0.9885\n",
      "2025-05-30 13:40:10,441 - INFO - Epoch [2/30] Batch [510/4715] Loss: 1.0043\n",
      "2025-05-30 13:40:12,123 - INFO - Epoch [2/30] Batch [520/4715] Loss: 0.8055\n",
      "2025-05-30 13:40:13,619 - INFO - Epoch [2/30] Batch [530/4715] Loss: 0.8892\n",
      "2025-05-30 13:40:15,210 - INFO - Epoch [2/30] Batch [540/4715] Loss: 0.7518\n",
      "2025-05-30 13:40:16,824 - INFO - Epoch [2/30] Batch [550/4715] Loss: 0.8813\n",
      "2025-05-30 13:40:18,458 - INFO - Epoch [2/30] Batch [560/4715] Loss: 0.9434\n",
      "2025-05-30 13:40:20,017 - INFO - Epoch [2/30] Batch [570/4715] Loss: 0.9790\n",
      "2025-05-30 13:40:21,614 - INFO - Epoch [2/30] Batch [580/4715] Loss: 0.7389\n",
      "2025-05-30 13:40:23,225 - INFO - Epoch [2/30] Batch [590/4715] Loss: 0.9082\n",
      "2025-05-30 13:40:24,857 - INFO - Epoch [2/30] Batch [600/4715] Loss: 0.8551\n",
      "2025-05-30 13:40:26,441 - INFO - Epoch [2/30] Batch [610/4715] Loss: 0.8737\n",
      "2025-05-30 13:40:27,923 - INFO - Epoch [2/30] Batch [620/4715] Loss: 0.8508\n",
      "2025-05-30 13:40:29,484 - INFO - Epoch [2/30] Batch [630/4715] Loss: 0.8500\n",
      "2025-05-30 13:40:31,025 - INFO - Epoch [2/30] Batch [640/4715] Loss: 0.8959\n",
      "2025-05-30 13:40:32,594 - INFO - Epoch [2/30] Batch [650/4715] Loss: 0.9906\n",
      "2025-05-30 13:40:34,215 - INFO - Epoch [2/30] Batch [660/4715] Loss: 0.7187\n",
      "2025-05-30 13:40:35,768 - INFO - Epoch [2/30] Batch [670/4715] Loss: 0.8027\n",
      "2025-05-30 13:40:37,289 - INFO - Epoch [2/30] Batch [680/4715] Loss: 0.8464\n",
      "2025-05-30 13:40:38,958 - INFO - Epoch [2/30] Batch [690/4715] Loss: 0.7993\n",
      "2025-05-30 13:40:40,574 - INFO - Epoch [2/30] Batch [700/4715] Loss: 0.6827\n",
      "2025-05-30 13:40:42,165 - INFO - Epoch [2/30] Batch [710/4715] Loss: 0.9911\n",
      "2025-05-30 13:40:43,707 - INFO - Epoch [2/30] Batch [720/4715] Loss: 0.8368\n",
      "2025-05-30 13:40:45,221 - INFO - Epoch [2/30] Batch [730/4715] Loss: 0.8437\n",
      "2025-05-30 13:40:46,791 - INFO - Epoch [2/30] Batch [740/4715] Loss: 0.6016\n",
      "2025-05-30 13:40:48,383 - INFO - Epoch [2/30] Batch [750/4715] Loss: 1.0185\n",
      "2025-05-30 13:40:49,909 - INFO - Epoch [2/30] Batch [760/4715] Loss: 0.8703\n",
      "2025-05-30 13:40:51,493 - INFO - Epoch [2/30] Batch [770/4715] Loss: 0.7831\n",
      "2025-05-30 13:40:53,125 - INFO - Epoch [2/30] Batch [780/4715] Loss: 0.8317\n",
      "2025-05-30 13:40:54,715 - INFO - Epoch [2/30] Batch [790/4715] Loss: 0.9330\n",
      "2025-05-30 13:40:56,273 - INFO - Epoch [2/30] Batch [800/4715] Loss: 0.8015\n",
      "2025-05-30 13:40:57,964 - INFO - Epoch [2/30] Batch [810/4715] Loss: 0.8245\n",
      "2025-05-30 13:40:59,528 - INFO - Epoch [2/30] Batch [820/4715] Loss: 0.9936\n",
      "2025-05-30 13:41:01,126 - INFO - Epoch [2/30] Batch [830/4715] Loss: 0.8626\n",
      "2025-05-30 13:41:02,723 - INFO - Epoch [2/30] Batch [840/4715] Loss: 0.8148\n",
      "2025-05-30 13:41:04,307 - INFO - Epoch [2/30] Batch [850/4715] Loss: 1.1771\n",
      "2025-05-30 13:41:05,827 - INFO - Epoch [2/30] Batch [860/4715] Loss: 0.8417\n",
      "2025-05-30 13:41:07,370 - INFO - Epoch [2/30] Batch [870/4715] Loss: 0.8981\n",
      "2025-05-30 13:41:08,818 - INFO - Epoch [2/30] Batch [880/4715] Loss: 0.8758\n",
      "2025-05-30 13:41:10,405 - INFO - Epoch [2/30] Batch [890/4715] Loss: 0.9250\n",
      "2025-05-30 13:41:12,018 - INFO - Epoch [2/30] Batch [900/4715] Loss: 0.9503\n",
      "2025-05-30 13:41:13,586 - INFO - Epoch [2/30] Batch [910/4715] Loss: 0.9841\n",
      "2025-05-30 13:41:15,237 - INFO - Epoch [2/30] Batch [920/4715] Loss: 0.9922\n",
      "2025-05-30 13:41:16,774 - INFO - Epoch [2/30] Batch [930/4715] Loss: 1.0521\n",
      "2025-05-30 13:41:18,365 - INFO - Epoch [2/30] Batch [940/4715] Loss: 0.9739\n",
      "2025-05-30 13:41:19,976 - INFO - Epoch [2/30] Batch [950/4715] Loss: 0.7554\n",
      "2025-05-30 13:41:21,584 - INFO - Epoch [2/30] Batch [960/4715] Loss: 1.0152\n",
      "2025-05-30 13:41:23,045 - INFO - Epoch [2/30] Batch [970/4715] Loss: 0.9120\n",
      "2025-05-30 13:41:24,588 - INFO - Epoch [2/30] Batch [980/4715] Loss: 0.7294\n",
      "2025-05-30 13:41:26,171 - INFO - Epoch [2/30] Batch [990/4715] Loss: 0.8944\n",
      "2025-05-30 13:41:27,718 - INFO - Epoch [2/30] Batch [1000/4715] Loss: 0.9926\n",
      "2025-05-30 13:41:29,297 - INFO - Epoch [2/30] Batch [1010/4715] Loss: 0.9084\n",
      "2025-05-30 13:41:30,961 - INFO - Epoch [2/30] Batch [1020/4715] Loss: 0.8225\n",
      "2025-05-30 13:41:32,462 - INFO - Epoch [2/30] Batch [1030/4715] Loss: 1.0001\n",
      "2025-05-30 13:41:34,083 - INFO - Epoch [2/30] Batch [1040/4715] Loss: 0.9811\n",
      "2025-05-30 13:41:35,658 - INFO - Epoch [2/30] Batch [1050/4715] Loss: 0.8007\n",
      "2025-05-30 13:41:37,249 - INFO - Epoch [2/30] Batch [1060/4715] Loss: 0.9491\n",
      "2025-05-30 13:41:38,841 - INFO - Epoch [2/30] Batch [1070/4715] Loss: 1.0345\n",
      "2025-05-30 13:41:40,465 - INFO - Epoch [2/30] Batch [1080/4715] Loss: 0.8313\n",
      "2025-05-30 13:41:42,022 - INFO - Epoch [2/30] Batch [1090/4715] Loss: 1.0338\n",
      "2025-05-30 13:41:43,587 - INFO - Epoch [2/30] Batch [1100/4715] Loss: 0.8951\n",
      "2025-05-30 13:41:45,181 - INFO - Epoch [2/30] Batch [1110/4715] Loss: 0.9852\n",
      "2025-05-30 13:41:46,753 - INFO - Epoch [2/30] Batch [1120/4715] Loss: 1.1211\n",
      "2025-05-30 13:41:48,368 - INFO - Epoch [2/30] Batch [1130/4715] Loss: 0.9906\n",
      "2025-05-30 13:41:50,058 - INFO - Epoch [2/30] Batch [1140/4715] Loss: 1.0002\n",
      "2025-05-30 13:41:51,640 - INFO - Epoch [2/30] Batch [1150/4715] Loss: 0.8121\n",
      "2025-05-30 13:41:53,210 - INFO - Epoch [2/30] Batch [1160/4715] Loss: 1.0546\n",
      "2025-05-30 13:41:54,793 - INFO - Epoch [2/30] Batch [1170/4715] Loss: 0.9681\n",
      "2025-05-30 13:41:56,418 - INFO - Epoch [2/30] Batch [1180/4715] Loss: 0.9598\n",
      "2025-05-30 13:41:58,220 - INFO - Epoch [2/30] Batch [1190/4715] Loss: 0.8602\n",
      "2025-05-30 13:41:59,787 - INFO - Epoch [2/30] Batch [1200/4715] Loss: 1.0096\n",
      "2025-05-30 13:42:01,384 - INFO - Epoch [2/30] Batch [1210/4715] Loss: 0.9568\n",
      "2025-05-30 13:42:03,006 - INFO - Epoch [2/30] Batch [1220/4715] Loss: 1.1135\n",
      "2025-05-30 13:42:04,649 - INFO - Epoch [2/30] Batch [1230/4715] Loss: 0.9062\n",
      "2025-05-30 13:42:06,204 - INFO - Epoch [2/30] Batch [1240/4715] Loss: 0.7567\n",
      "2025-05-30 13:42:07,821 - INFO - Epoch [2/30] Batch [1250/4715] Loss: 1.0139\n",
      "2025-05-30 13:42:09,406 - INFO - Epoch [2/30] Batch [1260/4715] Loss: 0.9623\n",
      "2025-05-30 13:42:10,988 - INFO - Epoch [2/30] Batch [1270/4715] Loss: 0.8867\n",
      "2025-05-30 13:42:12,574 - INFO - Epoch [2/30] Batch [1280/4715] Loss: 0.7992\n",
      "2025-05-30 13:42:14,095 - INFO - Epoch [2/30] Batch [1290/4715] Loss: 0.9857\n",
      "2025-05-30 13:42:15,623 - INFO - Epoch [2/30] Batch [1300/4715] Loss: 0.8059\n",
      "2025-05-30 13:42:17,259 - INFO - Epoch [2/30] Batch [1310/4715] Loss: 0.7881\n",
      "2025-05-30 13:42:18,845 - INFO - Epoch [2/30] Batch [1320/4715] Loss: 0.9408\n",
      "2025-05-30 13:42:20,440 - INFO - Epoch [2/30] Batch [1330/4715] Loss: 0.9547\n",
      "2025-05-30 13:42:21,971 - INFO - Epoch [2/30] Batch [1340/4715] Loss: 0.6743\n",
      "2025-05-30 13:42:23,526 - INFO - Epoch [2/30] Batch [1350/4715] Loss: 0.7105\n",
      "2025-05-30 13:42:25,124 - INFO - Epoch [2/30] Batch [1360/4715] Loss: 0.8171\n",
      "2025-05-30 13:42:26,723 - INFO - Epoch [2/30] Batch [1370/4715] Loss: 0.9894\n",
      "2025-05-30 13:42:28,306 - INFO - Epoch [2/30] Batch [1380/4715] Loss: 1.0064\n",
      "2025-05-30 13:42:29,854 - INFO - Epoch [2/30] Batch [1390/4715] Loss: 0.9652\n",
      "2025-05-30 13:42:31,458 - INFO - Epoch [2/30] Batch [1400/4715] Loss: 0.9571\n",
      "2025-05-30 13:42:32,988 - INFO - Epoch [2/30] Batch [1410/4715] Loss: 0.8928\n",
      "2025-05-30 13:42:34,505 - INFO - Epoch [2/30] Batch [1420/4715] Loss: 1.0491\n",
      "2025-05-30 13:42:36,105 - INFO - Epoch [2/30] Batch [1430/4715] Loss: 0.8702\n",
      "2025-05-30 13:42:37,625 - INFO - Epoch [2/30] Batch [1440/4715] Loss: 0.8730\n",
      "2025-05-30 13:42:39,275 - INFO - Epoch [2/30] Batch [1450/4715] Loss: 0.7314\n",
      "2025-05-30 13:42:40,793 - INFO - Epoch [2/30] Batch [1460/4715] Loss: 0.8988\n",
      "2025-05-30 13:42:42,339 - INFO - Epoch [2/30] Batch [1470/4715] Loss: 0.7346\n",
      "2025-05-30 13:42:43,886 - INFO - Epoch [2/30] Batch [1480/4715] Loss: 0.8356\n",
      "2025-05-30 13:42:45,530 - INFO - Epoch [2/30] Batch [1490/4715] Loss: 1.0000\n",
      "2025-05-30 13:42:47,122 - INFO - Epoch [2/30] Batch [1500/4715] Loss: 0.7448\n",
      "2025-05-30 13:42:48,627 - INFO - Epoch [2/30] Batch [1510/4715] Loss: 0.8446\n",
      "2025-05-30 13:42:50,242 - INFO - Epoch [2/30] Batch [1520/4715] Loss: 0.9487\n",
      "2025-05-30 13:42:51,878 - INFO - Epoch [2/30] Batch [1530/4715] Loss: 1.0135\n",
      "2025-05-30 13:42:53,487 - INFO - Epoch [2/30] Batch [1540/4715] Loss: 1.0771\n",
      "2025-05-30 13:42:55,073 - INFO - Epoch [2/30] Batch [1550/4715] Loss: 0.9145\n",
      "2025-05-30 13:42:56,698 - INFO - Epoch [2/30] Batch [1560/4715] Loss: 0.8201\n",
      "2025-05-30 13:42:58,310 - INFO - Epoch [2/30] Batch [1570/4715] Loss: 0.8818\n",
      "2025-05-30 13:42:59,843 - INFO - Epoch [2/30] Batch [1580/4715] Loss: 0.8746\n",
      "2025-05-30 13:43:01,386 - INFO - Epoch [2/30] Batch [1590/4715] Loss: 0.8852\n",
      "2025-05-30 13:43:02,920 - INFO - Epoch [2/30] Batch [1600/4715] Loss: 1.0601\n",
      "2025-05-30 13:43:04,469 - INFO - Epoch [2/30] Batch [1610/4715] Loss: 0.8167\n",
      "2025-05-30 13:43:06,067 - INFO - Epoch [2/30] Batch [1620/4715] Loss: 0.8859\n",
      "2025-05-30 13:43:07,560 - INFO - Epoch [2/30] Batch [1630/4715] Loss: 0.9231\n",
      "2025-05-30 13:43:09,218 - INFO - Epoch [2/30] Batch [1640/4715] Loss: 0.9571\n",
      "2025-05-30 13:43:10,797 - INFO - Epoch [2/30] Batch [1650/4715] Loss: 0.9037\n",
      "2025-05-30 13:43:12,422 - INFO - Epoch [2/30] Batch [1660/4715] Loss: 0.9603\n",
      "2025-05-30 13:43:14,006 - INFO - Epoch [2/30] Batch [1670/4715] Loss: 0.9404\n",
      "2025-05-30 13:43:15,563 - INFO - Epoch [2/30] Batch [1680/4715] Loss: 0.8388\n",
      "2025-05-30 13:43:17,155 - INFO - Epoch [2/30] Batch [1690/4715] Loss: 0.9957\n",
      "2025-05-30 13:43:18,760 - INFO - Epoch [2/30] Batch [1700/4715] Loss: 0.7968\n",
      "2025-05-30 13:43:20,363 - INFO - Epoch [2/30] Batch [1710/4715] Loss: 0.6510\n",
      "2025-05-30 13:43:21,896 - INFO - Epoch [2/30] Batch [1720/4715] Loss: 0.8871\n",
      "2025-05-30 13:43:23,406 - INFO - Epoch [2/30] Batch [1730/4715] Loss: 1.0592\n",
      "2025-05-30 13:43:24,958 - INFO - Epoch [2/30] Batch [1740/4715] Loss: 0.9205\n",
      "2025-05-30 13:43:26,528 - INFO - Epoch [2/30] Batch [1750/4715] Loss: 0.7054\n",
      "2025-05-30 13:43:28,117 - INFO - Epoch [2/30] Batch [1760/4715] Loss: 0.8920\n",
      "2025-05-30 13:43:29,695 - INFO - Epoch [2/30] Batch [1770/4715] Loss: 1.0391\n",
      "2025-05-30 13:43:31,254 - INFO - Epoch [2/30] Batch [1780/4715] Loss: 0.9227\n",
      "2025-05-30 13:43:32,886 - INFO - Epoch [2/30] Batch [1790/4715] Loss: 0.9073\n",
      "2025-05-30 13:43:34,439 - INFO - Epoch [2/30] Batch [1800/4715] Loss: 1.1104\n",
      "2025-05-30 13:43:36,004 - INFO - Epoch [2/30] Batch [1810/4715] Loss: 0.9064\n",
      "2025-05-30 13:43:37,544 - INFO - Epoch [2/30] Batch [1820/4715] Loss: 0.9803\n",
      "2025-05-30 13:43:39,169 - INFO - Epoch [2/30] Batch [1830/4715] Loss: 0.8613\n",
      "2025-05-30 13:43:40,766 - INFO - Epoch [2/30] Batch [1840/4715] Loss: 0.8729\n",
      "2025-05-30 13:43:42,351 - INFO - Epoch [2/30] Batch [1850/4715] Loss: 0.7755\n",
      "2025-05-30 13:43:43,962 - INFO - Epoch [2/30] Batch [1860/4715] Loss: 0.9431\n",
      "2025-05-30 13:43:45,566 - INFO - Epoch [2/30] Batch [1870/4715] Loss: 0.8558\n",
      "2025-05-30 13:43:47,191 - INFO - Epoch [2/30] Batch [1880/4715] Loss: 0.8001\n",
      "2025-05-30 13:43:48,804 - INFO - Epoch [2/30] Batch [1890/4715] Loss: 1.0348\n",
      "2025-05-30 13:43:50,407 - INFO - Epoch [2/30] Batch [1900/4715] Loss: 0.9611\n",
      "2025-05-30 13:43:51,949 - INFO - Epoch [2/30] Batch [1910/4715] Loss: 1.0464\n",
      "2025-05-30 13:43:53,650 - INFO - Epoch [2/30] Batch [1920/4715] Loss: 0.9614\n",
      "2025-05-30 13:43:55,235 - INFO - Epoch [2/30] Batch [1930/4715] Loss: 0.6794\n",
      "2025-05-30 13:43:56,766 - INFO - Epoch [2/30] Batch [1940/4715] Loss: 0.6742\n",
      "2025-05-30 13:43:58,353 - INFO - Epoch [2/30] Batch [1950/4715] Loss: 0.9851\n",
      "2025-05-30 13:43:59,887 - INFO - Epoch [2/30] Batch [1960/4715] Loss: 0.8763\n",
      "2025-05-30 13:44:01,440 - INFO - Epoch [2/30] Batch [1970/4715] Loss: 0.8583\n",
      "2025-05-30 13:44:03,018 - INFO - Epoch [2/30] Batch [1980/4715] Loss: 0.8264\n",
      "2025-05-30 13:44:04,589 - INFO - Epoch [2/30] Batch [1990/4715] Loss: 0.8635\n",
      "2025-05-30 13:44:06,124 - INFO - Epoch [2/30] Batch [2000/4715] Loss: 0.7343\n",
      "2025-05-30 13:44:07,822 - INFO - Epoch [2/30] Batch [2010/4715] Loss: 0.6403\n",
      "2025-05-30 13:44:09,458 - INFO - Epoch [2/30] Batch [2020/4715] Loss: 0.6510\n",
      "2025-05-30 13:44:10,995 - INFO - Epoch [2/30] Batch [2030/4715] Loss: 0.8348\n",
      "2025-05-30 13:44:12,620 - INFO - Epoch [2/30] Batch [2040/4715] Loss: 1.0333\n",
      "2025-05-30 13:44:14,167 - INFO - Epoch [2/30] Batch [2050/4715] Loss: 0.8968\n",
      "2025-05-30 13:44:15,669 - INFO - Epoch [2/30] Batch [2060/4715] Loss: 0.8791\n",
      "2025-05-30 13:44:17,251 - INFO - Epoch [2/30] Batch [2070/4715] Loss: 0.8760\n",
      "2025-05-30 13:44:18,863 - INFO - Epoch [2/30] Batch [2080/4715] Loss: 0.7964\n",
      "2025-05-30 13:44:20,425 - INFO - Epoch [2/30] Batch [2090/4715] Loss: 0.7883\n",
      "2025-05-30 13:44:21,988 - INFO - Epoch [2/30] Batch [2100/4715] Loss: 0.8302\n",
      "2025-05-30 13:44:23,529 - INFO - Epoch [2/30] Batch [2110/4715] Loss: 0.7062\n",
      "2025-05-30 13:44:25,078 - INFO - Epoch [2/30] Batch [2120/4715] Loss: 0.7926\n",
      "2025-05-30 13:44:26,706 - INFO - Epoch [2/30] Batch [2130/4715] Loss: 0.8418\n",
      "2025-05-30 13:44:28,273 - INFO - Epoch [2/30] Batch [2140/4715] Loss: 0.9255\n",
      "2025-05-30 13:44:29,878 - INFO - Epoch [2/30] Batch [2150/4715] Loss: 0.9413\n",
      "2025-05-30 13:44:31,468 - INFO - Epoch [2/30] Batch [2160/4715] Loss: 0.9080\n",
      "2025-05-30 13:44:33,165 - INFO - Epoch [2/30] Batch [2170/4715] Loss: 0.8635\n",
      "2025-05-30 13:44:34,725 - INFO - Epoch [2/30] Batch [2180/4715] Loss: 0.8038\n",
      "2025-05-30 13:44:36,274 - INFO - Epoch [2/30] Batch [2190/4715] Loss: 0.9853\n",
      "2025-05-30 13:44:37,823 - INFO - Epoch [2/30] Batch [2200/4715] Loss: 0.7988\n",
      "2025-05-30 13:44:39,386 - INFO - Epoch [2/30] Batch [2210/4715] Loss: 0.9068\n",
      "2025-05-30 13:44:40,997 - INFO - Epoch [2/30] Batch [2220/4715] Loss: 1.2011\n",
      "2025-05-30 13:44:42,595 - INFO - Epoch [2/30] Batch [2230/4715] Loss: 0.8740\n",
      "2025-05-30 13:44:44,109 - INFO - Epoch [2/30] Batch [2240/4715] Loss: 0.8009\n",
      "2025-05-30 13:44:45,609 - INFO - Epoch [2/30] Batch [2250/4715] Loss: 0.8703\n",
      "2025-05-30 13:44:47,203 - INFO - Epoch [2/30] Batch [2260/4715] Loss: 0.9736\n",
      "2025-05-30 13:44:48,762 - INFO - Epoch [2/30] Batch [2270/4715] Loss: 0.8130\n",
      "2025-05-30 13:44:50,347 - INFO - Epoch [2/30] Batch [2280/4715] Loss: 0.9333\n",
      "2025-05-30 13:44:51,985 - INFO - Epoch [2/30] Batch [2290/4715] Loss: 0.7757\n",
      "2025-05-30 13:44:53,742 - INFO - Epoch [2/30] Batch [2300/4715] Loss: 0.6694\n",
      "2025-05-30 13:44:55,315 - INFO - Epoch [2/30] Batch [2310/4715] Loss: 1.0397\n",
      "2025-05-30 13:44:56,858 - INFO - Epoch [2/30] Batch [2320/4715] Loss: 0.8353\n",
      "2025-05-30 13:44:58,444 - INFO - Epoch [2/30] Batch [2330/4715] Loss: 0.7066\n",
      "2025-05-30 13:45:00,104 - INFO - Epoch [2/30] Batch [2340/4715] Loss: 0.8362\n",
      "2025-05-30 13:45:01,750 - INFO - Epoch [2/30] Batch [2350/4715] Loss: 0.8295\n",
      "2025-05-30 13:45:03,359 - INFO - Epoch [2/30] Batch [2360/4715] Loss: 1.1460\n",
      "2025-05-30 13:45:04,934 - INFO - Epoch [2/30] Batch [2370/4715] Loss: 0.9291\n",
      "2025-05-30 13:45:06,487 - INFO - Epoch [2/30] Batch [2380/4715] Loss: 0.9345\n",
      "2025-05-30 13:45:08,126 - INFO - Epoch [2/30] Batch [2390/4715] Loss: 0.8199\n",
      "2025-05-30 13:45:09,743 - INFO - Epoch [2/30] Batch [2400/4715] Loss: 0.8444\n",
      "2025-05-30 13:45:11,307 - INFO - Epoch [2/30] Batch [2410/4715] Loss: 0.7952\n",
      "2025-05-30 13:45:12,962 - INFO - Epoch [2/30] Batch [2420/4715] Loss: 0.8773\n",
      "2025-05-30 13:45:14,530 - INFO - Epoch [2/30] Batch [2430/4715] Loss: 1.0038\n",
      "2025-05-30 13:45:16,164 - INFO - Epoch [2/30] Batch [2440/4715] Loss: 0.7191\n",
      "2025-05-30 13:45:17,725 - INFO - Epoch [2/30] Batch [2450/4715] Loss: 0.7971\n",
      "2025-05-30 13:45:19,222 - INFO - Epoch [2/30] Batch [2460/4715] Loss: 0.9246\n",
      "2025-05-30 13:45:20,744 - INFO - Epoch [2/30] Batch [2470/4715] Loss: 0.7785\n",
      "2025-05-30 13:45:22,322 - INFO - Epoch [2/30] Batch [2480/4715] Loss: 0.8296\n",
      "2025-05-30 13:45:24,024 - INFO - Epoch [2/30] Batch [2490/4715] Loss: 0.8267\n",
      "2025-05-30 13:45:25,542 - INFO - Epoch [2/30] Batch [2500/4715] Loss: 0.9953\n",
      "2025-05-30 13:45:27,143 - INFO - Epoch [2/30] Batch [2510/4715] Loss: 0.7560\n",
      "2025-05-30 13:45:28,714 - INFO - Epoch [2/30] Batch [2520/4715] Loss: 0.9568\n",
      "2025-05-30 13:45:30,249 - INFO - Epoch [2/30] Batch [2530/4715] Loss: 0.7197\n",
      "2025-05-30 13:45:31,845 - INFO - Epoch [2/30] Batch [2540/4715] Loss: 1.0206\n",
      "2025-05-30 13:45:33,404 - INFO - Epoch [2/30] Batch [2550/4715] Loss: 0.8992\n",
      "2025-05-30 13:45:34,902 - INFO - Epoch [2/30] Batch [2560/4715] Loss: 0.9040\n",
      "2025-05-30 13:45:36,458 - INFO - Epoch [2/30] Batch [2570/4715] Loss: 0.9185\n",
      "2025-05-30 13:45:38,017 - INFO - Epoch [2/30] Batch [2580/4715] Loss: 1.0095\n",
      "2025-05-30 13:45:39,554 - INFO - Epoch [2/30] Batch [2590/4715] Loss: 0.8277\n",
      "2025-05-30 13:45:41,104 - INFO - Epoch [2/30] Batch [2600/4715] Loss: 0.8155\n",
      "2025-05-30 13:45:42,673 - INFO - Epoch [2/30] Batch [2610/4715] Loss: 0.8399\n",
      "2025-05-30 13:45:44,270 - INFO - Epoch [2/30] Batch [2620/4715] Loss: 0.9198\n",
      "2025-05-30 13:45:45,843 - INFO - Epoch [2/30] Batch [2630/4715] Loss: 0.8348\n",
      "2025-05-30 13:45:47,454 - INFO - Epoch [2/30] Batch [2640/4715] Loss: 0.7414\n",
      "2025-05-30 13:45:49,063 - INFO - Epoch [2/30] Batch [2650/4715] Loss: 0.7122\n",
      "2025-05-30 13:45:50,681 - INFO - Epoch [2/30] Batch [2660/4715] Loss: 0.8133\n",
      "2025-05-30 13:45:52,278 - INFO - Epoch [2/30] Batch [2670/4715] Loss: 0.9709\n",
      "2025-05-30 13:45:53,945 - INFO - Epoch [2/30] Batch [2680/4715] Loss: 0.8530\n",
      "2025-05-30 13:45:55,494 - INFO - Epoch [2/30] Batch [2690/4715] Loss: 0.9915\n",
      "2025-05-30 13:45:57,028 - INFO - Epoch [2/30] Batch [2700/4715] Loss: 0.6792\n",
      "2025-05-30 13:45:58,622 - INFO - Epoch [2/30] Batch [2710/4715] Loss: 0.9635\n",
      "2025-05-30 13:46:00,163 - INFO - Epoch [2/30] Batch [2720/4715] Loss: 0.7636\n",
      "2025-05-30 13:46:01,828 - INFO - Epoch [2/30] Batch [2730/4715] Loss: 0.9413\n",
      "2025-05-30 13:46:03,357 - INFO - Epoch [2/30] Batch [2740/4715] Loss: 0.6964\n",
      "2025-05-30 13:46:04,915 - INFO - Epoch [2/30] Batch [2750/4715] Loss: 0.8961\n",
      "2025-05-30 13:46:06,488 - INFO - Epoch [2/30] Batch [2760/4715] Loss: 0.8512\n",
      "2025-05-30 13:46:08,072 - INFO - Epoch [2/30] Batch [2770/4715] Loss: 0.8236\n",
      "2025-05-30 13:46:09,669 - INFO - Epoch [2/30] Batch [2780/4715] Loss: 1.0262\n",
      "2025-05-30 13:46:11,217 - INFO - Epoch [2/30] Batch [2790/4715] Loss: 0.7227\n",
      "2025-05-30 13:46:12,904 - INFO - Epoch [2/30] Batch [2800/4715] Loss: 0.9024\n",
      "2025-05-30 13:46:14,506 - INFO - Epoch [2/30] Batch [2810/4715] Loss: 0.9428\n",
      "2025-05-30 13:46:16,102 - INFO - Epoch [2/30] Batch [2820/4715] Loss: 1.0709\n",
      "2025-05-30 13:46:17,608 - INFO - Epoch [2/30] Batch [2830/4715] Loss: 0.6621\n",
      "2025-05-30 13:46:19,096 - INFO - Epoch [2/30] Batch [2840/4715] Loss: 0.8259\n",
      "2025-05-30 13:46:20,677 - INFO - Epoch [2/30] Batch [2850/4715] Loss: 0.7443\n",
      "2025-05-30 13:46:22,150 - INFO - Epoch [2/30] Batch [2860/4715] Loss: 0.6786\n",
      "2025-05-30 13:46:23,748 - INFO - Epoch [2/30] Batch [2870/4715] Loss: 0.9103\n",
      "2025-05-30 13:46:25,297 - INFO - Epoch [2/30] Batch [2880/4715] Loss: 0.7500\n",
      "2025-05-30 13:46:26,894 - INFO - Epoch [2/30] Batch [2890/4715] Loss: 1.4546\n",
      "2025-05-30 13:46:28,568 - INFO - Epoch [2/30] Batch [2900/4715] Loss: 0.8775\n",
      "2025-05-30 13:46:30,221 - INFO - Epoch [2/30] Batch [2910/4715] Loss: 0.7143\n",
      "2025-05-30 13:46:31,864 - INFO - Epoch [2/30] Batch [2920/4715] Loss: 0.9170\n",
      "2025-05-30 13:46:33,457 - INFO - Epoch [2/30] Batch [2930/4715] Loss: 0.8288\n",
      "2025-05-30 13:46:35,097 - INFO - Epoch [2/30] Batch [2940/4715] Loss: 0.9026\n",
      "2025-05-30 13:46:36,710 - INFO - Epoch [2/30] Batch [2950/4715] Loss: 1.1371\n",
      "2025-05-30 13:46:38,263 - INFO - Epoch [2/30] Batch [2960/4715] Loss: 0.8447\n",
      "2025-05-30 13:46:39,863 - INFO - Epoch [2/30] Batch [2970/4715] Loss: 0.8251\n",
      "2025-05-30 13:46:41,419 - INFO - Epoch [2/30] Batch [2980/4715] Loss: 0.9164\n",
      "2025-05-30 13:46:42,924 - INFO - Epoch [2/30] Batch [2990/4715] Loss: 1.0427\n",
      "2025-05-30 13:46:44,413 - INFO - Epoch [2/30] Batch [3000/4715] Loss: 0.5974\n",
      "2025-05-30 13:46:45,973 - INFO - Epoch [2/30] Batch [3010/4715] Loss: 1.0382\n",
      "2025-05-30 13:46:47,558 - INFO - Epoch [2/30] Batch [3020/4715] Loss: 0.9289\n",
      "2025-05-30 13:46:49,210 - INFO - Epoch [2/30] Batch [3030/4715] Loss: 0.9161\n",
      "2025-05-30 13:46:50,849 - INFO - Epoch [2/30] Batch [3040/4715] Loss: 0.7878\n",
      "2025-05-30 13:46:52,427 - INFO - Epoch [2/30] Batch [3050/4715] Loss: 0.7790\n",
      "2025-05-30 13:46:53,990 - INFO - Epoch [2/30] Batch [3060/4715] Loss: 0.9035\n",
      "2025-05-30 13:46:55,618 - INFO - Epoch [2/30] Batch [3070/4715] Loss: 0.8508\n",
      "2025-05-30 13:46:57,176 - INFO - Epoch [2/30] Batch [3080/4715] Loss: 0.8428\n",
      "2025-05-30 13:46:58,725 - INFO - Epoch [2/30] Batch [3090/4715] Loss: 0.8308\n",
      "2025-05-30 13:47:00,274 - INFO - Epoch [2/30] Batch [3100/4715] Loss: 0.8546\n",
      "2025-05-30 13:47:01,850 - INFO - Epoch [2/30] Batch [3110/4715] Loss: 0.8144\n",
      "2025-05-30 13:47:03,441 - INFO - Epoch [2/30] Batch [3120/4715] Loss: 0.8679\n",
      "2025-05-30 13:47:05,011 - INFO - Epoch [2/30] Batch [3130/4715] Loss: 0.8956\n",
      "2025-05-30 13:47:06,601 - INFO - Epoch [2/30] Batch [3140/4715] Loss: 0.6767\n",
      "2025-05-30 13:47:08,170 - INFO - Epoch [2/30] Batch [3150/4715] Loss: 0.8305\n",
      "2025-05-30 13:47:09,733 - INFO - Epoch [2/30] Batch [3160/4715] Loss: 1.0124\n",
      "2025-05-30 13:47:11,296 - INFO - Epoch [2/30] Batch [3170/4715] Loss: 0.8406\n",
      "2025-05-30 13:47:12,845 - INFO - Epoch [2/30] Batch [3180/4715] Loss: 0.7628\n",
      "2025-05-30 13:47:14,402 - INFO - Epoch [2/30] Batch [3190/4715] Loss: 0.7071\n",
      "2025-05-30 13:47:15,918 - INFO - Epoch [2/30] Batch [3200/4715] Loss: 1.0541\n",
      "2025-05-30 13:47:17,440 - INFO - Epoch [2/30] Batch [3210/4715] Loss: 1.0170\n",
      "2025-05-30 13:47:19,061 - INFO - Epoch [2/30] Batch [3220/4715] Loss: 0.9094\n",
      "2025-05-30 13:47:20,680 - INFO - Epoch [2/30] Batch [3230/4715] Loss: 0.7906\n",
      "2025-05-30 13:47:22,261 - INFO - Epoch [2/30] Batch [3240/4715] Loss: 0.9263\n",
      "2025-05-30 13:47:23,840 - INFO - Epoch [2/30] Batch [3250/4715] Loss: 0.7418\n",
      "2025-05-30 13:47:25,479 - INFO - Epoch [2/30] Batch [3260/4715] Loss: 0.8028\n",
      "2025-05-30 13:47:27,120 - INFO - Epoch [2/30] Batch [3270/4715] Loss: 1.0522\n",
      "2025-05-30 13:47:28,667 - INFO - Epoch [2/30] Batch [3280/4715] Loss: 1.0539\n",
      "2025-05-30 13:47:30,250 - INFO - Epoch [2/30] Batch [3290/4715] Loss: 1.1602\n",
      "2025-05-30 13:47:31,882 - INFO - Epoch [2/30] Batch [3300/4715] Loss: 0.8492\n",
      "2025-05-30 13:47:33,473 - INFO - Epoch [2/30] Batch [3310/4715] Loss: 1.0206\n",
      "2025-05-30 13:47:35,084 - INFO - Epoch [2/30] Batch [3320/4715] Loss: 0.8500\n",
      "2025-05-30 13:47:36,765 - INFO - Epoch [2/30] Batch [3330/4715] Loss: 0.9376\n",
      "2025-05-30 13:47:38,364 - INFO - Epoch [2/30] Batch [3340/4715] Loss: 1.0494\n",
      "2025-05-30 13:47:39,869 - INFO - Epoch [2/30] Batch [3350/4715] Loss: 1.0117\n",
      "2025-05-30 13:47:41,387 - INFO - Epoch [2/30] Batch [3360/4715] Loss: 1.0349\n",
      "2025-05-30 13:47:42,917 - INFO - Epoch [2/30] Batch [3370/4715] Loss: 0.9641\n",
      "2025-05-30 13:47:44,523 - INFO - Epoch [2/30] Batch [3380/4715] Loss: 0.6520\n",
      "2025-05-30 13:47:46,107 - INFO - Epoch [2/30] Batch [3390/4715] Loss: 0.7807\n",
      "2025-05-30 13:47:47,745 - INFO - Epoch [2/30] Batch [3400/4715] Loss: 0.9523\n",
      "2025-05-30 13:47:49,329 - INFO - Epoch [2/30] Batch [3410/4715] Loss: 0.9228\n",
      "2025-05-30 13:47:50,829 - INFO - Epoch [2/30] Batch [3420/4715] Loss: 0.8332\n",
      "2025-05-30 13:47:52,406 - INFO - Epoch [2/30] Batch [3430/4715] Loss: 0.9874\n",
      "2025-05-30 13:47:53,985 - INFO - Epoch [2/30] Batch [3440/4715] Loss: 0.8606\n",
      "2025-05-30 13:47:55,608 - INFO - Epoch [2/30] Batch [3450/4715] Loss: 0.9266\n",
      "2025-05-30 13:47:57,205 - INFO - Epoch [2/30] Batch [3460/4715] Loss: 0.8755\n",
      "2025-05-30 13:47:58,838 - INFO - Epoch [2/30] Batch [3470/4715] Loss: 0.9148\n",
      "2025-05-30 13:48:00,428 - INFO - Epoch [2/30] Batch [3480/4715] Loss: 0.9224\n",
      "2025-05-30 13:48:01,942 - INFO - Epoch [2/30] Batch [3490/4715] Loss: 1.0342\n",
      "2025-05-30 13:48:03,534 - INFO - Epoch [2/30] Batch [3500/4715] Loss: 1.0521\n",
      "2025-05-30 13:48:05,130 - INFO - Epoch [2/30] Batch [3510/4715] Loss: 1.0772\n",
      "2025-05-30 13:48:06,725 - INFO - Epoch [2/30] Batch [3520/4715] Loss: 0.9118\n",
      "2025-05-30 13:48:08,297 - INFO - Epoch [2/30] Batch [3530/4715] Loss: 0.9327\n",
      "2025-05-30 13:48:09,904 - INFO - Epoch [2/30] Batch [3540/4715] Loss: 0.8813\n",
      "2025-05-30 13:48:11,478 - INFO - Epoch [2/30] Batch [3550/4715] Loss: 0.8612\n",
      "2025-05-30 13:48:13,006 - INFO - Epoch [2/30] Batch [3560/4715] Loss: 0.7470\n",
      "2025-05-30 13:48:14,641 - INFO - Epoch [2/30] Batch [3570/4715] Loss: 1.1110\n",
      "2025-05-30 13:48:16,166 - INFO - Epoch [2/30] Batch [3580/4715] Loss: 0.8848\n",
      "2025-05-30 13:48:17,694 - INFO - Epoch [2/30] Batch [3590/4715] Loss: 0.9593\n",
      "2025-05-30 13:48:19,279 - INFO - Epoch [2/30] Batch [3600/4715] Loss: 1.0208\n",
      "2025-05-30 13:48:20,820 - INFO - Epoch [2/30] Batch [3610/4715] Loss: 0.7741\n",
      "2025-05-30 13:48:22,376 - INFO - Epoch [2/30] Batch [3620/4715] Loss: 0.8547\n",
      "2025-05-30 13:48:23,888 - INFO - Epoch [2/30] Batch [3630/4715] Loss: 0.7442\n",
      "2025-05-30 13:48:25,390 - INFO - Epoch [2/30] Batch [3640/4715] Loss: 0.7964\n",
      "2025-05-30 13:48:26,886 - INFO - Epoch [2/30] Batch [3650/4715] Loss: 0.7285\n",
      "2025-05-30 13:48:28,425 - INFO - Epoch [2/30] Batch [3660/4715] Loss: 0.8222\n",
      "2025-05-30 13:48:29,962 - INFO - Epoch [2/30] Batch [3670/4715] Loss: 0.9841\n",
      "2025-05-30 13:48:31,523 - INFO - Epoch [2/30] Batch [3680/4715] Loss: 0.7593\n",
      "2025-05-30 13:48:33,099 - INFO - Epoch [2/30] Batch [3690/4715] Loss: 0.9107\n",
      "2025-05-30 13:48:34,697 - INFO - Epoch [2/30] Batch [3700/4715] Loss: 1.0558\n",
      "2025-05-30 13:48:36,245 - INFO - Epoch [2/30] Batch [3710/4715] Loss: 0.9982\n",
      "2025-05-30 13:48:37,781 - INFO - Epoch [2/30] Batch [3720/4715] Loss: 1.0671\n",
      "2025-05-30 13:48:39,486 - INFO - Epoch [2/30] Batch [3730/4715] Loss: 0.8217\n",
      "2025-05-30 13:48:41,006 - INFO - Epoch [2/30] Batch [3740/4715] Loss: 1.0031\n",
      "2025-05-30 13:48:42,545 - INFO - Epoch [2/30] Batch [3750/4715] Loss: 0.8188\n",
      "2025-05-30 13:48:44,149 - INFO - Epoch [2/30] Batch [3760/4715] Loss: 1.1722\n",
      "2025-05-30 13:48:45,761 - INFO - Epoch [2/30] Batch [3770/4715] Loss: 0.8290\n",
      "2025-05-30 13:48:47,323 - INFO - Epoch [2/30] Batch [3780/4715] Loss: 0.7926\n",
      "2025-05-30 13:48:49,014 - INFO - Epoch [2/30] Batch [3790/4715] Loss: 1.2018\n",
      "2025-05-30 13:48:50,609 - INFO - Epoch [2/30] Batch [3800/4715] Loss: 0.8692\n",
      "2025-05-30 13:48:52,290 - INFO - Epoch [2/30] Batch [3810/4715] Loss: 0.8518\n",
      "2025-05-30 13:48:53,949 - INFO - Epoch [2/30] Batch [3820/4715] Loss: 0.8225\n",
      "2025-05-30 13:48:55,491 - INFO - Epoch [2/30] Batch [3830/4715] Loss: 0.7935\n",
      "2025-05-30 13:48:56,992 - INFO - Epoch [2/30] Batch [3840/4715] Loss: 0.7498\n",
      "2025-05-30 13:48:58,547 - INFO - Epoch [2/30] Batch [3850/4715] Loss: 0.7604\n",
      "2025-05-30 13:49:00,075 - INFO - Epoch [2/30] Batch [3860/4715] Loss: 0.9509\n",
      "2025-05-30 13:49:01,666 - INFO - Epoch [2/30] Batch [3870/4715] Loss: 0.9079\n",
      "2025-05-30 13:49:03,249 - INFO - Epoch [2/30] Batch [3880/4715] Loss: 0.8804\n",
      "2025-05-30 13:49:04,861 - INFO - Epoch [2/30] Batch [3890/4715] Loss: 0.8791\n",
      "2025-05-30 13:49:06,388 - INFO - Epoch [2/30] Batch [3900/4715] Loss: 0.9622\n",
      "2025-05-30 13:49:07,924 - INFO - Epoch [2/30] Batch [3910/4715] Loss: 0.9826\n",
      "2025-05-30 13:49:09,527 - INFO - Epoch [2/30] Batch [3920/4715] Loss: 0.7995\n",
      "2025-05-30 13:49:11,086 - INFO - Epoch [2/30] Batch [3930/4715] Loss: 0.8316\n",
      "2025-05-30 13:49:12,625 - INFO - Epoch [2/30] Batch [3940/4715] Loss: 0.9139\n",
      "2025-05-30 13:49:14,175 - INFO - Epoch [2/30] Batch [3950/4715] Loss: 0.8564\n",
      "2025-05-30 13:49:15,744 - INFO - Epoch [2/30] Batch [3960/4715] Loss: 0.8947\n",
      "2025-05-30 13:49:17,279 - INFO - Epoch [2/30] Batch [3970/4715] Loss: 0.8238\n",
      "2025-05-30 13:49:18,780 - INFO - Epoch [2/30] Batch [3980/4715] Loss: 0.8977\n",
      "2025-05-30 13:49:20,370 - INFO - Epoch [2/30] Batch [3990/4715] Loss: 0.7358\n",
      "2025-05-30 13:49:22,065 - INFO - Epoch [2/30] Batch [4000/4715] Loss: 0.7187\n",
      "2025-05-30 13:49:23,648 - INFO - Epoch [2/30] Batch [4010/4715] Loss: 1.1295\n",
      "2025-05-30 13:49:25,224 - INFO - Epoch [2/30] Batch [4020/4715] Loss: 0.7377\n",
      "2025-05-30 13:49:26,829 - INFO - Epoch [2/30] Batch [4030/4715] Loss: 0.8488\n",
      "2025-05-30 13:49:28,475 - INFO - Epoch [2/30] Batch [4040/4715] Loss: 0.7556\n",
      "2025-05-30 13:49:30,045 - INFO - Epoch [2/30] Batch [4050/4715] Loss: 0.8974\n",
      "2025-05-30 13:49:31,628 - INFO - Epoch [2/30] Batch [4060/4715] Loss: 0.8197\n",
      "2025-05-30 13:49:33,170 - INFO - Epoch [2/30] Batch [4070/4715] Loss: 0.9107\n",
      "2025-05-30 13:49:34,718 - INFO - Epoch [2/30] Batch [4080/4715] Loss: 0.9388\n",
      "2025-05-30 13:49:36,310 - INFO - Epoch [2/30] Batch [4090/4715] Loss: 0.9451\n",
      "2025-05-30 13:49:37,949 - INFO - Epoch [2/30] Batch [4100/4715] Loss: 0.9200\n",
      "2025-05-30 13:49:39,546 - INFO - Epoch [2/30] Batch [4110/4715] Loss: 0.8847\n",
      "2025-05-30 13:49:41,046 - INFO - Epoch [2/30] Batch [4120/4715] Loss: 1.0563\n",
      "2025-05-30 13:49:42,686 - INFO - Epoch [2/30] Batch [4130/4715] Loss: 1.0254\n",
      "2025-05-30 13:49:44,193 - INFO - Epoch [2/30] Batch [4140/4715] Loss: 0.8576\n",
      "2025-05-30 13:49:45,835 - INFO - Epoch [2/30] Batch [4150/4715] Loss: 0.8971\n",
      "2025-05-30 13:49:47,520 - INFO - Epoch [2/30] Batch [4160/4715] Loss: 0.8298\n",
      "2025-05-30 13:49:49,047 - INFO - Epoch [2/30] Batch [4170/4715] Loss: 0.8786\n",
      "2025-05-30 13:49:50,624 - INFO - Epoch [2/30] Batch [4180/4715] Loss: 0.8244\n",
      "2025-05-30 13:49:52,224 - INFO - Epoch [2/30] Batch [4190/4715] Loss: 0.6984\n",
      "2025-05-30 13:49:53,791 - INFO - Epoch [2/30] Batch [4200/4715] Loss: 0.8020\n",
      "2025-05-30 13:49:55,389 - INFO - Epoch [2/30] Batch [4210/4715] Loss: 0.9830\n",
      "2025-05-30 13:49:56,861 - INFO - Epoch [2/30] Batch [4220/4715] Loss: 0.8577\n",
      "2025-05-30 13:49:58,389 - INFO - Epoch [2/30] Batch [4230/4715] Loss: 0.8386\n",
      "2025-05-30 13:49:59,963 - INFO - Epoch [2/30] Batch [4240/4715] Loss: 0.9215\n",
      "2025-05-30 13:50:01,591 - INFO - Epoch [2/30] Batch [4250/4715] Loss: 0.8554\n",
      "2025-05-30 13:50:03,195 - INFO - Epoch [2/30] Batch [4260/4715] Loss: 0.9688\n",
      "2025-05-30 13:50:04,815 - INFO - Epoch [2/30] Batch [4270/4715] Loss: 0.7773\n",
      "2025-05-30 13:50:06,344 - INFO - Epoch [2/30] Batch [4280/4715] Loss: 0.6903\n",
      "2025-05-30 13:50:07,925 - INFO - Epoch [2/30] Batch [4290/4715] Loss: 0.9641\n",
      "2025-05-30 13:50:09,488 - INFO - Epoch [2/30] Batch [4300/4715] Loss: 0.6845\n",
      "2025-05-30 13:50:11,106 - INFO - Epoch [2/30] Batch [4310/4715] Loss: 0.8657\n",
      "2025-05-30 13:50:12,667 - INFO - Epoch [2/30] Batch [4320/4715] Loss: 1.0830\n",
      "2025-05-30 13:50:14,241 - INFO - Epoch [2/30] Batch [4330/4715] Loss: 0.8514\n",
      "2025-05-30 13:50:15,858 - INFO - Epoch [2/30] Batch [4340/4715] Loss: 0.8270\n",
      "2025-05-30 13:50:17,426 - INFO - Epoch [2/30] Batch [4350/4715] Loss: 1.0641\n",
      "2025-05-30 13:50:19,082 - INFO - Epoch [2/30] Batch [4360/4715] Loss: 0.8195\n",
      "2025-05-30 13:50:20,665 - INFO - Epoch [2/30] Batch [4370/4715] Loss: 0.9478\n",
      "2025-05-30 13:50:22,239 - INFO - Epoch [2/30] Batch [4380/4715] Loss: 1.0051\n",
      "2025-05-30 13:50:23,857 - INFO - Epoch [2/30] Batch [4390/4715] Loss: 0.9104\n",
      "2025-05-30 13:50:25,393 - INFO - Epoch [2/30] Batch [4400/4715] Loss: 0.8564\n",
      "2025-05-30 13:50:26,949 - INFO - Epoch [2/30] Batch [4410/4715] Loss: 0.7157\n",
      "2025-05-30 13:50:28,560 - INFO - Epoch [2/30] Batch [4420/4715] Loss: 0.9232\n",
      "2025-05-30 13:50:30,067 - INFO - Epoch [2/30] Batch [4430/4715] Loss: 0.8331\n",
      "2025-05-30 13:50:31,644 - INFO - Epoch [2/30] Batch [4440/4715] Loss: 0.8899\n",
      "2025-05-30 13:50:33,248 - INFO - Epoch [2/30] Batch [4450/4715] Loss: 1.0439\n",
      "2025-05-30 13:50:34,816 - INFO - Epoch [2/30] Batch [4460/4715] Loss: 1.0064\n",
      "2025-05-30 13:50:36,445 - INFO - Epoch [2/30] Batch [4470/4715] Loss: 0.7973\n",
      "2025-05-30 13:50:38,112 - INFO - Epoch [2/30] Batch [4480/4715] Loss: 0.9556\n",
      "2025-05-30 13:50:39,666 - INFO - Epoch [2/30] Batch [4490/4715] Loss: 0.9305\n",
      "2025-05-30 13:50:41,166 - INFO - Epoch [2/30] Batch [4500/4715] Loss: 0.6390\n",
      "2025-05-30 13:50:42,863 - INFO - Epoch [2/30] Batch [4510/4715] Loss: 0.6889\n",
      "2025-05-30 13:50:44,423 - INFO - Epoch [2/30] Batch [4520/4715] Loss: 0.6765\n",
      "2025-05-30 13:50:45,993 - INFO - Epoch [2/30] Batch [4530/4715] Loss: 0.8481\n",
      "2025-05-30 13:50:47,604 - INFO - Epoch [2/30] Batch [4540/4715] Loss: 1.0771\n",
      "2025-05-30 13:50:49,223 - INFO - Epoch [2/30] Batch [4550/4715] Loss: 0.7407\n",
      "2025-05-30 13:50:50,785 - INFO - Epoch [2/30] Batch [4560/4715] Loss: 0.9411\n",
      "2025-05-30 13:50:52,355 - INFO - Epoch [2/30] Batch [4570/4715] Loss: 0.8993\n",
      "2025-05-30 13:50:53,918 - INFO - Epoch [2/30] Batch [4580/4715] Loss: 0.9255\n",
      "2025-05-30 13:50:55,517 - INFO - Epoch [2/30] Batch [4590/4715] Loss: 1.0897\n",
      "2025-05-30 13:50:57,092 - INFO - Epoch [2/30] Batch [4600/4715] Loss: 1.0182\n",
      "2025-05-30 13:50:58,641 - INFO - Epoch [2/30] Batch [4610/4715] Loss: 0.7926\n",
      "2025-05-30 13:51:00,116 - INFO - Epoch [2/30] Batch [4620/4715] Loss: 0.9366\n",
      "2025-05-30 13:51:01,741 - INFO - Epoch [2/30] Batch [4630/4715] Loss: 0.8829\n",
      "2025-05-30 13:51:03,322 - INFO - Epoch [2/30] Batch [4640/4715] Loss: 0.9527\n",
      "2025-05-30 13:51:04,914 - INFO - Epoch [2/30] Batch [4650/4715] Loss: 0.8559\n",
      "2025-05-30 13:51:06,427 - INFO - Epoch [2/30] Batch [4660/4715] Loss: 0.8474\n",
      "2025-05-30 13:51:08,045 - INFO - Epoch [2/30] Batch [4670/4715] Loss: 0.8077\n",
      "2025-05-30 13:51:09,573 - INFO - Epoch [2/30] Batch [4680/4715] Loss: 1.0728\n",
      "2025-05-30 13:51:11,177 - INFO - Epoch [2/30] Batch [4690/4715] Loss: 0.7390\n",
      "2025-05-30 13:51:12,724 - INFO - Epoch [2/30] Batch [4700/4715] Loss: 0.7063\n",
      "2025-05-30 13:51:14,319 - INFO - Epoch [2/30] Batch [4710/4715] Loss: 0.8763\n",
      "2025-05-30 13:51:53,043 - INFO - \n",
      "Epoch [2/30] Time: 783.70s\n",
      "2025-05-30 13:51:53,044 - INFO - Train Loss: 0.8940, Valid Loss: 0.8816\n",
      "2025-05-30 13:51:53,044 - INFO - Valid AUC (macro): 0.6851, F1 (macro): 0.5185\n",
      "2025-05-30 13:51:53,572 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\best_model.pth\n",
      "2025-05-30 13:51:53,579 - INFO - New best model saved with AUC: 0.6851\n",
      "2025-05-30 13:51:54,093 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 13:51:54,093 - INFO - Saved checkpoint at epoch 2\n",
      "2025-05-30 13:51:54,294 - INFO - Epoch [3/30] Batch [0/4715] Loss: 0.9013\n",
      "2025-05-30 13:51:56,024 - INFO - Epoch [3/30] Batch [10/4715] Loss: 0.7812\n",
      "2025-05-30 13:51:57,670 - INFO - Epoch [3/30] Batch [20/4715] Loss: 0.7534\n",
      "2025-05-30 13:51:59,246 - INFO - Epoch [3/30] Batch [30/4715] Loss: 0.7694\n",
      "2025-05-30 13:52:00,809 - INFO - Epoch [3/30] Batch [40/4715] Loss: 1.0058\n",
      "2025-05-30 13:52:02,524 - INFO - Epoch [3/30] Batch [50/4715] Loss: 0.8532\n",
      "2025-05-30 13:52:04,185 - INFO - Epoch [3/30] Batch [60/4715] Loss: 0.9576\n",
      "2025-05-30 13:52:05,807 - INFO - Epoch [3/30] Batch [70/4715] Loss: 0.9271\n",
      "2025-05-30 13:52:07,428 - INFO - Epoch [3/30] Batch [80/4715] Loss: 0.8078\n",
      "2025-05-30 13:52:09,005 - INFO - Epoch [3/30] Batch [90/4715] Loss: 0.6528\n",
      "2025-05-30 13:52:10,595 - INFO - Epoch [3/30] Batch [100/4715] Loss: 0.9079\n",
      "2025-05-30 13:52:12,223 - INFO - Epoch [3/30] Batch [110/4715] Loss: 1.0349\n",
      "2025-05-30 13:52:13,740 - INFO - Epoch [3/30] Batch [120/4715] Loss: 0.6784\n",
      "2025-05-30 13:52:15,269 - INFO - Epoch [3/30] Batch [130/4715] Loss: 0.8076\n",
      "2025-05-30 13:52:16,862 - INFO - Epoch [3/30] Batch [140/4715] Loss: 0.8475\n",
      "2025-05-30 13:52:18,374 - INFO - Epoch [3/30] Batch [150/4715] Loss: 0.8836\n",
      "2025-05-30 13:52:19,864 - INFO - Epoch [3/30] Batch [160/4715] Loss: 0.9164\n",
      "2025-05-30 13:52:21,444 - INFO - Epoch [3/30] Batch [170/4715] Loss: 0.9032\n",
      "2025-05-30 13:52:23,026 - INFO - Epoch [3/30] Batch [180/4715] Loss: 0.6706\n",
      "2025-05-30 13:52:24,579 - INFO - Epoch [3/30] Batch [190/4715] Loss: 0.8468\n",
      "2025-05-30 13:52:26,188 - INFO - Epoch [3/30] Batch [200/4715] Loss: 0.9303\n",
      "2025-05-30 13:52:27,762 - INFO - Epoch [3/30] Batch [210/4715] Loss: 0.6559\n",
      "2025-05-30 13:52:29,319 - INFO - Epoch [3/30] Batch [220/4715] Loss: 0.7865\n",
      "2025-05-30 13:52:31,008 - INFO - Epoch [3/30] Batch [230/4715] Loss: 0.8266\n",
      "2025-05-30 13:52:32,624 - INFO - Epoch [3/30] Batch [240/4715] Loss: 0.8733\n",
      "2025-05-30 13:52:34,168 - INFO - Epoch [3/30] Batch [250/4715] Loss: 0.6898\n",
      "2025-05-30 13:52:35,822 - INFO - Epoch [3/30] Batch [260/4715] Loss: 0.8028\n",
      "2025-05-30 13:52:37,349 - INFO - Epoch [3/30] Batch [270/4715] Loss: 0.8937\n",
      "2025-05-30 13:52:38,891 - INFO - Epoch [3/30] Batch [280/4715] Loss: 1.0310\n",
      "2025-05-30 13:52:40,474 - INFO - Epoch [3/30] Batch [290/4715] Loss: 0.9494\n",
      "2025-05-30 13:52:42,030 - INFO - Epoch [3/30] Batch [300/4715] Loss: 0.9075\n",
      "2025-05-30 13:52:43,485 - INFO - Epoch [3/30] Batch [310/4715] Loss: 1.0186\n",
      "2025-05-30 13:52:45,021 - INFO - Epoch [3/30] Batch [320/4715] Loss: 0.8107\n",
      "2025-05-30 13:52:46,587 - INFO - Epoch [3/30] Batch [330/4715] Loss: 1.0298\n",
      "2025-05-30 13:52:48,165 - INFO - Epoch [3/30] Batch [340/4715] Loss: 0.8508\n",
      "2025-05-30 13:52:49,705 - INFO - Epoch [3/30] Batch [350/4715] Loss: 0.9188\n",
      "2025-05-30 13:52:51,241 - INFO - Epoch [3/30] Batch [360/4715] Loss: 0.8206\n",
      "2025-05-30 13:52:52,830 - INFO - Epoch [3/30] Batch [370/4715] Loss: 0.6902\n",
      "2025-05-30 13:52:54,439 - INFO - Epoch [3/30] Batch [380/4715] Loss: 0.7251\n",
      "2025-05-30 13:52:56,065 - INFO - Epoch [3/30] Batch [390/4715] Loss: 0.9889\n",
      "2025-05-30 13:52:57,650 - INFO - Epoch [3/30] Batch [400/4715] Loss: 0.9161\n",
      "2025-05-30 13:52:59,178 - INFO - Epoch [3/30] Batch [410/4715] Loss: 0.8110\n",
      "2025-05-30 13:53:00,741 - INFO - Epoch [3/30] Batch [420/4715] Loss: 0.9790\n",
      "2025-05-30 13:53:02,318 - INFO - Epoch [3/30] Batch [430/4715] Loss: 0.8121\n",
      "2025-05-30 13:53:03,950 - INFO - Epoch [3/30] Batch [440/4715] Loss: 1.0345\n",
      "2025-05-30 13:53:05,548 - INFO - Epoch [3/30] Batch [450/4715] Loss: 0.8091\n",
      "2025-05-30 13:53:07,142 - INFO - Epoch [3/30] Batch [460/4715] Loss: 1.0417\n",
      "2025-05-30 13:53:08,610 - INFO - Epoch [3/30] Batch [470/4715] Loss: 0.8397\n",
      "2025-05-30 13:53:10,291 - INFO - Epoch [3/30] Batch [480/4715] Loss: 0.8766\n",
      "2025-05-30 13:53:11,805 - INFO - Epoch [3/30] Batch [490/4715] Loss: 0.8380\n",
      "2025-05-30 13:53:13,313 - INFO - Epoch [3/30] Batch [500/4715] Loss: 0.5987\n",
      "2025-05-30 13:53:14,910 - INFO - Epoch [3/30] Batch [510/4715] Loss: 0.8241\n",
      "2025-05-30 13:53:16,441 - INFO - Epoch [3/30] Batch [520/4715] Loss: 0.6878\n",
      "2025-05-30 13:53:18,049 - INFO - Epoch [3/30] Batch [530/4715] Loss: 0.9716\n",
      "2025-05-30 13:53:19,605 - INFO - Epoch [3/30] Batch [540/4715] Loss: 0.9350\n",
      "2025-05-30 13:53:21,205 - INFO - Epoch [3/30] Batch [550/4715] Loss: 0.8706\n",
      "2025-05-30 13:53:22,761 - INFO - Epoch [3/30] Batch [560/4715] Loss: 0.9032\n",
      "2025-05-30 13:53:24,307 - INFO - Epoch [3/30] Batch [570/4715] Loss: 0.9429\n",
      "2025-05-30 13:53:25,891 - INFO - Epoch [3/30] Batch [580/4715] Loss: 1.0177\n",
      "2025-05-30 13:53:27,495 - INFO - Epoch [3/30] Batch [590/4715] Loss: 0.9777\n",
      "2025-05-30 13:53:29,126 - INFO - Epoch [3/30] Batch [600/4715] Loss: 0.8536\n",
      "2025-05-30 13:53:30,690 - INFO - Epoch [3/30] Batch [610/4715] Loss: 0.9618\n",
      "2025-05-30 13:53:32,286 - INFO - Epoch [3/30] Batch [620/4715] Loss: 0.8757\n",
      "2025-05-30 13:53:33,878 - INFO - Epoch [3/30] Batch [630/4715] Loss: 0.8122\n",
      "2025-05-30 13:53:35,419 - INFO - Epoch [3/30] Batch [640/4715] Loss: 0.6544\n",
      "2025-05-30 13:53:36,948 - INFO - Epoch [3/30] Batch [650/4715] Loss: 0.8763\n",
      "2025-05-30 13:53:38,562 - INFO - Epoch [3/30] Batch [660/4715] Loss: 0.8673\n",
      "2025-05-30 13:53:40,163 - INFO - Epoch [3/30] Batch [670/4715] Loss: 0.8733\n",
      "2025-05-30 13:53:41,796 - INFO - Epoch [3/30] Batch [680/4715] Loss: 0.9986\n",
      "2025-05-30 13:53:43,310 - INFO - Epoch [3/30] Batch [690/4715] Loss: 1.0426\n",
      "2025-05-30 13:53:44,881 - INFO - Epoch [3/30] Batch [700/4715] Loss: 1.0079\n",
      "2025-05-30 13:53:46,470 - INFO - Epoch [3/30] Batch [710/4715] Loss: 0.9334\n",
      "2025-05-30 13:53:48,015 - INFO - Epoch [3/30] Batch [720/4715] Loss: 0.9117\n",
      "2025-05-30 13:53:49,535 - INFO - Epoch [3/30] Batch [730/4715] Loss: 0.8384\n",
      "2025-05-30 13:53:51,095 - INFO - Epoch [3/30] Batch [740/4715] Loss: 0.9101\n",
      "2025-05-30 13:53:52,703 - INFO - Epoch [3/30] Batch [750/4715] Loss: 1.0379\n",
      "2025-05-30 13:53:54,226 - INFO - Epoch [3/30] Batch [760/4715] Loss: 1.0540\n",
      "2025-05-30 13:53:55,825 - INFO - Epoch [3/30] Batch [770/4715] Loss: 0.7564\n",
      "2025-05-30 13:53:57,395 - INFO - Epoch [3/30] Batch [780/4715] Loss: 0.9755\n",
      "2025-05-30 13:53:58,923 - INFO - Epoch [3/30] Batch [790/4715] Loss: 0.9550\n",
      "2025-05-30 13:54:00,587 - INFO - Epoch [3/30] Batch [800/4715] Loss: 0.8512\n",
      "2025-05-30 13:54:02,218 - INFO - Epoch [3/30] Batch [810/4715] Loss: 0.7241\n",
      "2025-05-30 13:54:03,806 - INFO - Epoch [3/30] Batch [820/4715] Loss: 0.7809\n",
      "2025-05-30 13:54:05,420 - INFO - Epoch [3/30] Batch [830/4715] Loss: 0.8524\n",
      "2025-05-30 13:54:07,028 - INFO - Epoch [3/30] Batch [840/4715] Loss: 0.8535\n",
      "2025-05-30 13:54:08,682 - INFO - Epoch [3/30] Batch [850/4715] Loss: 0.9163\n",
      "2025-05-30 13:54:10,325 - INFO - Epoch [3/30] Batch [860/4715] Loss: 0.9715\n",
      "2025-05-30 13:54:11,960 - INFO - Epoch [3/30] Batch [870/4715] Loss: 0.7409\n",
      "2025-05-30 13:54:13,543 - INFO - Epoch [3/30] Batch [880/4715] Loss: 0.9701\n",
      "2025-05-30 13:54:15,106 - INFO - Epoch [3/30] Batch [890/4715] Loss: 0.9997\n",
      "2025-05-30 13:54:16,606 - INFO - Epoch [3/30] Batch [900/4715] Loss: 0.8046\n",
      "2025-05-30 13:54:18,141 - INFO - Epoch [3/30] Batch [910/4715] Loss: 0.9598\n",
      "2025-05-30 13:54:19,735 - INFO - Epoch [3/30] Batch [920/4715] Loss: 1.1062\n",
      "2025-05-30 13:54:21,282 - INFO - Epoch [3/30] Batch [930/4715] Loss: 0.9213\n",
      "2025-05-30 13:54:22,873 - INFO - Epoch [3/30] Batch [940/4715] Loss: 0.8089\n",
      "2025-05-30 13:54:24,426 - INFO - Epoch [3/30] Batch [950/4715] Loss: 0.5685\n",
      "2025-05-30 13:54:25,996 - INFO - Epoch [3/30] Batch [960/4715] Loss: 1.0629\n",
      "2025-05-30 13:54:27,621 - INFO - Epoch [3/30] Batch [970/4715] Loss: 0.9282\n",
      "2025-05-30 13:54:29,149 - INFO - Epoch [3/30] Batch [980/4715] Loss: 0.8820\n",
      "2025-05-30 13:54:30,677 - INFO - Epoch [3/30] Batch [990/4715] Loss: 0.9074\n",
      "2025-05-30 13:54:32,185 - INFO - Epoch [3/30] Batch [1000/4715] Loss: 1.0319\n",
      "2025-05-30 13:54:33,764 - INFO - Epoch [3/30] Batch [1010/4715] Loss: 0.8920\n",
      "2025-05-30 13:54:35,310 - INFO - Epoch [3/30] Batch [1020/4715] Loss: 0.6880\n",
      "2025-05-30 13:54:36,884 - INFO - Epoch [3/30] Batch [1030/4715] Loss: 1.0258\n",
      "2025-05-30 13:54:38,505 - INFO - Epoch [3/30] Batch [1040/4715] Loss: 1.0217\n",
      "2025-05-30 13:54:40,047 - INFO - Epoch [3/30] Batch [1050/4715] Loss: 0.9778\n",
      "2025-05-30 13:54:41,639 - INFO - Epoch [3/30] Batch [1060/4715] Loss: 0.7804\n",
      "2025-05-30 13:54:43,269 - INFO - Epoch [3/30] Batch [1070/4715] Loss: 0.7941\n",
      "2025-05-30 13:54:44,943 - INFO - Epoch [3/30] Batch [1080/4715] Loss: 0.9479\n",
      "2025-05-30 13:54:46,596 - INFO - Epoch [3/30] Batch [1090/4715] Loss: 1.1792\n",
      "2025-05-30 13:54:48,204 - INFO - Epoch [3/30] Batch [1100/4715] Loss: 0.8599\n",
      "2025-05-30 13:54:49,784 - INFO - Epoch [3/30] Batch [1110/4715] Loss: 0.8240\n",
      "2025-05-30 13:54:51,358 - INFO - Epoch [3/30] Batch [1120/4715] Loss: 1.0433\n",
      "2025-05-30 13:54:52,953 - INFO - Epoch [3/30] Batch [1130/4715] Loss: 0.9729\n",
      "2025-05-30 13:54:54,500 - INFO - Epoch [3/30] Batch [1140/4715] Loss: 0.8047\n",
      "2025-05-30 13:54:56,091 - INFO - Epoch [3/30] Batch [1150/4715] Loss: 0.8137\n",
      "2025-05-30 13:54:57,636 - INFO - Epoch [3/30] Batch [1160/4715] Loss: 0.9438\n",
      "2025-05-30 13:54:59,195 - INFO - Epoch [3/30] Batch [1170/4715] Loss: 0.8692\n",
      "2025-05-30 13:55:00,772 - INFO - Epoch [3/30] Batch [1180/4715] Loss: 0.7616\n",
      "2025-05-30 13:55:02,349 - INFO - Epoch [3/30] Batch [1190/4715] Loss: 0.8738\n",
      "2025-05-30 13:55:03,941 - INFO - Epoch [3/30] Batch [1200/4715] Loss: 0.9252\n",
      "2025-05-30 13:55:05,509 - INFO - Epoch [3/30] Batch [1210/4715] Loss: 0.9747\n",
      "2025-05-30 13:55:07,051 - INFO - Epoch [3/30] Batch [1220/4715] Loss: 0.8648\n",
      "2025-05-30 13:55:08,623 - INFO - Epoch [3/30] Batch [1230/4715] Loss: 0.9076\n",
      "2025-05-30 13:55:10,266 - INFO - Epoch [3/30] Batch [1240/4715] Loss: 0.8663\n",
      "2025-05-30 13:55:11,829 - INFO - Epoch [3/30] Batch [1250/4715] Loss: 0.7572\n",
      "2025-05-30 13:55:13,460 - INFO - Epoch [3/30] Batch [1260/4715] Loss: 0.8591\n",
      "2025-05-30 13:55:14,934 - INFO - Epoch [3/30] Batch [1270/4715] Loss: 0.8830\n",
      "2025-05-30 13:55:16,489 - INFO - Epoch [3/30] Batch [1280/4715] Loss: 0.9655\n",
      "2025-05-30 13:55:18,109 - INFO - Epoch [3/30] Batch [1290/4715] Loss: 0.8804\n",
      "2025-05-30 13:55:19,684 - INFO - Epoch [3/30] Batch [1300/4715] Loss: 0.6733\n",
      "2025-05-30 13:55:21,344 - INFO - Epoch [3/30] Batch [1310/4715] Loss: 0.9633\n",
      "2025-05-30 13:55:22,942 - INFO - Epoch [3/30] Batch [1320/4715] Loss: 0.9661\n",
      "2025-05-30 13:55:24,484 - INFO - Epoch [3/30] Batch [1330/4715] Loss: 0.8027\n",
      "2025-05-30 13:55:26,005 - INFO - Epoch [3/30] Batch [1340/4715] Loss: 0.6904\n",
      "2025-05-30 13:55:27,574 - INFO - Epoch [3/30] Batch [1350/4715] Loss: 0.7424\n",
      "2025-05-30 13:55:29,130 - INFO - Epoch [3/30] Batch [1360/4715] Loss: 0.9264\n",
      "2025-05-30 13:55:30,724 - INFO - Epoch [3/30] Batch [1370/4715] Loss: 0.8007\n",
      "2025-05-30 13:55:32,325 - INFO - Epoch [3/30] Batch [1380/4715] Loss: 0.7160\n",
      "2025-05-30 13:55:33,846 - INFO - Epoch [3/30] Batch [1390/4715] Loss: 0.8932\n",
      "2025-05-30 13:55:35,462 - INFO - Epoch [3/30] Batch [1400/4715] Loss: 0.8311\n",
      "2025-05-30 13:55:37,057 - INFO - Epoch [3/30] Batch [1410/4715] Loss: 1.1882\n",
      "2025-05-30 13:55:38,584 - INFO - Epoch [3/30] Batch [1420/4715] Loss: 0.8547\n",
      "2025-05-30 13:55:40,229 - INFO - Epoch [3/30] Batch [1430/4715] Loss: 0.9722\n",
      "2025-05-30 13:55:41,896 - INFO - Epoch [3/30] Batch [1440/4715] Loss: 0.9483\n",
      "2025-05-30 13:55:43,528 - INFO - Epoch [3/30] Batch [1450/4715] Loss: 0.8727\n",
      "2025-05-30 13:55:45,042 - INFO - Epoch [3/30] Batch [1460/4715] Loss: 0.7768\n",
      "2025-05-30 13:55:46,542 - INFO - Epoch [3/30] Batch [1470/4715] Loss: 0.9520\n",
      "2025-05-30 13:55:48,135 - INFO - Epoch [3/30] Batch [1480/4715] Loss: 0.9580\n",
      "2025-05-30 13:55:49,744 - INFO - Epoch [3/30] Batch [1490/4715] Loss: 0.7610\n",
      "2025-05-30 13:55:51,376 - INFO - Epoch [3/30] Batch [1500/4715] Loss: 0.7901\n",
      "2025-05-30 13:55:53,003 - INFO - Epoch [3/30] Batch [1510/4715] Loss: 1.1625\n",
      "2025-05-30 13:55:54,543 - INFO - Epoch [3/30] Batch [1520/4715] Loss: 0.9445\n",
      "2025-05-30 13:55:56,138 - INFO - Epoch [3/30] Batch [1530/4715] Loss: 0.8613\n",
      "2025-05-30 13:55:57,752 - INFO - Epoch [3/30] Batch [1540/4715] Loss: 0.7519\n",
      "2025-05-30 13:55:59,349 - INFO - Epoch [3/30] Batch [1550/4715] Loss: 0.7483\n",
      "2025-05-30 13:56:00,912 - INFO - Epoch [3/30] Batch [1560/4715] Loss: 0.8412\n",
      "2025-05-30 13:56:02,439 - INFO - Epoch [3/30] Batch [1570/4715] Loss: 0.8798\n",
      "2025-05-30 13:56:04,036 - INFO - Epoch [3/30] Batch [1580/4715] Loss: 0.9282\n",
      "2025-05-30 13:56:05,670 - INFO - Epoch [3/30] Batch [1590/4715] Loss: 0.9047\n",
      "2025-05-30 13:56:07,205 - INFO - Epoch [3/30] Batch [1600/4715] Loss: 0.8974\n",
      "2025-05-30 13:56:08,767 - INFO - Epoch [3/30] Batch [1610/4715] Loss: 0.8856\n",
      "2025-05-30 13:56:10,386 - INFO - Epoch [3/30] Batch [1620/4715] Loss: 0.6124\n",
      "2025-05-30 13:56:11,964 - INFO - Epoch [3/30] Batch [1630/4715] Loss: 0.8211\n",
      "2025-05-30 13:56:13,449 - INFO - Epoch [3/30] Batch [1640/4715] Loss: 0.7250\n",
      "2025-05-30 13:56:14,998 - INFO - Epoch [3/30] Batch [1650/4715] Loss: 0.8926\n",
      "2025-05-30 13:56:16,541 - INFO - Epoch [3/30] Batch [1660/4715] Loss: 0.8933\n",
      "2025-05-30 13:56:18,060 - INFO - Epoch [3/30] Batch [1670/4715] Loss: 0.9962\n",
      "2025-05-30 13:56:19,604 - INFO - Epoch [3/30] Batch [1680/4715] Loss: 0.7905\n",
      "2025-05-30 13:56:21,186 - INFO - Epoch [3/30] Batch [1690/4715] Loss: 0.9437\n",
      "2025-05-30 13:56:22,769 - INFO - Epoch [3/30] Batch [1700/4715] Loss: 0.9124\n",
      "2025-05-30 13:56:24,298 - INFO - Epoch [3/30] Batch [1710/4715] Loss: 0.8535\n",
      "2025-05-30 13:56:26,041 - INFO - Epoch [3/30] Batch [1720/4715] Loss: 0.7795\n",
      "2025-05-30 13:56:27,739 - INFO - Epoch [3/30] Batch [1730/4715] Loss: 0.7751\n",
      "2025-05-30 13:56:29,518 - INFO - Epoch [3/30] Batch [1740/4715] Loss: 1.0785\n",
      "2025-05-30 13:56:31,135 - INFO - Epoch [3/30] Batch [1750/4715] Loss: 0.8233\n",
      "2025-05-30 13:56:32,705 - INFO - Epoch [3/30] Batch [1760/4715] Loss: 1.0917\n",
      "2025-05-30 13:56:34,304 - INFO - Epoch [3/30] Batch [1770/4715] Loss: 0.9838\n",
      "2025-05-30 13:56:35,904 - INFO - Epoch [3/30] Batch [1780/4715] Loss: 0.9906\n",
      "2025-05-30 13:56:37,466 - INFO - Epoch [3/30] Batch [1790/4715] Loss: 0.8263\n",
      "2025-05-30 13:56:39,091 - INFO - Epoch [3/30] Batch [1800/4715] Loss: 0.7827\n",
      "2025-05-30 13:56:40,654 - INFO - Epoch [3/30] Batch [1810/4715] Loss: 0.8672\n",
      "2025-05-30 13:56:42,196 - INFO - Epoch [3/30] Batch [1820/4715] Loss: 0.8915\n",
      "2025-05-30 13:56:43,745 - INFO - Epoch [3/30] Batch [1830/4715] Loss: 0.9216\n",
      "2025-05-30 13:56:45,364 - INFO - Epoch [3/30] Batch [1840/4715] Loss: 0.6587\n",
      "2025-05-30 13:56:46,974 - INFO - Epoch [3/30] Batch [1850/4715] Loss: 0.9773\n",
      "2025-05-30 13:56:48,593 - INFO - Epoch [3/30] Batch [1860/4715] Loss: 0.7258\n",
      "2025-05-30 13:56:50,223 - INFO - Epoch [3/30] Batch [1870/4715] Loss: 0.9140\n",
      "2025-05-30 13:56:51,704 - INFO - Epoch [3/30] Batch [1880/4715] Loss: 1.0233\n",
      "2025-05-30 13:56:53,253 - INFO - Epoch [3/30] Batch [1890/4715] Loss: 0.8419\n",
      "2025-05-30 13:56:54,839 - INFO - Epoch [3/30] Batch [1900/4715] Loss: 1.0876\n",
      "2025-05-30 13:56:56,351 - INFO - Epoch [3/30] Batch [1910/4715] Loss: 1.0768\n",
      "2025-05-30 13:56:57,907 - INFO - Epoch [3/30] Batch [1920/4715] Loss: 0.8379\n",
      "2025-05-30 13:56:59,400 - INFO - Epoch [3/30] Batch [1930/4715] Loss: 0.8216\n",
      "2025-05-30 13:57:00,969 - INFO - Epoch [3/30] Batch [1940/4715] Loss: 1.1787\n",
      "2025-05-30 13:57:02,567 - INFO - Epoch [3/30] Batch [1950/4715] Loss: 0.8230\n",
      "2025-05-30 13:57:04,146 - INFO - Epoch [3/30] Batch [1960/4715] Loss: 0.8418\n",
      "2025-05-30 13:57:05,719 - INFO - Epoch [3/30] Batch [1970/4715] Loss: 0.9430\n",
      "2025-05-30 13:57:07,286 - INFO - Epoch [3/30] Batch [1980/4715] Loss: 0.7729\n",
      "2025-05-30 13:57:08,797 - INFO - Epoch [3/30] Batch [1990/4715] Loss: 1.0281\n",
      "2025-05-30 13:57:10,354 - INFO - Epoch [3/30] Batch [2000/4715] Loss: 0.8626\n",
      "2025-05-30 13:57:11,874 - INFO - Epoch [3/30] Batch [2010/4715] Loss: 0.8670\n",
      "2025-05-30 13:57:13,429 - INFO - Epoch [3/30] Batch [2020/4715] Loss: 0.7786\n",
      "2025-05-30 13:57:14,981 - INFO - Epoch [3/30] Batch [2030/4715] Loss: 1.0016\n",
      "2025-05-30 13:57:16,558 - INFO - Epoch [3/30] Batch [2040/4715] Loss: 0.9953\n",
      "2025-05-30 13:57:18,181 - INFO - Epoch [3/30] Batch [2050/4715] Loss: 1.0763\n",
      "2025-05-30 13:57:19,771 - INFO - Epoch [3/30] Batch [2060/4715] Loss: 0.8000\n",
      "2025-05-30 13:57:21,388 - INFO - Epoch [3/30] Batch [2070/4715] Loss: 0.7882\n",
      "2025-05-30 13:57:22,944 - INFO - Epoch [3/30] Batch [2080/4715] Loss: 0.9280\n",
      "2025-05-30 13:57:24,494 - INFO - Epoch [3/30] Batch [2090/4715] Loss: 0.9341\n",
      "2025-05-30 13:57:26,070 - INFO - Epoch [3/30] Batch [2100/4715] Loss: 0.9293\n",
      "2025-05-30 13:57:27,656 - INFO - Epoch [3/30] Batch [2110/4715] Loss: 0.8954\n",
      "2025-05-30 13:57:29,223 - INFO - Epoch [3/30] Batch [2120/4715] Loss: 0.9377\n",
      "2025-05-30 13:57:30,828 - INFO - Epoch [3/30] Batch [2130/4715] Loss: 0.9009\n",
      "2025-05-30 13:57:32,364 - INFO - Epoch [3/30] Batch [2140/4715] Loss: 0.9510\n",
      "2025-05-30 13:57:33,914 - INFO - Epoch [3/30] Batch [2150/4715] Loss: 0.9559\n",
      "2025-05-30 13:57:35,453 - INFO - Epoch [3/30] Batch [2160/4715] Loss: 0.8264\n",
      "2025-05-30 13:57:37,018 - INFO - Epoch [3/30] Batch [2170/4715] Loss: 0.8869\n",
      "2025-05-30 13:57:38,565 - INFO - Epoch [3/30] Batch [2180/4715] Loss: 0.7117\n",
      "2025-05-30 13:57:40,093 - INFO - Epoch [3/30] Batch [2190/4715] Loss: 0.7140\n",
      "2025-05-30 13:57:41,625 - INFO - Epoch [3/30] Batch [2200/4715] Loss: 1.0874\n",
      "2025-05-30 13:57:43,121 - INFO - Epoch [3/30] Batch [2210/4715] Loss: 0.9012\n",
      "2025-05-30 13:57:44,670 - INFO - Epoch [3/30] Batch [2220/4715] Loss: 1.0445\n",
      "2025-05-30 13:57:46,226 - INFO - Epoch [3/30] Batch [2230/4715] Loss: 0.7861\n",
      "2025-05-30 13:57:47,839 - INFO - Epoch [3/30] Batch [2240/4715] Loss: 0.7707\n",
      "2025-05-30 13:57:49,488 - INFO - Epoch [3/30] Batch [2250/4715] Loss: 1.0177\n",
      "2025-05-30 13:57:51,108 - INFO - Epoch [3/30] Batch [2260/4715] Loss: 0.8547\n",
      "2025-05-30 13:57:52,706 - INFO - Epoch [3/30] Batch [2270/4715] Loss: 0.9406\n",
      "2025-05-30 13:57:54,260 - INFO - Epoch [3/30] Batch [2280/4715] Loss: 0.7564\n",
      "2025-05-30 13:57:55,769 - INFO - Epoch [3/30] Batch [2290/4715] Loss: 0.7894\n",
      "2025-05-30 13:57:57,373 - INFO - Epoch [3/30] Batch [2300/4715] Loss: 1.0316\n",
      "2025-05-30 13:57:58,929 - INFO - Epoch [3/30] Batch [2310/4715] Loss: 0.8975\n",
      "2025-05-30 13:58:00,411 - INFO - Epoch [3/30] Batch [2320/4715] Loss: 0.8592\n",
      "2025-05-30 13:58:01,929 - INFO - Epoch [3/30] Batch [2330/4715] Loss: 0.7553\n",
      "2025-05-30 13:58:03,475 - INFO - Epoch [3/30] Batch [2340/4715] Loss: 0.8003\n",
      "2025-05-30 13:58:04,992 - INFO - Epoch [3/30] Batch [2350/4715] Loss: 1.1413\n",
      "2025-05-30 13:58:06,635 - INFO - Epoch [3/30] Batch [2360/4715] Loss: 0.8513\n",
      "2025-05-30 13:58:08,159 - INFO - Epoch [3/30] Batch [2370/4715] Loss: 0.9003\n",
      "2025-05-30 13:58:09,834 - INFO - Epoch [3/30] Batch [2380/4715] Loss: 0.8116\n",
      "2025-05-30 13:58:11,367 - INFO - Epoch [3/30] Batch [2390/4715] Loss: 1.0641\n",
      "2025-05-30 13:58:12,958 - INFO - Epoch [3/30] Batch [2400/4715] Loss: 0.8887\n",
      "2025-05-30 13:58:14,577 - INFO - Epoch [3/30] Batch [2410/4715] Loss: 0.8772\n",
      "2025-05-30 13:58:16,141 - INFO - Epoch [3/30] Batch [2420/4715] Loss: 0.7019\n",
      "2025-05-30 13:58:17,683 - INFO - Epoch [3/30] Batch [2430/4715] Loss: 0.8946\n",
      "2025-05-30 13:58:19,286 - INFO - Epoch [3/30] Batch [2440/4715] Loss: 0.7445\n",
      "2025-05-30 13:58:20,807 - INFO - Epoch [3/30] Batch [2450/4715] Loss: 1.1749\n",
      "2025-05-30 13:58:22,400 - INFO - Epoch [3/30] Batch [2460/4715] Loss: 0.8882\n",
      "2025-05-30 13:58:24,060 - INFO - Epoch [3/30] Batch [2470/4715] Loss: 0.6550\n",
      "2025-05-30 13:58:25,641 - INFO - Epoch [3/30] Batch [2480/4715] Loss: 1.0299\n",
      "2025-05-30 13:58:27,259 - INFO - Epoch [3/30] Batch [2490/4715] Loss: 0.8234\n",
      "2025-05-30 13:58:28,815 - INFO - Epoch [3/30] Batch [2500/4715] Loss: 0.8245\n",
      "2025-05-30 13:58:30,419 - INFO - Epoch [3/30] Batch [2510/4715] Loss: 0.7899\n",
      "2025-05-30 13:58:31,963 - INFO - Epoch [3/30] Batch [2520/4715] Loss: 1.0348\n",
      "2025-05-30 13:58:33,566 - INFO - Epoch [3/30] Batch [2530/4715] Loss: 0.8818\n",
      "2025-05-30 13:58:35,096 - INFO - Epoch [3/30] Batch [2540/4715] Loss: 0.6471\n",
      "2025-05-30 13:58:36,677 - INFO - Epoch [3/30] Batch [2550/4715] Loss: 0.7678\n",
      "2025-05-30 13:58:38,244 - INFO - Epoch [3/30] Batch [2560/4715] Loss: 0.7735\n",
      "2025-05-30 13:58:39,821 - INFO - Epoch [3/30] Batch [2570/4715] Loss: 0.7783\n",
      "2025-05-30 13:58:41,344 - INFO - Epoch [3/30] Batch [2580/4715] Loss: 0.9331\n",
      "2025-05-30 13:58:42,908 - INFO - Epoch [3/30] Batch [2590/4715] Loss: 0.7749\n",
      "2025-05-30 13:58:44,525 - INFO - Epoch [3/30] Batch [2600/4715] Loss: 0.9281\n",
      "2025-05-30 13:58:46,123 - INFO - Epoch [3/30] Batch [2610/4715] Loss: 0.6177\n",
      "2025-05-30 13:58:47,644 - INFO - Epoch [3/30] Batch [2620/4715] Loss: 0.9566\n",
      "2025-05-30 13:58:49,205 - INFO - Epoch [3/30] Batch [2630/4715] Loss: 0.7909\n",
      "2025-05-30 13:58:50,777 - INFO - Epoch [3/30] Batch [2640/4715] Loss: 0.8756\n",
      "2025-05-30 13:58:52,383 - INFO - Epoch [3/30] Batch [2650/4715] Loss: 1.1996\n",
      "2025-05-30 13:58:53,905 - INFO - Epoch [3/30] Batch [2660/4715] Loss: 1.0708\n",
      "2025-05-30 13:58:55,409 - INFO - Epoch [3/30] Batch [2670/4715] Loss: 0.7746\n",
      "2025-05-30 13:58:57,041 - INFO - Epoch [3/30] Batch [2680/4715] Loss: 0.9266\n",
      "2025-05-30 13:58:58,597 - INFO - Epoch [3/30] Batch [2690/4715] Loss: 0.6386\n",
      "2025-05-30 13:59:00,167 - INFO - Epoch [3/30] Batch [2700/4715] Loss: 0.6971\n",
      "2025-05-30 13:59:01,764 - INFO - Epoch [3/30] Batch [2710/4715] Loss: 0.5824\n",
      "2025-05-30 13:59:03,348 - INFO - Epoch [3/30] Batch [2720/4715] Loss: 0.9670\n",
      "2025-05-30 13:59:04,921 - INFO - Epoch [3/30] Batch [2730/4715] Loss: 0.9766\n",
      "2025-05-30 13:59:06,439 - INFO - Epoch [3/30] Batch [2740/4715] Loss: 0.8916\n",
      "2025-05-30 13:59:07,994 - INFO - Epoch [3/30] Batch [2750/4715] Loss: 0.8949\n",
      "2025-05-30 13:59:09,503 - INFO - Epoch [3/30] Batch [2760/4715] Loss: 1.0154\n",
      "2025-05-30 13:59:11,126 - INFO - Epoch [3/30] Batch [2770/4715] Loss: 0.7287\n",
      "2025-05-30 13:59:12,572 - INFO - Epoch [3/30] Batch [2780/4715] Loss: 0.8025\n",
      "2025-05-30 13:59:14,187 - INFO - Epoch [3/30] Batch [2790/4715] Loss: 0.9014\n",
      "2025-05-30 13:59:15,745 - INFO - Epoch [3/30] Batch [2800/4715] Loss: 0.9578\n",
      "2025-05-30 13:59:17,301 - INFO - Epoch [3/30] Batch [2810/4715] Loss: 0.9144\n",
      "2025-05-30 13:59:18,859 - INFO - Epoch [3/30] Batch [2820/4715] Loss: 1.0706\n",
      "2025-05-30 13:59:20,421 - INFO - Epoch [3/30] Batch [2830/4715] Loss: 1.0113\n",
      "2025-05-30 13:59:21,906 - INFO - Epoch [3/30] Batch [2840/4715] Loss: 0.8692\n",
      "2025-05-30 13:59:23,518 - INFO - Epoch [3/30] Batch [2850/4715] Loss: 0.9337\n",
      "2025-05-30 13:59:25,184 - INFO - Epoch [3/30] Batch [2860/4715] Loss: 0.9374\n",
      "2025-05-30 13:59:26,734 - INFO - Epoch [3/30] Batch [2870/4715] Loss: 1.1656\n",
      "2025-05-30 13:59:28,275 - INFO - Epoch [3/30] Batch [2880/4715] Loss: 0.8529\n",
      "2025-05-30 13:59:29,796 - INFO - Epoch [3/30] Batch [2890/4715] Loss: 0.6214\n",
      "2025-05-30 13:59:31,324 - INFO - Epoch [3/30] Batch [2900/4715] Loss: 0.8538\n",
      "2025-05-30 13:59:32,857 - INFO - Epoch [3/30] Batch [2910/4715] Loss: 0.9980\n",
      "2025-05-30 13:59:34,513 - INFO - Epoch [3/30] Batch [2920/4715] Loss: 1.0004\n",
      "2025-05-30 13:59:36,151 - INFO - Epoch [3/30] Batch [2930/4715] Loss: 1.0079\n",
      "2025-05-30 13:59:37,665 - INFO - Epoch [3/30] Batch [2940/4715] Loss: 0.8612\n",
      "2025-05-30 13:59:39,297 - INFO - Epoch [3/30] Batch [2950/4715] Loss: 0.7637\n",
      "2025-05-30 13:59:40,888 - INFO - Epoch [3/30] Batch [2960/4715] Loss: 0.7271\n",
      "2025-05-30 13:59:42,451 - INFO - Epoch [3/30] Batch [2970/4715] Loss: 0.7293\n",
      "2025-05-30 13:59:44,024 - INFO - Epoch [3/30] Batch [2980/4715] Loss: 0.8964\n",
      "2025-05-30 13:59:45,662 - INFO - Epoch [3/30] Batch [2990/4715] Loss: 0.9628\n",
      "2025-05-30 13:59:47,298 - INFO - Epoch [3/30] Batch [3000/4715] Loss: 1.1435\n",
      "2025-05-30 13:59:48,836 - INFO - Epoch [3/30] Batch [3010/4715] Loss: 0.8763\n",
      "2025-05-30 13:59:50,528 - INFO - Epoch [3/30] Batch [3020/4715] Loss: 0.9279\n",
      "2025-05-30 13:59:52,087 - INFO - Epoch [3/30] Batch [3030/4715] Loss: 0.9450\n",
      "2025-05-30 13:59:53,723 - INFO - Epoch [3/30] Batch [3040/4715] Loss: 0.8544\n",
      "2025-05-30 13:59:55,252 - INFO - Epoch [3/30] Batch [3050/4715] Loss: 1.0212\n",
      "2025-05-30 13:59:56,824 - INFO - Epoch [3/30] Batch [3060/4715] Loss: 0.7192\n",
      "2025-05-30 13:59:58,439 - INFO - Epoch [3/30] Batch [3070/4715] Loss: 0.8560\n",
      "2025-05-30 13:59:59,988 - INFO - Epoch [3/30] Batch [3080/4715] Loss: 0.7601\n",
      "2025-05-30 14:00:01,619 - INFO - Epoch [3/30] Batch [3090/4715] Loss: 0.7760\n",
      "2025-05-30 14:00:03,264 - INFO - Epoch [3/30] Batch [3100/4715] Loss: 0.9930\n",
      "2025-05-30 14:00:04,942 - INFO - Epoch [3/30] Batch [3110/4715] Loss: 0.7936\n",
      "2025-05-30 14:00:06,565 - INFO - Epoch [3/30] Batch [3120/4715] Loss: 0.8763\n",
      "2025-05-30 14:00:08,125 - INFO - Epoch [3/30] Batch [3130/4715] Loss: 0.7005\n",
      "2025-05-30 14:00:09,783 - INFO - Epoch [3/30] Batch [3140/4715] Loss: 0.7925\n",
      "2025-05-30 14:00:11,364 - INFO - Epoch [3/30] Batch [3150/4715] Loss: 0.7596\n",
      "2025-05-30 14:00:12,906 - INFO - Epoch [3/30] Batch [3160/4715] Loss: 0.9455\n",
      "2025-05-30 14:00:14,522 - INFO - Epoch [3/30] Batch [3170/4715] Loss: 0.8518\n",
      "2025-05-30 14:00:16,094 - INFO - Epoch [3/30] Batch [3180/4715] Loss: 0.9833\n",
      "2025-05-30 14:00:17,671 - INFO - Epoch [3/30] Batch [3190/4715] Loss: 0.8321\n",
      "2025-05-30 14:00:19,247 - INFO - Epoch [3/30] Batch [3200/4715] Loss: 0.7338\n",
      "2025-05-30 14:00:20,845 - INFO - Epoch [3/30] Batch [3210/4715] Loss: 0.8271\n",
      "2025-05-30 14:00:22,477 - INFO - Epoch [3/30] Batch [3220/4715] Loss: 1.1529\n",
      "2025-05-30 14:00:24,059 - INFO - Epoch [3/30] Batch [3230/4715] Loss: 0.8211\n",
      "2025-05-30 14:00:25,596 - INFO - Epoch [3/30] Batch [3240/4715] Loss: 0.9637\n",
      "2025-05-30 14:00:27,193 - INFO - Epoch [3/30] Batch [3250/4715] Loss: 0.7169\n",
      "2025-05-30 14:00:28,787 - INFO - Epoch [3/30] Batch [3260/4715] Loss: 0.9490\n",
      "2025-05-30 14:00:30,338 - INFO - Epoch [3/30] Batch [3270/4715] Loss: 0.8107\n",
      "2025-05-30 14:00:31,923 - INFO - Epoch [3/30] Batch [3280/4715] Loss: 0.8937\n",
      "2025-05-30 14:00:33,611 - INFO - Epoch [3/30] Batch [3290/4715] Loss: 0.7865\n",
      "2025-05-30 14:00:35,166 - INFO - Epoch [3/30] Batch [3300/4715] Loss: 0.9031\n",
      "2025-05-30 14:00:36,662 - INFO - Epoch [3/30] Batch [3310/4715] Loss: 0.8610\n",
      "2025-05-30 14:00:38,258 - INFO - Epoch [3/30] Batch [3320/4715] Loss: 0.7616\n",
      "2025-05-30 14:00:39,785 - INFO - Epoch [3/30] Batch [3330/4715] Loss: 0.9132\n",
      "2025-05-30 14:00:41,335 - INFO - Epoch [3/30] Batch [3340/4715] Loss: 0.9150\n",
      "2025-05-30 14:00:42,966 - INFO - Epoch [3/30] Batch [3350/4715] Loss: 0.8911\n",
      "2025-05-30 14:00:44,473 - INFO - Epoch [3/30] Batch [3360/4715] Loss: 0.8427\n",
      "2025-05-30 14:00:46,065 - INFO - Epoch [3/30] Batch [3370/4715] Loss: 0.8831\n",
      "2025-05-30 14:00:47,647 - INFO - Epoch [3/30] Batch [3380/4715] Loss: 0.8922\n",
      "2025-05-30 14:00:49,284 - INFO - Epoch [3/30] Batch [3390/4715] Loss: 0.6925\n",
      "2025-05-30 14:00:50,912 - INFO - Epoch [3/30] Batch [3400/4715] Loss: 0.8613\n",
      "2025-05-30 14:00:52,507 - INFO - Epoch [3/30] Batch [3410/4715] Loss: 0.9226\n",
      "2025-05-30 14:00:54,046 - INFO - Epoch [3/30] Batch [3420/4715] Loss: 0.8825\n",
      "2025-05-30 14:00:55,627 - INFO - Epoch [3/30] Batch [3430/4715] Loss: 0.8421\n",
      "2025-05-30 14:00:57,240 - INFO - Epoch [3/30] Batch [3440/4715] Loss: 0.7628\n",
      "2025-05-30 14:00:58,767 - INFO - Epoch [3/30] Batch [3450/4715] Loss: 0.8434\n",
      "2025-05-30 14:01:00,350 - INFO - Epoch [3/30] Batch [3460/4715] Loss: 0.6656\n",
      "2025-05-30 14:01:01,969 - INFO - Epoch [3/30] Batch [3470/4715] Loss: 0.6994\n",
      "2025-05-30 14:01:03,561 - INFO - Epoch [3/30] Batch [3480/4715] Loss: 1.1745\n",
      "2025-05-30 14:01:05,138 - INFO - Epoch [3/30] Batch [3490/4715] Loss: 0.8990\n",
      "2025-05-30 14:01:06,733 - INFO - Epoch [3/30] Batch [3500/4715] Loss: 0.7192\n",
      "2025-05-30 14:01:08,222 - INFO - Epoch [3/30] Batch [3510/4715] Loss: 0.7362\n",
      "2025-05-30 14:01:09,824 - INFO - Epoch [3/30] Batch [3520/4715] Loss: 1.1391\n",
      "2025-05-30 14:01:11,428 - INFO - Epoch [3/30] Batch [3530/4715] Loss: 0.7330\n",
      "2025-05-30 14:01:12,968 - INFO - Epoch [3/30] Batch [3540/4715] Loss: 0.7198\n",
      "2025-05-30 14:01:14,505 - INFO - Epoch [3/30] Batch [3550/4715] Loss: 0.9480\n",
      "2025-05-30 14:01:16,117 - INFO - Epoch [3/30] Batch [3560/4715] Loss: 0.8376\n",
      "2025-05-30 14:01:17,672 - INFO - Epoch [3/30] Batch [3570/4715] Loss: 0.6728\n",
      "2025-05-30 14:01:19,277 - INFO - Epoch [3/30] Batch [3580/4715] Loss: 0.8930\n",
      "2025-05-30 14:01:20,866 - INFO - Epoch [3/30] Batch [3590/4715] Loss: 0.8371\n",
      "2025-05-30 14:01:22,438 - INFO - Epoch [3/30] Batch [3600/4715] Loss: 0.8371\n",
      "2025-05-30 14:01:24,018 - INFO - Epoch [3/30] Batch [3610/4715] Loss: 0.6073\n",
      "2025-05-30 14:01:25,620 - INFO - Epoch [3/30] Batch [3620/4715] Loss: 0.8891\n",
      "2025-05-30 14:01:27,169 - INFO - Epoch [3/30] Batch [3630/4715] Loss: 1.1097\n",
      "2025-05-30 14:01:28,758 - INFO - Epoch [3/30] Batch [3640/4715] Loss: 0.7775\n",
      "2025-05-30 14:01:30,263 - INFO - Epoch [3/30] Batch [3650/4715] Loss: 0.8769\n",
      "2025-05-30 14:01:31,819 - INFO - Epoch [3/30] Batch [3660/4715] Loss: 0.9181\n",
      "2025-05-30 14:01:33,453 - INFO - Epoch [3/30] Batch [3670/4715] Loss: 0.8271\n",
      "2025-05-30 14:01:34,987 - INFO - Epoch [3/30] Batch [3680/4715] Loss: 0.7467\n",
      "2025-05-30 14:01:36,599 - INFO - Epoch [3/30] Batch [3690/4715] Loss: 0.8631\n",
      "2025-05-30 14:01:38,116 - INFO - Epoch [3/30] Batch [3700/4715] Loss: 1.0665\n",
      "2025-05-30 14:01:39,675 - INFO - Epoch [3/30] Batch [3710/4715] Loss: 0.7750\n",
      "2025-05-30 14:01:41,234 - INFO - Epoch [3/30] Batch [3720/4715] Loss: 0.8920\n",
      "2025-05-30 14:01:42,719 - INFO - Epoch [3/30] Batch [3730/4715] Loss: 0.7498\n",
      "2025-05-30 14:01:44,260 - INFO - Epoch [3/30] Batch [3740/4715] Loss: 0.8686\n",
      "2025-05-30 14:01:45,829 - INFO - Epoch [3/30] Batch [3750/4715] Loss: 0.9518\n",
      "2025-05-30 14:01:47,489 - INFO - Epoch [3/30] Batch [3760/4715] Loss: 0.8565\n",
      "2025-05-30 14:01:49,084 - INFO - Epoch [3/30] Batch [3770/4715] Loss: 0.8426\n",
      "2025-05-30 14:01:50,627 - INFO - Epoch [3/30] Batch [3780/4715] Loss: 0.9832\n",
      "2025-05-30 14:01:52,295 - INFO - Epoch [3/30] Batch [3790/4715] Loss: 0.9783\n",
      "2025-05-30 14:01:53,905 - INFO - Epoch [3/30] Batch [3800/4715] Loss: 0.9053\n",
      "2025-05-30 14:01:55,442 - INFO - Epoch [3/30] Batch [3810/4715] Loss: 1.2012\n",
      "2025-05-30 14:01:57,015 - INFO - Epoch [3/30] Batch [3820/4715] Loss: 0.9709\n",
      "2025-05-30 14:01:58,650 - INFO - Epoch [3/30] Batch [3830/4715] Loss: 0.9646\n",
      "2025-05-30 14:02:00,283 - INFO - Epoch [3/30] Batch [3840/4715] Loss: 1.0034\n",
      "2025-05-30 14:02:01,866 - INFO - Epoch [3/30] Batch [3850/4715] Loss: 1.0075\n",
      "2025-05-30 14:02:03,345 - INFO - Epoch [3/30] Batch [3860/4715] Loss: 1.0079\n",
      "2025-05-30 14:02:04,908 - INFO - Epoch [3/30] Batch [3870/4715] Loss: 0.7292\n",
      "2025-05-30 14:02:06,464 - INFO - Epoch [3/30] Batch [3880/4715] Loss: 1.0867\n",
      "2025-05-30 14:02:08,075 - INFO - Epoch [3/30] Batch [3890/4715] Loss: 1.0027\n",
      "2025-05-30 14:02:09,635 - INFO - Epoch [3/30] Batch [3900/4715] Loss: 1.2729\n",
      "2025-05-30 14:02:11,173 - INFO - Epoch [3/30] Batch [3910/4715] Loss: 0.9123\n",
      "2025-05-30 14:02:12,823 - INFO - Epoch [3/30] Batch [3920/4715] Loss: 0.8776\n",
      "2025-05-30 14:02:14,423 - INFO - Epoch [3/30] Batch [3930/4715] Loss: 0.7637\n",
      "2025-05-30 14:02:16,058 - INFO - Epoch [3/30] Batch [3940/4715] Loss: 0.8677\n",
      "2025-05-30 14:02:17,682 - INFO - Epoch [3/30] Batch [3950/4715] Loss: 0.7929\n",
      "2025-05-30 14:02:19,188 - INFO - Epoch [3/30] Batch [3960/4715] Loss: 0.7356\n",
      "2025-05-30 14:02:20,792 - INFO - Epoch [3/30] Batch [3970/4715] Loss: 1.0903\n",
      "2025-05-30 14:02:22,411 - INFO - Epoch [3/30] Batch [3980/4715] Loss: 0.8913\n",
      "2025-05-30 14:02:24,017 - INFO - Epoch [3/30] Batch [3990/4715] Loss: 0.8973\n",
      "2025-05-30 14:02:25,585 - INFO - Epoch [3/30] Batch [4000/4715] Loss: 1.0435\n",
      "2025-05-30 14:02:27,101 - INFO - Epoch [3/30] Batch [4010/4715] Loss: 0.9745\n",
      "2025-05-30 14:02:28,668 - INFO - Epoch [3/30] Batch [4020/4715] Loss: 0.7462\n",
      "2025-05-30 14:02:30,238 - INFO - Epoch [3/30] Batch [4030/4715] Loss: 0.9699\n",
      "2025-05-30 14:02:31,808 - INFO - Epoch [3/30] Batch [4040/4715] Loss: 0.7827\n",
      "2025-05-30 14:02:33,370 - INFO - Epoch [3/30] Batch [4050/4715] Loss: 0.6963\n",
      "2025-05-30 14:02:34,925 - INFO - Epoch [3/30] Batch [4060/4715] Loss: 0.6889\n",
      "2025-05-30 14:02:36,466 - INFO - Epoch [3/30] Batch [4070/4715] Loss: 1.1473\n",
      "2025-05-30 14:02:38,045 - INFO - Epoch [3/30] Batch [4080/4715] Loss: 0.8281\n",
      "2025-05-30 14:02:39,642 - INFO - Epoch [3/30] Batch [4090/4715] Loss: 0.8753\n",
      "2025-05-30 14:02:41,198 - INFO - Epoch [3/30] Batch [4100/4715] Loss: 0.8491\n",
      "2025-05-30 14:02:42,722 - INFO - Epoch [3/30] Batch [4110/4715] Loss: 0.7989\n",
      "2025-05-30 14:02:44,339 - INFO - Epoch [3/30] Batch [4120/4715] Loss: 0.8001\n",
      "2025-05-30 14:02:45,903 - INFO - Epoch [3/30] Batch [4130/4715] Loss: 1.0444\n",
      "2025-05-30 14:02:47,525 - INFO - Epoch [3/30] Batch [4140/4715] Loss: 0.6912\n",
      "2025-05-30 14:02:49,074 - INFO - Epoch [3/30] Batch [4150/4715] Loss: 0.8081\n",
      "2025-05-30 14:02:50,727 - INFO - Epoch [3/30] Batch [4160/4715] Loss: 0.9517\n",
      "2025-05-30 14:02:52,339 - INFO - Epoch [3/30] Batch [4170/4715] Loss: 0.9095\n",
      "2025-05-30 14:02:53,942 - INFO - Epoch [3/30] Batch [4180/4715] Loss: 1.0792\n",
      "2025-05-30 14:02:55,478 - INFO - Epoch [3/30] Batch [4190/4715] Loss: 0.8271\n",
      "2025-05-30 14:02:57,110 - INFO - Epoch [3/30] Batch [4200/4715] Loss: 1.0800\n",
      "2025-05-30 14:02:58,693 - INFO - Epoch [3/30] Batch [4210/4715] Loss: 0.8842\n",
      "2025-05-30 14:03:00,338 - INFO - Epoch [3/30] Batch [4220/4715] Loss: 0.8273\n",
      "2025-05-30 14:03:01,944 - INFO - Epoch [3/30] Batch [4230/4715] Loss: 0.8795\n",
      "2025-05-30 14:03:03,505 - INFO - Epoch [3/30] Batch [4240/4715] Loss: 0.7402\n",
      "2025-05-30 14:03:05,118 - INFO - Epoch [3/30] Batch [4250/4715] Loss: 0.8628\n",
      "2025-05-30 14:03:06,709 - INFO - Epoch [3/30] Batch [4260/4715] Loss: 0.7706\n",
      "2025-05-30 14:03:08,318 - INFO - Epoch [3/30] Batch [4270/4715] Loss: 0.7605\n",
      "2025-05-30 14:03:09,848 - INFO - Epoch [3/30] Batch [4280/4715] Loss: 0.8573\n",
      "2025-05-30 14:03:11,369 - INFO - Epoch [3/30] Batch [4290/4715] Loss: 0.9907\n",
      "2025-05-30 14:03:13,078 - INFO - Epoch [3/30] Batch [4300/4715] Loss: 0.9442\n",
      "2025-05-30 14:03:14,578 - INFO - Epoch [3/30] Batch [4310/4715] Loss: 1.0141\n",
      "2025-05-30 14:03:16,189 - INFO - Epoch [3/30] Batch [4320/4715] Loss: 1.1105\n",
      "2025-05-30 14:03:17,745 - INFO - Epoch [3/30] Batch [4330/4715] Loss: 0.7974\n",
      "2025-05-30 14:03:19,384 - INFO - Epoch [3/30] Batch [4340/4715] Loss: 0.9476\n",
      "2025-05-30 14:03:20,967 - INFO - Epoch [3/30] Batch [4350/4715] Loss: 0.7862\n",
      "2025-05-30 14:03:22,447 - INFO - Epoch [3/30] Batch [4360/4715] Loss: 0.8356\n",
      "2025-05-30 14:03:24,044 - INFO - Epoch [3/30] Batch [4370/4715] Loss: 0.9361\n",
      "2025-05-30 14:03:25,565 - INFO - Epoch [3/30] Batch [4380/4715] Loss: 0.7163\n",
      "2025-05-30 14:03:27,169 - INFO - Epoch [3/30] Batch [4390/4715] Loss: 0.7414\n",
      "2025-05-30 14:03:28,670 - INFO - Epoch [3/30] Batch [4400/4715] Loss: 0.9060\n",
      "2025-05-30 14:03:30,223 - INFO - Epoch [3/30] Batch [4410/4715] Loss: 0.7655\n",
      "2025-05-30 14:03:31,893 - INFO - Epoch [3/30] Batch [4420/4715] Loss: 0.9199\n",
      "2025-05-30 14:03:33,414 - INFO - Epoch [3/30] Batch [4430/4715] Loss: 0.8516\n",
      "2025-05-30 14:03:34,949 - INFO - Epoch [3/30] Batch [4440/4715] Loss: 0.8277\n",
      "2025-05-30 14:03:36,555 - INFO - Epoch [3/30] Batch [4450/4715] Loss: 0.7006\n",
      "2025-05-30 14:03:38,164 - INFO - Epoch [3/30] Batch [4460/4715] Loss: 0.8517\n",
      "2025-05-30 14:03:39,741 - INFO - Epoch [3/30] Batch [4470/4715] Loss: 0.7659\n",
      "2025-05-30 14:03:41,311 - INFO - Epoch [3/30] Batch [4480/4715] Loss: 0.9095\n",
      "2025-05-30 14:03:42,866 - INFO - Epoch [3/30] Batch [4490/4715] Loss: 0.7023\n",
      "2025-05-30 14:03:44,367 - INFO - Epoch [3/30] Batch [4500/4715] Loss: 0.9168\n",
      "2025-05-30 14:03:45,908 - INFO - Epoch [3/30] Batch [4510/4715] Loss: 0.8460\n",
      "2025-05-30 14:03:47,443 - INFO - Epoch [3/30] Batch [4520/4715] Loss: 0.8050\n",
      "2025-05-30 14:03:49,067 - INFO - Epoch [3/30] Batch [4530/4715] Loss: 0.8980\n",
      "2025-05-30 14:03:50,564 - INFO - Epoch [3/30] Batch [4540/4715] Loss: 0.7931\n",
      "2025-05-30 14:03:52,097 - INFO - Epoch [3/30] Batch [4550/4715] Loss: 0.7423\n",
      "2025-05-30 14:03:53,681 - INFO - Epoch [3/30] Batch [4560/4715] Loss: 0.8249\n",
      "2025-05-30 14:03:55,320 - INFO - Epoch [3/30] Batch [4570/4715] Loss: 0.8795\n",
      "2025-05-30 14:03:57,063 - INFO - Epoch [3/30] Batch [4580/4715] Loss: 0.9469\n",
      "2025-05-30 14:03:58,665 - INFO - Epoch [3/30] Batch [4590/4715] Loss: 0.9209\n",
      "2025-05-30 14:04:00,390 - INFO - Epoch [3/30] Batch [4600/4715] Loss: 0.9842\n",
      "2025-05-30 14:04:02,039 - INFO - Epoch [3/30] Batch [4610/4715] Loss: 0.9067\n",
      "2025-05-30 14:04:03,570 - INFO - Epoch [3/30] Batch [4620/4715] Loss: 0.7329\n",
      "2025-05-30 14:04:05,147 - INFO - Epoch [3/30] Batch [4630/4715] Loss: 1.0939\n",
      "2025-05-30 14:04:06,761 - INFO - Epoch [3/30] Batch [4640/4715] Loss: 1.1420\n",
      "2025-05-30 14:04:08,323 - INFO - Epoch [3/30] Batch [4650/4715] Loss: 1.1162\n",
      "2025-05-30 14:04:09,863 - INFO - Epoch [3/30] Batch [4660/4715] Loss: 0.9453\n",
      "2025-05-30 14:04:11,359 - INFO - Epoch [3/30] Batch [4670/4715] Loss: 0.9585\n",
      "2025-05-30 14:04:12,850 - INFO - Epoch [3/30] Batch [4680/4715] Loss: 0.9691\n",
      "2025-05-30 14:04:14,392 - INFO - Epoch [3/30] Batch [4690/4715] Loss: 0.7036\n",
      "2025-05-30 14:04:16,036 - INFO - Epoch [3/30] Batch [4700/4715] Loss: 0.7535\n",
      "2025-05-30 14:04:17,587 - INFO - Epoch [3/30] Batch [4710/4715] Loss: 0.9856\n",
      "2025-05-30 14:04:56,377 - INFO - \n",
      "Epoch [3/30] Time: 782.28s\n",
      "2025-05-30 14:04:56,377 - INFO - Train Loss: 0.8779, Valid Loss: 0.8609\n",
      "2025-05-30 14:04:56,377 - INFO - Valid AUC (macro): 0.6923, F1 (macro): 0.5158\n",
      "2025-05-30 14:04:56,920 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\best_model.pth\n",
      "2025-05-30 14:04:56,922 - INFO - New best model saved with AUC: 0.6923\n",
      "2025-05-30 14:04:57,437 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 14:04:57,438 - INFO - Saved checkpoint at epoch 3\n",
      "2025-05-30 14:04:57,641 - INFO - Epoch [4/30] Batch [0/4715] Loss: 0.9910\n",
      "2025-05-30 14:04:59,391 - INFO - Epoch [4/30] Batch [10/4715] Loss: 0.9516\n",
      "2025-05-30 14:05:00,995 - INFO - Epoch [4/30] Batch [20/4715] Loss: 1.0227\n",
      "2025-05-30 14:05:02,539 - INFO - Epoch [4/30] Batch [30/4715] Loss: 0.7354\n",
      "2025-05-30 14:05:04,031 - INFO - Epoch [4/30] Batch [40/4715] Loss: 0.7306\n",
      "2025-05-30 14:05:05,605 - INFO - Epoch [4/30] Batch [50/4715] Loss: 0.7249\n",
      "2025-05-30 14:05:07,246 - INFO - Epoch [4/30] Batch [60/4715] Loss: 0.7357\n",
      "2025-05-30 14:05:08,830 - INFO - Epoch [4/30] Batch [70/4715] Loss: 0.9195\n",
      "2025-05-30 14:05:10,436 - INFO - Epoch [4/30] Batch [80/4715] Loss: 0.7902\n",
      "2025-05-30 14:05:11,978 - INFO - Epoch [4/30] Batch [90/4715] Loss: 0.9338\n",
      "2025-05-30 14:05:13,517 - INFO - Epoch [4/30] Batch [100/4715] Loss: 0.9904\n",
      "2025-05-30 14:05:15,088 - INFO - Epoch [4/30] Batch [110/4715] Loss: 1.1250\n",
      "2025-05-30 14:05:16,671 - INFO - Epoch [4/30] Batch [120/4715] Loss: 0.9506\n",
      "2025-05-30 14:05:18,283 - INFO - Epoch [4/30] Batch [130/4715] Loss: 0.9158\n",
      "2025-05-30 14:05:19,859 - INFO - Epoch [4/30] Batch [140/4715] Loss: 0.8003\n",
      "2025-05-30 14:05:21,408 - INFO - Epoch [4/30] Batch [150/4715] Loss: 0.9416\n",
      "2025-05-30 14:05:22,971 - INFO - Epoch [4/30] Batch [160/4715] Loss: 0.8308\n",
      "2025-05-30 14:05:24,547 - INFO - Epoch [4/30] Batch [170/4715] Loss: 0.8427\n",
      "2025-05-30 14:05:26,108 - INFO - Epoch [4/30] Batch [180/4715] Loss: 0.8109\n",
      "2025-05-30 14:05:27,645 - INFO - Epoch [4/30] Batch [190/4715] Loss: 0.6629\n",
      "2025-05-30 14:05:29,277 - INFO - Epoch [4/30] Batch [200/4715] Loss: 0.7087\n",
      "2025-05-30 14:05:30,847 - INFO - Epoch [4/30] Batch [210/4715] Loss: 0.5142\n",
      "2025-05-30 14:05:32,384 - INFO - Epoch [4/30] Batch [220/4715] Loss: 0.6982\n",
      "2025-05-30 14:05:34,007 - INFO - Epoch [4/30] Batch [230/4715] Loss: 0.6587\n",
      "2025-05-30 14:05:35,625 - INFO - Epoch [4/30] Batch [240/4715] Loss: 0.9876\n",
      "2025-05-30 14:05:37,174 - INFO - Epoch [4/30] Batch [250/4715] Loss: 0.7407\n",
      "2025-05-30 14:05:38,792 - INFO - Epoch [4/30] Batch [260/4715] Loss: 0.8161\n",
      "2025-05-30 14:05:40,461 - INFO - Epoch [4/30] Batch [270/4715] Loss: 0.8633\n",
      "2025-05-30 14:05:41,904 - INFO - Epoch [4/30] Batch [280/4715] Loss: 0.8532\n",
      "2025-05-30 14:05:43,508 - INFO - Epoch [4/30] Batch [290/4715] Loss: 0.6365\n",
      "2025-05-30 14:05:45,023 - INFO - Epoch [4/30] Batch [300/4715] Loss: 0.6659\n",
      "2025-05-30 14:05:46,578 - INFO - Epoch [4/30] Batch [310/4715] Loss: 0.7418\n",
      "2025-05-30 14:05:48,233 - INFO - Epoch [4/30] Batch [320/4715] Loss: 0.8660\n",
      "2025-05-30 14:05:49,924 - INFO - Epoch [4/30] Batch [330/4715] Loss: 0.8585\n",
      "2025-05-30 14:05:51,465 - INFO - Epoch [4/30] Batch [340/4715] Loss: 0.7513\n",
      "2025-05-30 14:05:53,012 - INFO - Epoch [4/30] Batch [350/4715] Loss: 0.7468\n",
      "2025-05-30 14:05:54,572 - INFO - Epoch [4/30] Batch [360/4715] Loss: 0.8008\n",
      "2025-05-30 14:05:56,212 - INFO - Epoch [4/30] Batch [370/4715] Loss: 0.8242\n",
      "2025-05-30 14:05:57,746 - INFO - Epoch [4/30] Batch [380/4715] Loss: 0.9863\n",
      "2025-05-30 14:05:59,242 - INFO - Epoch [4/30] Batch [390/4715] Loss: 0.6879\n",
      "2025-05-30 14:06:00,786 - INFO - Epoch [4/30] Batch [400/4715] Loss: 0.9153\n",
      "2025-05-30 14:06:02,386 - INFO - Epoch [4/30] Batch [410/4715] Loss: 0.7955\n",
      "2025-05-30 14:06:03,969 - INFO - Epoch [4/30] Batch [420/4715] Loss: 0.9843\n",
      "2025-05-30 14:06:05,546 - INFO - Epoch [4/30] Batch [430/4715] Loss: 1.1914\n",
      "2025-05-30 14:06:07,141 - INFO - Epoch [4/30] Batch [440/4715] Loss: 0.8693\n",
      "2025-05-30 14:06:08,704 - INFO - Epoch [4/30] Batch [450/4715] Loss: 0.7923\n",
      "2025-05-30 14:06:10,269 - INFO - Epoch [4/30] Batch [460/4715] Loss: 0.8812\n",
      "2025-05-30 14:06:11,863 - INFO - Epoch [4/30] Batch [470/4715] Loss: 0.8332\n",
      "2025-05-30 14:06:13,525 - INFO - Epoch [4/30] Batch [480/4715] Loss: 0.9415\n",
      "2025-05-30 14:06:15,041 - INFO - Epoch [4/30] Batch [490/4715] Loss: 0.8227\n",
      "2025-05-30 14:06:16,527 - INFO - Epoch [4/30] Batch [500/4715] Loss: 0.9044\n",
      "2025-05-30 14:06:17,979 - INFO - Epoch [4/30] Batch [510/4715] Loss: 0.8212\n",
      "2025-05-30 14:06:19,503 - INFO - Epoch [4/30] Batch [520/4715] Loss: 1.0383\n",
      "2025-05-30 14:06:21,069 - INFO - Epoch [4/30] Batch [530/4715] Loss: 0.9815\n",
      "2025-05-30 14:06:22,646 - INFO - Epoch [4/30] Batch [540/4715] Loss: 1.0242\n",
      "2025-05-30 14:06:24,154 - INFO - Epoch [4/30] Batch [550/4715] Loss: 1.0815\n",
      "2025-05-30 14:06:25,695 - INFO - Epoch [4/30] Batch [560/4715] Loss: 0.7132\n",
      "2025-05-30 14:06:27,314 - INFO - Epoch [4/30] Batch [570/4715] Loss: 0.7636\n",
      "2025-05-30 14:06:28,956 - INFO - Epoch [4/30] Batch [580/4715] Loss: 0.7545\n",
      "2025-05-30 14:06:30,605 - INFO - Epoch [4/30] Batch [590/4715] Loss: 0.7878\n",
      "2025-05-30 14:06:32,175 - INFO - Epoch [4/30] Batch [600/4715] Loss: 0.9139\n",
      "2025-05-30 14:06:33,745 - INFO - Epoch [4/30] Batch [610/4715] Loss: 0.9601\n",
      "2025-05-30 14:06:35,296 - INFO - Epoch [4/30] Batch [620/4715] Loss: 0.8996\n",
      "2025-05-30 14:06:36,864 - INFO - Epoch [4/30] Batch [630/4715] Loss: 0.7948\n",
      "2025-05-30 14:06:38,414 - INFO - Epoch [4/30] Batch [640/4715] Loss: 0.7750\n",
      "2025-05-30 14:06:40,030 - INFO - Epoch [4/30] Batch [650/4715] Loss: 0.9839\n",
      "2025-05-30 14:06:41,649 - INFO - Epoch [4/30] Batch [660/4715] Loss: 1.0138\n",
      "2025-05-30 14:06:43,246 - INFO - Epoch [4/30] Batch [670/4715] Loss: 0.9456\n",
      "2025-05-30 14:06:44,841 - INFO - Epoch [4/30] Batch [680/4715] Loss: 0.7309\n",
      "2025-05-30 14:06:46,365 - INFO - Epoch [4/30] Batch [690/4715] Loss: 0.8344\n",
      "2025-05-30 14:06:47,966 - INFO - Epoch [4/30] Batch [700/4715] Loss: 0.8821\n",
      "2025-05-30 14:06:49,555 - INFO - Epoch [4/30] Batch [710/4715] Loss: 1.1142\n",
      "2025-05-30 14:06:51,150 - INFO - Epoch [4/30] Batch [720/4715] Loss: 0.9197\n",
      "2025-05-30 14:06:52,701 - INFO - Epoch [4/30] Batch [730/4715] Loss: 1.0146\n",
      "2025-05-30 14:06:54,206 - INFO - Epoch [4/30] Batch [740/4715] Loss: 0.7314\n",
      "2025-05-30 14:06:55,760 - INFO - Epoch [4/30] Batch [750/4715] Loss: 0.8962\n",
      "2025-05-30 14:06:57,331 - INFO - Epoch [4/30] Batch [760/4715] Loss: 0.7241\n",
      "2025-05-30 14:06:58,881 - INFO - Epoch [4/30] Batch [770/4715] Loss: 0.7040\n",
      "2025-05-30 14:07:00,470 - INFO - Epoch [4/30] Batch [780/4715] Loss: 0.9617\n",
      "2025-05-30 14:07:02,045 - INFO - Epoch [4/30] Batch [790/4715] Loss: 0.6669\n",
      "2025-05-30 14:07:03,596 - INFO - Epoch [4/30] Batch [800/4715] Loss: 0.7659\n",
      "2025-05-30 14:07:05,145 - INFO - Epoch [4/30] Batch [810/4715] Loss: 0.7461\n",
      "2025-05-30 14:07:06,719 - INFO - Epoch [4/30] Batch [820/4715] Loss: 0.8220\n",
      "2025-05-30 14:07:08,207 - INFO - Epoch [4/30] Batch [830/4715] Loss: 0.5823\n",
      "2025-05-30 14:07:09,877 - INFO - Epoch [4/30] Batch [840/4715] Loss: 0.8355\n",
      "2025-05-30 14:07:11,454 - INFO - Epoch [4/30] Batch [850/4715] Loss: 0.7807\n",
      "2025-05-30 14:07:13,062 - INFO - Epoch [4/30] Batch [860/4715] Loss: 0.7085\n",
      "2025-05-30 14:07:14,720 - INFO - Epoch [4/30] Batch [870/4715] Loss: 0.7749\n",
      "2025-05-30 14:07:16,251 - INFO - Epoch [4/30] Batch [880/4715] Loss: 0.7315\n",
      "2025-05-30 14:07:17,841 - INFO - Epoch [4/30] Batch [890/4715] Loss: 0.8256\n",
      "2025-05-30 14:07:19,515 - INFO - Epoch [4/30] Batch [900/4715] Loss: 0.7540\n",
      "2025-05-30 14:07:21,008 - INFO - Epoch [4/30] Batch [910/4715] Loss: 0.9951\n",
      "2025-05-30 14:07:22,592 - INFO - Epoch [4/30] Batch [920/4715] Loss: 0.7894\n",
      "2025-05-30 14:07:24,208 - INFO - Epoch [4/30] Batch [930/4715] Loss: 0.7955\n",
      "2025-05-30 14:07:25,739 - INFO - Epoch [4/30] Batch [940/4715] Loss: 1.0598\n",
      "2025-05-30 14:07:27,342 - INFO - Epoch [4/30] Batch [950/4715] Loss: 0.9056\n",
      "2025-05-30 14:07:28,967 - INFO - Epoch [4/30] Batch [960/4715] Loss: 0.7676\n",
      "2025-05-30 14:07:30,617 - INFO - Epoch [4/30] Batch [970/4715] Loss: 0.8925\n",
      "2025-05-30 14:07:32,165 - INFO - Epoch [4/30] Batch [980/4715] Loss: 0.9823\n",
      "2025-05-30 14:07:33,784 - INFO - Epoch [4/30] Batch [990/4715] Loss: 0.7659\n",
      "2025-05-30 14:07:35,427 - INFO - Epoch [4/30] Batch [1000/4715] Loss: 0.8267\n",
      "2025-05-30 14:07:37,087 - INFO - Epoch [4/30] Batch [1010/4715] Loss: 0.9965\n",
      "2025-05-30 14:07:38,691 - INFO - Epoch [4/30] Batch [1020/4715] Loss: 0.9144\n",
      "2025-05-30 14:07:40,199 - INFO - Epoch [4/30] Batch [1030/4715] Loss: 0.6323\n",
      "2025-05-30 14:07:41,775 - INFO - Epoch [4/30] Batch [1040/4715] Loss: 0.8906\n",
      "2025-05-30 14:07:43,326 - INFO - Epoch [4/30] Batch [1050/4715] Loss: 0.7323\n",
      "2025-05-30 14:07:45,005 - INFO - Epoch [4/30] Batch [1060/4715] Loss: 1.0506\n",
      "2025-05-30 14:07:46,671 - INFO - Epoch [4/30] Batch [1070/4715] Loss: 0.7975\n",
      "2025-05-30 14:07:48,164 - INFO - Epoch [4/30] Batch [1080/4715] Loss: 0.8785\n",
      "2025-05-30 14:07:49,706 - INFO - Epoch [4/30] Batch [1090/4715] Loss: 1.0564\n",
      "2025-05-30 14:07:51,276 - INFO - Epoch [4/30] Batch [1100/4715] Loss: 0.8590\n",
      "2025-05-30 14:07:52,839 - INFO - Epoch [4/30] Batch [1110/4715] Loss: 1.0426\n",
      "2025-05-30 14:07:54,361 - INFO - Epoch [4/30] Batch [1120/4715] Loss: 0.7641\n",
      "2025-05-30 14:07:55,909 - INFO - Epoch [4/30] Batch [1130/4715] Loss: 0.8782\n",
      "2025-05-30 14:07:57,472 - INFO - Epoch [4/30] Batch [1140/4715] Loss: 0.8005\n",
      "2025-05-30 14:07:58,986 - INFO - Epoch [4/30] Batch [1150/4715] Loss: 0.9529\n",
      "2025-05-30 14:08:00,557 - INFO - Epoch [4/30] Batch [1160/4715] Loss: 0.9097\n",
      "2025-05-30 14:08:02,135 - INFO - Epoch [4/30] Batch [1170/4715] Loss: 0.7933\n",
      "2025-05-30 14:08:03,764 - INFO - Epoch [4/30] Batch [1180/4715] Loss: 0.6836\n",
      "2025-05-30 14:08:05,317 - INFO - Epoch [4/30] Batch [1190/4715] Loss: 0.6241\n",
      "2025-05-30 14:08:06,871 - INFO - Epoch [4/30] Batch [1200/4715] Loss: 0.7836\n",
      "2025-05-30 14:08:08,473 - INFO - Epoch [4/30] Batch [1210/4715] Loss: 0.6863\n",
      "2025-05-30 14:08:10,078 - INFO - Epoch [4/30] Batch [1220/4715] Loss: 0.7144\n",
      "2025-05-30 14:08:11,602 - INFO - Epoch [4/30] Batch [1230/4715] Loss: 0.8182\n",
      "2025-05-30 14:08:13,167 - INFO - Epoch [4/30] Batch [1240/4715] Loss: 0.9380\n",
      "2025-05-30 14:08:14,687 - INFO - Epoch [4/30] Batch [1250/4715] Loss: 0.7239\n",
      "2025-05-30 14:08:16,231 - INFO - Epoch [4/30] Batch [1260/4715] Loss: 0.7063\n",
      "2025-05-30 14:08:17,683 - INFO - Epoch [4/30] Batch [1270/4715] Loss: 0.8784\n",
      "2025-05-30 14:08:19,329 - INFO - Epoch [4/30] Batch [1280/4715] Loss: 0.7015\n",
      "2025-05-30 14:08:20,822 - INFO - Epoch [4/30] Batch [1290/4715] Loss: 0.8426\n",
      "2025-05-30 14:08:22,306 - INFO - Epoch [4/30] Batch [1300/4715] Loss: 0.7027\n",
      "2025-05-30 14:08:23,948 - INFO - Epoch [4/30] Batch [1310/4715] Loss: 1.0373\n",
      "2025-05-30 14:08:25,523 - INFO - Epoch [4/30] Batch [1320/4715] Loss: 0.7229\n",
      "2025-05-30 14:08:27,150 - INFO - Epoch [4/30] Batch [1330/4715] Loss: 0.6797\n",
      "2025-05-30 14:08:28,747 - INFO - Epoch [4/30] Batch [1340/4715] Loss: 1.0398\n",
      "2025-05-30 14:08:30,286 - INFO - Epoch [4/30] Batch [1350/4715] Loss: 1.0082\n",
      "2025-05-30 14:08:31,839 - INFO - Epoch [4/30] Batch [1360/4715] Loss: 0.8713\n",
      "2025-05-30 14:08:33,310 - INFO - Epoch [4/30] Batch [1370/4715] Loss: 0.7630\n",
      "2025-05-30 14:08:34,964 - INFO - Epoch [4/30] Batch [1380/4715] Loss: 0.8439\n",
      "2025-05-30 14:08:36,547 - INFO - Epoch [4/30] Batch [1390/4715] Loss: 0.8451\n",
      "2025-05-30 14:08:38,089 - INFO - Epoch [4/30] Batch [1400/4715] Loss: 0.7243\n",
      "2025-05-30 14:08:39,585 - INFO - Epoch [4/30] Batch [1410/4715] Loss: 0.8736\n",
      "2025-05-30 14:08:41,180 - INFO - Epoch [4/30] Batch [1420/4715] Loss: 0.9533\n",
      "2025-05-30 14:08:42,798 - INFO - Epoch [4/30] Batch [1430/4715] Loss: 0.7469\n",
      "2025-05-30 14:08:44,340 - INFO - Epoch [4/30] Batch [1440/4715] Loss: 0.7945\n",
      "2025-05-30 14:08:46,024 - INFO - Epoch [4/30] Batch [1450/4715] Loss: 0.9507\n",
      "2025-05-30 14:08:47,611 - INFO - Epoch [4/30] Batch [1460/4715] Loss: 0.8245\n",
      "2025-05-30 14:08:49,208 - INFO - Epoch [4/30] Batch [1470/4715] Loss: 0.8573\n",
      "2025-05-30 14:08:50,720 - INFO - Epoch [4/30] Batch [1480/4715] Loss: 0.9354\n",
      "2025-05-30 14:08:52,285 - INFO - Epoch [4/30] Batch [1490/4715] Loss: 0.7426\n",
      "2025-05-30 14:08:53,876 - INFO - Epoch [4/30] Batch [1500/4715] Loss: 1.0594\n",
      "2025-05-30 14:08:55,502 - INFO - Epoch [4/30] Batch [1510/4715] Loss: 0.7311\n",
      "2025-05-30 14:08:57,036 - INFO - Epoch [4/30] Batch [1520/4715] Loss: 0.8071\n",
      "2025-05-30 14:08:58,689 - INFO - Epoch [4/30] Batch [1530/4715] Loss: 0.9821\n",
      "2025-05-30 14:09:00,328 - INFO - Epoch [4/30] Batch [1540/4715] Loss: 1.1162\n",
      "2025-05-30 14:09:01,877 - INFO - Epoch [4/30] Batch [1550/4715] Loss: 0.8103\n",
      "2025-05-30 14:09:03,405 - INFO - Epoch [4/30] Batch [1560/4715] Loss: 0.9759\n",
      "2025-05-30 14:09:04,905 - INFO - Epoch [4/30] Batch [1570/4715] Loss: 0.9575\n",
      "2025-05-30 14:09:06,422 - INFO - Epoch [4/30] Batch [1580/4715] Loss: 0.8051\n",
      "2025-05-30 14:09:08,019 - INFO - Epoch [4/30] Batch [1590/4715] Loss: 0.7564\n",
      "2025-05-30 14:09:09,572 - INFO - Epoch [4/30] Batch [1600/4715] Loss: 0.7734\n",
      "2025-05-30 14:09:11,185 - INFO - Epoch [4/30] Batch [1610/4715] Loss: 0.9036\n",
      "2025-05-30 14:09:12,755 - INFO - Epoch [4/30] Batch [1620/4715] Loss: 0.9755\n",
      "2025-05-30 14:09:14,317 - INFO - Epoch [4/30] Batch [1630/4715] Loss: 0.9247\n",
      "2025-05-30 14:09:15,934 - INFO - Epoch [4/30] Batch [1640/4715] Loss: 0.9923\n",
      "2025-05-30 14:09:17,524 - INFO - Epoch [4/30] Batch [1650/4715] Loss: 0.9688\n",
      "2025-05-30 14:09:19,178 - INFO - Epoch [4/30] Batch [1660/4715] Loss: 0.7842\n",
      "2025-05-30 14:09:20,726 - INFO - Epoch [4/30] Batch [1670/4715] Loss: 0.9562\n",
      "2025-05-30 14:09:22,310 - INFO - Epoch [4/30] Batch [1680/4715] Loss: 0.8118\n",
      "2025-05-30 14:09:23,855 - INFO - Epoch [4/30] Batch [1690/4715] Loss: 0.8166\n",
      "2025-05-30 14:09:25,477 - INFO - Epoch [4/30] Batch [1700/4715] Loss: 0.8358\n",
      "2025-05-30 14:09:27,020 - INFO - Epoch [4/30] Batch [1710/4715] Loss: 0.7542\n",
      "2025-05-30 14:09:28,542 - INFO - Epoch [4/30] Batch [1720/4715] Loss: 0.8962\n",
      "2025-05-30 14:09:30,124 - INFO - Epoch [4/30] Batch [1730/4715] Loss: 0.7361\n",
      "2025-05-30 14:09:31,728 - INFO - Epoch [4/30] Batch [1740/4715] Loss: 0.7980\n",
      "2025-05-30 14:09:33,277 - INFO - Epoch [4/30] Batch [1750/4715] Loss: 1.1786\n",
      "2025-05-30 14:09:34,886 - INFO - Epoch [4/30] Batch [1760/4715] Loss: 0.6939\n",
      "2025-05-30 14:09:36,541 - INFO - Epoch [4/30] Batch [1770/4715] Loss: 0.8824\n",
      "2025-05-30 14:09:38,238 - INFO - Epoch [4/30] Batch [1780/4715] Loss: 0.7112\n",
      "2025-05-30 14:09:39,806 - INFO - Epoch [4/30] Batch [1790/4715] Loss: 0.8233\n",
      "2025-05-30 14:09:41,410 - INFO - Epoch [4/30] Batch [1800/4715] Loss: 0.7625\n",
      "2025-05-30 14:09:43,099 - INFO - Epoch [4/30] Batch [1810/4715] Loss: 0.6932\n",
      "2025-05-30 14:09:44,841 - INFO - Epoch [4/30] Batch [1820/4715] Loss: 0.8821\n",
      "2025-05-30 14:09:46,466 - INFO - Epoch [4/30] Batch [1830/4715] Loss: 0.9956\n",
      "2025-05-30 14:09:47,987 - INFO - Epoch [4/30] Batch [1840/4715] Loss: 0.8311\n",
      "2025-05-30 14:09:49,543 - INFO - Epoch [4/30] Batch [1850/4715] Loss: 0.7659\n",
      "2025-05-30 14:09:51,105 - INFO - Epoch [4/30] Batch [1860/4715] Loss: 1.0429\n",
      "2025-05-30 14:09:52,696 - INFO - Epoch [4/30] Batch [1870/4715] Loss: 0.9781\n",
      "2025-05-30 14:09:54,370 - INFO - Epoch [4/30] Batch [1880/4715] Loss: 0.9015\n",
      "2025-05-30 14:09:55,870 - INFO - Epoch [4/30] Batch [1890/4715] Loss: 0.9366\n",
      "2025-05-30 14:09:57,468 - INFO - Epoch [4/30] Batch [1900/4715] Loss: 0.6937\n",
      "2025-05-30 14:09:59,144 - INFO - Epoch [4/30] Batch [1910/4715] Loss: 1.0155\n",
      "2025-05-30 14:10:00,741 - INFO - Epoch [4/30] Batch [1920/4715] Loss: 0.8193\n",
      "2025-05-30 14:10:02,309 - INFO - Epoch [4/30] Batch [1930/4715] Loss: 0.9234\n",
      "2025-05-30 14:10:03,851 - INFO - Epoch [4/30] Batch [1940/4715] Loss: 1.0806\n",
      "2025-05-30 14:10:05,455 - INFO - Epoch [4/30] Batch [1950/4715] Loss: 1.0399\n",
      "2025-05-30 14:10:07,025 - INFO - Epoch [4/30] Batch [1960/4715] Loss: 0.9500\n",
      "2025-05-30 14:10:08,587 - INFO - Epoch [4/30] Batch [1970/4715] Loss: 0.9031\n",
      "2025-05-30 14:10:10,163 - INFO - Epoch [4/30] Batch [1980/4715] Loss: 0.8110\n",
      "2025-05-30 14:10:11,692 - INFO - Epoch [4/30] Batch [1990/4715] Loss: 0.7525\n",
      "2025-05-30 14:10:13,185 - INFO - Epoch [4/30] Batch [2000/4715] Loss: 0.8722\n",
      "2025-05-30 14:10:14,748 - INFO - Epoch [4/30] Batch [2010/4715] Loss: 0.9811\n",
      "2025-05-30 14:10:16,297 - INFO - Epoch [4/30] Batch [2020/4715] Loss: 0.9697\n",
      "2025-05-30 14:10:17,907 - INFO - Epoch [4/30] Batch [2030/4715] Loss: 0.7346\n",
      "2025-05-30 14:10:19,475 - INFO - Epoch [4/30] Batch [2040/4715] Loss: 0.7773\n",
      "2025-05-30 14:10:21,117 - INFO - Epoch [4/30] Batch [2050/4715] Loss: 0.8702\n",
      "2025-05-30 14:10:22,661 - INFO - Epoch [4/30] Batch [2060/4715] Loss: 0.7563\n",
      "2025-05-30 14:10:24,266 - INFO - Epoch [4/30] Batch [2070/4715] Loss: 0.6970\n",
      "2025-05-30 14:10:25,777 - INFO - Epoch [4/30] Batch [2080/4715] Loss: 0.7072\n",
      "2025-05-30 14:10:27,322 - INFO - Epoch [4/30] Batch [2090/4715] Loss: 0.7237\n",
      "2025-05-30 14:10:29,007 - INFO - Epoch [4/30] Batch [2100/4715] Loss: 0.8524\n",
      "2025-05-30 14:10:30,535 - INFO - Epoch [4/30] Batch [2110/4715] Loss: 0.8588\n",
      "2025-05-30 14:10:32,158 - INFO - Epoch [4/30] Batch [2120/4715] Loss: 0.7871\n",
      "2025-05-30 14:10:33,640 - INFO - Epoch [4/30] Batch [2130/4715] Loss: 0.7782\n",
      "2025-05-30 14:10:35,189 - INFO - Epoch [4/30] Batch [2140/4715] Loss: 1.0219\n",
      "2025-05-30 14:10:36,659 - INFO - Epoch [4/30] Batch [2150/4715] Loss: 0.9934\n",
      "2025-05-30 14:10:38,224 - INFO - Epoch [4/30] Batch [2160/4715] Loss: 0.8814\n",
      "2025-05-30 14:10:39,857 - INFO - Epoch [4/30] Batch [2170/4715] Loss: 0.9077\n",
      "2025-05-30 14:10:41,364 - INFO - Epoch [4/30] Batch [2180/4715] Loss: 0.7403\n",
      "2025-05-30 14:10:42,940 - INFO - Epoch [4/30] Batch [2190/4715] Loss: 0.9254\n",
      "2025-05-30 14:10:44,537 - INFO - Epoch [4/30] Batch [2200/4715] Loss: 0.6869\n",
      "2025-05-30 14:10:46,065 - INFO - Epoch [4/30] Batch [2210/4715] Loss: 0.7141\n",
      "2025-05-30 14:10:47,640 - INFO - Epoch [4/30] Batch [2220/4715] Loss: 0.9845\n",
      "2025-05-30 14:10:49,253 - INFO - Epoch [4/30] Batch [2230/4715] Loss: 0.9936\n",
      "2025-05-30 14:10:50,809 - INFO - Epoch [4/30] Batch [2240/4715] Loss: 0.9075\n",
      "2025-05-30 14:10:52,392 - INFO - Epoch [4/30] Batch [2250/4715] Loss: 0.7363\n",
      "2025-05-30 14:10:53,997 - INFO - Epoch [4/30] Batch [2260/4715] Loss: 1.0944\n",
      "2025-05-30 14:10:55,540 - INFO - Epoch [4/30] Batch [2270/4715] Loss: 0.9214\n",
      "2025-05-30 14:10:57,107 - INFO - Epoch [4/30] Batch [2280/4715] Loss: 1.1161\n",
      "2025-05-30 14:10:58,617 - INFO - Epoch [4/30] Batch [2290/4715] Loss: 0.7951\n",
      "2025-05-30 14:11:00,139 - INFO - Epoch [4/30] Batch [2300/4715] Loss: 0.7009\n",
      "2025-05-30 14:11:01,723 - INFO - Epoch [4/30] Batch [2310/4715] Loss: 0.7787\n",
      "2025-05-30 14:11:03,311 - INFO - Epoch [4/30] Batch [2320/4715] Loss: 0.8255\n",
      "2025-05-30 14:11:04,887 - INFO - Epoch [4/30] Batch [2330/4715] Loss: 0.9106\n",
      "2025-05-30 14:11:06,514 - INFO - Epoch [4/30] Batch [2340/4715] Loss: 0.7850\n",
      "2025-05-30 14:11:08,026 - INFO - Epoch [4/30] Batch [2350/4715] Loss: 0.9864\n",
      "2025-05-30 14:11:09,610 - INFO - Epoch [4/30] Batch [2360/4715] Loss: 1.0903\n",
      "2025-05-30 14:11:11,194 - INFO - Epoch [4/30] Batch [2370/4715] Loss: 0.8453\n",
      "2025-05-30 14:11:12,791 - INFO - Epoch [4/30] Batch [2380/4715] Loss: 0.8282\n",
      "2025-05-30 14:11:14,298 - INFO - Epoch [4/30] Batch [2390/4715] Loss: 0.8774\n",
      "2025-05-30 14:11:15,866 - INFO - Epoch [4/30] Batch [2400/4715] Loss: 0.8419\n",
      "2025-05-30 14:11:17,406 - INFO - Epoch [4/30] Batch [2410/4715] Loss: 0.6823\n",
      "2025-05-30 14:11:18,981 - INFO - Epoch [4/30] Batch [2420/4715] Loss: 0.7488\n",
      "2025-05-30 14:11:20,538 - INFO - Epoch [4/30] Batch [2430/4715] Loss: 0.8707\n",
      "2025-05-30 14:11:22,060 - INFO - Epoch [4/30] Batch [2440/4715] Loss: 0.6137\n",
      "2025-05-30 14:11:23,655 - INFO - Epoch [4/30] Batch [2450/4715] Loss: 0.9032\n",
      "2025-05-30 14:11:25,196 - INFO - Epoch [4/30] Batch [2460/4715] Loss: 0.7740\n",
      "2025-05-30 14:11:26,744 - INFO - Epoch [4/30] Batch [2470/4715] Loss: 0.8831\n",
      "2025-05-30 14:11:28,286 - INFO - Epoch [4/30] Batch [2480/4715] Loss: 0.6470\n",
      "2025-05-30 14:11:29,793 - INFO - Epoch [4/30] Batch [2490/4715] Loss: 0.7087\n",
      "2025-05-30 14:11:31,264 - INFO - Epoch [4/30] Batch [2500/4715] Loss: 0.9068\n",
      "2025-05-30 14:11:32,764 - INFO - Epoch [4/30] Batch [2510/4715] Loss: 0.7505\n",
      "2025-05-30 14:11:34,305 - INFO - Epoch [4/30] Batch [2520/4715] Loss: 0.9249\n",
      "2025-05-30 14:11:35,870 - INFO - Epoch [4/30] Batch [2530/4715] Loss: 0.9745\n",
      "2025-05-30 14:11:37,419 - INFO - Epoch [4/30] Batch [2540/4715] Loss: 0.6522\n",
      "2025-05-30 14:11:38,892 - INFO - Epoch [4/30] Batch [2550/4715] Loss: 1.0801\n",
      "2025-05-30 14:11:40,426 - INFO - Epoch [4/30] Batch [2560/4715] Loss: 0.7830\n",
      "2025-05-30 14:11:41,937 - INFO - Epoch [4/30] Batch [2570/4715] Loss: 1.0291\n",
      "2025-05-30 14:11:43,490 - INFO - Epoch [4/30] Batch [2580/4715] Loss: 0.9985\n",
      "2025-05-30 14:11:45,053 - INFO - Epoch [4/30] Batch [2590/4715] Loss: 0.7780\n",
      "2025-05-30 14:11:46,664 - INFO - Epoch [4/30] Batch [2600/4715] Loss: 0.9027\n",
      "2025-05-30 14:11:48,296 - INFO - Epoch [4/30] Batch [2610/4715] Loss: 0.9085\n",
      "2025-05-30 14:11:49,839 - INFO - Epoch [4/30] Batch [2620/4715] Loss: 0.7820\n",
      "2025-05-30 14:11:51,408 - INFO - Epoch [4/30] Batch [2630/4715] Loss: 0.6667\n",
      "2025-05-30 14:11:53,034 - INFO - Epoch [4/30] Batch [2640/4715] Loss: 0.8835\n",
      "2025-05-30 14:11:54,526 - INFO - Epoch [4/30] Batch [2650/4715] Loss: 0.9968\n",
      "2025-05-30 14:11:56,068 - INFO - Epoch [4/30] Batch [2660/4715] Loss: 0.9371\n",
      "2025-05-30 14:11:57,652 - INFO - Epoch [4/30] Batch [2670/4715] Loss: 0.8770\n",
      "2025-05-30 14:11:59,291 - INFO - Epoch [4/30] Batch [2680/4715] Loss: 0.8794\n",
      "2025-05-30 14:12:00,888 - INFO - Epoch [4/30] Batch [2690/4715] Loss: 0.8223\n",
      "2025-05-30 14:12:02,409 - INFO - Epoch [4/30] Batch [2700/4715] Loss: 0.7476\n",
      "2025-05-30 14:12:04,004 - INFO - Epoch [4/30] Batch [2710/4715] Loss: 0.7990\n",
      "2025-05-30 14:12:05,674 - INFO - Epoch [4/30] Batch [2720/4715] Loss: 1.0030\n",
      "2025-05-30 14:12:07,195 - INFO - Epoch [4/30] Batch [2730/4715] Loss: 0.9335\n",
      "2025-05-30 14:12:08,736 - INFO - Epoch [4/30] Batch [2740/4715] Loss: 0.9986\n",
      "2025-05-30 14:12:10,368 - INFO - Epoch [4/30] Batch [2750/4715] Loss: 0.8786\n",
      "2025-05-30 14:12:11,841 - INFO - Epoch [4/30] Batch [2760/4715] Loss: 0.6363\n",
      "2025-05-30 14:12:13,385 - INFO - Epoch [4/30] Batch [2770/4715] Loss: 0.7822\n",
      "2025-05-30 14:12:14,897 - INFO - Epoch [4/30] Batch [2780/4715] Loss: 1.0179\n",
      "2025-05-30 14:12:16,508 - INFO - Epoch [4/30] Batch [2790/4715] Loss: 0.7296\n",
      "2025-05-30 14:12:18,077 - INFO - Epoch [4/30] Batch [2800/4715] Loss: 0.8596\n",
      "2025-05-30 14:12:19,550 - INFO - Epoch [4/30] Batch [2810/4715] Loss: 0.8575\n",
      "2025-05-30 14:12:21,078 - INFO - Epoch [4/30] Batch [2820/4715] Loss: 0.8699\n",
      "2025-05-30 14:12:22,676 - INFO - Epoch [4/30] Batch [2830/4715] Loss: 0.8531\n",
      "2025-05-30 14:12:24,245 - INFO - Epoch [4/30] Batch [2840/4715] Loss: 0.8294\n",
      "2025-05-30 14:12:25,885 - INFO - Epoch [4/30] Batch [2850/4715] Loss: 0.9695\n",
      "2025-05-30 14:12:27,437 - INFO - Epoch [4/30] Batch [2860/4715] Loss: 0.8452\n",
      "2025-05-30 14:12:28,948 - INFO - Epoch [4/30] Batch [2870/4715] Loss: 1.3784\n",
      "2025-05-30 14:12:30,435 - INFO - Epoch [4/30] Batch [2880/4715] Loss: 0.7817\n",
      "2025-05-30 14:12:32,047 - INFO - Epoch [4/30] Batch [2890/4715] Loss: 0.8821\n",
      "2025-05-30 14:12:33,629 - INFO - Epoch [4/30] Batch [2900/4715] Loss: 0.7871\n",
      "2025-05-30 14:12:35,160 - INFO - Epoch [4/30] Batch [2910/4715] Loss: 0.9075\n",
      "2025-05-30 14:12:36,758 - INFO - Epoch [4/30] Batch [2920/4715] Loss: 0.8828\n",
      "2025-05-30 14:12:38,340 - INFO - Epoch [4/30] Batch [2930/4715] Loss: 1.0412\n",
      "2025-05-30 14:12:39,970 - INFO - Epoch [4/30] Batch [2940/4715] Loss: 0.8771\n",
      "2025-05-30 14:12:41,540 - INFO - Epoch [4/30] Batch [2950/4715] Loss: 0.8918\n",
      "2025-05-30 14:12:43,103 - INFO - Epoch [4/30] Batch [2960/4715] Loss: 0.8291\n",
      "2025-05-30 14:12:44,686 - INFO - Epoch [4/30] Batch [2970/4715] Loss: 0.8496\n",
      "2025-05-30 14:12:46,290 - INFO - Epoch [4/30] Batch [2980/4715] Loss: 0.8443\n",
      "2025-05-30 14:12:47,903 - INFO - Epoch [4/30] Batch [2990/4715] Loss: 0.8270\n",
      "2025-05-30 14:12:49,504 - INFO - Epoch [4/30] Batch [3000/4715] Loss: 0.9345\n",
      "2025-05-30 14:12:51,069 - INFO - Epoch [4/30] Batch [3010/4715] Loss: 1.0925\n",
      "2025-05-30 14:12:52,645 - INFO - Epoch [4/30] Batch [3020/4715] Loss: 1.0285\n",
      "2025-05-30 14:12:54,216 - INFO - Epoch [4/30] Batch [3030/4715] Loss: 0.9447\n",
      "2025-05-30 14:12:55,778 - INFO - Epoch [4/30] Batch [3040/4715] Loss: 0.7933\n",
      "2025-05-30 14:12:57,361 - INFO - Epoch [4/30] Batch [3050/4715] Loss: 0.8183\n",
      "2025-05-30 14:12:58,910 - INFO - Epoch [4/30] Batch [3060/4715] Loss: 0.7676\n",
      "2025-05-30 14:13:00,570 - INFO - Epoch [4/30] Batch [3070/4715] Loss: 0.7516\n",
      "2025-05-30 14:13:02,376 - INFO - Epoch [4/30] Batch [3080/4715] Loss: 0.8837\n",
      "2025-05-30 14:13:03,973 - INFO - Epoch [4/30] Batch [3090/4715] Loss: 0.8601\n",
      "2025-05-30 14:13:05,606 - INFO - Epoch [4/30] Batch [3100/4715] Loss: 1.0981\n",
      "2025-05-30 14:13:07,141 - INFO - Epoch [4/30] Batch [3110/4715] Loss: 0.8243\n",
      "2025-05-30 14:13:08,745 - INFO - Epoch [4/30] Batch [3120/4715] Loss: 0.7062\n",
      "2025-05-30 14:13:10,308 - INFO - Epoch [4/30] Batch [3130/4715] Loss: 0.8375\n",
      "2025-05-30 14:13:12,006 - INFO - Epoch [4/30] Batch [3140/4715] Loss: 0.7331\n",
      "2025-05-30 14:13:13,555 - INFO - Epoch [4/30] Batch [3150/4715] Loss: 0.8541\n",
      "2025-05-30 14:13:15,219 - INFO - Epoch [4/30] Batch [3160/4715] Loss: 0.8833\n",
      "2025-05-30 14:13:16,719 - INFO - Epoch [4/30] Batch [3170/4715] Loss: 0.9485\n",
      "2025-05-30 14:13:18,288 - INFO - Epoch [4/30] Batch [3180/4715] Loss: 0.9244\n",
      "2025-05-30 14:13:19,867 - INFO - Epoch [4/30] Batch [3190/4715] Loss: 1.0014\n",
      "2025-05-30 14:13:21,526 - INFO - Epoch [4/30] Batch [3200/4715] Loss: 0.9519\n",
      "2025-05-30 14:13:23,158 - INFO - Epoch [4/30] Batch [3210/4715] Loss: 0.7131\n",
      "2025-05-30 14:13:24,789 - INFO - Epoch [4/30] Batch [3220/4715] Loss: 0.9425\n",
      "2025-05-30 14:13:26,345 - INFO - Epoch [4/30] Batch [3230/4715] Loss: 0.8399\n",
      "2025-05-30 14:13:27,998 - INFO - Epoch [4/30] Batch [3240/4715] Loss: 0.7731\n",
      "2025-05-30 14:13:29,606 - INFO - Epoch [4/30] Batch [3250/4715] Loss: 0.8634\n",
      "2025-05-30 14:13:31,043 - INFO - Epoch [4/30] Batch [3260/4715] Loss: 1.1847\n",
      "2025-05-30 14:13:32,575 - INFO - Epoch [4/30] Batch [3270/4715] Loss: 0.7591\n",
      "2025-05-30 14:13:34,144 - INFO - Epoch [4/30] Batch [3280/4715] Loss: 0.8738\n",
      "2025-05-30 14:13:35,672 - INFO - Epoch [4/30] Batch [3290/4715] Loss: 0.8044\n",
      "2025-05-30 14:13:37,228 - INFO - Epoch [4/30] Batch [3300/4715] Loss: 0.9384\n",
      "2025-05-30 14:13:38,905 - INFO - Epoch [4/30] Batch [3310/4715] Loss: 1.1194\n",
      "2025-05-30 14:13:40,515 - INFO - Epoch [4/30] Batch [3320/4715] Loss: 0.6883\n",
      "2025-05-30 14:13:42,027 - INFO - Epoch [4/30] Batch [3330/4715] Loss: 0.8749\n",
      "2025-05-30 14:13:43,555 - INFO - Epoch [4/30] Batch [3340/4715] Loss: 1.0423\n",
      "2025-05-30 14:13:45,154 - INFO - Epoch [4/30] Batch [3350/4715] Loss: 0.7128\n",
      "2025-05-30 14:13:46,763 - INFO - Epoch [4/30] Batch [3360/4715] Loss: 0.7785\n",
      "2025-05-30 14:13:48,436 - INFO - Epoch [4/30] Batch [3370/4715] Loss: 0.9041\n",
      "2025-05-30 14:13:49,973 - INFO - Epoch [4/30] Batch [3380/4715] Loss: 0.8646\n",
      "2025-05-30 14:13:51,689 - INFO - Epoch [4/30] Batch [3390/4715] Loss: 0.7850\n",
      "2025-05-30 14:13:53,376 - INFO - Epoch [4/30] Batch [3400/4715] Loss: 0.7203\n",
      "2025-05-30 14:13:54,904 - INFO - Epoch [4/30] Batch [3410/4715] Loss: 1.0285\n",
      "2025-05-30 14:13:56,446 - INFO - Epoch [4/30] Batch [3420/4715] Loss: 0.7866\n",
      "2025-05-30 14:13:58,019 - INFO - Epoch [4/30] Batch [3430/4715] Loss: 0.8779\n",
      "2025-05-30 14:13:59,592 - INFO - Epoch [4/30] Batch [3440/4715] Loss: 0.9619\n",
      "2025-05-30 14:14:01,225 - INFO - Epoch [4/30] Batch [3450/4715] Loss: 1.0665\n",
      "2025-05-30 14:14:02,865 - INFO - Epoch [4/30] Batch [3460/4715] Loss: 1.0051\n",
      "2025-05-30 14:14:04,422 - INFO - Epoch [4/30] Batch [3470/4715] Loss: 0.8223\n",
      "2025-05-30 14:14:05,908 - INFO - Epoch [4/30] Batch [3480/4715] Loss: 0.8806\n",
      "2025-05-30 14:14:07,456 - INFO - Epoch [4/30] Batch [3490/4715] Loss: 0.7623\n",
      "2025-05-30 14:14:09,026 - INFO - Epoch [4/30] Batch [3500/4715] Loss: 1.0365\n",
      "2025-05-30 14:14:10,573 - INFO - Epoch [4/30] Batch [3510/4715] Loss: 0.9228\n",
      "2025-05-30 14:14:12,205 - INFO - Epoch [4/30] Batch [3520/4715] Loss: 1.0317\n",
      "2025-05-30 14:14:13,796 - INFO - Epoch [4/30] Batch [3530/4715] Loss: 0.6770\n",
      "2025-05-30 14:14:15,331 - INFO - Epoch [4/30] Batch [3540/4715] Loss: 0.9117\n",
      "2025-05-30 14:14:16,887 - INFO - Epoch [4/30] Batch [3550/4715] Loss: 0.8592\n",
      "2025-05-30 14:14:18,442 - INFO - Epoch [4/30] Batch [3560/4715] Loss: 0.7167\n",
      "2025-05-30 14:14:19,972 - INFO - Epoch [4/30] Batch [3570/4715] Loss: 0.9201\n",
      "2025-05-30 14:14:21,563 - INFO - Epoch [4/30] Batch [3580/4715] Loss: 1.0892\n",
      "2025-05-30 14:14:23,203 - INFO - Epoch [4/30] Batch [3590/4715] Loss: 0.9331\n",
      "2025-05-30 14:14:24,770 - INFO - Epoch [4/30] Batch [3600/4715] Loss: 1.0496\n",
      "2025-05-30 14:14:26,339 - INFO - Epoch [4/30] Batch [3610/4715] Loss: 0.6708\n",
      "2025-05-30 14:14:27,909 - INFO - Epoch [4/30] Batch [3620/4715] Loss: 0.9396\n",
      "2025-05-30 14:14:29,611 - INFO - Epoch [4/30] Batch [3630/4715] Loss: 0.8831\n",
      "2025-05-30 14:14:31,220 - INFO - Epoch [4/30] Batch [3640/4715] Loss: 0.9375\n",
      "2025-05-30 14:14:32,762 - INFO - Epoch [4/30] Batch [3650/4715] Loss: 0.9675\n",
      "2025-05-30 14:14:34,306 - INFO - Epoch [4/30] Batch [3660/4715] Loss: 0.8536\n",
      "2025-05-30 14:14:35,936 - INFO - Epoch [4/30] Batch [3670/4715] Loss: 0.9194\n",
      "2025-05-30 14:14:37,481 - INFO - Epoch [4/30] Batch [3680/4715] Loss: 0.7205\n",
      "2025-05-30 14:14:39,070 - INFO - Epoch [4/30] Batch [3690/4715] Loss: 1.0550\n",
      "2025-05-30 14:14:40,613 - INFO - Epoch [4/30] Batch [3700/4715] Loss: 1.0570\n",
      "2025-05-30 14:14:42,244 - INFO - Epoch [4/30] Batch [3710/4715] Loss: 1.0650\n",
      "2025-05-30 14:14:43,818 - INFO - Epoch [4/30] Batch [3720/4715] Loss: 0.9154\n",
      "2025-05-30 14:14:45,413 - INFO - Epoch [4/30] Batch [3730/4715] Loss: 0.8982\n",
      "2025-05-30 14:14:47,009 - INFO - Epoch [4/30] Batch [3740/4715] Loss: 0.9187\n",
      "2025-05-30 14:14:48,544 - INFO - Epoch [4/30] Batch [3750/4715] Loss: 0.9334\n",
      "2025-05-30 14:14:50,239 - INFO - Epoch [4/30] Batch [3760/4715] Loss: 0.8713\n",
      "2025-05-30 14:14:51,794 - INFO - Epoch [4/30] Batch [3770/4715] Loss: 0.7562\n",
      "2025-05-30 14:14:53,399 - INFO - Epoch [4/30] Batch [3780/4715] Loss: 0.7645\n",
      "2025-05-30 14:14:55,056 - INFO - Epoch [4/30] Batch [3790/4715] Loss: 0.8346\n",
      "2025-05-30 14:14:56,656 - INFO - Epoch [4/30] Batch [3800/4715] Loss: 1.0322\n",
      "2025-05-30 14:14:58,281 - INFO - Epoch [4/30] Batch [3810/4715] Loss: 1.0193\n",
      "2025-05-30 14:14:59,916 - INFO - Epoch [4/30] Batch [3820/4715] Loss: 0.7585\n",
      "2025-05-30 14:15:01,544 - INFO - Epoch [4/30] Batch [3830/4715] Loss: 0.7095\n",
      "2025-05-30 14:15:03,129 - INFO - Epoch [4/30] Batch [3840/4715] Loss: 0.8035\n",
      "2025-05-30 14:15:04,674 - INFO - Epoch [4/30] Batch [3850/4715] Loss: 0.6927\n",
      "2025-05-30 14:15:06,317 - INFO - Epoch [4/30] Batch [3860/4715] Loss: 0.8350\n",
      "2025-05-30 14:15:08,045 - INFO - Epoch [4/30] Batch [3870/4715] Loss: 0.9298\n",
      "2025-05-30 14:15:09,605 - INFO - Epoch [4/30] Batch [3880/4715] Loss: 0.8605\n",
      "2025-05-30 14:15:11,205 - INFO - Epoch [4/30] Batch [3890/4715] Loss: 0.8785\n",
      "2025-05-30 14:15:12,763 - INFO - Epoch [4/30] Batch [3900/4715] Loss: 0.8453\n",
      "2025-05-30 14:15:14,408 - INFO - Epoch [4/30] Batch [3910/4715] Loss: 0.7946\n",
      "2025-05-30 14:15:15,903 - INFO - Epoch [4/30] Batch [3920/4715] Loss: 0.7566\n",
      "2025-05-30 14:15:17,430 - INFO - Epoch [4/30] Batch [3930/4715] Loss: 0.9674\n",
      "2025-05-30 14:15:19,109 - INFO - Epoch [4/30] Batch [3940/4715] Loss: 0.8349\n",
      "2025-05-30 14:15:20,666 - INFO - Epoch [4/30] Batch [3950/4715] Loss: 1.0407\n",
      "2025-05-30 14:15:22,208 - INFO - Epoch [4/30] Batch [3960/4715] Loss: 0.8461\n",
      "2025-05-30 14:15:23,887 - INFO - Epoch [4/30] Batch [3970/4715] Loss: 0.7620\n",
      "2025-05-30 14:15:25,485 - INFO - Epoch [4/30] Batch [3980/4715] Loss: 0.7817\n",
      "2025-05-30 14:15:27,091 - INFO - Epoch [4/30] Batch [3990/4715] Loss: 1.0027\n",
      "2025-05-30 14:15:28,646 - INFO - Epoch [4/30] Batch [4000/4715] Loss: 0.6235\n",
      "2025-05-30 14:15:30,187 - INFO - Epoch [4/30] Batch [4010/4715] Loss: 0.7705\n",
      "2025-05-30 14:15:31,752 - INFO - Epoch [4/30] Batch [4020/4715] Loss: 0.9153\n",
      "2025-05-30 14:15:33,300 - INFO - Epoch [4/30] Batch [4030/4715] Loss: 0.8396\n",
      "2025-05-30 14:15:34,898 - INFO - Epoch [4/30] Batch [4040/4715] Loss: 0.8690\n",
      "2025-05-30 14:15:36,446 - INFO - Epoch [4/30] Batch [4050/4715] Loss: 0.8291\n",
      "2025-05-30 14:15:37,990 - INFO - Epoch [4/30] Batch [4060/4715] Loss: 0.7354\n",
      "2025-05-30 14:15:39,581 - INFO - Epoch [4/30] Batch [4070/4715] Loss: 0.9412\n",
      "2025-05-30 14:15:41,135 - INFO - Epoch [4/30] Batch [4080/4715] Loss: 0.5841\n",
      "2025-05-30 14:15:42,690 - INFO - Epoch [4/30] Batch [4090/4715] Loss: 0.8945\n",
      "2025-05-30 14:15:44,309 - INFO - Epoch [4/30] Batch [4100/4715] Loss: 0.8567\n",
      "2025-05-30 14:15:45,844 - INFO - Epoch [4/30] Batch [4110/4715] Loss: 0.8156\n",
      "2025-05-30 14:15:47,427 - INFO - Epoch [4/30] Batch [4120/4715] Loss: 0.7799\n",
      "2025-05-30 14:15:48,976 - INFO - Epoch [4/30] Batch [4130/4715] Loss: 0.7990\n",
      "2025-05-30 14:15:50,504 - INFO - Epoch [4/30] Batch [4140/4715] Loss: 0.8264\n",
      "2025-05-30 14:15:52,067 - INFO - Epoch [4/30] Batch [4150/4715] Loss: 0.8908\n",
      "2025-05-30 14:15:53,595 - INFO - Epoch [4/30] Batch [4160/4715] Loss: 0.9925\n",
      "2025-05-30 14:15:55,172 - INFO - Epoch [4/30] Batch [4170/4715] Loss: 0.8705\n",
      "2025-05-30 14:15:56,685 - INFO - Epoch [4/30] Batch [4180/4715] Loss: 0.6842\n",
      "2025-05-30 14:15:58,325 - INFO - Epoch [4/30] Batch [4190/4715] Loss: 0.7850\n",
      "2025-05-30 14:15:59,894 - INFO - Epoch [4/30] Batch [4200/4715] Loss: 0.9620\n",
      "2025-05-30 14:16:01,419 - INFO - Epoch [4/30] Batch [4210/4715] Loss: 0.8157\n",
      "2025-05-30 14:16:03,006 - INFO - Epoch [4/30] Batch [4220/4715] Loss: 0.9146\n",
      "2025-05-30 14:16:04,568 - INFO - Epoch [4/30] Batch [4230/4715] Loss: 0.8006\n",
      "2025-05-30 14:16:06,194 - INFO - Epoch [4/30] Batch [4240/4715] Loss: 0.7099\n",
      "2025-05-30 14:16:07,694 - INFO - Epoch [4/30] Batch [4250/4715] Loss: 0.8062\n",
      "2025-05-30 14:16:09,284 - INFO - Epoch [4/30] Batch [4260/4715] Loss: 0.7667\n",
      "2025-05-30 14:16:10,826 - INFO - Epoch [4/30] Batch [4270/4715] Loss: 0.6945\n",
      "2025-05-30 14:16:12,355 - INFO - Epoch [4/30] Batch [4280/4715] Loss: 0.8291\n",
      "2025-05-30 14:16:13,875 - INFO - Epoch [4/30] Batch [4290/4715] Loss: 0.8915\n",
      "2025-05-30 14:16:15,456 - INFO - Epoch [4/30] Batch [4300/4715] Loss: 1.0444\n",
      "2025-05-30 14:16:17,091 - INFO - Epoch [4/30] Batch [4310/4715] Loss: 0.8292\n",
      "2025-05-30 14:16:18,723 - INFO - Epoch [4/30] Batch [4320/4715] Loss: 0.9457\n",
      "2025-05-30 14:16:20,280 - INFO - Epoch [4/30] Batch [4330/4715] Loss: 0.9344\n",
      "2025-05-30 14:16:21,828 - INFO - Epoch [4/30] Batch [4340/4715] Loss: 0.9829\n",
      "2025-05-30 14:16:23,444 - INFO - Epoch [4/30] Batch [4350/4715] Loss: 0.7522\n",
      "2025-05-30 14:16:25,042 - INFO - Epoch [4/30] Batch [4360/4715] Loss: 0.8565\n",
      "2025-05-30 14:16:26,592 - INFO - Epoch [4/30] Batch [4370/4715] Loss: 0.7670\n",
      "2025-05-30 14:16:28,294 - INFO - Epoch [4/30] Batch [4380/4715] Loss: 0.6058\n",
      "2025-05-30 14:16:29,860 - INFO - Epoch [4/30] Batch [4390/4715] Loss: 0.6553\n",
      "2025-05-30 14:16:31,392 - INFO - Epoch [4/30] Batch [4400/4715] Loss: 0.9588\n",
      "2025-05-30 14:16:32,941 - INFO - Epoch [4/30] Batch [4410/4715] Loss: 0.7922\n",
      "2025-05-30 14:16:34,475 - INFO - Epoch [4/30] Batch [4420/4715] Loss: 1.0466\n",
      "2025-05-30 14:16:35,996 - INFO - Epoch [4/30] Batch [4430/4715] Loss: 0.9281\n",
      "2025-05-30 14:16:37,490 - INFO - Epoch [4/30] Batch [4440/4715] Loss: 0.8578\n",
      "2025-05-30 14:16:39,039 - INFO - Epoch [4/30] Batch [4450/4715] Loss: 0.8840\n",
      "2025-05-30 14:16:40,667 - INFO - Epoch [4/30] Batch [4460/4715] Loss: 0.8680\n",
      "2025-05-30 14:16:42,192 - INFO - Epoch [4/30] Batch [4470/4715] Loss: 1.0547\n",
      "2025-05-30 14:16:43,887 - INFO - Epoch [4/30] Batch [4480/4715] Loss: 0.8407\n",
      "2025-05-30 14:16:45,468 - INFO - Epoch [4/30] Batch [4490/4715] Loss: 0.8448\n",
      "2025-05-30 14:16:47,130 - INFO - Epoch [4/30] Batch [4500/4715] Loss: 0.8724\n",
      "2025-05-30 14:16:48,804 - INFO - Epoch [4/30] Batch [4510/4715] Loss: 0.8959\n",
      "2025-05-30 14:16:50,387 - INFO - Epoch [4/30] Batch [4520/4715] Loss: 0.8767\n",
      "2025-05-30 14:16:52,016 - INFO - Epoch [4/30] Batch [4530/4715] Loss: 0.7655\n",
      "2025-05-30 14:16:53,706 - INFO - Epoch [4/30] Batch [4540/4715] Loss: 0.7644\n",
      "2025-05-30 14:16:55,325 - INFO - Epoch [4/30] Batch [4550/4715] Loss: 0.7784\n",
      "2025-05-30 14:16:56,909 - INFO - Epoch [4/30] Batch [4560/4715] Loss: 0.8959\n",
      "2025-05-30 14:16:58,576 - INFO - Epoch [4/30] Batch [4570/4715] Loss: 0.9701\n",
      "2025-05-30 14:17:00,125 - INFO - Epoch [4/30] Batch [4580/4715] Loss: 0.8570\n",
      "2025-05-30 14:17:01,597 - INFO - Epoch [4/30] Batch [4590/4715] Loss: 0.9452\n",
      "2025-05-30 14:17:03,174 - INFO - Epoch [4/30] Batch [4600/4715] Loss: 0.8950\n",
      "2025-05-30 14:17:04,730 - INFO - Epoch [4/30] Batch [4610/4715] Loss: 0.7787\n",
      "2025-05-30 14:17:06,286 - INFO - Epoch [4/30] Batch [4620/4715] Loss: 1.5093\n",
      "2025-05-30 14:17:07,886 - INFO - Epoch [4/30] Batch [4630/4715] Loss: 0.7009\n",
      "2025-05-30 14:17:09,425 - INFO - Epoch [4/30] Batch [4640/4715] Loss: 0.8164\n",
      "2025-05-30 14:17:11,008 - INFO - Epoch [4/30] Batch [4650/4715] Loss: 1.0110\n",
      "2025-05-30 14:17:12,625 - INFO - Epoch [4/30] Batch [4660/4715] Loss: 0.9464\n",
      "2025-05-30 14:17:14,205 - INFO - Epoch [4/30] Batch [4670/4715] Loss: 0.6410\n",
      "2025-05-30 14:17:15,766 - INFO - Epoch [4/30] Batch [4680/4715] Loss: 0.8133\n",
      "2025-05-30 14:17:17,384 - INFO - Epoch [4/30] Batch [4690/4715] Loss: 0.5246\n",
      "2025-05-30 14:17:18,975 - INFO - Epoch [4/30] Batch [4700/4715] Loss: 0.7340\n",
      "2025-05-30 14:17:20,586 - INFO - Epoch [4/30] Batch [4710/4715] Loss: 0.7144\n",
      "2025-05-30 14:17:59,397 - INFO - \n",
      "Epoch [4/30] Time: 781.96s\n",
      "2025-05-30 14:17:59,397 - INFO - Train Loss: 0.8656, Valid Loss: 0.8529\n",
      "2025-05-30 14:17:59,397 - INFO - Valid AUC (macro): 0.7028, F1 (macro): 0.5350\n",
      "2025-05-30 14:17:59,925 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\best_model.pth\n",
      "2025-05-30 14:17:59,925 - INFO - New best model saved with AUC: 0.7028\n",
      "2025-05-30 14:18:00,446 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 14:18:00,446 - INFO - Saved checkpoint at epoch 4\n",
      "2025-05-30 14:18:00,640 - INFO - Epoch [5/30] Batch [0/4715] Loss: 0.8217\n",
      "2025-05-30 14:18:02,328 - INFO - Epoch [5/30] Batch [10/4715] Loss: 0.9306\n",
      "2025-05-30 14:18:03,967 - INFO - Epoch [5/30] Batch [20/4715] Loss: 0.8159\n",
      "2025-05-30 14:18:05,557 - INFO - Epoch [5/30] Batch [30/4715] Loss: 0.9757\n",
      "2025-05-30 14:18:07,127 - INFO - Epoch [5/30] Batch [40/4715] Loss: 0.7323\n",
      "2025-05-30 14:18:08,734 - INFO - Epoch [5/30] Batch [50/4715] Loss: 0.8490\n",
      "2025-05-30 14:18:10,337 - INFO - Epoch [5/30] Batch [60/4715] Loss: 0.7322\n",
      "2025-05-30 14:18:11,900 - INFO - Epoch [5/30] Batch [70/4715] Loss: 0.9137\n",
      "2025-05-30 14:18:13,475 - INFO - Epoch [5/30] Batch [80/4715] Loss: 0.7628\n",
      "2025-05-30 14:18:15,033 - INFO - Epoch [5/30] Batch [90/4715] Loss: 0.7646\n",
      "2025-05-30 14:18:16,691 - INFO - Epoch [5/30] Batch [100/4715] Loss: 0.7460\n",
      "2025-05-30 14:18:18,310 - INFO - Epoch [5/30] Batch [110/4715] Loss: 0.7836\n",
      "2025-05-30 14:18:19,942 - INFO - Epoch [5/30] Batch [120/4715] Loss: 0.9066\n",
      "2025-05-30 14:18:21,523 - INFO - Epoch [5/30] Batch [130/4715] Loss: 0.6372\n",
      "2025-05-30 14:18:23,088 - INFO - Epoch [5/30] Batch [140/4715] Loss: 0.7916\n",
      "2025-05-30 14:18:24,621 - INFO - Epoch [5/30] Batch [150/4715] Loss: 0.5987\n",
      "2025-05-30 14:18:26,151 - INFO - Epoch [5/30] Batch [160/4715] Loss: 0.9709\n",
      "2025-05-30 14:18:27,741 - INFO - Epoch [5/30] Batch [170/4715] Loss: 0.9172\n",
      "2025-05-30 14:18:29,354 - INFO - Epoch [5/30] Batch [180/4715] Loss: 0.8262\n",
      "2025-05-30 14:18:30,950 - INFO - Epoch [5/30] Batch [190/4715] Loss: 0.7474\n",
      "2025-05-30 14:18:32,606 - INFO - Epoch [5/30] Batch [200/4715] Loss: 0.8892\n",
      "2025-05-30 14:18:34,154 - INFO - Epoch [5/30] Batch [210/4715] Loss: 0.9979\n",
      "2025-05-30 14:18:35,859 - INFO - Epoch [5/30] Batch [220/4715] Loss: 0.8298\n",
      "2025-05-30 14:18:37,472 - INFO - Epoch [5/30] Batch [230/4715] Loss: 0.8443\n",
      "2025-05-30 14:18:39,044 - INFO - Epoch [5/30] Batch [240/4715] Loss: 0.6409\n",
      "2025-05-30 14:18:40,619 - INFO - Epoch [5/30] Batch [250/4715] Loss: 1.0452\n",
      "2025-05-30 14:18:42,220 - INFO - Epoch [5/30] Batch [260/4715] Loss: 0.8918\n",
      "2025-05-30 14:18:43,806 - INFO - Epoch [5/30] Batch [270/4715] Loss: 0.9019\n",
      "2025-05-30 14:18:45,313 - INFO - Epoch [5/30] Batch [280/4715] Loss: 0.8286\n",
      "2025-05-30 14:18:46,973 - INFO - Epoch [5/30] Batch [290/4715] Loss: 0.8702\n",
      "2025-05-30 14:18:48,517 - INFO - Epoch [5/30] Batch [300/4715] Loss: 0.5435\n",
      "2025-05-30 14:18:50,106 - INFO - Epoch [5/30] Batch [310/4715] Loss: 0.8555\n",
      "2025-05-30 14:18:51,710 - INFO - Epoch [5/30] Batch [320/4715] Loss: 0.9602\n",
      "2025-05-30 14:18:53,245 - INFO - Epoch [5/30] Batch [330/4715] Loss: 0.8210\n",
      "2025-05-30 14:18:54,761 - INFO - Epoch [5/30] Batch [340/4715] Loss: 0.7882\n",
      "2025-05-30 14:18:56,294 - INFO - Epoch [5/30] Batch [350/4715] Loss: 0.7057\n",
      "2025-05-30 14:18:57,885 - INFO - Epoch [5/30] Batch [360/4715] Loss: 0.6857\n",
      "2025-05-30 14:18:59,496 - INFO - Epoch [5/30] Batch [370/4715] Loss: 0.8654\n",
      "2025-05-30 14:19:01,065 - INFO - Epoch [5/30] Batch [380/4715] Loss: 0.8035\n",
      "2025-05-30 14:19:02,619 - INFO - Epoch [5/30] Batch [390/4715] Loss: 0.4712\n",
      "2025-05-30 14:19:04,170 - INFO - Epoch [5/30] Batch [400/4715] Loss: 0.8557\n",
      "2025-05-30 14:19:05,707 - INFO - Epoch [5/30] Batch [410/4715] Loss: 0.8924\n",
      "2025-05-30 14:19:07,226 - INFO - Epoch [5/30] Batch [420/4715] Loss: 0.8170\n",
      "2025-05-30 14:19:08,796 - INFO - Epoch [5/30] Batch [430/4715] Loss: 0.8959\n",
      "2025-05-30 14:19:10,414 - INFO - Epoch [5/30] Batch [440/4715] Loss: 0.8192\n",
      "2025-05-30 14:19:11,893 - INFO - Epoch [5/30] Batch [450/4715] Loss: 0.7146\n",
      "2025-05-30 14:19:13,477 - INFO - Epoch [5/30] Batch [460/4715] Loss: 0.9914\n",
      "2025-05-30 14:19:15,065 - INFO - Epoch [5/30] Batch [470/4715] Loss: 1.1295\n",
      "2025-05-30 14:19:16,644 - INFO - Epoch [5/30] Batch [480/4715] Loss: 0.8350\n",
      "2025-05-30 14:19:18,179 - INFO - Epoch [5/30] Batch [490/4715] Loss: 0.8249\n",
      "2025-05-30 14:19:19,835 - INFO - Epoch [5/30] Batch [500/4715] Loss: 0.8613\n",
      "2025-05-30 14:19:21,472 - INFO - Epoch [5/30] Batch [510/4715] Loss: 0.8399\n",
      "2025-05-30 14:19:23,024 - INFO - Epoch [5/30] Batch [520/4715] Loss: 0.8994\n",
      "2025-05-30 14:19:24,559 - INFO - Epoch [5/30] Batch [530/4715] Loss: 0.7836\n",
      "2025-05-30 14:19:26,124 - INFO - Epoch [5/30] Batch [540/4715] Loss: 0.7240\n",
      "2025-05-30 14:19:27,635 - INFO - Epoch [5/30] Batch [550/4715] Loss: 0.6949\n",
      "2025-05-30 14:19:29,304 - INFO - Epoch [5/30] Batch [560/4715] Loss: 0.9932\n",
      "2025-05-30 14:19:30,924 - INFO - Epoch [5/30] Batch [570/4715] Loss: 1.0682\n",
      "2025-05-30 14:19:32,507 - INFO - Epoch [5/30] Batch [580/4715] Loss: 0.6506\n",
      "2025-05-30 14:19:34,114 - INFO - Epoch [5/30] Batch [590/4715] Loss: 0.8868\n",
      "2025-05-30 14:19:35,711 - INFO - Epoch [5/30] Batch [600/4715] Loss: 0.7648\n",
      "2025-05-30 14:19:37,342 - INFO - Epoch [5/30] Batch [610/4715] Loss: 0.9337\n",
      "2025-05-30 14:19:38,897 - INFO - Epoch [5/30] Batch [620/4715] Loss: 0.7482\n",
      "2025-05-30 14:19:40,458 - INFO - Epoch [5/30] Batch [630/4715] Loss: 0.8958\n",
      "2025-05-30 14:19:42,064 - INFO - Epoch [5/30] Batch [640/4715] Loss: 0.8383\n",
      "2025-05-30 14:19:43,639 - INFO - Epoch [5/30] Batch [650/4715] Loss: 0.9337\n",
      "2025-05-30 14:19:45,242 - INFO - Epoch [5/30] Batch [660/4715] Loss: 0.8681\n",
      "2025-05-30 14:19:46,885 - INFO - Epoch [5/30] Batch [670/4715] Loss: 0.7827\n",
      "2025-05-30 14:19:48,544 - INFO - Epoch [5/30] Batch [680/4715] Loss: 0.9287\n",
      "2025-05-30 14:19:50,101 - INFO - Epoch [5/30] Batch [690/4715] Loss: 0.7182\n",
      "2025-05-30 14:19:51,722 - INFO - Epoch [5/30] Batch [700/4715] Loss: 0.8565\n",
      "2025-05-30 14:19:53,288 - INFO - Epoch [5/30] Batch [710/4715] Loss: 0.7233\n",
      "2025-05-30 14:19:54,859 - INFO - Epoch [5/30] Batch [720/4715] Loss: 0.7082\n",
      "2025-05-30 14:19:56,460 - INFO - Epoch [5/30] Batch [730/4715] Loss: 1.0392\n",
      "2025-05-30 14:19:58,085 - INFO - Epoch [5/30] Batch [740/4715] Loss: 0.8840\n",
      "2025-05-30 14:19:59,702 - INFO - Epoch [5/30] Batch [750/4715] Loss: 0.8164\n",
      "2025-05-30 14:20:01,340 - INFO - Epoch [5/30] Batch [760/4715] Loss: 0.8340\n",
      "2025-05-30 14:20:02,894 - INFO - Epoch [5/30] Batch [770/4715] Loss: 1.0277\n",
      "2025-05-30 14:20:04,484 - INFO - Epoch [5/30] Batch [780/4715] Loss: 0.7996\n",
      "2025-05-30 14:20:05,950 - INFO - Epoch [5/30] Batch [790/4715] Loss: 0.8117\n",
      "2025-05-30 14:20:07,608 - INFO - Epoch [5/30] Batch [800/4715] Loss: 0.8897\n",
      "2025-05-30 14:20:09,237 - INFO - Epoch [5/30] Batch [810/4715] Loss: 0.8422\n",
      "2025-05-30 14:20:10,862 - INFO - Epoch [5/30] Batch [820/4715] Loss: 0.8463\n",
      "2025-05-30 14:20:12,374 - INFO - Epoch [5/30] Batch [830/4715] Loss: 0.8203\n",
      "2025-05-30 14:20:13,960 - INFO - Epoch [5/30] Batch [840/4715] Loss: 0.9954\n",
      "2025-05-30 14:20:15,439 - INFO - Epoch [5/30] Batch [850/4715] Loss: 0.7372\n",
      "2025-05-30 14:20:17,027 - INFO - Epoch [5/30] Batch [860/4715] Loss: 0.7990\n",
      "2025-05-30 14:20:18,644 - INFO - Epoch [5/30] Batch [870/4715] Loss: 0.8465\n",
      "2025-05-30 14:20:20,243 - INFO - Epoch [5/30] Batch [880/4715] Loss: 0.8226\n",
      "2025-05-30 14:20:21,827 - INFO - Epoch [5/30] Batch [890/4715] Loss: 0.8049\n",
      "2025-05-30 14:20:23,440 - INFO - Epoch [5/30] Batch [900/4715] Loss: 0.6376\n",
      "2025-05-30 14:20:24,973 - INFO - Epoch [5/30] Batch [910/4715] Loss: 0.8605\n",
      "2025-05-30 14:20:26,559 - INFO - Epoch [5/30] Batch [920/4715] Loss: 1.1389\n",
      "2025-05-30 14:20:28,092 - INFO - Epoch [5/30] Batch [930/4715] Loss: 0.8735\n",
      "2025-05-30 14:20:29,689 - INFO - Epoch [5/30] Batch [940/4715] Loss: 0.7656\n",
      "2025-05-30 14:20:31,212 - INFO - Epoch [5/30] Batch [950/4715] Loss: 0.7998\n",
      "2025-05-30 14:20:32,773 - INFO - Epoch [5/30] Batch [960/4715] Loss: 0.9542\n",
      "2025-05-30 14:20:34,266 - INFO - Epoch [5/30] Batch [970/4715] Loss: 0.9589\n",
      "2025-05-30 14:20:35,870 - INFO - Epoch [5/30] Batch [980/4715] Loss: 1.0015\n",
      "2025-05-30 14:20:37,375 - INFO - Epoch [5/30] Batch [990/4715] Loss: 1.2650\n",
      "2025-05-30 14:20:38,927 - INFO - Epoch [5/30] Batch [1000/4715] Loss: 0.7196\n",
      "2025-05-30 14:20:40,448 - INFO - Epoch [5/30] Batch [1010/4715] Loss: 0.7827\n",
      "2025-05-30 14:20:41,960 - INFO - Epoch [5/30] Batch [1020/4715] Loss: 0.8208\n",
      "2025-05-30 14:20:43,560 - INFO - Epoch [5/30] Batch [1030/4715] Loss: 0.8257\n",
      "2025-05-30 14:20:45,150 - INFO - Epoch [5/30] Batch [1040/4715] Loss: 0.6988\n",
      "2025-05-30 14:20:46,768 - INFO - Epoch [5/30] Batch [1050/4715] Loss: 0.8336\n",
      "2025-05-30 14:20:48,275 - INFO - Epoch [5/30] Batch [1060/4715] Loss: 1.0246\n",
      "2025-05-30 14:20:49,853 - INFO - Epoch [5/30] Batch [1070/4715] Loss: 1.0250\n",
      "2025-05-30 14:20:51,491 - INFO - Epoch [5/30] Batch [1080/4715] Loss: 0.9444\n",
      "2025-05-30 14:20:53,046 - INFO - Epoch [5/30] Batch [1090/4715] Loss: 0.8433\n",
      "2025-05-30 14:20:54,556 - INFO - Epoch [5/30] Batch [1100/4715] Loss: 0.9946\n",
      "2025-05-30 14:20:56,047 - INFO - Epoch [5/30] Batch [1110/4715] Loss: 0.7158\n",
      "2025-05-30 14:20:57,639 - INFO - Epoch [5/30] Batch [1120/4715] Loss: 0.7945\n",
      "2025-05-30 14:20:59,265 - INFO - Epoch [5/30] Batch [1130/4715] Loss: 0.9992\n",
      "2025-05-30 14:21:00,867 - INFO - Epoch [5/30] Batch [1140/4715] Loss: 0.6717\n",
      "2025-05-30 14:21:02,521 - INFO - Epoch [5/30] Batch [1150/4715] Loss: 0.7981\n",
      "2025-05-30 14:21:04,157 - INFO - Epoch [5/30] Batch [1160/4715] Loss: 1.0082\n",
      "2025-05-30 14:21:05,694 - INFO - Epoch [5/30] Batch [1170/4715] Loss: 0.8826\n",
      "2025-05-30 14:21:07,239 - INFO - Epoch [5/30] Batch [1180/4715] Loss: 0.7123\n",
      "2025-05-30 14:21:08,806 - INFO - Epoch [5/30] Batch [1190/4715] Loss: 0.7995\n",
      "2025-05-30 14:21:10,434 - INFO - Epoch [5/30] Batch [1200/4715] Loss: 0.5806\n",
      "2025-05-30 14:21:11,961 - INFO - Epoch [5/30] Batch [1210/4715] Loss: 0.8744\n",
      "2025-05-30 14:21:13,536 - INFO - Epoch [5/30] Batch [1220/4715] Loss: 0.8062\n",
      "2025-05-30 14:21:15,126 - INFO - Epoch [5/30] Batch [1230/4715] Loss: 0.8052\n",
      "2025-05-30 14:21:16,689 - INFO - Epoch [5/30] Batch [1240/4715] Loss: 0.7777\n",
      "2025-05-30 14:21:18,185 - INFO - Epoch [5/30] Batch [1250/4715] Loss: 0.8183\n",
      "2025-05-30 14:21:19,745 - INFO - Epoch [5/30] Batch [1260/4715] Loss: 1.2233\n",
      "2025-05-30 14:21:21,283 - INFO - Epoch [5/30] Batch [1270/4715] Loss: 0.7923\n",
      "2025-05-30 14:21:22,801 - INFO - Epoch [5/30] Batch [1280/4715] Loss: 0.7870\n",
      "2025-05-30 14:21:24,359 - INFO - Epoch [5/30] Batch [1290/4715] Loss: 1.0673\n",
      "2025-05-30 14:21:25,955 - INFO - Epoch [5/30] Batch [1300/4715] Loss: 0.9231\n",
      "2025-05-30 14:21:27,519 - INFO - Epoch [5/30] Batch [1310/4715] Loss: 0.8928\n",
      "2025-05-30 14:21:29,057 - INFO - Epoch [5/30] Batch [1320/4715] Loss: 0.8836\n",
      "2025-05-30 14:21:30,666 - INFO - Epoch [5/30] Batch [1330/4715] Loss: 0.9297\n",
      "2025-05-30 14:21:32,198 - INFO - Epoch [5/30] Batch [1340/4715] Loss: 0.8538\n",
      "2025-05-30 14:21:33,767 - INFO - Epoch [5/30] Batch [1350/4715] Loss: 1.1897\n",
      "2025-05-30 14:21:35,386 - INFO - Epoch [5/30] Batch [1360/4715] Loss: 0.7672\n",
      "2025-05-30 14:21:36,970 - INFO - Epoch [5/30] Batch [1370/4715] Loss: 0.9855\n",
      "2025-05-30 14:21:38,609 - INFO - Epoch [5/30] Batch [1380/4715] Loss: 0.7437\n",
      "2025-05-30 14:21:40,258 - INFO - Epoch [5/30] Batch [1390/4715] Loss: 0.8817\n",
      "2025-05-30 14:21:41,843 - INFO - Epoch [5/30] Batch [1400/4715] Loss: 1.0218\n",
      "2025-05-30 14:21:43,394 - INFO - Epoch [5/30] Batch [1410/4715] Loss: 0.7729\n",
      "2025-05-30 14:21:44,961 - INFO - Epoch [5/30] Batch [1420/4715] Loss: 0.8053\n",
      "2025-05-30 14:21:46,542 - INFO - Epoch [5/30] Batch [1430/4715] Loss: 0.8435\n",
      "2025-05-30 14:21:48,181 - INFO - Epoch [5/30] Batch [1440/4715] Loss: 0.7384\n",
      "2025-05-30 14:21:49,726 - INFO - Epoch [5/30] Batch [1450/4715] Loss: 1.1825\n",
      "2025-05-30 14:21:51,260 - INFO - Epoch [5/30] Batch [1460/4715] Loss: 0.9689\n",
      "2025-05-30 14:21:52,906 - INFO - Epoch [5/30] Batch [1470/4715] Loss: 0.9369\n",
      "2025-05-30 14:21:54,538 - INFO - Epoch [5/30] Batch [1480/4715] Loss: 0.6825\n",
      "2025-05-30 14:21:56,064 - INFO - Epoch [5/30] Batch [1490/4715] Loss: 0.7971\n",
      "2025-05-30 14:21:57,683 - INFO - Epoch [5/30] Batch [1500/4715] Loss: 0.9074\n",
      "2025-05-30 14:21:59,230 - INFO - Epoch [5/30] Batch [1510/4715] Loss: 0.9252\n",
      "2025-05-30 14:22:00,785 - INFO - Epoch [5/30] Batch [1520/4715] Loss: 0.6869\n",
      "2025-05-30 14:22:02,362 - INFO - Epoch [5/30] Batch [1530/4715] Loss: 0.8383\n",
      "2025-05-30 14:22:03,904 - INFO - Epoch [5/30] Batch [1540/4715] Loss: 1.2350\n",
      "2025-05-30 14:22:05,508 - INFO - Epoch [5/30] Batch [1550/4715] Loss: 0.7807\n",
      "2025-05-30 14:22:07,050 - INFO - Epoch [5/30] Batch [1560/4715] Loss: 0.6656\n",
      "2025-05-30 14:22:08,658 - INFO - Epoch [5/30] Batch [1570/4715] Loss: 0.7074\n",
      "2025-05-30 14:22:10,210 - INFO - Epoch [5/30] Batch [1580/4715] Loss: 0.9436\n",
      "2025-05-30 14:22:11,773 - INFO - Epoch [5/30] Batch [1590/4715] Loss: 0.9934\n",
      "2025-05-30 14:22:13,273 - INFO - Epoch [5/30] Batch [1600/4715] Loss: 0.9603\n",
      "2025-05-30 14:22:14,934 - INFO - Epoch [5/30] Batch [1610/4715] Loss: 0.8778\n",
      "2025-05-30 14:22:16,496 - INFO - Epoch [5/30] Batch [1620/4715] Loss: 0.8414\n",
      "2025-05-30 14:22:17,939 - INFO - Epoch [5/30] Batch [1630/4715] Loss: 0.8041\n",
      "2025-05-30 14:22:19,537 - INFO - Epoch [5/30] Batch [1640/4715] Loss: 0.8232\n",
      "2025-05-30 14:22:21,024 - INFO - Epoch [5/30] Batch [1650/4715] Loss: 1.0416\n",
      "2025-05-30 14:22:22,605 - INFO - Epoch [5/30] Batch [1660/4715] Loss: 0.7556\n",
      "2025-05-30 14:22:24,275 - INFO - Epoch [5/30] Batch [1670/4715] Loss: 0.9087\n",
      "2025-05-30 14:22:25,935 - INFO - Epoch [5/30] Batch [1680/4715] Loss: 1.0116\n",
      "2025-05-30 14:22:27,472 - INFO - Epoch [5/30] Batch [1690/4715] Loss: 0.9142\n",
      "2025-05-30 14:22:29,104 - INFO - Epoch [5/30] Batch [1700/4715] Loss: 0.8471\n",
      "2025-05-30 14:22:30,748 - INFO - Epoch [5/30] Batch [1710/4715] Loss: 1.1414\n",
      "2025-05-30 14:22:32,348 - INFO - Epoch [5/30] Batch [1720/4715] Loss: 0.8144\n",
      "2025-05-30 14:22:33,887 - INFO - Epoch [5/30] Batch [1730/4715] Loss: 0.9544\n",
      "2025-05-30 14:22:35,422 - INFO - Epoch [5/30] Batch [1740/4715] Loss: 0.9124\n",
      "2025-05-30 14:22:36,992 - INFO - Epoch [5/30] Batch [1750/4715] Loss: 0.8788\n",
      "2025-05-30 14:22:38,492 - INFO - Epoch [5/30] Batch [1760/4715] Loss: 0.8831\n",
      "2025-05-30 14:22:40,096 - INFO - Epoch [5/30] Batch [1770/4715] Loss: 0.9082\n",
      "2025-05-30 14:22:41,694 - INFO - Epoch [5/30] Batch [1780/4715] Loss: 0.8234\n",
      "2025-05-30 14:22:43,322 - INFO - Epoch [5/30] Batch [1790/4715] Loss: 0.8411\n",
      "2025-05-30 14:22:44,918 - INFO - Epoch [5/30] Batch [1800/4715] Loss: 0.8944\n",
      "2025-05-30 14:22:46,472 - INFO - Epoch [5/30] Batch [1810/4715] Loss: 1.0300\n",
      "2025-05-30 14:22:48,027 - INFO - Epoch [5/30] Batch [1820/4715] Loss: 0.8087\n",
      "2025-05-30 14:22:49,661 - INFO - Epoch [5/30] Batch [1830/4715] Loss: 0.9042\n",
      "2025-05-30 14:22:51,167 - INFO - Epoch [5/30] Batch [1840/4715] Loss: 0.7415\n",
      "2025-05-30 14:22:52,709 - INFO - Epoch [5/30] Batch [1850/4715] Loss: 0.8473\n",
      "2025-05-30 14:22:54,307 - INFO - Epoch [5/30] Batch [1860/4715] Loss: 0.9002\n",
      "2025-05-30 14:22:55,897 - INFO - Epoch [5/30] Batch [1870/4715] Loss: 0.6351\n",
      "2025-05-30 14:22:57,474 - INFO - Epoch [5/30] Batch [1880/4715] Loss: 0.7047\n",
      "2025-05-30 14:22:59,064 - INFO - Epoch [5/30] Batch [1890/4715] Loss: 1.0271\n",
      "2025-05-30 14:23:00,627 - INFO - Epoch [5/30] Batch [1900/4715] Loss: 0.7294\n",
      "2025-05-30 14:23:02,232 - INFO - Epoch [5/30] Batch [1910/4715] Loss: 0.8047\n",
      "2025-05-30 14:23:03,766 - INFO - Epoch [5/30] Batch [1920/4715] Loss: 0.7043\n",
      "2025-05-30 14:23:05,378 - INFO - Epoch [5/30] Batch [1930/4715] Loss: 0.7314\n",
      "2025-05-30 14:23:06,955 - INFO - Epoch [5/30] Batch [1940/4715] Loss: 1.0098\n",
      "2025-05-30 14:23:08,448 - INFO - Epoch [5/30] Batch [1950/4715] Loss: 0.8542\n",
      "2025-05-30 14:23:10,006 - INFO - Epoch [5/30] Batch [1960/4715] Loss: 0.9258\n",
      "2025-05-30 14:23:11,621 - INFO - Epoch [5/30] Batch [1970/4715] Loss: 0.8914\n",
      "2025-05-30 14:23:13,198 - INFO - Epoch [5/30] Batch [1980/4715] Loss: 0.9909\n",
      "2025-05-30 14:23:14,914 - INFO - Epoch [5/30] Batch [1990/4715] Loss: 0.8245\n",
      "2025-05-30 14:23:16,518 - INFO - Epoch [5/30] Batch [2000/4715] Loss: 0.7805\n",
      "2025-05-30 14:23:18,118 - INFO - Epoch [5/30] Batch [2010/4715] Loss: 0.7797\n",
      "2025-05-30 14:23:19,699 - INFO - Epoch [5/30] Batch [2020/4715] Loss: 0.8903\n",
      "2025-05-30 14:23:21,241 - INFO - Epoch [5/30] Batch [2030/4715] Loss: 1.1312\n",
      "2025-05-30 14:23:22,873 - INFO - Epoch [5/30] Batch [2040/4715] Loss: 0.8446\n",
      "2025-05-30 14:23:24,374 - INFO - Epoch [5/30] Batch [2050/4715] Loss: 0.7783\n",
      "2025-05-30 14:23:25,985 - INFO - Epoch [5/30] Batch [2060/4715] Loss: 0.9105\n",
      "2025-05-30 14:23:27,560 - INFO - Epoch [5/30] Batch [2070/4715] Loss: 0.6861\n",
      "2025-05-30 14:23:29,068 - INFO - Epoch [5/30] Batch [2080/4715] Loss: 0.9345\n",
      "2025-05-30 14:23:30,569 - INFO - Epoch [5/30] Batch [2090/4715] Loss: 1.0307\n",
      "2025-05-30 14:23:32,194 - INFO - Epoch [5/30] Batch [2100/4715] Loss: 0.8963\n",
      "2025-05-30 14:23:33,847 - INFO - Epoch [5/30] Batch [2110/4715] Loss: 0.8961\n",
      "2025-05-30 14:23:35,389 - INFO - Epoch [5/30] Batch [2120/4715] Loss: 0.9071\n",
      "2025-05-30 14:23:37,049 - INFO - Epoch [5/30] Batch [2130/4715] Loss: 0.7292\n",
      "2025-05-30 14:23:38,625 - INFO - Epoch [5/30] Batch [2140/4715] Loss: 0.9610\n",
      "2025-05-30 14:23:40,244 - INFO - Epoch [5/30] Batch [2150/4715] Loss: 0.7987\n",
      "2025-05-30 14:23:41,848 - INFO - Epoch [5/30] Batch [2160/4715] Loss: 0.7030\n",
      "2025-05-30 14:23:43,390 - INFO - Epoch [5/30] Batch [2170/4715] Loss: 0.6734\n",
      "2025-05-30 14:23:44,925 - INFO - Epoch [5/30] Batch [2180/4715] Loss: 0.8683\n",
      "2025-05-30 14:23:46,508 - INFO - Epoch [5/30] Batch [2190/4715] Loss: 1.0239\n",
      "2025-05-30 14:23:48,057 - INFO - Epoch [5/30] Batch [2200/4715] Loss: 0.9368\n",
      "2025-05-30 14:23:49,620 - INFO - Epoch [5/30] Batch [2210/4715] Loss: 0.9189\n",
      "2025-05-30 14:23:51,161 - INFO - Epoch [5/30] Batch [2220/4715] Loss: 0.7216\n",
      "2025-05-30 14:23:52,704 - INFO - Epoch [5/30] Batch [2230/4715] Loss: 0.8744\n",
      "2025-05-30 14:23:54,319 - INFO - Epoch [5/30] Batch [2240/4715] Loss: 0.8993\n",
      "2025-05-30 14:23:55,858 - INFO - Epoch [5/30] Batch [2250/4715] Loss: 0.6930\n",
      "2025-05-30 14:23:57,461 - INFO - Epoch [5/30] Batch [2260/4715] Loss: 0.8517\n",
      "2025-05-30 14:23:59,007 - INFO - Epoch [5/30] Batch [2270/4715] Loss: 1.0104\n",
      "2025-05-30 14:24:00,566 - INFO - Epoch [5/30] Batch [2280/4715] Loss: 0.7784\n",
      "2025-05-30 14:24:02,150 - INFO - Epoch [5/30] Batch [2290/4715] Loss: 0.7549\n",
      "2025-05-30 14:24:03,721 - INFO - Epoch [5/30] Batch [2300/4715] Loss: 0.6364\n",
      "2025-05-30 14:24:05,296 - INFO - Epoch [5/30] Batch [2310/4715] Loss: 0.7489\n",
      "2025-05-30 14:24:06,824 - INFO - Epoch [5/30] Batch [2320/4715] Loss: 0.8983\n",
      "2025-05-30 14:24:08,332 - INFO - Epoch [5/30] Batch [2330/4715] Loss: 0.7391\n",
      "2025-05-30 14:24:09,894 - INFO - Epoch [5/30] Batch [2340/4715] Loss: 0.9779\n",
      "2025-05-30 14:24:11,450 - INFO - Epoch [5/30] Batch [2350/4715] Loss: 1.0286\n",
      "2025-05-30 14:24:13,005 - INFO - Epoch [5/30] Batch [2360/4715] Loss: 0.7504\n",
      "2025-05-30 14:24:14,568 - INFO - Epoch [5/30] Batch [2370/4715] Loss: 0.7635\n",
      "2025-05-30 14:24:16,124 - INFO - Epoch [5/30] Batch [2380/4715] Loss: 0.7773\n",
      "2025-05-30 14:24:17,666 - INFO - Epoch [5/30] Batch [2390/4715] Loss: 0.7972\n",
      "2025-05-30 14:24:19,241 - INFO - Epoch [5/30] Batch [2400/4715] Loss: 0.9548\n",
      "2025-05-30 14:24:20,759 - INFO - Epoch [5/30] Batch [2410/4715] Loss: 0.8033\n",
      "2025-05-30 14:24:22,334 - INFO - Epoch [5/30] Batch [2420/4715] Loss: 0.9916\n",
      "2025-05-30 14:24:23,806 - INFO - Epoch [5/30] Batch [2430/4715] Loss: 0.7817\n",
      "2025-05-30 14:24:25,396 - INFO - Epoch [5/30] Batch [2440/4715] Loss: 0.7040\n",
      "2025-05-30 14:24:26,973 - INFO - Epoch [5/30] Batch [2450/4715] Loss: 0.9363\n",
      "2025-05-30 14:24:28,591 - INFO - Epoch [5/30] Batch [2460/4715] Loss: 0.7972\n",
      "2025-05-30 14:24:30,188 - INFO - Epoch [5/30] Batch [2470/4715] Loss: 0.9202\n",
      "2025-05-30 14:24:31,772 - INFO - Epoch [5/30] Batch [2480/4715] Loss: 0.9483\n",
      "2025-05-30 14:24:33,342 - INFO - Epoch [5/30] Batch [2490/4715] Loss: 0.7831\n",
      "2025-05-30 14:24:34,995 - INFO - Epoch [5/30] Batch [2500/4715] Loss: 0.6924\n",
      "2025-05-30 14:24:36,564 - INFO - Epoch [5/30] Batch [2510/4715] Loss: 0.9031\n",
      "2025-05-30 14:24:38,127 - INFO - Epoch [5/30] Batch [2520/4715] Loss: 0.8881\n",
      "2025-05-30 14:24:39,648 - INFO - Epoch [5/30] Batch [2530/4715] Loss: 0.9787\n",
      "2025-05-30 14:24:41,266 - INFO - Epoch [5/30] Batch [2540/4715] Loss: 0.8482\n",
      "2025-05-30 14:24:42,803 - INFO - Epoch [5/30] Batch [2550/4715] Loss: 0.8255\n",
      "2025-05-30 14:24:44,375 - INFO - Epoch [5/30] Batch [2560/4715] Loss: 0.7619\n",
      "2025-05-30 14:24:45,975 - INFO - Epoch [5/30] Batch [2570/4715] Loss: 0.9997\n",
      "2025-05-30 14:24:47,622 - INFO - Epoch [5/30] Batch [2580/4715] Loss: 0.7597\n",
      "2025-05-30 14:24:49,168 - INFO - Epoch [5/30] Batch [2590/4715] Loss: 1.0150\n",
      "2025-05-30 14:24:50,806 - INFO - Epoch [5/30] Batch [2600/4715] Loss: 1.0147\n",
      "2025-05-30 14:24:52,405 - INFO - Epoch [5/30] Batch [2610/4715] Loss: 1.0199\n",
      "2025-05-30 14:24:53,976 - INFO - Epoch [5/30] Batch [2620/4715] Loss: 0.9331\n",
      "2025-05-30 14:24:55,556 - INFO - Epoch [5/30] Batch [2630/4715] Loss: 0.9894\n",
      "2025-05-30 14:24:57,087 - INFO - Epoch [5/30] Batch [2640/4715] Loss: 0.9224\n",
      "2025-05-30 14:24:58,588 - INFO - Epoch [5/30] Batch [2650/4715] Loss: 0.8031\n",
      "2025-05-30 14:25:00,109 - INFO - Epoch [5/30] Batch [2660/4715] Loss: 0.6751\n",
      "2025-05-30 14:25:01,686 - INFO - Epoch [5/30] Batch [2670/4715] Loss: 0.7573\n",
      "2025-05-30 14:25:03,323 - INFO - Epoch [5/30] Batch [2680/4715] Loss: 0.9546\n",
      "2025-05-30 14:25:04,939 - INFO - Epoch [5/30] Batch [2690/4715] Loss: 0.7829\n",
      "2025-05-30 14:25:06,516 - INFO - Epoch [5/30] Batch [2700/4715] Loss: 0.7855\n",
      "2025-05-30 14:25:08,090 - INFO - Epoch [5/30] Batch [2710/4715] Loss: 1.0754\n",
      "2025-05-30 14:25:09,625 - INFO - Epoch [5/30] Batch [2720/4715] Loss: 0.7896\n",
      "2025-05-30 14:25:11,140 - INFO - Epoch [5/30] Batch [2730/4715] Loss: 0.9261\n",
      "2025-05-30 14:25:12,799 - INFO - Epoch [5/30] Batch [2740/4715] Loss: 0.7351\n",
      "2025-05-30 14:25:14,389 - INFO - Epoch [5/30] Batch [2750/4715] Loss: 0.7941\n",
      "2025-05-30 14:25:15,987 - INFO - Epoch [5/30] Batch [2760/4715] Loss: 0.8415\n",
      "2025-05-30 14:25:17,615 - INFO - Epoch [5/30] Batch [2770/4715] Loss: 0.8920\n",
      "2025-05-30 14:25:19,186 - INFO - Epoch [5/30] Batch [2780/4715] Loss: 1.0416\n",
      "2025-05-30 14:25:20,834 - INFO - Epoch [5/30] Batch [2790/4715] Loss: 0.8219\n",
      "2025-05-30 14:25:22,413 - INFO - Epoch [5/30] Batch [2800/4715] Loss: 1.0056\n",
      "2025-05-30 14:25:24,002 - INFO - Epoch [5/30] Batch [2810/4715] Loss: 0.9790\n",
      "2025-05-30 14:25:25,530 - INFO - Epoch [5/30] Batch [2820/4715] Loss: 0.8519\n",
      "2025-05-30 14:25:27,064 - INFO - Epoch [5/30] Batch [2830/4715] Loss: 0.9124\n",
      "2025-05-30 14:25:28,641 - INFO - Epoch [5/30] Batch [2840/4715] Loss: 1.0187\n",
      "2025-05-30 14:25:30,287 - INFO - Epoch [5/30] Batch [2850/4715] Loss: 0.6576\n",
      "2025-05-30 14:25:31,892 - INFO - Epoch [5/30] Batch [2860/4715] Loss: 0.8539\n",
      "2025-05-30 14:25:33,496 - INFO - Epoch [5/30] Batch [2870/4715] Loss: 0.6947\n",
      "2025-05-30 14:25:35,065 - INFO - Epoch [5/30] Batch [2880/4715] Loss: 0.7433\n",
      "2025-05-30 14:25:36,642 - INFO - Epoch [5/30] Batch [2890/4715] Loss: 0.7580\n",
      "2025-05-30 14:25:38,236 - INFO - Epoch [5/30] Batch [2900/4715] Loss: 1.1201\n",
      "2025-05-30 14:25:39,823 - INFO - Epoch [5/30] Batch [2910/4715] Loss: 0.7698\n",
      "2025-05-30 14:25:41,416 - INFO - Epoch [5/30] Batch [2920/4715] Loss: 0.9933\n",
      "2025-05-30 14:25:43,046 - INFO - Epoch [5/30] Batch [2930/4715] Loss: 1.0344\n",
      "2025-05-30 14:25:44,642 - INFO - Epoch [5/30] Batch [2940/4715] Loss: 0.9694\n",
      "2025-05-30 14:25:46,164 - INFO - Epoch [5/30] Batch [2950/4715] Loss: 0.8320\n",
      "2025-05-30 14:25:47,741 - INFO - Epoch [5/30] Batch [2960/4715] Loss: 0.8631\n",
      "2025-05-30 14:25:49,339 - INFO - Epoch [5/30] Batch [2970/4715] Loss: 0.7634\n",
      "2025-05-30 14:25:50,908 - INFO - Epoch [5/30] Batch [2980/4715] Loss: 0.9469\n",
      "2025-05-30 14:25:52,411 - INFO - Epoch [5/30] Batch [2990/4715] Loss: 0.9689\n",
      "2025-05-30 14:25:54,020 - INFO - Epoch [5/30] Batch [3000/4715] Loss: 0.8836\n",
      "2025-05-30 14:25:55,527 - INFO - Epoch [5/30] Batch [3010/4715] Loss: 1.0175\n",
      "2025-05-30 14:25:57,048 - INFO - Epoch [5/30] Batch [3020/4715] Loss: 0.6418\n",
      "2025-05-30 14:25:58,701 - INFO - Epoch [5/30] Batch [3030/4715] Loss: 0.9085\n",
      "2025-05-30 14:26:00,262 - INFO - Epoch [5/30] Batch [3040/4715] Loss: 0.7918\n",
      "2025-05-30 14:26:01,833 - INFO - Epoch [5/30] Batch [3050/4715] Loss: 0.8017\n",
      "2025-05-30 14:26:03,493 - INFO - Epoch [5/30] Batch [3060/4715] Loss: 0.9122\n",
      "2025-05-30 14:26:05,070 - INFO - Epoch [5/30] Batch [3070/4715] Loss: 0.6494\n",
      "2025-05-30 14:26:06,636 - INFO - Epoch [5/30] Batch [3080/4715] Loss: 0.9038\n",
      "2025-05-30 14:26:08,207 - INFO - Epoch [5/30] Batch [3090/4715] Loss: 0.7107\n",
      "2025-05-30 14:26:09,754 - INFO - Epoch [5/30] Batch [3100/4715] Loss: 0.7983\n",
      "2025-05-30 14:26:11,404 - INFO - Epoch [5/30] Batch [3110/4715] Loss: 0.6949\n",
      "2025-05-30 14:26:13,001 - INFO - Epoch [5/30] Batch [3120/4715] Loss: 0.6134\n",
      "2025-05-30 14:26:14,626 - INFO - Epoch [5/30] Batch [3130/4715] Loss: 0.7177\n",
      "2025-05-30 14:26:16,158 - INFO - Epoch [5/30] Batch [3140/4715] Loss: 0.6780\n",
      "2025-05-30 14:26:17,690 - INFO - Epoch [5/30] Batch [3150/4715] Loss: 0.7815\n",
      "2025-05-30 14:26:19,294 - INFO - Epoch [5/30] Batch [3160/4715] Loss: 0.8048\n",
      "2025-05-30 14:26:20,783 - INFO - Epoch [5/30] Batch [3170/4715] Loss: 0.9726\n",
      "2025-05-30 14:26:22,343 - INFO - Epoch [5/30] Batch [3180/4715] Loss: 0.8860\n",
      "2025-05-30 14:26:23,823 - INFO - Epoch [5/30] Batch [3190/4715] Loss: 0.9230\n",
      "2025-05-30 14:26:25,427 - INFO - Epoch [5/30] Batch [3200/4715] Loss: 0.8156\n",
      "2025-05-30 14:26:27,058 - INFO - Epoch [5/30] Batch [3210/4715] Loss: 0.7391\n",
      "2025-05-30 14:26:28,735 - INFO - Epoch [5/30] Batch [3220/4715] Loss: 0.7991\n",
      "2025-05-30 14:26:30,340 - INFO - Epoch [5/30] Batch [3230/4715] Loss: 0.7307\n",
      "2025-05-30 14:26:31,872 - INFO - Epoch [5/30] Batch [3240/4715] Loss: 0.8130\n",
      "2025-05-30 14:26:33,428 - INFO - Epoch [5/30] Batch [3250/4715] Loss: 0.8190\n",
      "2025-05-30 14:26:35,014 - INFO - Epoch [5/30] Batch [3260/4715] Loss: 0.6720\n",
      "2025-05-30 14:26:36,574 - INFO - Epoch [5/30] Batch [3270/4715] Loss: 0.7591\n",
      "2025-05-30 14:26:38,095 - INFO - Epoch [5/30] Batch [3280/4715] Loss: 1.0342\n",
      "2025-05-30 14:26:39,642 - INFO - Epoch [5/30] Batch [3290/4715] Loss: 0.7705\n",
      "2025-05-30 14:26:41,222 - INFO - Epoch [5/30] Batch [3300/4715] Loss: 0.9361\n",
      "2025-05-30 14:26:42,846 - INFO - Epoch [5/30] Batch [3310/4715] Loss: 0.9142\n",
      "2025-05-30 14:26:44,458 - INFO - Epoch [5/30] Batch [3320/4715] Loss: 0.8222\n",
      "2025-05-30 14:26:46,076 - INFO - Epoch [5/30] Batch [3330/4715] Loss: 0.8869\n",
      "2025-05-30 14:26:47,619 - INFO - Epoch [5/30] Batch [3340/4715] Loss: 0.7752\n",
      "2025-05-30 14:26:49,194 - INFO - Epoch [5/30] Batch [3350/4715] Loss: 0.9036\n",
      "2025-05-30 14:26:50,758 - INFO - Epoch [5/30] Batch [3360/4715] Loss: 0.9139\n",
      "2025-05-30 14:26:52,347 - INFO - Epoch [5/30] Batch [3370/4715] Loss: 0.7831\n",
      "2025-05-30 14:26:53,932 - INFO - Epoch [5/30] Batch [3380/4715] Loss: 0.8993\n",
      "2025-05-30 14:26:55,561 - INFO - Epoch [5/30] Batch [3390/4715] Loss: 0.7228\n",
      "2025-05-30 14:26:57,183 - INFO - Epoch [5/30] Batch [3400/4715] Loss: 0.8139\n",
      "2025-05-30 14:26:58,786 - INFO - Epoch [5/30] Batch [3410/4715] Loss: 1.1244\n",
      "2025-05-30 14:27:00,327 - INFO - Epoch [5/30] Batch [3420/4715] Loss: 0.9969\n",
      "2025-05-30 14:27:01,956 - INFO - Epoch [5/30] Batch [3430/4715] Loss: 0.9078\n",
      "2025-05-30 14:27:03,446 - INFO - Epoch [5/30] Batch [3440/4715] Loss: 0.8680\n",
      "2025-05-30 14:27:05,007 - INFO - Epoch [5/30] Batch [3450/4715] Loss: 0.7764\n",
      "2025-05-30 14:27:06,592 - INFO - Epoch [5/30] Batch [3460/4715] Loss: 0.9782\n",
      "2025-05-30 14:27:08,065 - INFO - Epoch [5/30] Batch [3470/4715] Loss: 0.8261\n",
      "2025-05-30 14:27:09,642 - INFO - Epoch [5/30] Batch [3480/4715] Loss: 0.7089\n",
      "2025-05-30 14:27:11,204 - INFO - Epoch [5/30] Batch [3490/4715] Loss: 0.9180\n",
      "2025-05-30 14:27:12,803 - INFO - Epoch [5/30] Batch [3500/4715] Loss: 0.9257\n",
      "2025-05-30 14:27:14,360 - INFO - Epoch [5/30] Batch [3510/4715] Loss: 0.8632\n",
      "2025-05-30 14:27:15,941 - INFO - Epoch [5/30] Batch [3520/4715] Loss: 0.9920\n",
      "2025-05-30 14:27:17,523 - INFO - Epoch [5/30] Batch [3530/4715] Loss: 0.9444\n",
      "2025-05-30 14:27:19,129 - INFO - Epoch [5/30] Batch [3540/4715] Loss: 0.9800\n",
      "2025-05-30 14:27:20,706 - INFO - Epoch [5/30] Batch [3550/4715] Loss: 0.8346\n",
      "2025-05-30 14:27:22,310 - INFO - Epoch [5/30] Batch [3560/4715] Loss: 0.9480\n",
      "2025-05-30 14:27:23,958 - INFO - Epoch [5/30] Batch [3570/4715] Loss: 0.8157\n",
      "2025-05-30 14:27:25,522 - INFO - Epoch [5/30] Batch [3580/4715] Loss: 1.0336\n",
      "2025-05-30 14:27:27,144 - INFO - Epoch [5/30] Batch [3590/4715] Loss: 0.7055\n",
      "2025-05-30 14:27:28,797 - INFO - Epoch [5/30] Batch [3600/4715] Loss: 1.1109\n",
      "2025-05-30 14:27:30,422 - INFO - Epoch [5/30] Batch [3610/4715] Loss: 0.8124\n",
      "2025-05-30 14:27:32,016 - INFO - Epoch [5/30] Batch [3620/4715] Loss: 0.8635\n",
      "2025-05-30 14:27:33,513 - INFO - Epoch [5/30] Batch [3630/4715] Loss: 0.7304\n",
      "2025-05-30 14:27:35,159 - INFO - Epoch [5/30] Batch [3640/4715] Loss: 0.9176\n",
      "2025-05-30 14:27:36,683 - INFO - Epoch [5/30] Batch [3650/4715] Loss: 0.7547\n",
      "2025-05-30 14:27:38,298 - INFO - Epoch [5/30] Batch [3660/4715] Loss: 0.9296\n",
      "2025-05-30 14:27:39,847 - INFO - Epoch [5/30] Batch [3670/4715] Loss: 0.9308\n",
      "2025-05-30 14:27:41,368 - INFO - Epoch [5/30] Batch [3680/4715] Loss: 0.6934\n",
      "2025-05-30 14:27:42,940 - INFO - Epoch [5/30] Batch [3690/4715] Loss: 0.9300\n",
      "2025-05-30 14:27:44,527 - INFO - Epoch [5/30] Batch [3700/4715] Loss: 0.8684\n",
      "2025-05-30 14:27:46,077 - INFO - Epoch [5/30] Batch [3710/4715] Loss: 0.6941\n",
      "2025-05-30 14:27:47,662 - INFO - Epoch [5/30] Batch [3720/4715] Loss: 0.9377\n",
      "2025-05-30 14:27:49,265 - INFO - Epoch [5/30] Batch [3730/4715] Loss: 0.8779\n",
      "2025-05-30 14:27:50,763 - INFO - Epoch [5/30] Batch [3740/4715] Loss: 0.9345\n",
      "2025-05-30 14:27:52,328 - INFO - Epoch [5/30] Batch [3750/4715] Loss: 0.8786\n",
      "2025-05-30 14:27:53,884 - INFO - Epoch [5/30] Batch [3760/4715] Loss: 1.0531\n",
      "2025-05-30 14:27:55,457 - INFO - Epoch [5/30] Batch [3770/4715] Loss: 0.7101\n",
      "2025-05-30 14:27:57,060 - INFO - Epoch [5/30] Batch [3780/4715] Loss: 0.9229\n",
      "2025-05-30 14:27:58,642 - INFO - Epoch [5/30] Batch [3790/4715] Loss: 0.8951\n",
      "2025-05-30 14:28:00,065 - INFO - Epoch [5/30] Batch [3800/4715] Loss: 0.7561\n",
      "2025-05-30 14:28:01,563 - INFO - Epoch [5/30] Batch [3810/4715] Loss: 0.8775\n",
      "2025-05-30 14:28:03,177 - INFO - Epoch [5/30] Batch [3820/4715] Loss: 0.8477\n",
      "2025-05-30 14:28:04,754 - INFO - Epoch [5/30] Batch [3830/4715] Loss: 0.6471\n",
      "2025-05-30 14:28:06,339 - INFO - Epoch [5/30] Batch [3840/4715] Loss: 0.7050\n",
      "2025-05-30 14:28:07,919 - INFO - Epoch [5/30] Batch [3850/4715] Loss: 0.8211\n",
      "2025-05-30 14:28:09,435 - INFO - Epoch [5/30] Batch [3860/4715] Loss: 1.0100\n",
      "2025-05-30 14:28:10,969 - INFO - Epoch [5/30] Batch [3870/4715] Loss: 0.8814\n",
      "2025-05-30 14:28:12,569 - INFO - Epoch [5/30] Batch [3880/4715] Loss: 1.0437\n",
      "2025-05-30 14:28:14,085 - INFO - Epoch [5/30] Batch [3890/4715] Loss: 0.5865\n",
      "2025-05-30 14:28:15,674 - INFO - Epoch [5/30] Batch [3900/4715] Loss: 1.0536\n",
      "2025-05-30 14:28:17,248 - INFO - Epoch [5/30] Batch [3910/4715] Loss: 1.3393\n",
      "2025-05-30 14:28:18,845 - INFO - Epoch [5/30] Batch [3920/4715] Loss: 0.9895\n",
      "2025-05-30 14:28:20,408 - INFO - Epoch [5/30] Batch [3930/4715] Loss: 0.7384\n",
      "2025-05-30 14:28:22,089 - INFO - Epoch [5/30] Batch [3940/4715] Loss: 0.9184\n",
      "2025-05-30 14:28:23,663 - INFO - Epoch [5/30] Batch [3950/4715] Loss: 0.8887\n",
      "2025-05-30 14:28:25,155 - INFO - Epoch [5/30] Batch [3960/4715] Loss: 0.8090\n",
      "2025-05-30 14:28:26,681 - INFO - Epoch [5/30] Batch [3970/4715] Loss: 0.9465\n",
      "2025-05-30 14:28:28,270 - INFO - Epoch [5/30] Batch [3980/4715] Loss: 0.9514\n",
      "2025-05-30 14:28:29,993 - INFO - Epoch [5/30] Batch [3990/4715] Loss: 1.0766\n",
      "2025-05-30 14:28:31,569 - INFO - Epoch [5/30] Batch [4000/4715] Loss: 0.7442\n",
      "2025-05-30 14:28:33,091 - INFO - Epoch [5/30] Batch [4010/4715] Loss: 0.6082\n",
      "2025-05-30 14:28:34,667 - INFO - Epoch [5/30] Batch [4020/4715] Loss: 0.9462\n",
      "2025-05-30 14:28:36,265 - INFO - Epoch [5/30] Batch [4030/4715] Loss: 0.8935\n",
      "2025-05-30 14:28:37,934 - INFO - Epoch [5/30] Batch [4040/4715] Loss: 0.8612\n",
      "2025-05-30 14:28:39,434 - INFO - Epoch [5/30] Batch [4050/4715] Loss: 1.0194\n",
      "2025-05-30 14:28:40,862 - INFO - Epoch [5/30] Batch [4060/4715] Loss: 0.6970\n",
      "2025-05-30 14:28:42,467 - INFO - Epoch [5/30] Batch [4070/4715] Loss: 0.8844\n",
      "2025-05-30 14:28:44,010 - INFO - Epoch [5/30] Batch [4080/4715] Loss: 1.1080\n",
      "2025-05-30 14:28:45,555 - INFO - Epoch [5/30] Batch [4090/4715] Loss: 0.6609\n",
      "2025-05-30 14:28:47,137 - INFO - Epoch [5/30] Batch [4100/4715] Loss: 0.9838\n",
      "2025-05-30 14:28:48,669 - INFO - Epoch [5/30] Batch [4110/4715] Loss: 0.8032\n",
      "2025-05-30 14:28:50,149 - INFO - Epoch [5/30] Batch [4120/4715] Loss: 1.1269\n",
      "2025-05-30 14:28:51,670 - INFO - Epoch [5/30] Batch [4130/4715] Loss: 0.9235\n",
      "2025-05-30 14:28:53,323 - INFO - Epoch [5/30] Batch [4140/4715] Loss: 0.8167\n",
      "2025-05-30 14:28:54,969 - INFO - Epoch [5/30] Batch [4150/4715] Loss: 1.0308\n",
      "2025-05-30 14:28:56,545 - INFO - Epoch [5/30] Batch [4160/4715] Loss: 0.8931\n",
      "2025-05-30 14:28:58,108 - INFO - Epoch [5/30] Batch [4170/4715] Loss: 0.8842\n",
      "2025-05-30 14:28:59,726 - INFO - Epoch [5/30] Batch [4180/4715] Loss: 0.8324\n",
      "2025-05-30 14:29:01,513 - INFO - Epoch [5/30] Batch [4190/4715] Loss: 0.7934\n",
      "2025-05-30 14:29:03,227 - INFO - Epoch [5/30] Batch [4200/4715] Loss: 0.9529\n",
      "2025-05-30 14:29:04,787 - INFO - Epoch [5/30] Batch [4210/4715] Loss: 0.9942\n",
      "2025-05-30 14:29:06,403 - INFO - Epoch [5/30] Batch [4220/4715] Loss: 0.7240\n",
      "2025-05-30 14:29:07,971 - INFO - Epoch [5/30] Batch [4230/4715] Loss: 0.9211\n",
      "2025-05-30 14:29:09,624 - INFO - Epoch [5/30] Batch [4240/4715] Loss: 0.8611\n",
      "2025-05-30 14:29:11,319 - INFO - Epoch [5/30] Batch [4250/4715] Loss: 0.7011\n",
      "2025-05-30 14:29:12,943 - INFO - Epoch [5/30] Batch [4260/4715] Loss: 0.9810\n",
      "2025-05-30 14:29:14,516 - INFO - Epoch [5/30] Batch [4270/4715] Loss: 0.7339\n",
      "2025-05-30 14:29:16,216 - INFO - Epoch [5/30] Batch [4280/4715] Loss: 1.0114\n",
      "2025-05-30 14:29:17,903 - INFO - Epoch [5/30] Batch [4290/4715] Loss: 0.7698\n",
      "2025-05-30 14:29:19,396 - INFO - Epoch [5/30] Batch [4300/4715] Loss: 0.7672\n",
      "2025-05-30 14:29:20,944 - INFO - Epoch [5/30] Batch [4310/4715] Loss: 0.8363\n",
      "2025-05-30 14:29:22,504 - INFO - Epoch [5/30] Batch [4320/4715] Loss: 0.6898\n",
      "2025-05-30 14:29:24,049 - INFO - Epoch [5/30] Batch [4330/4715] Loss: 0.7910\n",
      "2025-05-30 14:29:25,635 - INFO - Epoch [5/30] Batch [4340/4715] Loss: 0.7408\n",
      "2025-05-30 14:29:27,126 - INFO - Epoch [5/30] Batch [4350/4715] Loss: 0.7649\n",
      "2025-05-30 14:29:28,696 - INFO - Epoch [5/30] Batch [4360/4715] Loss: 0.8877\n",
      "2025-05-30 14:29:30,235 - INFO - Epoch [5/30] Batch [4370/4715] Loss: 0.9536\n",
      "2025-05-30 14:29:31,720 - INFO - Epoch [5/30] Batch [4380/4715] Loss: 0.9475\n",
      "2025-05-30 14:29:33,266 - INFO - Epoch [5/30] Batch [4390/4715] Loss: 0.6937\n",
      "2025-05-30 14:29:34,794 - INFO - Epoch [5/30] Batch [4400/4715] Loss: 0.8672\n",
      "2025-05-30 14:29:36,447 - INFO - Epoch [5/30] Batch [4410/4715] Loss: 0.7485\n",
      "2025-05-30 14:29:37,958 - INFO - Epoch [5/30] Batch [4420/4715] Loss: 0.8612\n",
      "2025-05-30 14:29:39,510 - INFO - Epoch [5/30] Batch [4430/4715] Loss: 0.6577\n",
      "2025-05-30 14:29:41,096 - INFO - Epoch [5/30] Batch [4440/4715] Loss: 0.8070\n",
      "2025-05-30 14:29:42,670 - INFO - Epoch [5/30] Batch [4450/4715] Loss: 0.7287\n",
      "2025-05-30 14:29:44,217 - INFO - Epoch [5/30] Batch [4460/4715] Loss: 0.7633\n",
      "2025-05-30 14:29:45,739 - INFO - Epoch [5/30] Batch [4470/4715] Loss: 0.9386\n",
      "2025-05-30 14:29:47,344 - INFO - Epoch [5/30] Batch [4480/4715] Loss: 0.5947\n",
      "2025-05-30 14:29:48,810 - INFO - Epoch [5/30] Batch [4490/4715] Loss: 0.7929\n",
      "2025-05-30 14:29:50,360 - INFO - Epoch [5/30] Batch [4500/4715] Loss: 0.8884\n",
      "2025-05-30 14:29:51,938 - INFO - Epoch [5/30] Batch [4510/4715] Loss: 0.7766\n",
      "2025-05-30 14:29:53,525 - INFO - Epoch [5/30] Batch [4520/4715] Loss: 0.6972\n",
      "2025-05-30 14:29:55,067 - INFO - Epoch [5/30] Batch [4530/4715] Loss: 0.9374\n",
      "2025-05-30 14:29:56,705 - INFO - Epoch [5/30] Batch [4540/4715] Loss: 0.8130\n",
      "2025-05-30 14:29:58,269 - INFO - Epoch [5/30] Batch [4550/4715] Loss: 0.7013\n",
      "2025-05-30 14:29:59,882 - INFO - Epoch [5/30] Batch [4560/4715] Loss: 0.8352\n",
      "2025-05-30 14:30:01,451 - INFO - Epoch [5/30] Batch [4570/4715] Loss: 0.7601\n",
      "2025-05-30 14:30:03,014 - INFO - Epoch [5/30] Batch [4580/4715] Loss: 0.8736\n",
      "2025-05-30 14:30:04,597 - INFO - Epoch [5/30] Batch [4590/4715] Loss: 0.7854\n",
      "2025-05-30 14:30:06,173 - INFO - Epoch [5/30] Batch [4600/4715] Loss: 0.9338\n",
      "2025-05-30 14:30:07,708 - INFO - Epoch [5/30] Batch [4610/4715] Loss: 0.7732\n",
      "2025-05-30 14:30:09,236 - INFO - Epoch [5/30] Batch [4620/4715] Loss: 0.9809\n",
      "2025-05-30 14:30:10,799 - INFO - Epoch [5/30] Batch [4630/4715] Loss: 0.8341\n",
      "2025-05-30 14:30:12,473 - INFO - Epoch [5/30] Batch [4640/4715] Loss: 0.8205\n",
      "2025-05-30 14:30:14,043 - INFO - Epoch [5/30] Batch [4650/4715] Loss: 0.8128\n",
      "2025-05-30 14:30:15,626 - INFO - Epoch [5/30] Batch [4660/4715] Loss: 1.1669\n",
      "2025-05-30 14:30:17,240 - INFO - Epoch [5/30] Batch [4670/4715] Loss: 0.7127\n",
      "2025-05-30 14:30:18,740 - INFO - Epoch [5/30] Batch [4680/4715] Loss: 0.8086\n",
      "2025-05-30 14:30:20,268 - INFO - Epoch [5/30] Batch [4690/4715] Loss: 0.9527\n",
      "2025-05-30 14:30:21,745 - INFO - Epoch [5/30] Batch [4700/4715] Loss: 0.6579\n",
      "2025-05-30 14:30:23,328 - INFO - Epoch [5/30] Batch [4710/4715] Loss: 0.8981\n",
      "2025-05-30 14:31:02,222 - INFO - \n",
      "Epoch [5/30] Time: 781.78s\n",
      "2025-05-30 14:31:02,223 - INFO - Train Loss: 0.8597, Valid Loss: 0.8462\n",
      "2025-05-30 14:31:02,223 - INFO - Valid AUC (macro): 0.7123, F1 (macro): 0.5249\n",
      "2025-05-30 14:31:02,751 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\best_model.pth\n",
      "2025-05-30 14:31:02,752 - INFO - New best model saved with AUC: 0.7123\n",
      "2025-05-30 14:31:03,348 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\checkpoint_epoch_5.pth\n",
      "2025-05-30 14:31:03,869 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 14:31:03,876 - INFO - Saved checkpoint at epoch 5\n",
      "2025-05-30 14:31:04,147 - INFO - Epoch [6/30] Batch [0/4715] Loss: 1.0018\n",
      "2025-05-30 14:31:05,827 - INFO - Epoch [6/30] Batch [10/4715] Loss: 0.6605\n",
      "2025-05-30 14:31:07,442 - INFO - Epoch [6/30] Batch [20/4715] Loss: 1.0227\n",
      "2025-05-30 14:31:09,078 - INFO - Epoch [6/30] Batch [30/4715] Loss: 0.6323\n",
      "2025-05-30 14:31:10,614 - INFO - Epoch [6/30] Batch [40/4715] Loss: 0.9186\n",
      "2025-05-30 14:31:12,224 - INFO - Epoch [6/30] Batch [50/4715] Loss: 0.9561\n",
      "2025-05-30 14:31:13,838 - INFO - Epoch [6/30] Batch [60/4715] Loss: 0.6922\n",
      "2025-05-30 14:31:15,423 - INFO - Epoch [6/30] Batch [70/4715] Loss: 0.7931\n",
      "2025-05-30 14:31:17,041 - INFO - Epoch [6/30] Batch [80/4715] Loss: 0.8305\n",
      "2025-05-30 14:31:18,584 - INFO - Epoch [6/30] Batch [90/4715] Loss: 0.6574\n",
      "2025-05-30 14:31:20,128 - INFO - Epoch [6/30] Batch [100/4715] Loss: 0.9070\n",
      "2025-05-30 14:31:21,684 - INFO - Epoch [6/30] Batch [110/4715] Loss: 0.9982\n",
      "2025-05-30 14:31:23,234 - INFO - Epoch [6/30] Batch [120/4715] Loss: 1.0116\n",
      "2025-05-30 14:31:24,918 - INFO - Epoch [6/30] Batch [130/4715] Loss: 0.9368\n",
      "2025-05-30 14:31:26,657 - INFO - Epoch [6/30] Batch [140/4715] Loss: 0.7773\n",
      "2025-05-30 14:31:28,164 - INFO - Epoch [6/30] Batch [150/4715] Loss: 0.9497\n",
      "2025-05-30 14:31:29,675 - INFO - Epoch [6/30] Batch [160/4715] Loss: 1.1641\n",
      "2025-05-30 14:31:31,320 - INFO - Epoch [6/30] Batch [170/4715] Loss: 0.9960\n",
      "2025-05-30 14:31:33,095 - INFO - Epoch [6/30] Batch [180/4715] Loss: 0.7046\n",
      "2025-05-30 14:31:34,724 - INFO - Epoch [6/30] Batch [190/4715] Loss: 0.8725\n",
      "2025-05-30 14:31:36,422 - INFO - Epoch [6/30] Batch [200/4715] Loss: 0.6468\n",
      "2025-05-30 14:31:37,939 - INFO - Epoch [6/30] Batch [210/4715] Loss: 0.8367\n",
      "2025-05-30 14:31:39,499 - INFO - Epoch [6/30] Batch [220/4715] Loss: 1.0100\n",
      "2025-05-30 14:31:41,004 - INFO - Epoch [6/30] Batch [230/4715] Loss: 0.8082\n",
      "2025-05-30 14:31:42,527 - INFO - Epoch [6/30] Batch [240/4715] Loss: 0.9922\n",
      "2025-05-30 14:31:44,104 - INFO - Epoch [6/30] Batch [250/4715] Loss: 0.8448\n",
      "2025-05-30 14:31:45,646 - INFO - Epoch [6/30] Batch [260/4715] Loss: 0.8864\n",
      "2025-05-30 14:31:47,141 - INFO - Epoch [6/30] Batch [270/4715] Loss: 0.9081\n",
      "2025-05-30 14:31:48,674 - INFO - Epoch [6/30] Batch [280/4715] Loss: 0.9582\n",
      "2025-05-30 14:31:50,223 - INFO - Epoch [6/30] Batch [290/4715] Loss: 0.9484\n",
      "2025-05-30 14:31:51,804 - INFO - Epoch [6/30] Batch [300/4715] Loss: 0.8002\n",
      "2025-05-30 14:31:53,341 - INFO - Epoch [6/30] Batch [310/4715] Loss: 0.6849\n",
      "2025-05-30 14:31:54,890 - INFO - Epoch [6/30] Batch [320/4715] Loss: 0.9130\n",
      "2025-05-30 14:31:56,435 - INFO - Epoch [6/30] Batch [330/4715] Loss: 0.7940\n",
      "2025-05-30 14:31:58,038 - INFO - Epoch [6/30] Batch [340/4715] Loss: 0.7723\n",
      "2025-05-30 14:31:59,592 - INFO - Epoch [6/30] Batch [350/4715] Loss: 0.9136\n",
      "2025-05-30 14:32:01,141 - INFO - Epoch [6/30] Batch [360/4715] Loss: 0.8631\n",
      "2025-05-30 14:32:02,685 - INFO - Epoch [6/30] Batch [370/4715] Loss: 0.6940\n",
      "2025-05-30 14:32:04,265 - INFO - Epoch [6/30] Batch [380/4715] Loss: 1.1803\n",
      "2025-05-30 14:32:05,822 - INFO - Epoch [6/30] Batch [390/4715] Loss: 0.9041\n",
      "2025-05-30 14:32:07,414 - INFO - Epoch [6/30] Batch [400/4715] Loss: 0.9192\n",
      "2025-05-30 14:32:09,019 - INFO - Epoch [6/30] Batch [410/4715] Loss: 0.7909\n",
      "2025-05-30 14:32:10,573 - INFO - Epoch [6/30] Batch [420/4715] Loss: 0.6419\n",
      "2025-05-30 14:32:12,177 - INFO - Epoch [6/30] Batch [430/4715] Loss: 0.6730\n",
      "2025-05-30 14:32:13,763 - INFO - Epoch [6/30] Batch [440/4715] Loss: 0.6190\n",
      "2025-05-30 14:32:15,425 - INFO - Epoch [6/30] Batch [450/4715] Loss: 1.0196\n",
      "2025-05-30 14:32:16,969 - INFO - Epoch [6/30] Batch [460/4715] Loss: 0.6405\n",
      "2025-05-30 14:32:18,522 - INFO - Epoch [6/30] Batch [470/4715] Loss: 0.8263\n",
      "2025-05-30 14:32:20,140 - INFO - Epoch [6/30] Batch [480/4715] Loss: 0.7102\n",
      "2025-05-30 14:32:21,721 - INFO - Epoch [6/30] Batch [490/4715] Loss: 0.8169\n",
      "2025-05-30 14:32:23,257 - INFO - Epoch [6/30] Batch [500/4715] Loss: 0.7834\n",
      "2025-05-30 14:32:24,790 - INFO - Epoch [6/30] Batch [510/4715] Loss: 0.9614\n",
      "2025-05-30 14:32:26,382 - INFO - Epoch [6/30] Batch [520/4715] Loss: 0.8282\n",
      "2025-05-30 14:32:27,992 - INFO - Epoch [6/30] Batch [530/4715] Loss: 0.6880\n",
      "2025-05-30 14:32:29,525 - INFO - Epoch [6/30] Batch [540/4715] Loss: 0.8575\n",
      "2025-05-30 14:32:31,097 - INFO - Epoch [6/30] Batch [550/4715] Loss: 1.1033\n",
      "2025-05-30 14:32:32,717 - INFO - Epoch [6/30] Batch [560/4715] Loss: 0.8870\n",
      "2025-05-30 14:32:34,278 - INFO - Epoch [6/30] Batch [570/4715] Loss: 0.9747\n",
      "2025-05-30 14:32:35,904 - INFO - Epoch [6/30] Batch [580/4715] Loss: 0.9459\n",
      "2025-05-30 14:32:37,441 - INFO - Epoch [6/30] Batch [590/4715] Loss: 1.0762\n",
      "2025-05-30 14:32:39,061 - INFO - Epoch [6/30] Batch [600/4715] Loss: 0.7907\n",
      "2025-05-30 14:32:40,569 - INFO - Epoch [6/30] Batch [610/4715] Loss: 0.7825\n",
      "2025-05-30 14:32:42,105 - INFO - Epoch [6/30] Batch [620/4715] Loss: 1.0644\n",
      "2025-05-30 14:32:43,626 - INFO - Epoch [6/30] Batch [630/4715] Loss: 0.8311\n",
      "2025-05-30 14:32:45,163 - INFO - Epoch [6/30] Batch [640/4715] Loss: 0.9177\n",
      "2025-05-30 14:32:46,696 - INFO - Epoch [6/30] Batch [650/4715] Loss: 1.0654\n",
      "2025-05-30 14:32:48,336 - INFO - Epoch [6/30] Batch [660/4715] Loss: 0.6564\n",
      "2025-05-30 14:32:49,925 - INFO - Epoch [6/30] Batch [670/4715] Loss: 0.6198\n",
      "2025-05-30 14:32:51,565 - INFO - Epoch [6/30] Batch [680/4715] Loss: 0.8385\n",
      "2025-05-30 14:32:53,213 - INFO - Epoch [6/30] Batch [690/4715] Loss: 1.0631\n",
      "2025-05-30 14:32:54,794 - INFO - Epoch [6/30] Batch [700/4715] Loss: 0.7496\n",
      "2025-05-30 14:32:56,371 - INFO - Epoch [6/30] Batch [710/4715] Loss: 0.7146\n",
      "2025-05-30 14:32:57,927 - INFO - Epoch [6/30] Batch [720/4715] Loss: 0.7892\n",
      "2025-05-30 14:32:59,510 - INFO - Epoch [6/30] Batch [730/4715] Loss: 0.8020\n",
      "2025-05-30 14:33:01,165 - INFO - Epoch [6/30] Batch [740/4715] Loss: 0.7862\n",
      "2025-05-30 14:33:02,672 - INFO - Epoch [6/30] Batch [750/4715] Loss: 0.7222\n",
      "2025-05-30 14:33:04,224 - INFO - Epoch [6/30] Batch [760/4715] Loss: 0.9189\n",
      "2025-05-30 14:33:05,864 - INFO - Epoch [6/30] Batch [770/4715] Loss: 0.7635\n",
      "2025-05-30 14:33:07,387 - INFO - Epoch [6/30] Batch [780/4715] Loss: 1.0579\n",
      "2025-05-30 14:33:08,936 - INFO - Epoch [6/30] Batch [790/4715] Loss: 0.8391\n",
      "2025-05-30 14:33:10,542 - INFO - Epoch [6/30] Batch [800/4715] Loss: 0.7942\n",
      "2025-05-30 14:33:12,109 - INFO - Epoch [6/30] Batch [810/4715] Loss: 0.8097\n",
      "2025-05-30 14:33:13,693 - INFO - Epoch [6/30] Batch [820/4715] Loss: 0.6224\n",
      "2025-05-30 14:33:15,304 - INFO - Epoch [6/30] Batch [830/4715] Loss: 1.1302\n",
      "2025-05-30 14:33:16,903 - INFO - Epoch [6/30] Batch [840/4715] Loss: 0.7941\n",
      "2025-05-30 14:33:18,423 - INFO - Epoch [6/30] Batch [850/4715] Loss: 0.8444\n",
      "2025-05-30 14:33:20,014 - INFO - Epoch [6/30] Batch [860/4715] Loss: 0.7463\n",
      "2025-05-30 14:33:21,638 - INFO - Epoch [6/30] Batch [870/4715] Loss: 0.8390\n",
      "2025-05-30 14:33:23,229 - INFO - Epoch [6/30] Batch [880/4715] Loss: 0.9660\n",
      "2025-05-30 14:33:24,778 - INFO - Epoch [6/30] Batch [890/4715] Loss: 0.8331\n",
      "2025-05-30 14:33:26,375 - INFO - Epoch [6/30] Batch [900/4715] Loss: 0.8070\n",
      "2025-05-30 14:33:27,973 - INFO - Epoch [6/30] Batch [910/4715] Loss: 0.7828\n",
      "2025-05-30 14:33:29,562 - INFO - Epoch [6/30] Batch [920/4715] Loss: 0.7888\n",
      "2025-05-30 14:33:31,107 - INFO - Epoch [6/30] Batch [930/4715] Loss: 0.7114\n",
      "2025-05-30 14:33:32,636 - INFO - Epoch [6/30] Batch [940/4715] Loss: 0.8056\n",
      "2025-05-30 14:33:34,106 - INFO - Epoch [6/30] Batch [950/4715] Loss: 0.7767\n",
      "2025-05-30 14:33:35,738 - INFO - Epoch [6/30] Batch [960/4715] Loss: 0.8999\n",
      "2025-05-30 14:33:37,234 - INFO - Epoch [6/30] Batch [970/4715] Loss: 0.9870\n",
      "2025-05-30 14:33:38,921 - INFO - Epoch [6/30] Batch [980/4715] Loss: 0.7431\n",
      "2025-05-30 14:33:40,508 - INFO - Epoch [6/30] Batch [990/4715] Loss: 0.8739\n",
      "2025-05-30 14:33:42,107 - INFO - Epoch [6/30] Batch [1000/4715] Loss: 0.7679\n",
      "2025-05-30 14:33:43,721 - INFO - Epoch [6/30] Batch [1010/4715] Loss: 0.8996\n",
      "2025-05-30 14:33:45,267 - INFO - Epoch [6/30] Batch [1020/4715] Loss: 1.0055\n",
      "2025-05-30 14:33:46,809 - INFO - Epoch [6/30] Batch [1030/4715] Loss: 0.7880\n",
      "2025-05-30 14:33:48,378 - INFO - Epoch [6/30] Batch [1040/4715] Loss: 0.7540\n",
      "2025-05-30 14:33:50,011 - INFO - Epoch [6/30] Batch [1050/4715] Loss: 0.7765\n",
      "2025-05-30 14:33:51,629 - INFO - Epoch [6/30] Batch [1060/4715] Loss: 0.7380\n",
      "2025-05-30 14:33:53,237 - INFO - Epoch [6/30] Batch [1070/4715] Loss: 0.7434\n",
      "2025-05-30 14:33:54,784 - INFO - Epoch [6/30] Batch [1080/4715] Loss: 0.8609\n",
      "2025-05-30 14:33:56,417 - INFO - Epoch [6/30] Batch [1090/4715] Loss: 0.9622\n",
      "2025-05-30 14:33:57,968 - INFO - Epoch [6/30] Batch [1100/4715] Loss: 0.9799\n",
      "2025-05-30 14:33:59,587 - INFO - Epoch [6/30] Batch [1110/4715] Loss: 0.7679\n",
      "2025-05-30 14:34:01,140 - INFO - Epoch [6/30] Batch [1120/4715] Loss: 0.7750\n",
      "2025-05-30 14:34:02,735 - INFO - Epoch [6/30] Batch [1130/4715] Loss: 0.8066\n",
      "2025-05-30 14:34:04,388 - INFO - Epoch [6/30] Batch [1140/4715] Loss: 0.7263\n",
      "2025-05-30 14:34:05,930 - INFO - Epoch [6/30] Batch [1150/4715] Loss: 0.8427\n",
      "2025-05-30 14:34:07,477 - INFO - Epoch [6/30] Batch [1160/4715] Loss: 0.7529\n",
      "2025-05-30 14:34:09,035 - INFO - Epoch [6/30] Batch [1170/4715] Loss: 1.0077\n",
      "2025-05-30 14:34:10,708 - INFO - Epoch [6/30] Batch [1180/4715] Loss: 1.0178\n",
      "2025-05-30 14:34:12,320 - INFO - Epoch [6/30] Batch [1190/4715] Loss: 0.8987\n",
      "2025-05-30 14:34:13,835 - INFO - Epoch [6/30] Batch [1200/4715] Loss: 0.8529\n",
      "2025-05-30 14:34:15,444 - INFO - Epoch [6/30] Batch [1210/4715] Loss: 1.0275\n",
      "2025-05-30 14:34:16,987 - INFO - Epoch [6/30] Batch [1220/4715] Loss: 0.9421\n",
      "2025-05-30 14:34:18,565 - INFO - Epoch [6/30] Batch [1230/4715] Loss: 0.8657\n",
      "2025-05-30 14:34:20,105 - INFO - Epoch [6/30] Batch [1240/4715] Loss: 0.6527\n",
      "2025-05-30 14:34:21,665 - INFO - Epoch [6/30] Batch [1250/4715] Loss: 0.7747\n",
      "2025-05-30 14:34:23,265 - INFO - Epoch [6/30] Batch [1260/4715] Loss: 0.8928\n",
      "2025-05-30 14:34:24,981 - INFO - Epoch [6/30] Batch [1270/4715] Loss: 0.7226\n",
      "2025-05-30 14:34:26,530 - INFO - Epoch [6/30] Batch [1280/4715] Loss: 0.7876\n",
      "2025-05-30 14:34:28,163 - INFO - Epoch [6/30] Batch [1290/4715] Loss: 0.6301\n",
      "2025-05-30 14:34:29,719 - INFO - Epoch [6/30] Batch [1300/4715] Loss: 0.9271\n",
      "2025-05-30 14:34:31,287 - INFO - Epoch [6/30] Batch [1310/4715] Loss: 0.6018\n",
      "2025-05-30 14:34:32,871 - INFO - Epoch [6/30] Batch [1320/4715] Loss: 0.7576\n",
      "2025-05-30 14:34:34,399 - INFO - Epoch [6/30] Batch [1330/4715] Loss: 1.0187\n",
      "2025-05-30 14:34:35,915 - INFO - Epoch [6/30] Batch [1340/4715] Loss: 0.7356\n",
      "2025-05-30 14:34:37,524 - INFO - Epoch [6/30] Batch [1350/4715] Loss: 0.9764\n",
      "2025-05-30 14:34:39,094 - INFO - Epoch [6/30] Batch [1360/4715] Loss: 0.7502\n",
      "2025-05-30 14:34:40,677 - INFO - Epoch [6/30] Batch [1370/4715] Loss: 0.7646\n",
      "2025-05-30 14:34:42,247 - INFO - Epoch [6/30] Batch [1380/4715] Loss: 0.7794\n",
      "2025-05-30 14:34:43,791 - INFO - Epoch [6/30] Batch [1390/4715] Loss: 0.7053\n",
      "2025-05-30 14:34:45,402 - INFO - Epoch [6/30] Batch [1400/4715] Loss: 0.9913\n",
      "2025-05-30 14:34:46,977 - INFO - Epoch [6/30] Batch [1410/4715] Loss: 0.9187\n",
      "2025-05-30 14:34:48,539 - INFO - Epoch [6/30] Batch [1420/4715] Loss: 0.8018\n",
      "2025-05-30 14:34:50,095 - INFO - Epoch [6/30] Batch [1430/4715] Loss: 0.7213\n",
      "2025-05-30 14:34:51,589 - INFO - Epoch [6/30] Batch [1440/4715] Loss: 0.8830\n",
      "2025-05-30 14:34:53,200 - INFO - Epoch [6/30] Batch [1450/4715] Loss: 1.0372\n",
      "2025-05-30 14:34:54,818 - INFO - Epoch [6/30] Batch [1460/4715] Loss: 0.9007\n",
      "2025-05-30 14:34:56,319 - INFO - Epoch [6/30] Batch [1470/4715] Loss: 0.7696\n",
      "2025-05-30 14:34:57,895 - INFO - Epoch [6/30] Batch [1480/4715] Loss: 0.9909\n",
      "2025-05-30 14:34:59,451 - INFO - Epoch [6/30] Batch [1490/4715] Loss: 0.8599\n",
      "2025-05-30 14:35:01,038 - INFO - Epoch [6/30] Batch [1500/4715] Loss: 0.9051\n",
      "2025-05-30 14:35:02,694 - INFO - Epoch [6/30] Batch [1510/4715] Loss: 1.0760\n",
      "2025-05-30 14:35:04,278 - INFO - Epoch [6/30] Batch [1520/4715] Loss: 0.8381\n",
      "2025-05-30 14:35:05,875 - INFO - Epoch [6/30] Batch [1530/4715] Loss: 0.6996\n",
      "2025-05-30 14:35:07,447 - INFO - Epoch [6/30] Batch [1540/4715] Loss: 0.7875\n",
      "2025-05-30 14:35:08,964 - INFO - Epoch [6/30] Batch [1550/4715] Loss: 0.8923\n",
      "2025-05-30 14:35:10,543 - INFO - Epoch [6/30] Batch [1560/4715] Loss: 0.9206\n",
      "2025-05-30 14:35:12,126 - INFO - Epoch [6/30] Batch [1570/4715] Loss: 0.7781\n",
      "2025-05-30 14:35:13,745 - INFO - Epoch [6/30] Batch [1580/4715] Loss: 0.6730\n",
      "2025-05-30 14:35:15,405 - INFO - Epoch [6/30] Batch [1590/4715] Loss: 0.9556\n",
      "2025-05-30 14:35:16,963 - INFO - Epoch [6/30] Batch [1600/4715] Loss: 0.7809\n",
      "2025-05-30 14:35:18,639 - INFO - Epoch [6/30] Batch [1610/4715] Loss: 0.9210\n",
      "2025-05-30 14:35:20,378 - INFO - Epoch [6/30] Batch [1620/4715] Loss: 0.6519\n",
      "2025-05-30 14:35:21,926 - INFO - Epoch [6/30] Batch [1630/4715] Loss: 0.6784\n",
      "2025-05-30 14:35:23,468 - INFO - Epoch [6/30] Batch [1640/4715] Loss: 1.0197\n",
      "2025-05-30 14:35:25,040 - INFO - Epoch [6/30] Batch [1650/4715] Loss: 0.7155\n",
      "2025-05-30 14:35:26,628 - INFO - Epoch [6/30] Batch [1660/4715] Loss: 0.8303\n",
      "2025-05-30 14:35:28,177 - INFO - Epoch [6/30] Batch [1670/4715] Loss: 1.0847\n",
      "2025-05-30 14:35:29,775 - INFO - Epoch [6/30] Batch [1680/4715] Loss: 0.9108\n",
      "2025-05-30 14:35:31,318 - INFO - Epoch [6/30] Batch [1690/4715] Loss: 0.9326\n",
      "2025-05-30 14:35:32,942 - INFO - Epoch [6/30] Batch [1700/4715] Loss: 0.8044\n",
      "2025-05-30 14:35:34,563 - INFO - Epoch [6/30] Batch [1710/4715] Loss: 0.8560\n",
      "2025-05-30 14:35:36,120 - INFO - Epoch [6/30] Batch [1720/4715] Loss: 0.8749\n",
      "2025-05-30 14:35:37,630 - INFO - Epoch [6/30] Batch [1730/4715] Loss: 0.9003\n",
      "2025-05-30 14:35:39,213 - INFO - Epoch [6/30] Batch [1740/4715] Loss: 0.9000\n",
      "2025-05-30 14:35:40,717 - INFO - Epoch [6/30] Batch [1750/4715] Loss: 1.0174\n",
      "2025-05-30 14:35:42,315 - INFO - Epoch [6/30] Batch [1760/4715] Loss: 0.5829\n",
      "2025-05-30 14:35:43,867 - INFO - Epoch [6/30] Batch [1770/4715] Loss: 1.1771\n",
      "2025-05-30 14:35:45,500 - INFO - Epoch [6/30] Batch [1780/4715] Loss: 0.9041\n",
      "2025-05-30 14:35:47,057 - INFO - Epoch [6/30] Batch [1790/4715] Loss: 1.0660\n",
      "2025-05-30 14:35:48,610 - INFO - Epoch [6/30] Batch [1800/4715] Loss: 0.8322\n",
      "2025-05-30 14:35:50,222 - INFO - Epoch [6/30] Batch [1810/4715] Loss: 1.0994\n",
      "2025-05-30 14:35:51,776 - INFO - Epoch [6/30] Batch [1820/4715] Loss: 0.7344\n",
      "2025-05-30 14:35:53,275 - INFO - Epoch [6/30] Batch [1830/4715] Loss: 0.9080\n",
      "2025-05-30 14:35:54,896 - INFO - Epoch [6/30] Batch [1840/4715] Loss: 0.8625\n",
      "2025-05-30 14:35:56,473 - INFO - Epoch [6/30] Batch [1850/4715] Loss: 0.8095\n",
      "2025-05-30 14:35:58,077 - INFO - Epoch [6/30] Batch [1860/4715] Loss: 0.8858\n",
      "2025-05-30 14:35:59,719 - INFO - Epoch [6/30] Batch [1870/4715] Loss: 0.7477\n",
      "2025-05-30 14:36:01,315 - INFO - Epoch [6/30] Batch [1880/4715] Loss: 0.8055\n",
      "2025-05-30 14:36:02,835 - INFO - Epoch [6/30] Batch [1890/4715] Loss: 0.7684\n",
      "2025-05-30 14:36:04,425 - INFO - Epoch [6/30] Batch [1900/4715] Loss: 0.8746\n",
      "2025-05-30 14:36:06,002 - INFO - Epoch [6/30] Batch [1910/4715] Loss: 0.7360\n",
      "2025-05-30 14:36:07,579 - INFO - Epoch [6/30] Batch [1920/4715] Loss: 0.7572\n",
      "2025-05-30 14:36:09,100 - INFO - Epoch [6/30] Batch [1930/4715] Loss: 0.9518\n",
      "2025-05-30 14:36:10,642 - INFO - Epoch [6/30] Batch [1940/4715] Loss: 0.6415\n",
      "2025-05-30 14:36:12,295 - INFO - Epoch [6/30] Batch [1950/4715] Loss: 0.9082\n",
      "2025-05-30 14:36:13,850 - INFO - Epoch [6/30] Batch [1960/4715] Loss: 0.8750\n",
      "2025-05-30 14:36:15,392 - INFO - Epoch [6/30] Batch [1970/4715] Loss: 1.1176\n",
      "2025-05-30 14:36:16,918 - INFO - Epoch [6/30] Batch [1980/4715] Loss: 0.8315\n",
      "2025-05-30 14:36:18,469 - INFO - Epoch [6/30] Batch [1990/4715] Loss: 0.9331\n",
      "2025-05-30 14:36:20,044 - INFO - Epoch [6/30] Batch [2000/4715] Loss: 0.9950\n",
      "2025-05-30 14:36:21,622 - INFO - Epoch [6/30] Batch [2010/4715] Loss: 0.8462\n",
      "2025-05-30 14:36:23,122 - INFO - Epoch [6/30] Batch [2020/4715] Loss: 0.6602\n",
      "2025-05-30 14:36:24,706 - INFO - Epoch [6/30] Batch [2030/4715] Loss: 0.9666\n",
      "2025-05-30 14:36:26,241 - INFO - Epoch [6/30] Batch [2040/4715] Loss: 0.8470\n",
      "2025-05-30 14:36:27,784 - INFO - Epoch [6/30] Batch [2050/4715] Loss: 0.9029\n",
      "2025-05-30 14:36:29,403 - INFO - Epoch [6/30] Batch [2060/4715] Loss: 0.6255\n",
      "2025-05-30 14:36:31,059 - INFO - Epoch [6/30] Batch [2070/4715] Loss: 0.8781\n",
      "2025-05-30 14:36:32,608 - INFO - Epoch [6/30] Batch [2080/4715] Loss: 0.9033\n",
      "2025-05-30 14:36:34,158 - INFO - Epoch [6/30] Batch [2090/4715] Loss: 0.8350\n",
      "2025-05-30 14:36:35,767 - INFO - Epoch [6/30] Batch [2100/4715] Loss: 0.6674\n",
      "2025-05-30 14:36:37,395 - INFO - Epoch [6/30] Batch [2110/4715] Loss: 0.8744\n",
      "2025-05-30 14:36:38,921 - INFO - Epoch [6/30] Batch [2120/4715] Loss: 0.7960\n",
      "2025-05-30 14:36:40,565 - INFO - Epoch [6/30] Batch [2130/4715] Loss: 0.7036\n",
      "2025-05-30 14:36:42,111 - INFO - Epoch [6/30] Batch [2140/4715] Loss: 0.7191\n",
      "2025-05-30 14:36:43,800 - INFO - Epoch [6/30] Batch [2150/4715] Loss: 0.7437\n",
      "2025-05-30 14:36:45,396 - INFO - Epoch [6/30] Batch [2160/4715] Loss: 0.8191\n",
      "2025-05-30 14:36:46,945 - INFO - Epoch [6/30] Batch [2170/4715] Loss: 0.6410\n",
      "2025-05-30 14:36:48,622 - INFO - Epoch [6/30] Batch [2180/4715] Loss: 0.7432\n",
      "2025-05-30 14:36:50,162 - INFO - Epoch [6/30] Batch [2190/4715] Loss: 0.8769\n",
      "2025-05-30 14:36:51,745 - INFO - Epoch [6/30] Batch [2200/4715] Loss: 0.7869\n",
      "2025-05-30 14:36:53,273 - INFO - Epoch [6/30] Batch [2210/4715] Loss: 0.8699\n",
      "2025-05-30 14:36:54,884 - INFO - Epoch [6/30] Batch [2220/4715] Loss: 1.2428\n",
      "2025-05-30 14:36:56,423 - INFO - Epoch [6/30] Batch [2230/4715] Loss: 1.0539\n",
      "2025-05-30 14:36:58,084 - INFO - Epoch [6/30] Batch [2240/4715] Loss: 0.9416\n",
      "2025-05-30 14:36:59,720 - INFO - Epoch [6/30] Batch [2250/4715] Loss: 1.0693\n",
      "2025-05-30 14:37:01,283 - INFO - Epoch [6/30] Batch [2260/4715] Loss: 0.7181\n",
      "2025-05-30 14:37:02,860 - INFO - Epoch [6/30] Batch [2270/4715] Loss: 0.8482\n",
      "2025-05-30 14:37:04,468 - INFO - Epoch [6/30] Batch [2280/4715] Loss: 0.7989\n",
      "2025-05-30 14:37:06,036 - INFO - Epoch [6/30] Batch [2290/4715] Loss: 0.8923\n",
      "2025-05-30 14:37:07,677 - INFO - Epoch [6/30] Batch [2300/4715] Loss: 0.8356\n",
      "2025-05-30 14:37:09,216 - INFO - Epoch [6/30] Batch [2310/4715] Loss: 0.7643\n",
      "2025-05-30 14:37:10,699 - INFO - Epoch [6/30] Batch [2320/4715] Loss: 0.9085\n",
      "2025-05-30 14:37:12,365 - INFO - Epoch [6/30] Batch [2330/4715] Loss: 0.7051\n",
      "2025-05-30 14:37:13,992 - INFO - Epoch [6/30] Batch [2340/4715] Loss: 0.7617\n",
      "2025-05-30 14:37:15,605 - INFO - Epoch [6/30] Batch [2350/4715] Loss: 0.8070\n",
      "2025-05-30 14:37:17,236 - INFO - Epoch [6/30] Batch [2360/4715] Loss: 0.8551\n",
      "2025-05-30 14:37:18,866 - INFO - Epoch [6/30] Batch [2370/4715] Loss: 0.6907\n",
      "2025-05-30 14:37:20,513 - INFO - Epoch [6/30] Batch [2380/4715] Loss: 0.9221\n",
      "2025-05-30 14:37:22,075 - INFO - Epoch [6/30] Batch [2390/4715] Loss: 0.7472\n",
      "2025-05-30 14:37:23,681 - INFO - Epoch [6/30] Batch [2400/4715] Loss: 0.7918\n",
      "2025-05-30 14:37:25,194 - INFO - Epoch [6/30] Batch [2410/4715] Loss: 0.7913\n",
      "2025-05-30 14:37:26,743 - INFO - Epoch [6/30] Batch [2420/4715] Loss: 0.7929\n",
      "2025-05-30 14:37:28,272 - INFO - Epoch [6/30] Batch [2430/4715] Loss: 0.8570\n",
      "2025-05-30 14:37:29,823 - INFO - Epoch [6/30] Batch [2440/4715] Loss: 0.8022\n",
      "2025-05-30 14:37:31,326 - INFO - Epoch [6/30] Batch [2450/4715] Loss: 0.6886\n",
      "2025-05-30 14:37:32,917 - INFO - Epoch [6/30] Batch [2460/4715] Loss: 1.0940\n",
      "2025-05-30 14:37:34,424 - INFO - Epoch [6/30] Batch [2470/4715] Loss: 0.7434\n",
      "2025-05-30 14:37:35,945 - INFO - Epoch [6/30] Batch [2480/4715] Loss: 0.8343\n",
      "2025-05-30 14:37:37,508 - INFO - Epoch [6/30] Batch [2490/4715] Loss: 0.8610\n",
      "2025-05-30 14:37:39,022 - INFO - Epoch [6/30] Batch [2500/4715] Loss: 0.9560\n",
      "2025-05-30 14:37:40,636 - INFO - Epoch [6/30] Batch [2510/4715] Loss: 0.8376\n",
      "2025-05-30 14:37:42,139 - INFO - Epoch [6/30] Batch [2520/4715] Loss: 0.7189\n",
      "2025-05-30 14:37:43,752 - INFO - Epoch [6/30] Batch [2530/4715] Loss: 0.7282\n",
      "2025-05-30 14:37:45,367 - INFO - Epoch [6/30] Batch [2540/4715] Loss: 0.8910\n",
      "2025-05-30 14:37:46,926 - INFO - Epoch [6/30] Batch [2550/4715] Loss: 0.7539\n",
      "2025-05-30 14:37:48,510 - INFO - Epoch [6/30] Batch [2560/4715] Loss: 0.8490\n",
      "2025-05-30 14:37:50,072 - INFO - Epoch [6/30] Batch [2570/4715] Loss: 0.9532\n",
      "2025-05-30 14:37:51,669 - INFO - Epoch [6/30] Batch [2580/4715] Loss: 0.8974\n",
      "2025-05-30 14:37:53,241 - INFO - Epoch [6/30] Batch [2590/4715] Loss: 1.0176\n",
      "2025-05-30 14:37:54,767 - INFO - Epoch [6/30] Batch [2600/4715] Loss: 0.9520\n",
      "2025-05-30 14:37:56,330 - INFO - Epoch [6/30] Batch [2610/4715] Loss: 0.7804\n",
      "2025-05-30 14:37:57,852 - INFO - Epoch [6/30] Batch [2620/4715] Loss: 0.7926\n",
      "2025-05-30 14:37:59,490 - INFO - Epoch [6/30] Batch [2630/4715] Loss: 0.8196\n",
      "2025-05-30 14:38:01,095 - INFO - Epoch [6/30] Batch [2640/4715] Loss: 0.8336\n",
      "2025-05-30 14:38:02,650 - INFO - Epoch [6/30] Batch [2650/4715] Loss: 1.0666\n",
      "2025-05-30 14:38:04,321 - INFO - Epoch [6/30] Batch [2660/4715] Loss: 0.8265\n",
      "2025-05-30 14:38:05,861 - INFO - Epoch [6/30] Batch [2670/4715] Loss: 0.9376\n",
      "2025-05-30 14:38:07,345 - INFO - Epoch [6/30] Batch [2680/4715] Loss: 0.7809\n",
      "2025-05-30 14:38:08,929 - INFO - Epoch [6/30] Batch [2690/4715] Loss: 0.8911\n",
      "2025-05-30 14:38:10,474 - INFO - Epoch [6/30] Batch [2700/4715] Loss: 0.8244\n",
      "2025-05-30 14:38:12,026 - INFO - Epoch [6/30] Batch [2710/4715] Loss: 0.7054\n",
      "2025-05-30 14:38:13,564 - INFO - Epoch [6/30] Batch [2720/4715] Loss: 0.8449\n",
      "2025-05-30 14:38:15,153 - INFO - Epoch [6/30] Batch [2730/4715] Loss: 0.9963\n",
      "2025-05-30 14:38:16,784 - INFO - Epoch [6/30] Batch [2740/4715] Loss: 1.0130\n",
      "2025-05-30 14:38:18,270 - INFO - Epoch [6/30] Batch [2750/4715] Loss: 1.0948\n",
      "2025-05-30 14:38:19,875 - INFO - Epoch [6/30] Batch [2760/4715] Loss: 0.7908\n",
      "2025-05-30 14:38:21,436 - INFO - Epoch [6/30] Batch [2770/4715] Loss: 0.7793\n",
      "2025-05-30 14:38:23,042 - INFO - Epoch [6/30] Batch [2780/4715] Loss: 0.8590\n",
      "2025-05-30 14:38:24,646 - INFO - Epoch [6/30] Batch [2790/4715] Loss: 0.8022\n",
      "2025-05-30 14:38:26,336 - INFO - Epoch [6/30] Batch [2800/4715] Loss: 0.9016\n",
      "2025-05-30 14:38:27,814 - INFO - Epoch [6/30] Batch [2810/4715] Loss: 0.8388\n",
      "2025-05-30 14:38:29,446 - INFO - Epoch [6/30] Batch [2820/4715] Loss: 0.7617\n",
      "2025-05-30 14:38:31,002 - INFO - Epoch [6/30] Batch [2830/4715] Loss: 0.7617\n",
      "2025-05-30 14:38:32,523 - INFO - Epoch [6/30] Batch [2840/4715] Loss: 0.8189\n",
      "2025-05-30 14:38:34,077 - INFO - Epoch [6/30] Batch [2850/4715] Loss: 0.8934\n",
      "2025-05-30 14:38:35,578 - INFO - Epoch [6/30] Batch [2860/4715] Loss: 0.8124\n",
      "2025-05-30 14:38:37,197 - INFO - Epoch [6/30] Batch [2870/4715] Loss: 0.8700\n",
      "2025-05-30 14:38:38,745 - INFO - Epoch [6/30] Batch [2880/4715] Loss: 0.8628\n",
      "2025-05-30 14:38:40,385 - INFO - Epoch [6/30] Batch [2890/4715] Loss: 0.7265\n",
      "2025-05-30 14:38:41,927 - INFO - Epoch [6/30] Batch [2900/4715] Loss: 0.8603\n",
      "2025-05-30 14:38:43,535 - INFO - Epoch [6/30] Batch [2910/4715] Loss: 0.6450\n",
      "2025-05-30 14:38:45,246 - INFO - Epoch [6/30] Batch [2920/4715] Loss: 0.6545\n",
      "2025-05-30 14:38:46,821 - INFO - Epoch [6/30] Batch [2930/4715] Loss: 0.7235\n",
      "2025-05-30 14:38:48,372 - INFO - Epoch [6/30] Batch [2940/4715] Loss: 1.0015\n",
      "2025-05-30 14:38:49,969 - INFO - Epoch [6/30] Batch [2950/4715] Loss: 0.6225\n",
      "2025-05-30 14:38:51,562 - INFO - Epoch [6/30] Batch [2960/4715] Loss: 0.8938\n",
      "2025-05-30 14:38:53,173 - INFO - Epoch [6/30] Batch [2970/4715] Loss: 0.9212\n",
      "2025-05-30 14:38:54,769 - INFO - Epoch [6/30] Batch [2980/4715] Loss: 0.7254\n",
      "2025-05-30 14:38:56,407 - INFO - Epoch [6/30] Batch [2990/4715] Loss: 0.7670\n",
      "2025-05-30 14:38:58,055 - INFO - Epoch [6/30] Batch [3000/4715] Loss: 0.7927\n",
      "2025-05-30 14:38:59,596 - INFO - Epoch [6/30] Batch [3010/4715] Loss: 0.8836\n",
      "2025-05-30 14:39:01,140 - INFO - Epoch [6/30] Batch [3020/4715] Loss: 0.9014\n",
      "2025-05-30 14:39:02,701 - INFO - Epoch [6/30] Batch [3030/4715] Loss: 0.8269\n",
      "2025-05-30 14:39:04,314 - INFO - Epoch [6/30] Batch [3040/4715] Loss: 0.8264\n",
      "2025-05-30 14:39:05,972 - INFO - Epoch [6/30] Batch [3050/4715] Loss: 0.8108\n",
      "2025-05-30 14:39:07,535 - INFO - Epoch [6/30] Batch [3060/4715] Loss: 0.7620\n",
      "2025-05-30 14:39:09,134 - INFO - Epoch [6/30] Batch [3070/4715] Loss: 1.0107\n",
      "2025-05-30 14:39:10,705 - INFO - Epoch [6/30] Batch [3080/4715] Loss: 0.7383\n",
      "2025-05-30 14:39:12,278 - INFO - Epoch [6/30] Batch [3090/4715] Loss: 0.8145\n",
      "2025-05-30 14:39:13,876 - INFO - Epoch [6/30] Batch [3100/4715] Loss: 1.1237\n",
      "2025-05-30 14:39:15,487 - INFO - Epoch [6/30] Batch [3110/4715] Loss: 0.8997\n",
      "2025-05-30 14:39:17,022 - INFO - Epoch [6/30] Batch [3120/4715] Loss: 0.9710\n",
      "2025-05-30 14:39:18,550 - INFO - Epoch [6/30] Batch [3130/4715] Loss: 0.7496\n",
      "2025-05-30 14:39:20,175 - INFO - Epoch [6/30] Batch [3140/4715] Loss: 0.9012\n",
      "2025-05-30 14:39:21,744 - INFO - Epoch [6/30] Batch [3150/4715] Loss: 0.7983\n",
      "2025-05-30 14:39:23,361 - INFO - Epoch [6/30] Batch [3160/4715] Loss: 0.7716\n",
      "2025-05-30 14:39:24,877 - INFO - Epoch [6/30] Batch [3170/4715] Loss: 0.8110\n",
      "2025-05-30 14:39:26,412 - INFO - Epoch [6/30] Batch [3180/4715] Loss: 0.8398\n",
      "2025-05-30 14:39:27,958 - INFO - Epoch [6/30] Batch [3190/4715] Loss: 0.7366\n",
      "2025-05-30 14:39:29,565 - INFO - Epoch [6/30] Batch [3200/4715] Loss: 0.8798\n",
      "2025-05-30 14:39:31,186 - INFO - Epoch [6/30] Batch [3210/4715] Loss: 0.9067\n",
      "2025-05-30 14:39:32,830 - INFO - Epoch [6/30] Batch [3220/4715] Loss: 0.6368\n",
      "2025-05-30 14:39:34,438 - INFO - Epoch [6/30] Batch [3230/4715] Loss: 0.8346\n",
      "2025-05-30 14:39:36,018 - INFO - Epoch [6/30] Batch [3240/4715] Loss: 0.8866\n",
      "2025-05-30 14:39:37,606 - INFO - Epoch [6/30] Batch [3250/4715] Loss: 0.6372\n",
      "2025-05-30 14:39:39,141 - INFO - Epoch [6/30] Batch [3260/4715] Loss: 0.6726\n",
      "2025-05-30 14:39:40,741 - INFO - Epoch [6/30] Batch [3270/4715] Loss: 0.9872\n",
      "2025-05-30 14:39:42,352 - INFO - Epoch [6/30] Batch [3280/4715] Loss: 0.9140\n",
      "2025-05-30 14:39:43,943 - INFO - Epoch [6/30] Batch [3290/4715] Loss: 0.8210\n",
      "2025-05-30 14:39:45,498 - INFO - Epoch [6/30] Batch [3300/4715] Loss: 0.9146\n",
      "2025-05-30 14:39:47,091 - INFO - Epoch [6/30] Batch [3310/4715] Loss: 0.7552\n",
      "2025-05-30 14:39:48,751 - INFO - Epoch [6/30] Batch [3320/4715] Loss: 1.0357\n",
      "2025-05-30 14:39:50,298 - INFO - Epoch [6/30] Batch [3330/4715] Loss: 0.7254\n",
      "2025-05-30 14:39:51,888 - INFO - Epoch [6/30] Batch [3340/4715] Loss: 0.7964\n",
      "2025-05-30 14:39:53,535 - INFO - Epoch [6/30] Batch [3350/4715] Loss: 0.9164\n",
      "2025-05-30 14:39:55,134 - INFO - Epoch [6/30] Batch [3360/4715] Loss: 1.1590\n",
      "2025-05-30 14:39:56,750 - INFO - Epoch [6/30] Batch [3370/4715] Loss: 0.7228\n",
      "2025-05-30 14:39:58,340 - INFO - Epoch [6/30] Batch [3380/4715] Loss: 0.7443\n",
      "2025-05-30 14:39:59,875 - INFO - Epoch [6/30] Batch [3390/4715] Loss: 0.7041\n",
      "2025-05-30 14:40:01,424 - INFO - Epoch [6/30] Batch [3400/4715] Loss: 0.9777\n",
      "2025-05-30 14:40:03,077 - INFO - Epoch [6/30] Batch [3410/4715] Loss: 1.0652\n",
      "2025-05-30 14:40:04,646 - INFO - Epoch [6/30] Batch [3420/4715] Loss: 0.6890\n",
      "2025-05-30 14:40:06,175 - INFO - Epoch [6/30] Batch [3430/4715] Loss: 0.8607\n",
      "2025-05-30 14:40:07,823 - INFO - Epoch [6/30] Batch [3440/4715] Loss: 0.9568\n",
      "2025-05-30 14:40:09,404 - INFO - Epoch [6/30] Batch [3450/4715] Loss: 0.9827\n",
      "2025-05-30 14:40:10,925 - INFO - Epoch [6/30] Batch [3460/4715] Loss: 0.7492\n",
      "2025-05-30 14:40:12,460 - INFO - Epoch [6/30] Batch [3470/4715] Loss: 0.6962\n",
      "2025-05-30 14:40:14,005 - INFO - Epoch [6/30] Batch [3480/4715] Loss: 0.8655\n",
      "2025-05-30 14:40:15,544 - INFO - Epoch [6/30] Batch [3490/4715] Loss: 0.7353\n",
      "2025-05-30 14:40:17,123 - INFO - Epoch [6/30] Batch [3500/4715] Loss: 0.8226\n",
      "2025-05-30 14:40:18,784 - INFO - Epoch [6/30] Batch [3510/4715] Loss: 0.9504\n",
      "2025-05-30 14:40:20,408 - INFO - Epoch [6/30] Batch [3520/4715] Loss: 1.0063\n",
      "2025-05-30 14:40:21,983 - INFO - Epoch [6/30] Batch [3530/4715] Loss: 0.9097\n",
      "2025-05-30 14:40:23,650 - INFO - Epoch [6/30] Batch [3540/4715] Loss: 1.1344\n",
      "2025-05-30 14:40:25,490 - INFO - Epoch [6/30] Batch [3550/4715] Loss: 0.8509\n",
      "2025-05-30 14:40:27,081 - INFO - Epoch [6/30] Batch [3560/4715] Loss: 1.0244\n",
      "2025-05-30 14:40:28,584 - INFO - Epoch [6/30] Batch [3570/4715] Loss: 0.6194\n",
      "2025-05-30 14:40:30,217 - INFO - Epoch [6/30] Batch [3580/4715] Loss: 0.9746\n",
      "2025-05-30 14:40:31,808 - INFO - Epoch [6/30] Batch [3590/4715] Loss: 0.8895\n",
      "2025-05-30 14:40:33,373 - INFO - Epoch [6/30] Batch [3600/4715] Loss: 0.8673\n",
      "2025-05-30 14:40:34,894 - INFO - Epoch [6/30] Batch [3610/4715] Loss: 0.9627\n",
      "2025-05-30 14:40:36,471 - INFO - Epoch [6/30] Batch [3620/4715] Loss: 0.9977\n",
      "2025-05-30 14:40:38,138 - INFO - Epoch [6/30] Batch [3630/4715] Loss: 0.7411\n",
      "2025-05-30 14:40:39,742 - INFO - Epoch [6/30] Batch [3640/4715] Loss: 0.6982\n",
      "2025-05-30 14:40:41,357 - INFO - Epoch [6/30] Batch [3650/4715] Loss: 1.0281\n",
      "2025-05-30 14:40:42,888 - INFO - Epoch [6/30] Batch [3660/4715] Loss: 0.7315\n",
      "2025-05-30 14:40:44,423 - INFO - Epoch [6/30] Batch [3670/4715] Loss: 0.8284\n",
      "2025-05-30 14:40:46,076 - INFO - Epoch [6/30] Batch [3680/4715] Loss: 0.8380\n",
      "2025-05-30 14:40:47,682 - INFO - Epoch [6/30] Batch [3690/4715] Loss: 0.9232\n",
      "2025-05-30 14:40:49,306 - INFO - Epoch [6/30] Batch [3700/4715] Loss: 0.7529\n",
      "2025-05-30 14:40:50,876 - INFO - Epoch [6/30] Batch [3710/4715] Loss: 0.7965\n",
      "2025-05-30 14:40:52,474 - INFO - Epoch [6/30] Batch [3720/4715] Loss: 0.9980\n",
      "2025-05-30 14:40:54,006 - INFO - Epoch [6/30] Batch [3730/4715] Loss: 0.8118\n",
      "2025-05-30 14:40:55,664 - INFO - Epoch [6/30] Batch [3740/4715] Loss: 0.8028\n",
      "2025-05-30 14:40:57,284 - INFO - Epoch [6/30] Batch [3750/4715] Loss: 0.5916\n",
      "2025-05-30 14:40:58,842 - INFO - Epoch [6/30] Batch [3760/4715] Loss: 0.8000\n",
      "2025-05-30 14:41:00,370 - INFO - Epoch [6/30] Batch [3770/4715] Loss: 0.8733\n",
      "2025-05-30 14:41:01,975 - INFO - Epoch [6/30] Batch [3780/4715] Loss: 0.7549\n",
      "2025-05-30 14:41:03,560 - INFO - Epoch [6/30] Batch [3790/4715] Loss: 0.8369\n",
      "2025-05-30 14:41:05,140 - INFO - Epoch [6/30] Batch [3800/4715] Loss: 0.9878\n",
      "2025-05-30 14:41:06,697 - INFO - Epoch [6/30] Batch [3810/4715] Loss: 0.6320\n",
      "2025-05-30 14:41:08,222 - INFO - Epoch [6/30] Batch [3820/4715] Loss: 0.8678\n",
      "2025-05-30 14:41:09,739 - INFO - Epoch [6/30] Batch [3830/4715] Loss: 0.7325\n",
      "2025-05-30 14:41:11,307 - INFO - Epoch [6/30] Batch [3840/4715] Loss: 0.9606\n",
      "2025-05-30 14:41:12,788 - INFO - Epoch [6/30] Batch [3850/4715] Loss: 0.6573\n",
      "2025-05-30 14:41:14,275 - INFO - Epoch [6/30] Batch [3860/4715] Loss: 0.7996\n",
      "2025-05-30 14:41:15,775 - INFO - Epoch [6/30] Batch [3870/4715] Loss: 0.9180\n",
      "2025-05-30 14:41:17,310 - INFO - Epoch [6/30] Batch [3880/4715] Loss: 1.0047\n",
      "2025-05-30 14:41:18,942 - INFO - Epoch [6/30] Batch [3890/4715] Loss: 1.0739\n",
      "2025-05-30 14:41:20,595 - INFO - Epoch [6/30] Batch [3900/4715] Loss: 0.7758\n",
      "2025-05-30 14:41:22,130 - INFO - Epoch [6/30] Batch [3910/4715] Loss: 1.0645\n",
      "2025-05-30 14:41:23,715 - INFO - Epoch [6/30] Batch [3920/4715] Loss: 1.0728\n",
      "2025-05-30 14:41:25,193 - INFO - Epoch [6/30] Batch [3930/4715] Loss: 0.6592\n",
      "2025-05-30 14:41:26,716 - INFO - Epoch [6/30] Batch [3940/4715] Loss: 0.7096\n",
      "2025-05-30 14:41:28,299 - INFO - Epoch [6/30] Batch [3950/4715] Loss: 0.7881\n",
      "2025-05-30 14:41:29,805 - INFO - Epoch [6/30] Batch [3960/4715] Loss: 0.6832\n",
      "2025-05-30 14:41:31,387 - INFO - Epoch [6/30] Batch [3970/4715] Loss: 0.8507\n",
      "2025-05-30 14:41:32,953 - INFO - Epoch [6/30] Batch [3980/4715] Loss: 1.1417\n",
      "2025-05-30 14:41:34,507 - INFO - Epoch [6/30] Batch [3990/4715] Loss: 0.7753\n",
      "2025-05-30 14:41:36,116 - INFO - Epoch [6/30] Batch [4000/4715] Loss: 0.8369\n",
      "2025-05-30 14:41:37,674 - INFO - Epoch [6/30] Batch [4010/4715] Loss: 0.7754\n",
      "2025-05-30 14:41:39,315 - INFO - Epoch [6/30] Batch [4020/4715] Loss: 0.7879\n",
      "2025-05-30 14:41:40,858 - INFO - Epoch [6/30] Batch [4030/4715] Loss: 0.7514\n",
      "2025-05-30 14:41:42,376 - INFO - Epoch [6/30] Batch [4040/4715] Loss: 1.0778\n",
      "2025-05-30 14:41:43,925 - INFO - Epoch [6/30] Batch [4050/4715] Loss: 0.7347\n",
      "2025-05-30 14:41:45,558 - INFO - Epoch [6/30] Batch [4060/4715] Loss: 0.7950\n",
      "2025-05-30 14:41:47,189 - INFO - Epoch [6/30] Batch [4070/4715] Loss: 0.8459\n",
      "2025-05-30 14:41:48,842 - INFO - Epoch [6/30] Batch [4080/4715] Loss: 0.8400\n",
      "2025-05-30 14:41:50,425 - INFO - Epoch [6/30] Batch [4090/4715] Loss: 0.8033\n",
      "2025-05-30 14:41:51,934 - INFO - Epoch [6/30] Batch [4100/4715] Loss: 0.7390\n",
      "2025-05-30 14:41:53,505 - INFO - Epoch [6/30] Batch [4110/4715] Loss: 0.8791\n",
      "2025-05-30 14:41:55,093 - INFO - Epoch [6/30] Batch [4120/4715] Loss: 0.9527\n",
      "2025-05-30 14:41:56,642 - INFO - Epoch [6/30] Batch [4130/4715] Loss: 0.8407\n",
      "2025-05-30 14:41:58,246 - INFO - Epoch [6/30] Batch [4140/4715] Loss: 0.9044\n",
      "2025-05-30 14:41:59,878 - INFO - Epoch [6/30] Batch [4150/4715] Loss: 0.6122\n",
      "2025-05-30 14:42:01,406 - INFO - Epoch [6/30] Batch [4160/4715] Loss: 0.7817\n",
      "2025-05-30 14:42:02,985 - INFO - Epoch [6/30] Batch [4170/4715] Loss: 0.6253\n",
      "2025-05-30 14:42:04,658 - INFO - Epoch [6/30] Batch [4180/4715] Loss: 0.7676\n",
      "2025-05-30 14:42:06,216 - INFO - Epoch [6/30] Batch [4190/4715] Loss: 0.7204\n",
      "2025-05-30 14:42:07,880 - INFO - Epoch [6/30] Batch [4200/4715] Loss: 0.9149\n",
      "2025-05-30 14:42:09,567 - INFO - Epoch [6/30] Batch [4210/4715] Loss: 1.0155\n",
      "2025-05-30 14:42:11,208 - INFO - Epoch [6/30] Batch [4220/4715] Loss: 0.8177\n",
      "2025-05-30 14:42:12,707 - INFO - Epoch [6/30] Batch [4230/4715] Loss: 0.7808\n",
      "2025-05-30 14:42:14,285 - INFO - Epoch [6/30] Batch [4240/4715] Loss: 0.8596\n",
      "2025-05-30 14:42:15,950 - INFO - Epoch [6/30] Batch [4250/4715] Loss: 0.8416\n",
      "2025-05-30 14:42:17,463 - INFO - Epoch [6/30] Batch [4260/4715] Loss: 0.8690\n",
      "2025-05-30 14:42:19,006 - INFO - Epoch [6/30] Batch [4270/4715] Loss: 0.9511\n",
      "2025-05-30 14:42:20,611 - INFO - Epoch [6/30] Batch [4280/4715] Loss: 1.0513\n",
      "2025-05-30 14:42:22,180 - INFO - Epoch [6/30] Batch [4290/4715] Loss: 0.8440\n",
      "2025-05-30 14:42:23,813 - INFO - Epoch [6/30] Batch [4300/4715] Loss: 0.7202\n",
      "2025-05-30 14:42:25,375 - INFO - Epoch [6/30] Batch [4310/4715] Loss: 1.0031\n",
      "2025-05-30 14:42:27,021 - INFO - Epoch [6/30] Batch [4320/4715] Loss: 0.9678\n",
      "2025-05-30 14:42:28,540 - INFO - Epoch [6/30] Batch [4330/4715] Loss: 0.8178\n",
      "2025-05-30 14:42:30,098 - INFO - Epoch [6/30] Batch [4340/4715] Loss: 0.6492\n",
      "2025-05-30 14:42:31,598 - INFO - Epoch [6/30] Batch [4350/4715] Loss: 0.7771\n",
      "2025-05-30 14:42:33,186 - INFO - Epoch [6/30] Batch [4360/4715] Loss: 0.7981\n",
      "2025-05-30 14:42:34,742 - INFO - Epoch [6/30] Batch [4370/4715] Loss: 0.9119\n",
      "2025-05-30 14:42:36,272 - INFO - Epoch [6/30] Batch [4380/4715] Loss: 0.8536\n",
      "2025-05-30 14:42:37,870 - INFO - Epoch [6/30] Batch [4390/4715] Loss: 1.0638\n",
      "2025-05-30 14:42:39,463 - INFO - Epoch [6/30] Batch [4400/4715] Loss: 0.8902\n",
      "2025-05-30 14:42:41,042 - INFO - Epoch [6/30] Batch [4410/4715] Loss: 0.9927\n",
      "2025-05-30 14:42:42,666 - INFO - Epoch [6/30] Batch [4420/4715] Loss: 0.7442\n",
      "2025-05-30 14:42:44,240 - INFO - Epoch [6/30] Batch [4430/4715] Loss: 0.7259\n",
      "2025-05-30 14:42:45,917 - INFO - Epoch [6/30] Batch [4440/4715] Loss: 1.0076\n",
      "2025-05-30 14:42:47,524 - INFO - Epoch [6/30] Batch [4450/4715] Loss: 0.8807\n",
      "2025-05-30 14:42:49,085 - INFO - Epoch [6/30] Batch [4460/4715] Loss: 0.8742\n",
      "2025-05-30 14:42:50,594 - INFO - Epoch [6/30] Batch [4470/4715] Loss: 0.7975\n",
      "2025-05-30 14:42:52,143 - INFO - Epoch [6/30] Batch [4480/4715] Loss: 0.9560\n",
      "2025-05-30 14:42:53,733 - INFO - Epoch [6/30] Batch [4490/4715] Loss: 0.9353\n",
      "2025-05-30 14:42:55,247 - INFO - Epoch [6/30] Batch [4500/4715] Loss: 0.9813\n",
      "2025-05-30 14:42:56,893 - INFO - Epoch [6/30] Batch [4510/4715] Loss: 0.7891\n",
      "2025-05-30 14:42:58,540 - INFO - Epoch [6/30] Batch [4520/4715] Loss: 0.6348\n",
      "2025-05-30 14:43:00,109 - INFO - Epoch [6/30] Batch [4530/4715] Loss: 0.8822\n",
      "2025-05-30 14:43:01,721 - INFO - Epoch [6/30] Batch [4540/4715] Loss: 0.7975\n",
      "2025-05-30 14:43:03,374 - INFO - Epoch [6/30] Batch [4550/4715] Loss: 0.9545\n",
      "2025-05-30 14:43:04,959 - INFO - Epoch [6/30] Batch [4560/4715] Loss: 0.7984\n",
      "2025-05-30 14:43:06,527 - INFO - Epoch [6/30] Batch [4570/4715] Loss: 0.6039\n",
      "2025-05-30 14:43:08,181 - INFO - Epoch [6/30] Batch [4580/4715] Loss: 0.7311\n",
      "2025-05-30 14:43:09,761 - INFO - Epoch [6/30] Batch [4590/4715] Loss: 0.8278\n",
      "2025-05-30 14:43:11,421 - INFO - Epoch [6/30] Batch [4600/4715] Loss: 0.5641\n",
      "2025-05-30 14:43:13,016 - INFO - Epoch [6/30] Batch [4610/4715] Loss: 0.8700\n",
      "2025-05-30 14:43:14,583 - INFO - Epoch [6/30] Batch [4620/4715] Loss: 0.7335\n",
      "2025-05-30 14:43:16,077 - INFO - Epoch [6/30] Batch [4630/4715] Loss: 0.7532\n",
      "2025-05-30 14:43:17,722 - INFO - Epoch [6/30] Batch [4640/4715] Loss: 1.0109\n",
      "2025-05-30 14:43:19,323 - INFO - Epoch [6/30] Batch [4650/4715] Loss: 1.0693\n",
      "2025-05-30 14:43:20,963 - INFO - Epoch [6/30] Batch [4660/4715] Loss: 0.8921\n",
      "2025-05-30 14:43:22,515 - INFO - Epoch [6/30] Batch [4670/4715] Loss: 0.9383\n",
      "2025-05-30 14:43:24,186 - INFO - Epoch [6/30] Batch [4680/4715] Loss: 0.9907\n",
      "2025-05-30 14:43:25,885 - INFO - Epoch [6/30] Batch [4690/4715] Loss: 0.7827\n",
      "2025-05-30 14:43:27,502 - INFO - Epoch [6/30] Batch [4700/4715] Loss: 1.0270\n",
      "2025-05-30 14:43:29,009 - INFO - Epoch [6/30] Batch [4710/4715] Loss: 0.9232\n",
      "2025-05-30 14:44:07,785 - INFO - \n",
      "Epoch [6/30] Time: 783.91s\n",
      "2025-05-30 14:44:07,785 - INFO - Train Loss: 0.8508, Valid Loss: 0.8465\n",
      "2025-05-30 14:44:07,785 - INFO - Valid AUC (macro): 0.7168, F1 (macro): 0.5258\n",
      "2025-05-30 14:44:08,314 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\best_model.pth\n",
      "2025-05-30 14:44:08,315 - INFO - New best model saved with AUC: 0.7168\n",
      "2025-05-30 14:44:08,822 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 14:44:08,822 - INFO - Saved checkpoint at epoch 6\n",
      "2025-05-30 14:44:09,068 - INFO - Epoch [7/30] Batch [0/4715] Loss: 1.1256\n",
      "2025-05-30 14:44:11,029 - INFO - Epoch [7/30] Batch [10/4715] Loss: 0.8423\n",
      "2025-05-30 14:44:12,683 - INFO - Epoch [7/30] Batch [20/4715] Loss: 0.8772\n",
      "2025-05-30 14:44:14,224 - INFO - Epoch [7/30] Batch [30/4715] Loss: 1.0251\n",
      "2025-05-30 14:44:15,786 - INFO - Epoch [7/30] Batch [40/4715] Loss: 0.7985\n",
      "2025-05-30 14:44:17,417 - INFO - Epoch [7/30] Batch [50/4715] Loss: 0.6535\n",
      "2025-05-30 14:44:19,040 - INFO - Epoch [7/30] Batch [60/4715] Loss: 0.7238\n",
      "2025-05-30 14:44:20,565 - INFO - Epoch [7/30] Batch [70/4715] Loss: 0.7757\n",
      "2025-05-30 14:44:22,149 - INFO - Epoch [7/30] Batch [80/4715] Loss: 1.0355\n",
      "2025-05-30 14:44:23,725 - INFO - Epoch [7/30] Batch [90/4715] Loss: 0.5708\n",
      "2025-05-30 14:44:25,416 - INFO - Epoch [7/30] Batch [100/4715] Loss: 1.0204\n",
      "2025-05-30 14:44:26,986 - INFO - Epoch [7/30] Batch [110/4715] Loss: 0.6783\n",
      "2025-05-30 14:44:28,492 - INFO - Epoch [7/30] Batch [120/4715] Loss: 0.9841\n",
      "2025-05-30 14:44:30,073 - INFO - Epoch [7/30] Batch [130/4715] Loss: 0.7360\n",
      "2025-05-30 14:44:31,643 - INFO - Epoch [7/30] Batch [140/4715] Loss: 0.9677\n",
      "2025-05-30 14:44:33,150 - INFO - Epoch [7/30] Batch [150/4715] Loss: 0.7466\n",
      "2025-05-30 14:44:34,784 - INFO - Epoch [7/30] Batch [160/4715] Loss: 0.7858\n",
      "2025-05-30 14:44:36,299 - INFO - Epoch [7/30] Batch [170/4715] Loss: 0.8879\n",
      "2025-05-30 14:44:38,045 - INFO - Epoch [7/30] Batch [180/4715] Loss: 0.7649\n",
      "2025-05-30 14:44:39,623 - INFO - Epoch [7/30] Batch [190/4715] Loss: 0.8806\n",
      "2025-05-30 14:44:41,172 - INFO - Epoch [7/30] Batch [200/4715] Loss: 0.9500\n",
      "2025-05-30 14:44:42,693 - INFO - Epoch [7/30] Batch [210/4715] Loss: 1.0245\n",
      "2025-05-30 14:44:44,360 - INFO - Epoch [7/30] Batch [220/4715] Loss: 0.8158\n",
      "2025-05-30 14:44:45,944 - INFO - Epoch [7/30] Batch [230/4715] Loss: 1.0080\n",
      "2025-05-30 14:44:47,605 - INFO - Epoch [7/30] Batch [240/4715] Loss: 1.0262\n",
      "2025-05-30 14:44:49,125 - INFO - Epoch [7/30] Batch [250/4715] Loss: 0.8757\n",
      "2025-05-30 14:44:50,694 - INFO - Epoch [7/30] Batch [260/4715] Loss: 0.9063\n",
      "2025-05-30 14:44:52,306 - INFO - Epoch [7/30] Batch [270/4715] Loss: 0.8241\n",
      "2025-05-30 14:44:53,868 - INFO - Epoch [7/30] Batch [280/4715] Loss: 0.8102\n",
      "2025-05-30 14:44:55,432 - INFO - Epoch [7/30] Batch [290/4715] Loss: 0.8070\n",
      "2025-05-30 14:44:56,973 - INFO - Epoch [7/30] Batch [300/4715] Loss: 0.8854\n",
      "2025-05-30 14:44:58,508 - INFO - Epoch [7/30] Batch [310/4715] Loss: 0.7224\n",
      "2025-05-30 14:45:00,155 - INFO - Epoch [7/30] Batch [320/4715] Loss: 0.7169\n",
      "2025-05-30 14:45:01,707 - INFO - Epoch [7/30] Batch [330/4715] Loss: 0.9401\n",
      "2025-05-30 14:45:03,370 - INFO - Epoch [7/30] Batch [340/4715] Loss: 0.7502\n",
      "2025-05-30 14:45:04,877 - INFO - Epoch [7/30] Batch [350/4715] Loss: 0.7193\n",
      "2025-05-30 14:45:06,523 - INFO - Epoch [7/30] Batch [360/4715] Loss: 0.6461\n",
      "2025-05-30 14:45:08,106 - INFO - Epoch [7/30] Batch [370/4715] Loss: 1.0009\n",
      "2025-05-30 14:45:09,704 - INFO - Epoch [7/30] Batch [380/4715] Loss: 0.9318\n",
      "2025-05-30 14:45:11,260 - INFO - Epoch [7/30] Batch [390/4715] Loss: 0.7726\n",
      "2025-05-30 14:45:12,818 - INFO - Epoch [7/30] Batch [400/4715] Loss: 0.8068\n",
      "2025-05-30 14:45:14,464 - INFO - Epoch [7/30] Batch [410/4715] Loss: 0.9838\n",
      "2025-05-30 14:45:15,948 - INFO - Epoch [7/30] Batch [420/4715] Loss: 0.7505\n",
      "2025-05-30 14:45:17,517 - INFO - Epoch [7/30] Batch [430/4715] Loss: 0.8129\n",
      "2025-05-30 14:45:19,060 - INFO - Epoch [7/30] Batch [440/4715] Loss: 0.9489\n",
      "2025-05-30 14:45:20,657 - INFO - Epoch [7/30] Batch [450/4715] Loss: 0.8627\n",
      "2025-05-30 14:45:22,200 - INFO - Epoch [7/30] Batch [460/4715] Loss: 0.7611\n",
      "2025-05-30 14:45:23,823 - INFO - Epoch [7/30] Batch [470/4715] Loss: 0.8267\n",
      "2025-05-30 14:45:25,324 - INFO - Epoch [7/30] Batch [480/4715] Loss: 1.1502\n",
      "2025-05-30 14:45:26,845 - INFO - Epoch [7/30] Batch [490/4715] Loss: 0.8861\n",
      "2025-05-30 14:45:28,424 - INFO - Epoch [7/30] Batch [500/4715] Loss: 0.5844\n",
      "2025-05-30 14:45:29,984 - INFO - Epoch [7/30] Batch [510/4715] Loss: 0.8764\n",
      "2025-05-30 14:45:31,576 - INFO - Epoch [7/30] Batch [520/4715] Loss: 0.8095\n",
      "2025-05-30 14:45:33,096 - INFO - Epoch [7/30] Batch [530/4715] Loss: 0.7361\n",
      "2025-05-30 14:45:34,749 - INFO - Epoch [7/30] Batch [540/4715] Loss: 0.9918\n",
      "2025-05-30 14:45:36,374 - INFO - Epoch [7/30] Batch [550/4715] Loss: 0.8715\n",
      "2025-05-30 14:45:37,895 - INFO - Epoch [7/30] Batch [560/4715] Loss: 0.6034\n",
      "2025-05-30 14:45:39,430 - INFO - Epoch [7/30] Batch [570/4715] Loss: 0.7829\n",
      "2025-05-30 14:45:41,076 - INFO - Epoch [7/30] Batch [580/4715] Loss: 0.8514\n",
      "2025-05-30 14:45:42,620 - INFO - Epoch [7/30] Batch [590/4715] Loss: 1.0336\n",
      "2025-05-30 14:45:44,185 - INFO - Epoch [7/30] Batch [600/4715] Loss: 0.9074\n",
      "2025-05-30 14:45:45,738 - INFO - Epoch [7/30] Batch [610/4715] Loss: 0.8562\n",
      "2025-05-30 14:45:47,303 - INFO - Epoch [7/30] Batch [620/4715] Loss: 0.8299\n",
      "2025-05-30 14:45:48,817 - INFO - Epoch [7/30] Batch [630/4715] Loss: 0.7834\n",
      "2025-05-30 14:45:50,422 - INFO - Epoch [7/30] Batch [640/4715] Loss: 1.0120\n",
      "2025-05-30 14:45:51,994 - INFO - Epoch [7/30] Batch [650/4715] Loss: 0.8896\n",
      "2025-05-30 14:45:53,454 - INFO - Epoch [7/30] Batch [660/4715] Loss: 1.0037\n",
      "2025-05-30 14:45:55,023 - INFO - Epoch [7/30] Batch [670/4715] Loss: 0.7321\n",
      "2025-05-30 14:45:56,574 - INFO - Epoch [7/30] Batch [680/4715] Loss: 0.7797\n",
      "2025-05-30 14:45:58,106 - INFO - Epoch [7/30] Batch [690/4715] Loss: 0.7559\n",
      "2025-05-30 14:45:59,669 - INFO - Epoch [7/30] Batch [700/4715] Loss: 0.8751\n",
      "2025-05-30 14:46:01,302 - INFO - Epoch [7/30] Batch [710/4715] Loss: 0.8377\n",
      "2025-05-30 14:46:02,836 - INFO - Epoch [7/30] Batch [720/4715] Loss: 0.8676\n",
      "2025-05-30 14:46:04,418 - INFO - Epoch [7/30] Batch [730/4715] Loss: 0.8599\n",
      "2025-05-30 14:46:06,041 - INFO - Epoch [7/30] Batch [740/4715] Loss: 0.9618\n",
      "2025-05-30 14:46:07,623 - INFO - Epoch [7/30] Batch [750/4715] Loss: 0.7487\n",
      "2025-05-30 14:46:09,108 - INFO - Epoch [7/30] Batch [760/4715] Loss: 0.7666\n",
      "2025-05-30 14:46:10,678 - INFO - Epoch [7/30] Batch [770/4715] Loss: 0.7229\n",
      "2025-05-30 14:46:12,206 - INFO - Epoch [7/30] Batch [780/4715] Loss: 0.8143\n",
      "2025-05-30 14:46:13,824 - INFO - Epoch [7/30] Batch [790/4715] Loss: 0.6460\n",
      "2025-05-30 14:46:15,442 - INFO - Epoch [7/30] Batch [800/4715] Loss: 1.0862\n",
      "2025-05-30 14:46:16,928 - INFO - Epoch [7/30] Batch [810/4715] Loss: 0.7670\n",
      "2025-05-30 14:46:18,498 - INFO - Epoch [7/30] Batch [820/4715] Loss: 0.8939\n",
      "2025-05-30 14:46:20,026 - INFO - Epoch [7/30] Batch [830/4715] Loss: 0.7677\n",
      "2025-05-30 14:46:21,624 - INFO - Epoch [7/30] Batch [840/4715] Loss: 0.6199\n",
      "2025-05-30 14:46:23,187 - INFO - Epoch [7/30] Batch [850/4715] Loss: 0.9795\n",
      "2025-05-30 14:46:24,805 - INFO - Epoch [7/30] Batch [860/4715] Loss: 0.9770\n",
      "2025-05-30 14:46:26,388 - INFO - Epoch [7/30] Batch [870/4715] Loss: 0.8159\n",
      "2025-05-30 14:46:27,923 - INFO - Epoch [7/30] Batch [880/4715] Loss: 0.9335\n",
      "2025-05-30 14:46:29,527 - INFO - Epoch [7/30] Batch [890/4715] Loss: 0.7466\n",
      "2025-05-30 14:46:31,125 - INFO - Epoch [7/30] Batch [900/4715] Loss: 0.8725\n",
      "2025-05-30 14:46:32,666 - INFO - Epoch [7/30] Batch [910/4715] Loss: 0.8764\n",
      "2025-05-30 14:46:34,188 - INFO - Epoch [7/30] Batch [920/4715] Loss: 0.6932\n",
      "2025-05-30 14:46:35,804 - INFO - Epoch [7/30] Batch [930/4715] Loss: 0.8710\n",
      "2025-05-30 14:46:37,369 - INFO - Epoch [7/30] Batch [940/4715] Loss: 1.1923\n",
      "2025-05-30 14:46:38,858 - INFO - Epoch [7/30] Batch [950/4715] Loss: 0.6664\n",
      "2025-05-30 14:46:40,543 - INFO - Epoch [7/30] Batch [960/4715] Loss: 0.8167\n",
      "2025-05-30 14:46:42,085 - INFO - Epoch [7/30] Batch [970/4715] Loss: 0.9517\n",
      "2025-05-30 14:46:43,603 - INFO - Epoch [7/30] Batch [980/4715] Loss: 0.8479\n",
      "2025-05-30 14:46:45,123 - INFO - Epoch [7/30] Batch [990/4715] Loss: 0.7435\n",
      "2025-05-30 14:46:46,684 - INFO - Epoch [7/30] Batch [1000/4715] Loss: 1.0835\n",
      "2025-05-30 14:46:48,256 - INFO - Epoch [7/30] Batch [1010/4715] Loss: 0.9257\n",
      "2025-05-30 14:46:49,818 - INFO - Epoch [7/30] Batch [1020/4715] Loss: 1.0107\n",
      "2025-05-30 14:46:51,343 - INFO - Epoch [7/30] Batch [1030/4715] Loss: 0.7448\n",
      "2025-05-30 14:46:52,829 - INFO - Epoch [7/30] Batch [1040/4715] Loss: 0.7362\n",
      "2025-05-30 14:46:54,469 - INFO - Epoch [7/30] Batch [1050/4715] Loss: 0.8684\n",
      "2025-05-30 14:46:56,035 - INFO - Epoch [7/30] Batch [1060/4715] Loss: 0.9858\n",
      "2025-05-30 14:46:57,650 - INFO - Epoch [7/30] Batch [1070/4715] Loss: 0.6572\n",
      "2025-05-30 14:46:59,178 - INFO - Epoch [7/30] Batch [1080/4715] Loss: 0.9628\n",
      "2025-05-30 14:47:00,740 - INFO - Epoch [7/30] Batch [1090/4715] Loss: 0.9120\n",
      "2025-05-30 14:47:02,362 - INFO - Epoch [7/30] Batch [1100/4715] Loss: 0.8363\n",
      "2025-05-30 14:47:03,949 - INFO - Epoch [7/30] Batch [1110/4715] Loss: 0.9718\n",
      "2025-05-30 14:47:05,538 - INFO - Epoch [7/30] Batch [1120/4715] Loss: 0.9652\n",
      "2025-05-30 14:47:07,175 - INFO - Epoch [7/30] Batch [1130/4715] Loss: 1.0701\n",
      "2025-05-30 14:47:08,769 - INFO - Epoch [7/30] Batch [1140/4715] Loss: 0.7449\n",
      "2025-05-30 14:47:10,403 - INFO - Epoch [7/30] Batch [1150/4715] Loss: 0.8125\n",
      "2025-05-30 14:47:12,023 - INFO - Epoch [7/30] Batch [1160/4715] Loss: 0.8115\n",
      "2025-05-30 14:47:13,610 - INFO - Epoch [7/30] Batch [1170/4715] Loss: 0.7962\n",
      "2025-05-30 14:47:15,315 - INFO - Epoch [7/30] Batch [1180/4715] Loss: 0.7797\n",
      "2025-05-30 14:47:16,862 - INFO - Epoch [7/30] Batch [1190/4715] Loss: 0.9479\n",
      "2025-05-30 14:47:18,444 - INFO - Epoch [7/30] Batch [1200/4715] Loss: 0.6913\n",
      "2025-05-30 14:47:20,055 - INFO - Epoch [7/30] Batch [1210/4715] Loss: 0.8777\n",
      "2025-05-30 14:47:21,703 - INFO - Epoch [7/30] Batch [1220/4715] Loss: 0.9318\n",
      "2025-05-30 14:47:23,419 - INFO - Epoch [7/30] Batch [1230/4715] Loss: 0.7666\n",
      "2025-05-30 14:47:24,987 - INFO - Epoch [7/30] Batch [1240/4715] Loss: 0.8550\n",
      "2025-05-30 14:47:26,570 - INFO - Epoch [7/30] Batch [1250/4715] Loss: 0.9602\n",
      "2025-05-30 14:47:28,244 - INFO - Epoch [7/30] Batch [1260/4715] Loss: 0.8100\n",
      "2025-05-30 14:47:29,754 - INFO - Epoch [7/30] Batch [1270/4715] Loss: 0.7988\n",
      "2025-05-30 14:47:31,304 - INFO - Epoch [7/30] Batch [1280/4715] Loss: 0.8508\n",
      "2025-05-30 14:47:32,887 - INFO - Epoch [7/30] Batch [1290/4715] Loss: 1.2218\n",
      "2025-05-30 14:47:34,433 - INFO - Epoch [7/30] Batch [1300/4715] Loss: 0.8578\n",
      "2025-05-30 14:47:35,946 - INFO - Epoch [7/30] Batch [1310/4715] Loss: 0.9535\n",
      "2025-05-30 14:47:37,567 - INFO - Epoch [7/30] Batch [1320/4715] Loss: 0.7197\n",
      "2025-05-30 14:47:39,063 - INFO - Epoch [7/30] Batch [1330/4715] Loss: 0.7768\n",
      "2025-05-30 14:47:40,607 - INFO - Epoch [7/30] Batch [1340/4715] Loss: 0.8233\n",
      "2025-05-30 14:47:42,198 - INFO - Epoch [7/30] Batch [1350/4715] Loss: 1.1902\n",
      "2025-05-30 14:47:43,763 - INFO - Epoch [7/30] Batch [1360/4715] Loss: 1.0847\n",
      "2025-05-30 14:47:45,341 - INFO - Epoch [7/30] Batch [1370/4715] Loss: 0.6712\n",
      "2025-05-30 14:47:46,927 - INFO - Epoch [7/30] Batch [1380/4715] Loss: 0.7201\n",
      "2025-05-30 14:47:48,488 - INFO - Epoch [7/30] Batch [1390/4715] Loss: 0.8655\n",
      "2025-05-30 14:47:50,139 - INFO - Epoch [7/30] Batch [1400/4715] Loss: 0.9275\n",
      "2025-05-30 14:47:51,810 - INFO - Epoch [7/30] Batch [1410/4715] Loss: 0.7144\n",
      "2025-05-30 14:47:53,324 - INFO - Epoch [7/30] Batch [1420/4715] Loss: 0.6699\n",
      "2025-05-30 14:47:54,908 - INFO - Epoch [7/30] Batch [1430/4715] Loss: 0.5560\n",
      "2025-05-30 14:47:56,491 - INFO - Epoch [7/30] Batch [1440/4715] Loss: 0.6560\n",
      "2025-05-30 14:47:58,107 - INFO - Epoch [7/30] Batch [1450/4715] Loss: 0.8113\n",
      "2025-05-30 14:47:59,624 - INFO - Epoch [7/30] Batch [1460/4715] Loss: 0.6338\n",
      "2025-05-30 14:48:01,266 - INFO - Epoch [7/30] Batch [1470/4715] Loss: 0.7525\n",
      "2025-05-30 14:48:02,909 - INFO - Epoch [7/30] Batch [1480/4715] Loss: 1.0162\n",
      "2025-05-30 14:48:04,471 - INFO - Epoch [7/30] Batch [1490/4715] Loss: 0.8071\n",
      "2025-05-30 14:48:05,986 - INFO - Epoch [7/30] Batch [1500/4715] Loss: 0.9403\n",
      "2025-05-30 14:48:07,519 - INFO - Epoch [7/30] Batch [1510/4715] Loss: 0.7405\n",
      "2025-05-30 14:48:09,085 - INFO - Epoch [7/30] Batch [1520/4715] Loss: 0.8290\n",
      "2025-05-30 14:48:10,695 - INFO - Epoch [7/30] Batch [1530/4715] Loss: 1.0659\n",
      "2025-05-30 14:48:12,221 - INFO - Epoch [7/30] Batch [1540/4715] Loss: 0.9295\n",
      "2025-05-30 14:48:13,773 - INFO - Epoch [7/30] Batch [1550/4715] Loss: 0.8696\n",
      "2025-05-30 14:48:15,356 - INFO - Epoch [7/30] Batch [1560/4715] Loss: 0.7757\n",
      "2025-05-30 14:48:16,945 - INFO - Epoch [7/30] Batch [1570/4715] Loss: 0.8973\n",
      "2025-05-30 14:48:18,569 - INFO - Epoch [7/30] Batch [1580/4715] Loss: 0.8321\n",
      "2025-05-30 14:48:20,022 - INFO - Epoch [7/30] Batch [1590/4715] Loss: 1.0610\n",
      "2025-05-30 14:48:21,523 - INFO - Epoch [7/30] Batch [1600/4715] Loss: 0.8675\n",
      "2025-05-30 14:48:23,092 - INFO - Epoch [7/30] Batch [1610/4715] Loss: 0.8662\n",
      "2025-05-30 14:48:24,724 - INFO - Epoch [7/30] Batch [1620/4715] Loss: 0.5754\n",
      "2025-05-30 14:48:26,520 - INFO - Epoch [7/30] Batch [1630/4715] Loss: 0.8327\n",
      "2025-05-30 14:48:28,093 - INFO - Epoch [7/30] Batch [1640/4715] Loss: 0.8023\n",
      "2025-05-30 14:48:29,630 - INFO - Epoch [7/30] Batch [1650/4715] Loss: 0.7999\n",
      "2025-05-30 14:48:31,256 - INFO - Epoch [7/30] Batch [1660/4715] Loss: 0.7047\n",
      "2025-05-30 14:48:32,823 - INFO - Epoch [7/30] Batch [1670/4715] Loss: 0.7382\n",
      "2025-05-30 14:48:34,421 - INFO - Epoch [7/30] Batch [1680/4715] Loss: 0.8111\n",
      "2025-05-30 14:48:35,990 - INFO - Epoch [7/30] Batch [1690/4715] Loss: 0.7124\n",
      "2025-05-30 14:48:37,555 - INFO - Epoch [7/30] Batch [1700/4715] Loss: 0.8663\n",
      "2025-05-30 14:48:39,109 - INFO - Epoch [7/30] Batch [1710/4715] Loss: 0.8201\n",
      "2025-05-30 14:48:40,726 - INFO - Epoch [7/30] Batch [1720/4715] Loss: 1.1693\n",
      "2025-05-30 14:48:42,326 - INFO - Epoch [7/30] Batch [1730/4715] Loss: 0.7865\n",
      "2025-05-30 14:48:43,993 - INFO - Epoch [7/30] Batch [1740/4715] Loss: 0.8883\n",
      "2025-05-30 14:48:45,608 - INFO - Epoch [7/30] Batch [1750/4715] Loss: 0.6764\n",
      "2025-05-30 14:48:47,206 - INFO - Epoch [7/30] Batch [1760/4715] Loss: 0.8499\n",
      "2025-05-30 14:48:48,779 - INFO - Epoch [7/30] Batch [1770/4715] Loss: 0.5949\n",
      "2025-05-30 14:48:50,340 - INFO - Epoch [7/30] Batch [1780/4715] Loss: 0.9038\n",
      "2025-05-30 14:48:51,908 - INFO - Epoch [7/30] Batch [1790/4715] Loss: 0.7108\n",
      "2025-05-30 14:48:53,506 - INFO - Epoch [7/30] Batch [1800/4715] Loss: 0.9278\n",
      "2025-05-30 14:48:55,203 - INFO - Epoch [7/30] Batch [1810/4715] Loss: 0.8923\n",
      "2025-05-30 14:48:56,875 - INFO - Epoch [7/30] Batch [1820/4715] Loss: 0.7735\n",
      "2025-05-30 14:48:58,493 - INFO - Epoch [7/30] Batch [1830/4715] Loss: 0.7697\n",
      "2025-05-30 14:49:00,088 - INFO - Epoch [7/30] Batch [1840/4715] Loss: 0.6404\n",
      "2025-05-30 14:49:01,667 - INFO - Epoch [7/30] Batch [1850/4715] Loss: 0.6486\n",
      "2025-05-30 14:49:03,205 - INFO - Epoch [7/30] Batch [1860/4715] Loss: 0.6056\n",
      "2025-05-30 14:49:04,800 - INFO - Epoch [7/30] Batch [1870/4715] Loss: 0.9784\n",
      "2025-05-30 14:49:06,293 - INFO - Epoch [7/30] Batch [1880/4715] Loss: 0.9708\n",
      "2025-05-30 14:49:07,914 - INFO - Epoch [7/30] Batch [1890/4715] Loss: 0.9666\n",
      "2025-05-30 14:49:09,488 - INFO - Epoch [7/30] Batch [1900/4715] Loss: 0.7288\n",
      "2025-05-30 14:49:11,059 - INFO - Epoch [7/30] Batch [1910/4715] Loss: 0.9099\n",
      "2025-05-30 14:49:12,710 - INFO - Epoch [7/30] Batch [1920/4715] Loss: 0.8990\n",
      "2025-05-30 14:49:14,370 - INFO - Epoch [7/30] Batch [1930/4715] Loss: 0.8065\n",
      "2025-05-30 14:49:15,898 - INFO - Epoch [7/30] Batch [1940/4715] Loss: 1.0452\n",
      "2025-05-30 14:49:17,426 - INFO - Epoch [7/30] Batch [1950/4715] Loss: 1.0425\n",
      "2025-05-30 14:49:18,985 - INFO - Epoch [7/30] Batch [1960/4715] Loss: 1.0122\n",
      "2025-05-30 14:49:20,585 - INFO - Epoch [7/30] Batch [1970/4715] Loss: 0.8652\n",
      "2025-05-30 14:49:22,378 - INFO - Epoch [7/30] Batch [1980/4715] Loss: 0.8092\n",
      "2025-05-30 14:49:23,927 - INFO - Epoch [7/30] Batch [1990/4715] Loss: 0.8629\n",
      "2025-05-30 14:49:25,490 - INFO - Epoch [7/30] Batch [2000/4715] Loss: 0.8023\n",
      "2025-05-30 14:49:27,087 - INFO - Epoch [7/30] Batch [2010/4715] Loss: 0.7737\n",
      "2025-05-30 14:49:28,650 - INFO - Epoch [7/30] Batch [2020/4715] Loss: 0.9505\n",
      "2025-05-30 14:49:30,172 - INFO - Epoch [7/30] Batch [2030/4715] Loss: 0.7396\n",
      "2025-05-30 14:49:31,741 - INFO - Epoch [7/30] Batch [2040/4715] Loss: 0.9795\n",
      "2025-05-30 14:49:33,309 - INFO - Epoch [7/30] Batch [2050/4715] Loss: 0.6982\n",
      "2025-05-30 14:49:34,806 - INFO - Epoch [7/30] Batch [2060/4715] Loss: 0.8712\n",
      "2025-05-30 14:49:36,341 - INFO - Epoch [7/30] Batch [2070/4715] Loss: 0.8117\n",
      "2025-05-30 14:49:37,915 - INFO - Epoch [7/30] Batch [2080/4715] Loss: 0.6995\n",
      "2025-05-30 14:49:39,450 - INFO - Epoch [7/30] Batch [2090/4715] Loss: 0.9820\n",
      "2025-05-30 14:49:41,056 - INFO - Epoch [7/30] Batch [2100/4715] Loss: 0.8513\n",
      "2025-05-30 14:49:42,666 - INFO - Epoch [7/30] Batch [2110/4715] Loss: 0.7797\n",
      "2025-05-30 14:49:44,243 - INFO - Epoch [7/30] Batch [2120/4715] Loss: 0.6634\n",
      "2025-05-30 14:49:45,847 - INFO - Epoch [7/30] Batch [2130/4715] Loss: 0.8908\n",
      "2025-05-30 14:49:47,396 - INFO - Epoch [7/30] Batch [2140/4715] Loss: 0.9353\n",
      "2025-05-30 14:49:49,065 - INFO - Epoch [7/30] Batch [2150/4715] Loss: 0.7689\n",
      "2025-05-30 14:49:50,619 - INFO - Epoch [7/30] Batch [2160/4715] Loss: 0.9723\n",
      "2025-05-30 14:49:52,207 - INFO - Epoch [7/30] Batch [2170/4715] Loss: 0.9775\n",
      "2025-05-30 14:49:53,786 - INFO - Epoch [7/30] Batch [2180/4715] Loss: 0.9360\n",
      "2025-05-30 14:49:55,389 - INFO - Epoch [7/30] Batch [2190/4715] Loss: 1.0069\n",
      "2025-05-30 14:49:57,022 - INFO - Epoch [7/30] Batch [2200/4715] Loss: 0.8035\n",
      "2025-05-30 14:49:58,585 - INFO - Epoch [7/30] Batch [2210/4715] Loss: 1.0289\n",
      "2025-05-30 14:50:00,156 - INFO - Epoch [7/30] Batch [2220/4715] Loss: 0.6612\n",
      "2025-05-30 14:50:01,740 - INFO - Epoch [7/30] Batch [2230/4715] Loss: 0.7316\n",
      "2025-05-30 14:50:03,325 - INFO - Epoch [7/30] Batch [2240/4715] Loss: 0.8596\n",
      "2025-05-30 14:50:04,905 - INFO - Epoch [7/30] Batch [2250/4715] Loss: 0.8744\n",
      "2025-05-30 14:50:06,455 - INFO - Epoch [7/30] Batch [2260/4715] Loss: 0.6369\n",
      "2025-05-30 14:50:08,061 - INFO - Epoch [7/30] Batch [2270/4715] Loss: 0.7174\n",
      "2025-05-30 14:50:09,690 - INFO - Epoch [7/30] Batch [2280/4715] Loss: 0.9737\n",
      "2025-05-30 14:50:11,309 - INFO - Epoch [7/30] Batch [2290/4715] Loss: 1.1320\n",
      "2025-05-30 14:50:12,893 - INFO - Epoch [7/30] Batch [2300/4715] Loss: 0.7876\n",
      "2025-05-30 14:50:14,491 - INFO - Epoch [7/30] Batch [2310/4715] Loss: 0.8666\n",
      "2025-05-30 14:50:16,170 - INFO - Epoch [7/30] Batch [2320/4715] Loss: 0.7741\n",
      "2025-05-30 14:50:17,755 - INFO - Epoch [7/30] Batch [2330/4715] Loss: 0.8306\n",
      "2025-05-30 14:50:19,403 - INFO - Epoch [7/30] Batch [2340/4715] Loss: 0.8368\n",
      "2025-05-30 14:50:21,005 - INFO - Epoch [7/30] Batch [2350/4715] Loss: 0.7781\n",
      "2025-05-30 14:50:22,644 - INFO - Epoch [7/30] Batch [2360/4715] Loss: 0.8901\n",
      "2025-05-30 14:50:24,207 - INFO - Epoch [7/30] Batch [2370/4715] Loss: 0.8263\n",
      "2025-05-30 14:50:25,716 - INFO - Epoch [7/30] Batch [2380/4715] Loss: 0.7269\n",
      "2025-05-30 14:50:27,325 - INFO - Epoch [7/30] Batch [2390/4715] Loss: 0.8590\n",
      "2025-05-30 14:50:28,825 - INFO - Epoch [7/30] Batch [2400/4715] Loss: 0.8663\n",
      "2025-05-30 14:50:30,367 - INFO - Epoch [7/30] Batch [2410/4715] Loss: 0.8267\n",
      "2025-05-30 14:50:31,992 - INFO - Epoch [7/30] Batch [2420/4715] Loss: 0.6207\n",
      "2025-05-30 14:50:33,514 - INFO - Epoch [7/30] Batch [2430/4715] Loss: 0.9748\n",
      "2025-05-30 14:50:35,138 - INFO - Epoch [7/30] Batch [2440/4715] Loss: 0.8055\n",
      "2025-05-30 14:50:36,743 - INFO - Epoch [7/30] Batch [2450/4715] Loss: 0.7988\n",
      "2025-05-30 14:50:38,368 - INFO - Epoch [7/30] Batch [2460/4715] Loss: 0.6347\n",
      "2025-05-30 14:50:39,910 - INFO - Epoch [7/30] Batch [2470/4715] Loss: 0.6941\n",
      "2025-05-30 14:50:41,494 - INFO - Epoch [7/30] Batch [2480/4715] Loss: 0.7946\n",
      "2025-05-30 14:50:42,987 - INFO - Epoch [7/30] Batch [2490/4715] Loss: 0.8433\n",
      "2025-05-30 14:50:44,565 - INFO - Epoch [7/30] Batch [2500/4715] Loss: 0.9627\n",
      "2025-05-30 14:50:46,071 - INFO - Epoch [7/30] Batch [2510/4715] Loss: 0.9811\n",
      "2025-05-30 14:50:47,624 - INFO - Epoch [7/30] Batch [2520/4715] Loss: 0.7297\n",
      "2025-05-30 14:50:49,210 - INFO - Epoch [7/30] Batch [2530/4715] Loss: 0.9072\n",
      "2025-05-30 14:50:50,696 - INFO - Epoch [7/30] Batch [2540/4715] Loss: 0.8526\n",
      "2025-05-30 14:50:52,328 - INFO - Epoch [7/30] Batch [2550/4715] Loss: 0.8664\n",
      "2025-05-30 14:50:53,905 - INFO - Epoch [7/30] Batch [2560/4715] Loss: 0.9349\n",
      "2025-05-30 14:50:55,442 - INFO - Epoch [7/30] Batch [2570/4715] Loss: 0.8100\n",
      "2025-05-30 14:50:56,984 - INFO - Epoch [7/30] Batch [2580/4715] Loss: 0.7284\n",
      "2025-05-30 14:50:58,602 - INFO - Epoch [7/30] Batch [2590/4715] Loss: 0.6782\n",
      "2025-05-30 14:51:00,234 - INFO - Epoch [7/30] Batch [2600/4715] Loss: 0.7272\n",
      "2025-05-30 14:51:01,819 - INFO - Epoch [7/30] Batch [2610/4715] Loss: 0.4995\n",
      "2025-05-30 14:51:03,365 - INFO - Epoch [7/30] Batch [2620/4715] Loss: 0.8375\n",
      "2025-05-30 14:51:04,934 - INFO - Epoch [7/30] Batch [2630/4715] Loss: 0.7455\n",
      "2025-05-30 14:51:06,523 - INFO - Epoch [7/30] Batch [2640/4715] Loss: 0.7441\n",
      "2025-05-30 14:51:08,022 - INFO - Epoch [7/30] Batch [2650/4715] Loss: 0.8732\n",
      "2025-05-30 14:51:09,559 - INFO - Epoch [7/30] Batch [2660/4715] Loss: 0.9074\n",
      "2025-05-30 14:51:11,164 - INFO - Epoch [7/30] Batch [2670/4715] Loss: 1.0128\n",
      "2025-05-30 14:51:12,644 - INFO - Epoch [7/30] Batch [2680/4715] Loss: 0.7287\n",
      "2025-05-30 14:51:14,096 - INFO - Epoch [7/30] Batch [2690/4715] Loss: 0.9430\n",
      "2025-05-30 14:51:15,737 - INFO - Epoch [7/30] Batch [2700/4715] Loss: 0.6057\n",
      "2025-05-30 14:51:17,387 - INFO - Epoch [7/30] Batch [2710/4715] Loss: 1.0084\n",
      "2025-05-30 14:51:19,041 - INFO - Epoch [7/30] Batch [2720/4715] Loss: 0.8080\n",
      "2025-05-30 14:51:20,623 - INFO - Epoch [7/30] Batch [2730/4715] Loss: 0.8507\n",
      "2025-05-30 14:51:22,159 - INFO - Epoch [7/30] Batch [2740/4715] Loss: 0.9759\n",
      "2025-05-30 14:51:23,816 - INFO - Epoch [7/30] Batch [2750/4715] Loss: 0.6398\n",
      "2025-05-30 14:51:25,424 - INFO - Epoch [7/30] Batch [2760/4715] Loss: 0.6735\n",
      "2025-05-30 14:51:27,024 - INFO - Epoch [7/30] Batch [2770/4715] Loss: 0.7857\n",
      "2025-05-30 14:51:28,662 - INFO - Epoch [7/30] Batch [2780/4715] Loss: 0.8436\n",
      "2025-05-30 14:51:30,240 - INFO - Epoch [7/30] Batch [2790/4715] Loss: 0.8558\n",
      "2025-05-30 14:51:31,848 - INFO - Epoch [7/30] Batch [2800/4715] Loss: 0.6834\n",
      "2025-05-30 14:51:33,376 - INFO - Epoch [7/30] Batch [2810/4715] Loss: 0.9012\n",
      "2025-05-30 14:51:34,857 - INFO - Epoch [7/30] Batch [2820/4715] Loss: 1.1222\n",
      "2025-05-30 14:51:36,519 - INFO - Epoch [7/30] Batch [2830/4715] Loss: 1.0908\n",
      "2025-05-30 14:51:38,118 - INFO - Epoch [7/30] Batch [2840/4715] Loss: 0.6467\n",
      "2025-05-30 14:51:39,697 - INFO - Epoch [7/30] Batch [2850/4715] Loss: 1.0077\n",
      "2025-05-30 14:51:41,328 - INFO - Epoch [7/30] Batch [2860/4715] Loss: 0.7638\n",
      "2025-05-30 14:51:42,928 - INFO - Epoch [7/30] Batch [2870/4715] Loss: 0.8417\n",
      "2025-05-30 14:51:44,456 - INFO - Epoch [7/30] Batch [2880/4715] Loss: 0.8948\n",
      "2025-05-30 14:51:46,082 - INFO - Epoch [7/30] Batch [2890/4715] Loss: 0.9898\n",
      "2025-05-30 14:51:47,691 - INFO - Epoch [7/30] Batch [2900/4715] Loss: 0.8228\n",
      "2025-05-30 14:51:49,219 - INFO - Epoch [7/30] Batch [2910/4715] Loss: 0.9092\n",
      "2025-05-30 14:51:50,795 - INFO - Epoch [7/30] Batch [2920/4715] Loss: 0.9218\n",
      "2025-05-30 14:51:52,344 - INFO - Epoch [7/30] Batch [2930/4715] Loss: 0.8345\n",
      "2025-05-30 14:51:53,976 - INFO - Epoch [7/30] Batch [2940/4715] Loss: 0.8204\n",
      "2025-05-30 14:51:55,546 - INFO - Epoch [7/30] Batch [2950/4715] Loss: 0.7833\n",
      "2025-05-30 14:51:57,206 - INFO - Epoch [7/30] Batch [2960/4715] Loss: 0.8109\n",
      "2025-05-30 14:51:58,788 - INFO - Epoch [7/30] Batch [2970/4715] Loss: 0.8738\n",
      "2025-05-30 14:52:00,387 - INFO - Epoch [7/30] Batch [2980/4715] Loss: 0.9130\n",
      "2025-05-30 14:52:01,966 - INFO - Epoch [7/30] Batch [2990/4715] Loss: 0.9812\n",
      "2025-05-30 14:52:03,623 - INFO - Epoch [7/30] Batch [3000/4715] Loss: 0.7574\n",
      "2025-05-30 14:52:05,222 - INFO - Epoch [7/30] Batch [3010/4715] Loss: 1.0379\n",
      "2025-05-30 14:52:06,846 - INFO - Epoch [7/30] Batch [3020/4715] Loss: 0.6972\n",
      "2025-05-30 14:52:08,367 - INFO - Epoch [7/30] Batch [3030/4715] Loss: 0.8805\n",
      "2025-05-30 14:52:09,874 - INFO - Epoch [7/30] Batch [3040/4715] Loss: 0.8233\n",
      "2025-05-30 14:52:11,444 - INFO - Epoch [7/30] Batch [3050/4715] Loss: 0.8904\n",
      "2025-05-30 14:52:13,086 - INFO - Epoch [7/30] Batch [3060/4715] Loss: 0.8915\n",
      "2025-05-30 14:52:14,664 - INFO - Epoch [7/30] Batch [3070/4715] Loss: 0.7065\n",
      "2025-05-30 14:52:16,259 - INFO - Epoch [7/30] Batch [3080/4715] Loss: 0.7756\n",
      "2025-05-30 14:52:17,800 - INFO - Epoch [7/30] Batch [3090/4715] Loss: 0.8428\n",
      "2025-05-30 14:52:19,369 - INFO - Epoch [7/30] Batch [3100/4715] Loss: 0.8591\n",
      "2025-05-30 14:52:20,897 - INFO - Epoch [7/30] Batch [3110/4715] Loss: 1.2534\n",
      "2025-05-30 14:52:22,424 - INFO - Epoch [7/30] Batch [3120/4715] Loss: 0.6888\n",
      "2025-05-30 14:52:24,036 - INFO - Epoch [7/30] Batch [3130/4715] Loss: 0.8537\n",
      "2025-05-30 14:52:25,578 - INFO - Epoch [7/30] Batch [3140/4715] Loss: 0.9766\n",
      "2025-05-30 14:52:27,106 - INFO - Epoch [7/30] Batch [3150/4715] Loss: 0.8985\n",
      "2025-05-30 14:52:28,696 - INFO - Epoch [7/30] Batch [3160/4715] Loss: 0.7924\n",
      "2025-05-30 14:52:30,367 - INFO - Epoch [7/30] Batch [3170/4715] Loss: 1.1031\n",
      "2025-05-30 14:52:32,065 - INFO - Epoch [7/30] Batch [3180/4715] Loss: 0.9823\n",
      "2025-05-30 14:52:33,808 - INFO - Epoch [7/30] Batch [3190/4715] Loss: 0.9203\n",
      "2025-05-30 14:52:35,338 - INFO - Epoch [7/30] Batch [3200/4715] Loss: 0.8937\n",
      "2025-05-30 14:52:37,010 - INFO - Epoch [7/30] Batch [3210/4715] Loss: 0.9791\n",
      "2025-05-30 14:52:38,658 - INFO - Epoch [7/30] Batch [3220/4715] Loss: 0.7743\n",
      "2025-05-30 14:52:40,260 - INFO - Epoch [7/30] Batch [3230/4715] Loss: 0.8451\n",
      "2025-05-30 14:52:41,907 - INFO - Epoch [7/30] Batch [3240/4715] Loss: 0.7213\n",
      "2025-05-30 14:52:43,468 - INFO - Epoch [7/30] Batch [3250/4715] Loss: 0.7566\n",
      "2025-05-30 14:52:45,040 - INFO - Epoch [7/30] Batch [3260/4715] Loss: 0.9548\n",
      "2025-05-30 14:52:46,619 - INFO - Epoch [7/30] Batch [3270/4715] Loss: 0.9788\n",
      "2025-05-30 14:52:48,173 - INFO - Epoch [7/30] Batch [3280/4715] Loss: 0.8533\n",
      "2025-05-30 14:52:49,833 - INFO - Epoch [7/30] Batch [3290/4715] Loss: 0.9888\n",
      "2025-05-30 14:52:51,408 - INFO - Epoch [7/30] Batch [3300/4715] Loss: 0.6654\n",
      "2025-05-30 14:52:52,978 - INFO - Epoch [7/30] Batch [3310/4715] Loss: 0.9281\n",
      "2025-05-30 14:52:54,562 - INFO - Epoch [7/30] Batch [3320/4715] Loss: 0.7524\n",
      "2025-05-30 14:52:56,096 - INFO - Epoch [7/30] Batch [3330/4715] Loss: 0.7183\n",
      "2025-05-30 14:52:57,673 - INFO - Epoch [7/30] Batch [3340/4715] Loss: 1.0364\n",
      "2025-05-30 14:52:59,249 - INFO - Epoch [7/30] Batch [3350/4715] Loss: 0.8994\n",
      "2025-05-30 14:53:00,923 - INFO - Epoch [7/30] Batch [3360/4715] Loss: 0.7021\n",
      "2025-05-30 14:53:02,481 - INFO - Epoch [7/30] Batch [3370/4715] Loss: 0.8306\n",
      "2025-05-30 14:53:04,076 - INFO - Epoch [7/30] Batch [3380/4715] Loss: 0.5590\n",
      "2025-05-30 14:53:05,625 - INFO - Epoch [7/30] Batch [3390/4715] Loss: 0.7083\n",
      "2025-05-30 14:53:07,218 - INFO - Epoch [7/30] Batch [3400/4715] Loss: 0.7108\n",
      "2025-05-30 14:53:08,861 - INFO - Epoch [7/30] Batch [3410/4715] Loss: 0.7492\n",
      "2025-05-30 14:53:10,502 - INFO - Epoch [7/30] Batch [3420/4715] Loss: 0.7956\n",
      "2025-05-30 14:53:12,105 - INFO - Epoch [7/30] Batch [3430/4715] Loss: 0.7693\n",
      "2025-05-30 14:53:13,684 - INFO - Epoch [7/30] Batch [3440/4715] Loss: 0.6489\n",
      "2025-05-30 14:53:15,224 - INFO - Epoch [7/30] Batch [3450/4715] Loss: 1.0606\n",
      "2025-05-30 14:53:16,739 - INFO - Epoch [7/30] Batch [3460/4715] Loss: 0.9172\n",
      "2025-05-30 14:53:18,273 - INFO - Epoch [7/30] Batch [3470/4715] Loss: 0.8373\n",
      "2025-05-30 14:53:19,869 - INFO - Epoch [7/30] Batch [3480/4715] Loss: 1.1700\n",
      "2025-05-30 14:53:21,435 - INFO - Epoch [7/30] Batch [3490/4715] Loss: 0.8032\n",
      "2025-05-30 14:53:23,041 - INFO - Epoch [7/30] Batch [3500/4715] Loss: 0.9612\n",
      "2025-05-30 14:53:24,642 - INFO - Epoch [7/30] Batch [3510/4715] Loss: 0.8223\n",
      "2025-05-30 14:53:26,115 - INFO - Epoch [7/30] Batch [3520/4715] Loss: 1.0470\n",
      "2025-05-30 14:53:27,656 - INFO - Epoch [7/30] Batch [3530/4715] Loss: 1.1475\n",
      "2025-05-30 14:53:29,246 - INFO - Epoch [7/30] Batch [3540/4715] Loss: 0.6260\n",
      "2025-05-30 14:53:30,883 - INFO - Epoch [7/30] Batch [3550/4715] Loss: 0.9890\n",
      "2025-05-30 14:53:32,521 - INFO - Epoch [7/30] Batch [3560/4715] Loss: 0.7829\n",
      "2025-05-30 14:53:34,074 - INFO - Epoch [7/30] Batch [3570/4715] Loss: 0.5698\n",
      "2025-05-30 14:53:35,618 - INFO - Epoch [7/30] Batch [3580/4715] Loss: 0.8422\n",
      "2025-05-30 14:53:37,185 - INFO - Epoch [7/30] Batch [3590/4715] Loss: 1.1193\n",
      "2025-05-30 14:53:38,788 - INFO - Epoch [7/30] Batch [3600/4715] Loss: 0.9561\n",
      "2025-05-30 14:53:40,359 - INFO - Epoch [7/30] Batch [3610/4715] Loss: 0.9905\n",
      "2025-05-30 14:53:41,880 - INFO - Epoch [7/30] Batch [3620/4715] Loss: 0.8274\n",
      "2025-05-30 14:53:43,561 - INFO - Epoch [7/30] Batch [3630/4715] Loss: 0.8861\n",
      "2025-05-30 14:53:45,145 - INFO - Epoch [7/30] Batch [3640/4715] Loss: 1.1713\n",
      "2025-05-30 14:53:46,737 - INFO - Epoch [7/30] Batch [3650/4715] Loss: 0.7674\n",
      "2025-05-30 14:53:48,249 - INFO - Epoch [7/30] Batch [3660/4715] Loss: 0.8656\n",
      "2025-05-30 14:53:49,722 - INFO - Epoch [7/30] Batch [3670/4715] Loss: 0.9323\n",
      "2025-05-30 14:53:51,326 - INFO - Epoch [7/30] Batch [3680/4715] Loss: 0.7637\n",
      "2025-05-30 14:53:52,962 - INFO - Epoch [7/30] Batch [3690/4715] Loss: 0.9207\n",
      "2025-05-30 14:53:54,493 - INFO - Epoch [7/30] Batch [3700/4715] Loss: 0.7770\n",
      "2025-05-30 14:53:56,023 - INFO - Epoch [7/30] Batch [3710/4715] Loss: 0.9602\n",
      "2025-05-30 14:53:57,607 - INFO - Epoch [7/30] Batch [3720/4715] Loss: 1.1384\n",
      "2025-05-30 14:53:59,140 - INFO - Epoch [7/30] Batch [3730/4715] Loss: 0.9259\n",
      "2025-05-30 14:54:00,644 - INFO - Epoch [7/30] Batch [3740/4715] Loss: 0.7994\n",
      "2025-05-30 14:54:02,184 - INFO - Epoch [7/30] Batch [3750/4715] Loss: 0.8822\n",
      "2025-05-30 14:54:03,786 - INFO - Epoch [7/30] Batch [3760/4715] Loss: 0.7465\n",
      "2025-05-30 14:54:05,377 - INFO - Epoch [7/30] Batch [3770/4715] Loss: 1.0518\n",
      "2025-05-30 14:54:06,974 - INFO - Epoch [7/30] Batch [3780/4715] Loss: 0.7461\n",
      "2025-05-30 14:54:08,552 - INFO - Epoch [7/30] Batch [3790/4715] Loss: 0.9874\n",
      "2025-05-30 14:54:10,052 - INFO - Epoch [7/30] Batch [3800/4715] Loss: 0.7055\n",
      "2025-05-30 14:54:11,607 - INFO - Epoch [7/30] Batch [3810/4715] Loss: 0.8866\n",
      "2025-05-30 14:54:13,246 - INFO - Epoch [7/30] Batch [3820/4715] Loss: 0.8624\n",
      "2025-05-30 14:54:14,795 - INFO - Epoch [7/30] Batch [3830/4715] Loss: 0.4829\n",
      "2025-05-30 14:54:16,365 - INFO - Epoch [7/30] Batch [3840/4715] Loss: 0.8094\n",
      "2025-05-30 14:54:17,885 - INFO - Epoch [7/30] Batch [3850/4715] Loss: 1.1362\n",
      "2025-05-30 14:54:19,460 - INFO - Epoch [7/30] Batch [3860/4715] Loss: 0.7552\n",
      "2025-05-30 14:54:20,969 - INFO - Epoch [7/30] Batch [3870/4715] Loss: 0.7536\n",
      "2025-05-30 14:54:22,504 - INFO - Epoch [7/30] Batch [3880/4715] Loss: 0.7734\n",
      "2025-05-30 14:54:24,129 - INFO - Epoch [7/30] Batch [3890/4715] Loss: 0.7346\n",
      "2025-05-30 14:54:25,748 - INFO - Epoch [7/30] Batch [3900/4715] Loss: 0.7953\n",
      "2025-05-30 14:54:27,373 - INFO - Epoch [7/30] Batch [3910/4715] Loss: 0.7536\n",
      "2025-05-30 14:54:28,916 - INFO - Epoch [7/30] Batch [3920/4715] Loss: 0.8215\n",
      "2025-05-30 14:54:30,470 - INFO - Epoch [7/30] Batch [3930/4715] Loss: 0.8627\n",
      "2025-05-30 14:54:32,026 - INFO - Epoch [7/30] Batch [3940/4715] Loss: 0.6818\n",
      "2025-05-30 14:54:33,596 - INFO - Epoch [7/30] Batch [3950/4715] Loss: 1.0091\n",
      "2025-05-30 14:54:35,173 - INFO - Epoch [7/30] Batch [3960/4715] Loss: 0.7481\n",
      "2025-05-30 14:54:36,666 - INFO - Epoch [7/30] Batch [3970/4715] Loss: 0.9095\n",
      "2025-05-30 14:54:38,313 - INFO - Epoch [7/30] Batch [3980/4715] Loss: 0.7740\n",
      "2025-05-30 14:54:39,974 - INFO - Epoch [7/30] Batch [3990/4715] Loss: 0.9039\n",
      "2025-05-30 14:54:41,588 - INFO - Epoch [7/30] Batch [4000/4715] Loss: 0.6456\n",
      "2025-05-30 14:54:43,121 - INFO - Epoch [7/30] Batch [4010/4715] Loss: 0.6991\n",
      "2025-05-30 14:54:44,674 - INFO - Epoch [7/30] Batch [4020/4715] Loss: 0.7659\n",
      "2025-05-30 14:54:46,183 - INFO - Epoch [7/30] Batch [4030/4715] Loss: 1.0127\n",
      "2025-05-30 14:54:47,753 - INFO - Epoch [7/30] Batch [4040/4715] Loss: 0.6315\n",
      "2025-05-30 14:54:49,363 - INFO - Epoch [7/30] Batch [4050/4715] Loss: 0.5945\n",
      "2025-05-30 14:54:51,085 - INFO - Epoch [7/30] Batch [4060/4715] Loss: 0.5984\n",
      "2025-05-30 14:54:52,761 - INFO - Epoch [7/30] Batch [4070/4715] Loss: 0.8652\n",
      "2025-05-30 14:54:54,446 - INFO - Epoch [7/30] Batch [4080/4715] Loss: 0.8217\n",
      "2025-05-30 14:54:56,044 - INFO - Epoch [7/30] Batch [4090/4715] Loss: 0.7073\n",
      "2025-05-30 14:54:57,659 - INFO - Epoch [7/30] Batch [4100/4715] Loss: 0.7326\n",
      "2025-05-30 14:54:59,285 - INFO - Epoch [7/30] Batch [4110/4715] Loss: 0.6201\n",
      "2025-05-30 14:55:00,843 - INFO - Epoch [7/30] Batch [4120/4715] Loss: 0.9926\n",
      "2025-05-30 14:55:02,475 - INFO - Epoch [7/30] Batch [4130/4715] Loss: 0.7914\n",
      "2025-05-30 14:55:04,093 - INFO - Epoch [7/30] Batch [4140/4715] Loss: 0.9705\n",
      "2025-05-30 14:55:05,705 - INFO - Epoch [7/30] Batch [4150/4715] Loss: 0.7721\n",
      "2025-05-30 14:55:07,274 - INFO - Epoch [7/30] Batch [4160/4715] Loss: 0.7559\n",
      "2025-05-30 14:55:08,941 - INFO - Epoch [7/30] Batch [4170/4715] Loss: 0.8683\n",
      "2025-05-30 14:55:10,535 - INFO - Epoch [7/30] Batch [4180/4715] Loss: 0.8867\n",
      "2025-05-30 14:55:12,095 - INFO - Epoch [7/30] Batch [4190/4715] Loss: 0.8117\n",
      "2025-05-30 14:55:13,775 - INFO - Epoch [7/30] Batch [4200/4715] Loss: 0.6122\n",
      "2025-05-30 14:55:15,324 - INFO - Epoch [7/30] Batch [4210/4715] Loss: 0.7655\n",
      "2025-05-30 14:55:16,821 - INFO - Epoch [7/30] Batch [4220/4715] Loss: 0.8979\n",
      "2025-05-30 14:55:18,407 - INFO - Epoch [7/30] Batch [4230/4715] Loss: 0.8785\n",
      "2025-05-30 14:55:19,922 - INFO - Epoch [7/30] Batch [4240/4715] Loss: 0.8923\n",
      "2025-05-30 14:55:21,442 - INFO - Epoch [7/30] Batch [4250/4715] Loss: 0.6734\n",
      "2025-05-30 14:55:23,026 - INFO - Epoch [7/30] Batch [4260/4715] Loss: 0.7676\n",
      "2025-05-30 14:55:24,641 - INFO - Epoch [7/30] Batch [4270/4715] Loss: 0.8822\n",
      "2025-05-30 14:55:26,242 - INFO - Epoch [7/30] Batch [4280/4715] Loss: 0.7977\n",
      "2025-05-30 14:55:27,777 - INFO - Epoch [7/30] Batch [4290/4715] Loss: 0.6627\n",
      "2025-05-30 14:55:29,375 - INFO - Epoch [7/30] Batch [4300/4715] Loss: 0.7225\n",
      "2025-05-30 14:55:31,139 - INFO - Epoch [7/30] Batch [4310/4715] Loss: 0.8281\n",
      "2025-05-30 14:55:32,709 - INFO - Epoch [7/30] Batch [4320/4715] Loss: 0.7120\n",
      "2025-05-30 14:55:34,195 - INFO - Epoch [7/30] Batch [4330/4715] Loss: 0.7265\n",
      "2025-05-30 14:55:35,723 - INFO - Epoch [7/30] Batch [4340/4715] Loss: 0.7945\n",
      "2025-05-30 14:55:37,293 - INFO - Epoch [7/30] Batch [4350/4715] Loss: 0.7446\n",
      "2025-05-30 14:55:38,897 - INFO - Epoch [7/30] Batch [4360/4715] Loss: 0.8461\n",
      "2025-05-30 14:55:40,474 - INFO - Epoch [7/30] Batch [4370/4715] Loss: 0.8415\n",
      "2025-05-30 14:55:42,023 - INFO - Epoch [7/30] Batch [4380/4715] Loss: 0.7846\n",
      "2025-05-30 14:55:43,604 - INFO - Epoch [7/30] Batch [4390/4715] Loss: 0.9237\n",
      "2025-05-30 14:55:45,158 - INFO - Epoch [7/30] Batch [4400/4715] Loss: 0.8176\n",
      "2025-05-30 14:55:46,745 - INFO - Epoch [7/30] Batch [4410/4715] Loss: 0.9638\n",
      "2025-05-30 14:55:48,274 - INFO - Epoch [7/30] Batch [4420/4715] Loss: 0.8037\n",
      "2025-05-30 14:55:49,815 - INFO - Epoch [7/30] Batch [4430/4715] Loss: 0.9040\n",
      "2025-05-30 14:55:51,392 - INFO - Epoch [7/30] Batch [4440/4715] Loss: 0.6557\n",
      "2025-05-30 14:55:52,892 - INFO - Epoch [7/30] Batch [4450/4715] Loss: 0.7830\n",
      "2025-05-30 14:55:54,448 - INFO - Epoch [7/30] Batch [4460/4715] Loss: 0.6607\n",
      "2025-05-30 14:55:55,941 - INFO - Epoch [7/30] Batch [4470/4715] Loss: 0.8365\n",
      "2025-05-30 14:55:57,573 - INFO - Epoch [7/30] Batch [4480/4715] Loss: 0.7658\n",
      "2025-05-30 14:55:59,087 - INFO - Epoch [7/30] Batch [4490/4715] Loss: 0.8795\n",
      "2025-05-30 14:56:00,608 - INFO - Epoch [7/30] Batch [4500/4715] Loss: 1.2496\n",
      "2025-05-30 14:56:02,164 - INFO - Epoch [7/30] Batch [4510/4715] Loss: 0.7321\n",
      "2025-05-30 14:56:03,721 - INFO - Epoch [7/30] Batch [4520/4715] Loss: 0.8723\n",
      "2025-05-30 14:56:05,297 - INFO - Epoch [7/30] Batch [4530/4715] Loss: 0.6351\n",
      "2025-05-30 14:56:06,832 - INFO - Epoch [7/30] Batch [4540/4715] Loss: 0.7937\n",
      "2025-05-30 14:56:08,368 - INFO - Epoch [7/30] Batch [4550/4715] Loss: 0.7607\n",
      "2025-05-30 14:56:09,992 - INFO - Epoch [7/30] Batch [4560/4715] Loss: 0.9076\n",
      "2025-05-30 14:56:11,547 - INFO - Epoch [7/30] Batch [4570/4715] Loss: 0.7330\n",
      "2025-05-30 14:56:13,123 - INFO - Epoch [7/30] Batch [4580/4715] Loss: 0.8337\n",
      "2025-05-30 14:56:14,725 - INFO - Epoch [7/30] Batch [4590/4715] Loss: 0.9505\n",
      "2025-05-30 14:56:16,277 - INFO - Epoch [7/30] Batch [4600/4715] Loss: 0.7903\n",
      "2025-05-30 14:56:17,812 - INFO - Epoch [7/30] Batch [4610/4715] Loss: 0.8625\n",
      "2025-05-30 14:56:19,357 - INFO - Epoch [7/30] Batch [4620/4715] Loss: 0.8066\n",
      "2025-05-30 14:56:20,924 - INFO - Epoch [7/30] Batch [4630/4715] Loss: 0.8480\n",
      "2025-05-30 14:56:22,540 - INFO - Epoch [7/30] Batch [4640/4715] Loss: 0.9463\n",
      "2025-05-30 14:56:24,105 - INFO - Epoch [7/30] Batch [4650/4715] Loss: 0.9302\n",
      "2025-05-30 14:56:25,615 - INFO - Epoch [7/30] Batch [4660/4715] Loss: 0.9498\n",
      "2025-05-30 14:56:27,223 - INFO - Epoch [7/30] Batch [4670/4715] Loss: 0.7495\n",
      "2025-05-30 14:56:28,779 - INFO - Epoch [7/30] Batch [4680/4715] Loss: 0.7456\n",
      "2025-05-30 14:56:30,342 - INFO - Epoch [7/30] Batch [4690/4715] Loss: 0.9640\n",
      "2025-05-30 14:56:31,897 - INFO - Epoch [7/30] Batch [4700/4715] Loss: 0.9634\n",
      "2025-05-30 14:56:33,414 - INFO - Epoch [7/30] Batch [4710/4715] Loss: 0.7181\n",
      "2025-05-30 14:57:12,302 - INFO - \n",
      "Epoch [7/30] Time: 783.48s\n",
      "2025-05-30 14:57:12,303 - INFO - Train Loss: 0.8430, Valid Loss: 0.8370\n",
      "2025-05-30 14:57:12,303 - INFO - Valid AUC (macro): 0.7204, F1 (macro): 0.5508\n",
      "2025-05-30 14:57:12,835 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\best_model.pth\n",
      "2025-05-30 14:57:12,836 - INFO - New best model saved with AUC: 0.7204\n",
      "2025-05-30 14:57:13,357 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 14:57:13,357 - INFO - Saved checkpoint at epoch 7\n",
      "2025-05-30 14:57:13,570 - INFO - Epoch [8/30] Batch [0/4715] Loss: 0.8545\n",
      "2025-05-30 14:57:15,494 - INFO - Epoch [8/30] Batch [10/4715] Loss: 0.7975\n",
      "2025-05-30 14:57:17,041 - INFO - Epoch [8/30] Batch [20/4715] Loss: 0.8582\n",
      "2025-05-30 14:57:18,485 - INFO - Epoch [8/30] Batch [30/4715] Loss: 0.8694\n",
      "2025-05-30 14:57:19,967 - INFO - Epoch [8/30] Batch [40/4715] Loss: 0.7714\n",
      "2025-05-30 14:57:21,509 - INFO - Epoch [8/30] Batch [50/4715] Loss: 0.8556\n",
      "2025-05-30 14:57:23,038 - INFO - Epoch [8/30] Batch [60/4715] Loss: 0.7752\n",
      "2025-05-30 14:57:24,586 - INFO - Epoch [8/30] Batch [70/4715] Loss: 0.6768\n",
      "2025-05-30 14:57:26,127 - INFO - Epoch [8/30] Batch [80/4715] Loss: 0.7759\n",
      "2025-05-30 14:57:27,753 - INFO - Epoch [8/30] Batch [90/4715] Loss: 0.7677\n",
      "2025-05-30 14:57:29,375 - INFO - Epoch [8/30] Batch [100/4715] Loss: 0.9880\n",
      "2025-05-30 14:57:30,864 - INFO - Epoch [8/30] Batch [110/4715] Loss: 0.8098\n",
      "2025-05-30 14:57:32,385 - INFO - Epoch [8/30] Batch [120/4715] Loss: 0.8189\n",
      "2025-05-30 14:57:33,927 - INFO - Epoch [8/30] Batch [130/4715] Loss: 0.8443\n",
      "2025-05-30 14:57:35,573 - INFO - Epoch [8/30] Batch [140/4715] Loss: 0.7662\n",
      "2025-05-30 14:57:37,136 - INFO - Epoch [8/30] Batch [150/4715] Loss: 0.8589\n",
      "2025-05-30 14:57:38,747 - INFO - Epoch [8/30] Batch [160/4715] Loss: 0.5584\n",
      "2025-05-30 14:57:40,422 - INFO - Epoch [8/30] Batch [170/4715] Loss: 0.8525\n",
      "2025-05-30 14:57:41,962 - INFO - Epoch [8/30] Batch [180/4715] Loss: 0.7569\n",
      "2025-05-30 14:57:43,538 - INFO - Epoch [8/30] Batch [190/4715] Loss: 0.7419\n",
      "2025-05-30 14:57:45,067 - INFO - Epoch [8/30] Batch [200/4715] Loss: 0.8588\n",
      "2025-05-30 14:57:46,644 - INFO - Epoch [8/30] Batch [210/4715] Loss: 0.5698\n",
      "2025-05-30 14:57:48,207 - INFO - Epoch [8/30] Batch [220/4715] Loss: 0.6297\n",
      "2025-05-30 14:57:49,737 - INFO - Epoch [8/30] Batch [230/4715] Loss: 0.9996\n",
      "2025-05-30 14:57:51,269 - INFO - Epoch [8/30] Batch [240/4715] Loss: 0.6945\n",
      "2025-05-30 14:57:52,904 - INFO - Epoch [8/30] Batch [250/4715] Loss: 0.7188\n",
      "2025-05-30 14:57:54,451 - INFO - Epoch [8/30] Batch [260/4715] Loss: 0.9551\n",
      "2025-05-30 14:57:55,944 - INFO - Epoch [8/30] Batch [270/4715] Loss: 0.8273\n",
      "2025-05-30 14:57:57,542 - INFO - Epoch [8/30] Batch [280/4715] Loss: 0.7732\n",
      "2025-05-30 14:57:59,144 - INFO - Epoch [8/30] Batch [290/4715] Loss: 0.7869\n",
      "2025-05-30 14:58:00,718 - INFO - Epoch [8/30] Batch [300/4715] Loss: 0.9443\n",
      "2025-05-30 14:58:02,340 - INFO - Epoch [8/30] Batch [310/4715] Loss: 0.9488\n",
      "2025-05-30 14:58:03,868 - INFO - Epoch [8/30] Batch [320/4715] Loss: 0.6982\n",
      "2025-05-30 14:58:05,376 - INFO - Epoch [8/30] Batch [330/4715] Loss: 0.9424\n",
      "2025-05-30 14:58:06,987 - INFO - Epoch [8/30] Batch [340/4715] Loss: 0.7987\n",
      "2025-05-30 14:58:08,574 - INFO - Epoch [8/30] Batch [350/4715] Loss: 0.6959\n",
      "2025-05-30 14:58:10,126 - INFO - Epoch [8/30] Batch [360/4715] Loss: 1.0567\n",
      "2025-05-30 14:58:11,687 - INFO - Epoch [8/30] Batch [370/4715] Loss: 0.5784\n",
      "2025-05-30 14:58:13,176 - INFO - Epoch [8/30] Batch [380/4715] Loss: 1.0043\n",
      "2025-05-30 14:58:14,731 - INFO - Epoch [8/30] Batch [390/4715] Loss: 0.9568\n",
      "2025-05-30 14:58:16,308 - INFO - Epoch [8/30] Batch [400/4715] Loss: 0.7041\n",
      "2025-05-30 14:58:17,850 - INFO - Epoch [8/30] Batch [410/4715] Loss: 0.9749\n",
      "2025-05-30 14:58:19,447 - INFO - Epoch [8/30] Batch [420/4715] Loss: 1.1613\n",
      "2025-05-30 14:58:20,996 - INFO - Epoch [8/30] Batch [430/4715] Loss: 0.9442\n",
      "2025-05-30 14:58:22,662 - INFO - Epoch [8/30] Batch [440/4715] Loss: 0.8547\n",
      "2025-05-30 14:58:24,223 - INFO - Epoch [8/30] Batch [450/4715] Loss: 0.9946\n",
      "2025-05-30 14:58:25,726 - INFO - Epoch [8/30] Batch [460/4715] Loss: 0.9060\n",
      "2025-05-30 14:58:27,331 - INFO - Epoch [8/30] Batch [470/4715] Loss: 0.7125\n",
      "2025-05-30 14:58:28,942 - INFO - Epoch [8/30] Batch [480/4715] Loss: 0.6012\n",
      "2025-05-30 14:58:30,617 - INFO - Epoch [8/30] Batch [490/4715] Loss: 0.6719\n",
      "2025-05-30 14:58:32,218 - INFO - Epoch [8/30] Batch [500/4715] Loss: 0.8040\n",
      "2025-05-30 14:58:33,705 - INFO - Epoch [8/30] Batch [510/4715] Loss: 0.7857\n",
      "2025-05-30 14:58:35,304 - INFO - Epoch [8/30] Batch [520/4715] Loss: 0.8078\n",
      "2025-05-30 14:58:36,841 - INFO - Epoch [8/30] Batch [530/4715] Loss: 0.9214\n",
      "2025-05-30 14:58:38,442 - INFO - Epoch [8/30] Batch [540/4715] Loss: 0.9351\n",
      "2025-05-30 14:58:40,048 - INFO - Epoch [8/30] Batch [550/4715] Loss: 0.7165\n",
      "2025-05-30 14:58:41,608 - INFO - Epoch [8/30] Batch [560/4715] Loss: 0.8646\n",
      "2025-05-30 14:58:43,136 - INFO - Epoch [8/30] Batch [570/4715] Loss: 0.7628\n",
      "2025-05-30 14:58:44,729 - INFO - Epoch [8/30] Batch [580/4715] Loss: 0.6732\n",
      "2025-05-30 14:58:46,326 - INFO - Epoch [8/30] Batch [590/4715] Loss: 0.7979\n",
      "2025-05-30 14:58:47,896 - INFO - Epoch [8/30] Batch [600/4715] Loss: 1.0886\n",
      "2025-05-30 14:58:49,389 - INFO - Epoch [8/30] Batch [610/4715] Loss: 0.9501\n",
      "2025-05-30 14:58:50,959 - INFO - Epoch [8/30] Batch [620/4715] Loss: 0.7513\n",
      "2025-05-30 14:58:52,549 - INFO - Epoch [8/30] Batch [630/4715] Loss: 0.8166\n",
      "2025-05-30 14:58:54,113 - INFO - Epoch [8/30] Batch [640/4715] Loss: 0.6344\n",
      "2025-05-30 14:58:55,697 - INFO - Epoch [8/30] Batch [650/4715] Loss: 0.8587\n",
      "2025-05-30 14:58:57,224 - INFO - Epoch [8/30] Batch [660/4715] Loss: 0.7378\n",
      "2025-05-30 14:58:58,743 - INFO - Epoch [8/30] Batch [670/4715] Loss: 0.6424\n",
      "2025-05-30 14:59:00,287 - INFO - Epoch [8/30] Batch [680/4715] Loss: 0.6752\n",
      "2025-05-30 14:59:01,921 - INFO - Epoch [8/30] Batch [690/4715] Loss: 0.9605\n",
      "2025-05-30 14:59:03,462 - INFO - Epoch [8/30] Batch [700/4715] Loss: 0.9674\n",
      "2025-05-30 14:59:05,017 - INFO - Epoch [8/30] Batch [710/4715] Loss: 0.8953\n",
      "2025-05-30 14:59:06,615 - INFO - Epoch [8/30] Batch [720/4715] Loss: 0.8342\n",
      "2025-05-30 14:59:08,137 - INFO - Epoch [8/30] Batch [730/4715] Loss: 0.8106\n",
      "2025-05-30 14:59:09,670 - INFO - Epoch [8/30] Batch [740/4715] Loss: 1.0275\n",
      "2025-05-30 14:59:11,274 - INFO - Epoch [8/30] Batch [750/4715] Loss: 1.1973\n",
      "2025-05-30 14:59:12,927 - INFO - Epoch [8/30] Batch [760/4715] Loss: 0.8784\n",
      "2025-05-30 14:59:14,537 - INFO - Epoch [8/30] Batch [770/4715] Loss: 0.6092\n",
      "2025-05-30 14:59:16,143 - INFO - Epoch [8/30] Batch [780/4715] Loss: 0.7182\n",
      "2025-05-30 14:59:17,767 - INFO - Epoch [8/30] Batch [790/4715] Loss: 0.8225\n",
      "2025-05-30 14:59:19,309 - INFO - Epoch [8/30] Batch [800/4715] Loss: 0.8412\n",
      "2025-05-30 14:59:20,866 - INFO - Epoch [8/30] Batch [810/4715] Loss: 0.8127\n",
      "2025-05-30 14:59:22,408 - INFO - Epoch [8/30] Batch [820/4715] Loss: 0.7192\n",
      "2025-05-30 14:59:23,998 - INFO - Epoch [8/30] Batch [830/4715] Loss: 0.9210\n",
      "2025-05-30 14:59:25,547 - INFO - Epoch [8/30] Batch [840/4715] Loss: 0.7209\n",
      "2025-05-30 14:59:27,158 - INFO - Epoch [8/30] Batch [850/4715] Loss: 1.0589\n",
      "2025-05-30 14:59:28,720 - INFO - Epoch [8/30] Batch [860/4715] Loss: 0.6994\n",
      "2025-05-30 14:59:30,256 - INFO - Epoch [8/30] Batch [870/4715] Loss: 1.1441\n",
      "2025-05-30 14:59:31,895 - INFO - Epoch [8/30] Batch [880/4715] Loss: 0.7756\n",
      "2025-05-30 14:59:33,423 - INFO - Epoch [8/30] Batch [890/4715] Loss: 0.8059\n",
      "2025-05-30 14:59:34,942 - INFO - Epoch [8/30] Batch [900/4715] Loss: 0.8035\n",
      "2025-05-30 14:59:36,526 - INFO - Epoch [8/30] Batch [910/4715] Loss: 1.0290\n",
      "2025-05-30 14:59:38,125 - INFO - Epoch [8/30] Batch [920/4715] Loss: 0.7608\n",
      "2025-05-30 14:59:39,667 - INFO - Epoch [8/30] Batch [930/4715] Loss: 0.9463\n",
      "2025-05-30 14:59:41,273 - INFO - Epoch [8/30] Batch [940/4715] Loss: 0.7995\n",
      "2025-05-30 14:59:42,793 - INFO - Epoch [8/30] Batch [950/4715] Loss: 0.9257\n",
      "2025-05-30 14:59:44,350 - INFO - Epoch [8/30] Batch [960/4715] Loss: 0.6985\n",
      "2025-05-30 14:59:45,965 - INFO - Epoch [8/30] Batch [970/4715] Loss: 0.8362\n",
      "2025-05-30 14:59:47,522 - INFO - Epoch [8/30] Batch [980/4715] Loss: 0.6203\n",
      "2025-05-30 14:59:49,085 - INFO - Epoch [8/30] Batch [990/4715] Loss: 0.7963\n",
      "2025-05-30 14:59:50,637 - INFO - Epoch [8/30] Batch [1000/4715] Loss: 0.8224\n",
      "2025-05-30 14:59:52,238 - INFO - Epoch [8/30] Batch [1010/4715] Loss: 1.1226\n",
      "2025-05-30 14:59:53,850 - INFO - Epoch [8/30] Batch [1020/4715] Loss: 0.7501\n",
      "2025-05-30 14:59:55,487 - INFO - Epoch [8/30] Batch [1030/4715] Loss: 0.8009\n",
      "2025-05-30 14:59:57,072 - INFO - Epoch [8/30] Batch [1040/4715] Loss: 0.7763\n",
      "2025-05-30 14:59:58,649 - INFO - Epoch [8/30] Batch [1050/4715] Loss: 0.7419\n",
      "2025-05-30 15:00:00,128 - INFO - Epoch [8/30] Batch [1060/4715] Loss: 0.7548\n",
      "2025-05-30 15:00:01,763 - INFO - Epoch [8/30] Batch [1070/4715] Loss: 0.7219\n",
      "2025-05-30 15:00:03,344 - INFO - Epoch [8/30] Batch [1080/4715] Loss: 0.9706\n",
      "2025-05-30 15:00:04,917 - INFO - Epoch [8/30] Batch [1090/4715] Loss: 0.7825\n",
      "2025-05-30 15:00:06,540 - INFO - Epoch [8/30] Batch [1100/4715] Loss: 0.9518\n",
      "2025-05-30 15:00:08,006 - INFO - Epoch [8/30] Batch [1110/4715] Loss: 0.6641\n",
      "2025-05-30 15:00:09,546 - INFO - Epoch [8/30] Batch [1120/4715] Loss: 0.8003\n",
      "2025-05-30 15:00:11,035 - INFO - Epoch [8/30] Batch [1130/4715] Loss: 0.7879\n",
      "2025-05-30 15:00:12,553 - INFO - Epoch [8/30] Batch [1140/4715] Loss: 0.9754\n",
      "2025-05-30 15:00:14,068 - INFO - Epoch [8/30] Batch [1150/4715] Loss: 1.0826\n",
      "2025-05-30 15:00:15,686 - INFO - Epoch [8/30] Batch [1160/4715] Loss: 0.7453\n",
      "2025-05-30 15:00:17,236 - INFO - Epoch [8/30] Batch [1170/4715] Loss: 0.8950\n",
      "2025-05-30 15:00:18,777 - INFO - Epoch [8/30] Batch [1180/4715] Loss: 0.8764\n",
      "2025-05-30 15:00:20,325 - INFO - Epoch [8/30] Batch [1190/4715] Loss: 0.7802\n",
      "2025-05-30 15:00:21,888 - INFO - Epoch [8/30] Batch [1200/4715] Loss: 0.7281\n",
      "2025-05-30 15:00:23,465 - INFO - Epoch [8/30] Batch [1210/4715] Loss: 0.8127\n",
      "2025-05-30 15:00:25,114 - INFO - Epoch [8/30] Batch [1220/4715] Loss: 0.7842\n",
      "2025-05-30 15:00:26,674 - INFO - Epoch [8/30] Batch [1230/4715] Loss: 0.7105\n",
      "2025-05-30 15:00:28,236 - INFO - Epoch [8/30] Batch [1240/4715] Loss: 0.8905\n",
      "2025-05-30 15:00:29,750 - INFO - Epoch [8/30] Batch [1250/4715] Loss: 0.6680\n",
      "2025-05-30 15:00:31,304 - INFO - Epoch [8/30] Batch [1260/4715] Loss: 0.8183\n",
      "2025-05-30 15:00:32,906 - INFO - Epoch [8/30] Batch [1270/4715] Loss: 0.7649\n",
      "2025-05-30 15:00:34,543 - INFO - Epoch [8/30] Batch [1280/4715] Loss: 0.6745\n",
      "2025-05-30 15:00:36,239 - INFO - Epoch [8/30] Batch [1290/4715] Loss: 0.6947\n",
      "2025-05-30 15:00:37,765 - INFO - Epoch [8/30] Batch [1300/4715] Loss: 1.0471\n",
      "2025-05-30 15:00:39,368 - INFO - Epoch [8/30] Batch [1310/4715] Loss: 0.8970\n",
      "2025-05-30 15:00:40,959 - INFO - Epoch [8/30] Batch [1320/4715] Loss: 0.8287\n",
      "2025-05-30 15:00:42,554 - INFO - Epoch [8/30] Batch [1330/4715] Loss: 0.8706\n",
      "2025-05-30 15:00:44,148 - INFO - Epoch [8/30] Batch [1340/4715] Loss: 0.8640\n",
      "2025-05-30 15:00:45,623 - INFO - Epoch [8/30] Batch [1350/4715] Loss: 0.7934\n",
      "2025-05-30 15:00:47,170 - INFO - Epoch [8/30] Batch [1360/4715] Loss: 0.8132\n",
      "2025-05-30 15:00:48,746 - INFO - Epoch [8/30] Batch [1370/4715] Loss: 0.8466\n",
      "2025-05-30 15:00:50,319 - INFO - Epoch [8/30] Batch [1380/4715] Loss: 1.2209\n",
      "2025-05-30 15:00:51,865 - INFO - Epoch [8/30] Batch [1390/4715] Loss: 0.6797\n",
      "2025-05-30 15:00:53,365 - INFO - Epoch [8/30] Batch [1400/4715] Loss: 0.9176\n",
      "2025-05-30 15:00:54,927 - INFO - Epoch [8/30] Batch [1410/4715] Loss: 0.9606\n",
      "2025-05-30 15:00:56,477 - INFO - Epoch [8/30] Batch [1420/4715] Loss: 0.8279\n",
      "2025-05-30 15:00:57,998 - INFO - Epoch [8/30] Batch [1430/4715] Loss: 0.7674\n",
      "2025-05-30 15:00:59,505 - INFO - Epoch [8/30] Batch [1440/4715] Loss: 0.7677\n",
      "2025-05-30 15:01:01,007 - INFO - Epoch [8/30] Batch [1450/4715] Loss: 0.8533\n",
      "2025-05-30 15:01:02,585 - INFO - Epoch [8/30] Batch [1460/4715] Loss: 0.7455\n",
      "2025-05-30 15:01:04,161 - INFO - Epoch [8/30] Batch [1470/4715] Loss: 0.8006\n",
      "2025-05-30 15:01:05,804 - INFO - Epoch [8/30] Batch [1480/4715] Loss: 0.9355\n",
      "2025-05-30 15:01:07,354 - INFO - Epoch [8/30] Batch [1490/4715] Loss: 0.7682\n",
      "2025-05-30 15:01:08,884 - INFO - Epoch [8/30] Batch [1500/4715] Loss: 1.0214\n",
      "2025-05-30 15:01:10,503 - INFO - Epoch [8/30] Batch [1510/4715] Loss: 0.9338\n",
      "2025-05-30 15:01:12,097 - INFO - Epoch [8/30] Batch [1520/4715] Loss: 1.0270\n",
      "2025-05-30 15:01:13,660 - INFO - Epoch [8/30] Batch [1530/4715] Loss: 0.8273\n",
      "2025-05-30 15:01:15,188 - INFO - Epoch [8/30] Batch [1540/4715] Loss: 0.7902\n",
      "2025-05-30 15:01:16,695 - INFO - Epoch [8/30] Batch [1550/4715] Loss: 1.0912\n",
      "2025-05-30 15:01:18,242 - INFO - Epoch [8/30] Batch [1560/4715] Loss: 0.8618\n",
      "2025-05-30 15:01:19,802 - INFO - Epoch [8/30] Batch [1570/4715] Loss: 0.8073\n",
      "2025-05-30 15:01:21,411 - INFO - Epoch [8/30] Batch [1580/4715] Loss: 0.7313\n",
      "2025-05-30 15:01:23,029 - INFO - Epoch [8/30] Batch [1590/4715] Loss: 0.7010\n",
      "2025-05-30 15:01:24,591 - INFO - Epoch [8/30] Batch [1600/4715] Loss: 0.6238\n",
      "2025-05-30 15:01:26,168 - INFO - Epoch [8/30] Batch [1610/4715] Loss: 0.7198\n",
      "2025-05-30 15:01:27,704 - INFO - Epoch [8/30] Batch [1620/4715] Loss: 0.8180\n",
      "2025-05-30 15:01:29,220 - INFO - Epoch [8/30] Batch [1630/4715] Loss: 0.8286\n",
      "2025-05-30 15:01:30,806 - INFO - Epoch [8/30] Batch [1640/4715] Loss: 1.0169\n",
      "2025-05-30 15:01:32,405 - INFO - Epoch [8/30] Batch [1650/4715] Loss: 0.8209\n",
      "2025-05-30 15:01:33,989 - INFO - Epoch [8/30] Batch [1660/4715] Loss: 0.8151\n",
      "2025-05-30 15:01:35,447 - INFO - Epoch [8/30] Batch [1670/4715] Loss: 1.0211\n",
      "2025-05-30 15:01:36,963 - INFO - Epoch [8/30] Batch [1680/4715] Loss: 0.9081\n",
      "2025-05-30 15:01:38,540 - INFO - Epoch [8/30] Batch [1690/4715] Loss: 0.7093\n",
      "2025-05-30 15:01:40,126 - INFO - Epoch [8/30] Batch [1700/4715] Loss: 0.9767\n",
      "2025-05-30 15:01:41,684 - INFO - Epoch [8/30] Batch [1710/4715] Loss: 0.7637\n",
      "2025-05-30 15:01:43,287 - INFO - Epoch [8/30] Batch [1720/4715] Loss: 1.3350\n",
      "2025-05-30 15:01:44,839 - INFO - Epoch [8/30] Batch [1730/4715] Loss: 1.2356\n",
      "2025-05-30 15:01:46,415 - INFO - Epoch [8/30] Batch [1740/4715] Loss: 0.5069\n",
      "2025-05-30 15:01:47,928 - INFO - Epoch [8/30] Batch [1750/4715] Loss: 1.2483\n",
      "2025-05-30 15:01:49,470 - INFO - Epoch [8/30] Batch [1760/4715] Loss: 0.6496\n",
      "2025-05-30 15:01:51,023 - INFO - Epoch [8/30] Batch [1770/4715] Loss: 0.9529\n",
      "2025-05-30 15:01:52,521 - INFO - Epoch [8/30] Batch [1780/4715] Loss: 0.8638\n",
      "2025-05-30 15:01:54,096 - INFO - Epoch [8/30] Batch [1790/4715] Loss: 0.9945\n",
      "2025-05-30 15:01:55,742 - INFO - Epoch [8/30] Batch [1800/4715] Loss: 0.8847\n",
      "2025-05-30 15:01:57,354 - INFO - Epoch [8/30] Batch [1810/4715] Loss: 0.8545\n",
      "2025-05-30 15:01:58,895 - INFO - Epoch [8/30] Batch [1820/4715] Loss: 0.9643\n",
      "2025-05-30 15:02:00,391 - INFO - Epoch [8/30] Batch [1830/4715] Loss: 0.6808\n",
      "2025-05-30 15:02:01,951 - INFO - Epoch [8/30] Batch [1840/4715] Loss: 0.8889\n",
      "2025-05-30 15:02:03,522 - INFO - Epoch [8/30] Batch [1850/4715] Loss: 0.7024\n",
      "2025-05-30 15:02:05,176 - INFO - Epoch [8/30] Batch [1860/4715] Loss: 0.8237\n",
      "2025-05-30 15:02:06,806 - INFO - Epoch [8/30] Batch [1870/4715] Loss: 0.9249\n",
      "2025-05-30 15:02:08,359 - INFO - Epoch [8/30] Batch [1880/4715] Loss: 1.0346\n",
      "2025-05-30 15:02:09,857 - INFO - Epoch [8/30] Batch [1890/4715] Loss: 0.8450\n",
      "2025-05-30 15:02:11,376 - INFO - Epoch [8/30] Batch [1900/4715] Loss: 0.7608\n",
      "2025-05-30 15:02:12,964 - INFO - Epoch [8/30] Batch [1910/4715] Loss: 0.9907\n",
      "2025-05-30 15:02:14,522 - INFO - Epoch [8/30] Batch [1920/4715] Loss: 0.6666\n",
      "2025-05-30 15:02:16,004 - INFO - Epoch [8/30] Batch [1930/4715] Loss: 0.7759\n",
      "2025-05-30 15:02:17,563 - INFO - Epoch [8/30] Batch [1940/4715] Loss: 0.8963\n",
      "2025-05-30 15:02:19,157 - INFO - Epoch [8/30] Batch [1950/4715] Loss: 1.1309\n",
      "2025-05-30 15:02:20,725 - INFO - Epoch [8/30] Batch [1960/4715] Loss: 0.8538\n",
      "2025-05-30 15:02:22,266 - INFO - Epoch [8/30] Batch [1970/4715] Loss: 0.8294\n",
      "2025-05-30 15:02:23,765 - INFO - Epoch [8/30] Batch [1980/4715] Loss: 0.8336\n",
      "2025-05-30 15:02:25,223 - INFO - Epoch [8/30] Batch [1990/4715] Loss: 0.8251\n",
      "2025-05-30 15:02:26,823 - INFO - Epoch [8/30] Batch [2000/4715] Loss: 0.4920\n",
      "2025-05-30 15:02:28,323 - INFO - Epoch [8/30] Batch [2010/4715] Loss: 0.6592\n",
      "2025-05-30 15:02:29,886 - INFO - Epoch [8/30] Batch [2020/4715] Loss: 0.8662\n",
      "2025-05-30 15:02:31,422 - INFO - Epoch [8/30] Batch [2030/4715] Loss: 0.8683\n",
      "2025-05-30 15:02:33,011 - INFO - Epoch [8/30] Batch [2040/4715] Loss: 0.6754\n",
      "2025-05-30 15:02:34,522 - INFO - Epoch [8/30] Batch [2050/4715] Loss: 0.7131\n",
      "2025-05-30 15:02:36,007 - INFO - Epoch [8/30] Batch [2060/4715] Loss: 0.8710\n",
      "2025-05-30 15:02:37,522 - INFO - Epoch [8/30] Batch [2070/4715] Loss: 0.9357\n",
      "2025-05-30 15:02:39,046 - INFO - Epoch [8/30] Batch [2080/4715] Loss: 1.0590\n",
      "2025-05-30 15:02:40,623 - INFO - Epoch [8/30] Batch [2090/4715] Loss: 0.8659\n",
      "2025-05-30 15:02:42,219 - INFO - Epoch [8/30] Batch [2100/4715] Loss: 0.6542\n",
      "2025-05-30 15:02:43,769 - INFO - Epoch [8/30] Batch [2110/4715] Loss: 0.7213\n",
      "2025-05-30 15:02:45,364 - INFO - Epoch [8/30] Batch [2120/4715] Loss: 0.7303\n",
      "2025-05-30 15:02:46,907 - INFO - Epoch [8/30] Batch [2130/4715] Loss: 0.7499\n",
      "2025-05-30 15:02:48,423 - INFO - Epoch [8/30] Batch [2140/4715] Loss: 0.9368\n",
      "2025-05-30 15:02:50,006 - INFO - Epoch [8/30] Batch [2150/4715] Loss: 0.6208\n",
      "2025-05-30 15:02:51,576 - INFO - Epoch [8/30] Batch [2160/4715] Loss: 0.8359\n",
      "2025-05-30 15:02:53,104 - INFO - Epoch [8/30] Batch [2170/4715] Loss: 0.7869\n",
      "2025-05-30 15:02:54,644 - INFO - Epoch [8/30] Batch [2180/4715] Loss: 0.9535\n",
      "2025-05-30 15:02:56,230 - INFO - Epoch [8/30] Batch [2190/4715] Loss: 0.7405\n",
      "2025-05-30 15:02:57,751 - INFO - Epoch [8/30] Batch [2200/4715] Loss: 0.9381\n",
      "2025-05-30 15:02:59,279 - INFO - Epoch [8/30] Batch [2210/4715] Loss: 0.8666\n",
      "2025-05-30 15:03:00,772 - INFO - Epoch [8/30] Batch [2220/4715] Loss: 0.8726\n",
      "2025-05-30 15:03:02,321 - INFO - Epoch [8/30] Batch [2230/4715] Loss: 0.6053\n",
      "2025-05-30 15:03:03,877 - INFO - Epoch [8/30] Batch [2240/4715] Loss: 1.0891\n",
      "2025-05-30 15:03:05,425 - INFO - Epoch [8/30] Batch [2250/4715] Loss: 0.7169\n",
      "2025-05-30 15:03:06,942 - INFO - Epoch [8/30] Batch [2260/4715] Loss: 0.4938\n",
      "2025-05-30 15:03:08,461 - INFO - Epoch [8/30] Batch [2270/4715] Loss: 0.6496\n",
      "2025-05-30 15:03:09,989 - INFO - Epoch [8/30] Batch [2280/4715] Loss: 0.8838\n",
      "2025-05-30 15:03:11,544 - INFO - Epoch [8/30] Batch [2290/4715] Loss: 0.8054\n",
      "2025-05-30 15:03:13,138 - INFO - Epoch [8/30] Batch [2300/4715] Loss: 0.6486\n",
      "2025-05-30 15:03:14,691 - INFO - Epoch [8/30] Batch [2310/4715] Loss: 0.7338\n",
      "2025-05-30 15:03:16,190 - INFO - Epoch [8/30] Batch [2320/4715] Loss: 0.6577\n",
      "2025-05-30 15:03:17,746 - INFO - Epoch [8/30] Batch [2330/4715] Loss: 0.8944\n",
      "2025-05-30 15:03:19,344 - INFO - Epoch [8/30] Batch [2340/4715] Loss: 0.7495\n",
      "2025-05-30 15:03:20,961 - INFO - Epoch [8/30] Batch [2350/4715] Loss: 0.8512\n",
      "2025-05-30 15:03:22,525 - INFO - Epoch [8/30] Batch [2360/4715] Loss: 0.6847\n",
      "2025-05-30 15:03:24,109 - INFO - Epoch [8/30] Batch [2370/4715] Loss: 0.7407\n",
      "2025-05-30 15:03:25,609 - INFO - Epoch [8/30] Batch [2380/4715] Loss: 0.7156\n",
      "2025-05-30 15:03:27,178 - INFO - Epoch [8/30] Batch [2390/4715] Loss: 0.5692\n",
      "2025-05-30 15:03:28,748 - INFO - Epoch [8/30] Batch [2400/4715] Loss: 1.0182\n",
      "2025-05-30 15:03:30,312 - INFO - Epoch [8/30] Batch [2410/4715] Loss: 0.9883\n",
      "2025-05-30 15:03:31,922 - INFO - Epoch [8/30] Batch [2420/4715] Loss: 0.6732\n",
      "2025-05-30 15:03:33,502 - INFO - Epoch [8/30] Batch [2430/4715] Loss: 0.6799\n",
      "2025-05-30 15:03:35,132 - INFO - Epoch [8/30] Batch [2440/4715] Loss: 0.8390\n",
      "2025-05-30 15:03:36,673 - INFO - Epoch [8/30] Batch [2450/4715] Loss: 1.0010\n",
      "2025-05-30 15:03:38,228 - INFO - Epoch [8/30] Batch [2460/4715] Loss: 0.7102\n",
      "2025-05-30 15:03:39,777 - INFO - Epoch [8/30] Batch [2470/4715] Loss: 0.9741\n",
      "2025-05-30 15:03:41,347 - INFO - Epoch [8/30] Batch [2480/4715] Loss: 0.7261\n",
      "2025-05-30 15:03:42,924 - INFO - Epoch [8/30] Batch [2490/4715] Loss: 0.8257\n",
      "2025-05-30 15:03:44,549 - INFO - Epoch [8/30] Batch [2500/4715] Loss: 1.0447\n",
      "2025-05-30 15:03:46,122 - INFO - Epoch [8/30] Batch [2510/4715] Loss: 0.8235\n",
      "2025-05-30 15:03:47,788 - INFO - Epoch [8/30] Batch [2520/4715] Loss: 0.7654\n",
      "2025-05-30 15:03:49,307 - INFO - Epoch [8/30] Batch [2530/4715] Loss: 0.8604\n",
      "2025-05-30 15:03:50,868 - INFO - Epoch [8/30] Batch [2540/4715] Loss: 0.8156\n",
      "2025-05-30 15:03:52,416 - INFO - Epoch [8/30] Batch [2550/4715] Loss: 0.8477\n",
      "2025-05-30 15:03:53,974 - INFO - Epoch [8/30] Batch [2560/4715] Loss: 0.6428\n",
      "2025-05-30 15:03:55,539 - INFO - Epoch [8/30] Batch [2570/4715] Loss: 0.8008\n",
      "2025-05-30 15:03:57,092 - INFO - Epoch [8/30] Batch [2580/4715] Loss: 0.8689\n",
      "2025-05-30 15:03:58,843 - INFO - Epoch [8/30] Batch [2590/4715] Loss: 0.9027\n",
      "2025-05-30 15:04:00,385 - INFO - Epoch [8/30] Batch [2600/4715] Loss: 0.6951\n",
      "2025-05-30 15:04:01,864 - INFO - Epoch [8/30] Batch [2610/4715] Loss: 0.8211\n",
      "2025-05-30 15:04:03,406 - INFO - Epoch [8/30] Batch [2620/4715] Loss: 0.8208\n",
      "2025-05-30 15:04:05,066 - INFO - Epoch [8/30] Batch [2630/4715] Loss: 0.8536\n",
      "2025-05-30 15:04:06,619 - INFO - Epoch [8/30] Batch [2640/4715] Loss: 0.8341\n",
      "2025-05-30 15:04:08,161 - INFO - Epoch [8/30] Batch [2650/4715] Loss: 0.9821\n",
      "2025-05-30 15:04:09,807 - INFO - Epoch [8/30] Batch [2660/4715] Loss: 0.7053\n",
      "2025-05-30 15:04:11,304 - INFO - Epoch [8/30] Batch [2670/4715] Loss: 0.8248\n",
      "2025-05-30 15:04:12,840 - INFO - Epoch [8/30] Batch [2680/4715] Loss: 0.8120\n",
      "2025-05-30 15:04:14,442 - INFO - Epoch [8/30] Batch [2690/4715] Loss: 1.0231\n",
      "2025-05-30 15:04:15,977 - INFO - Epoch [8/30] Batch [2700/4715] Loss: 0.9055\n",
      "2025-05-30 15:04:17,534 - INFO - Epoch [8/30] Batch [2710/4715] Loss: 0.7214\n",
      "2025-05-30 15:04:19,047 - INFO - Epoch [8/30] Batch [2720/4715] Loss: 0.7330\n",
      "2025-05-30 15:04:20,624 - INFO - Epoch [8/30] Batch [2730/4715] Loss: 0.7943\n",
      "2025-05-30 15:04:22,207 - INFO - Epoch [8/30] Batch [2740/4715] Loss: 0.7410\n",
      "2025-05-30 15:04:23,770 - INFO - Epoch [8/30] Batch [2750/4715] Loss: 0.8519\n",
      "2025-05-30 15:04:25,305 - INFO - Epoch [8/30] Batch [2760/4715] Loss: 0.7927\n",
      "2025-05-30 15:04:26,846 - INFO - Epoch [8/30] Batch [2770/4715] Loss: 0.6437\n",
      "2025-05-30 15:04:28,464 - INFO - Epoch [8/30] Batch [2780/4715] Loss: 0.9978\n",
      "2025-05-30 15:04:30,097 - INFO - Epoch [8/30] Batch [2790/4715] Loss: 0.7325\n",
      "2025-05-30 15:04:31,707 - INFO - Epoch [8/30] Batch [2800/4715] Loss: 1.0821\n",
      "2025-05-30 15:04:33,348 - INFO - Epoch [8/30] Batch [2810/4715] Loss: 0.7779\n",
      "2025-05-30 15:04:34,921 - INFO - Epoch [8/30] Batch [2820/4715] Loss: 0.6180\n",
      "2025-05-30 15:04:36,466 - INFO - Epoch [8/30] Batch [2830/4715] Loss: 0.6421\n",
      "2025-05-30 15:04:38,154 - INFO - Epoch [8/30] Batch [2840/4715] Loss: 0.8364\n",
      "2025-05-30 15:04:39,668 - INFO - Epoch [8/30] Batch [2850/4715] Loss: 0.8634\n",
      "2025-05-30 15:04:41,224 - INFO - Epoch [8/30] Batch [2860/4715] Loss: 0.9443\n",
      "2025-05-30 15:04:42,857 - INFO - Epoch [8/30] Batch [2870/4715] Loss: 0.9551\n",
      "2025-05-30 15:04:44,486 - INFO - Epoch [8/30] Batch [2880/4715] Loss: 0.9918\n",
      "2025-05-30 15:04:46,079 - INFO - Epoch [8/30] Batch [2890/4715] Loss: 0.8025\n",
      "2025-05-30 15:04:47,626 - INFO - Epoch [8/30] Batch [2900/4715] Loss: 0.7122\n",
      "2025-05-30 15:04:49,239 - INFO - Epoch [8/30] Batch [2910/4715] Loss: 0.8841\n",
      "2025-05-30 15:04:50,837 - INFO - Epoch [8/30] Batch [2920/4715] Loss: 0.8611\n",
      "2025-05-30 15:04:52,447 - INFO - Epoch [8/30] Batch [2930/4715] Loss: 0.8534\n",
      "2025-05-30 15:04:54,024 - INFO - Epoch [8/30] Batch [2940/4715] Loss: 0.8783\n",
      "2025-05-30 15:04:55,637 - INFO - Epoch [8/30] Batch [2950/4715] Loss: 0.6688\n",
      "2025-05-30 15:04:57,171 - INFO - Epoch [8/30] Batch [2960/4715] Loss: 0.8106\n",
      "2025-05-30 15:04:58,803 - INFO - Epoch [8/30] Batch [2970/4715] Loss: 0.8230\n",
      "2025-05-30 15:05:00,372 - INFO - Epoch [8/30] Batch [2980/4715] Loss: 0.8253\n",
      "2025-05-30 15:05:01,942 - INFO - Epoch [8/30] Batch [2990/4715] Loss: 1.0142\n",
      "2025-05-30 15:05:03,546 - INFO - Epoch [8/30] Batch [3000/4715] Loss: 0.9172\n",
      "2025-05-30 15:05:05,123 - INFO - Epoch [8/30] Batch [3010/4715] Loss: 0.6453\n",
      "2025-05-30 15:05:06,693 - INFO - Epoch [8/30] Batch [3020/4715] Loss: 0.8043\n",
      "2025-05-30 15:05:08,429 - INFO - Epoch [8/30] Batch [3030/4715] Loss: 0.9617\n",
      "2025-05-30 15:05:09,985 - INFO - Epoch [8/30] Batch [3040/4715] Loss: 0.7986\n",
      "2025-05-30 15:05:11,610 - INFO - Epoch [8/30] Batch [3050/4715] Loss: 0.7901\n",
      "2025-05-30 15:05:13,210 - INFO - Epoch [8/30] Batch [3060/4715] Loss: 0.7329\n",
      "2025-05-30 15:05:14,909 - INFO - Epoch [8/30] Batch [3070/4715] Loss: 0.9691\n",
      "2025-05-30 15:05:16,439 - INFO - Epoch [8/30] Batch [3080/4715] Loss: 0.9014\n",
      "2025-05-30 15:05:18,066 - INFO - Epoch [8/30] Batch [3090/4715] Loss: 0.9849\n",
      "2025-05-30 15:05:19,576 - INFO - Epoch [8/30] Batch [3100/4715] Loss: 0.7366\n",
      "2025-05-30 15:05:21,141 - INFO - Epoch [8/30] Batch [3110/4715] Loss: 0.5834\n",
      "2025-05-30 15:05:22,663 - INFO - Epoch [8/30] Batch [3120/4715] Loss: 0.6901\n",
      "2025-05-30 15:05:24,223 - INFO - Epoch [8/30] Batch [3130/4715] Loss: 0.7253\n",
      "2025-05-30 15:05:25,792 - INFO - Epoch [8/30] Batch [3140/4715] Loss: 0.5715\n",
      "2025-05-30 15:05:27,336 - INFO - Epoch [8/30] Batch [3150/4715] Loss: 0.8751\n",
      "2025-05-30 15:05:28,916 - INFO - Epoch [8/30] Batch [3160/4715] Loss: 1.0549\n",
      "2025-05-30 15:05:30,434 - INFO - Epoch [8/30] Batch [3170/4715] Loss: 0.8443\n",
      "2025-05-30 15:05:32,018 - INFO - Epoch [8/30] Batch [3180/4715] Loss: 0.7633\n",
      "2025-05-30 15:05:33,639 - INFO - Epoch [8/30] Batch [3190/4715] Loss: 0.8439\n",
      "2025-05-30 15:05:35,305 - INFO - Epoch [8/30] Batch [3200/4715] Loss: 0.9092\n",
      "2025-05-30 15:05:36,829 - INFO - Epoch [8/30] Batch [3210/4715] Loss: 0.6968\n",
      "2025-05-30 15:05:38,417 - INFO - Epoch [8/30] Batch [3220/4715] Loss: 0.8055\n",
      "2025-05-30 15:05:39,989 - INFO - Epoch [8/30] Batch [3230/4715] Loss: 0.9440\n",
      "2025-05-30 15:05:41,593 - INFO - Epoch [8/30] Batch [3240/4715] Loss: 0.8618\n",
      "2025-05-30 15:05:43,198 - INFO - Epoch [8/30] Batch [3250/4715] Loss: 0.7292\n",
      "2025-05-30 15:05:44,802 - INFO - Epoch [8/30] Batch [3260/4715] Loss: 0.8044\n",
      "2025-05-30 15:05:46,365 - INFO - Epoch [8/30] Batch [3270/4715] Loss: 0.7603\n",
      "2025-05-30 15:05:47,927 - INFO - Epoch [8/30] Batch [3280/4715] Loss: 0.7966\n",
      "2025-05-30 15:05:49,428 - INFO - Epoch [8/30] Batch [3290/4715] Loss: 0.7080\n",
      "2025-05-30 15:05:50,977 - INFO - Epoch [8/30] Batch [3300/4715] Loss: 0.8518\n",
      "2025-05-30 15:05:52,540 - INFO - Epoch [8/30] Batch [3310/4715] Loss: 0.7558\n",
      "2025-05-30 15:05:54,109 - INFO - Epoch [8/30] Batch [3320/4715] Loss: 0.8921\n",
      "2025-05-30 15:05:55,706 - INFO - Epoch [8/30] Batch [3330/4715] Loss: 0.8668\n",
      "2025-05-30 15:05:57,264 - INFO - Epoch [8/30] Batch [3340/4715] Loss: 0.7864\n",
      "2025-05-30 15:05:58,874 - INFO - Epoch [8/30] Batch [3350/4715] Loss: 0.9518\n",
      "2025-05-30 15:06:00,388 - INFO - Epoch [8/30] Batch [3360/4715] Loss: 0.8131\n",
      "2025-05-30 15:06:01,867 - INFO - Epoch [8/30] Batch [3370/4715] Loss: 0.8821\n",
      "2025-05-30 15:06:03,444 - INFO - Epoch [8/30] Batch [3380/4715] Loss: 0.7703\n",
      "2025-05-30 15:06:05,121 - INFO - Epoch [8/30] Batch [3390/4715] Loss: 0.9525\n",
      "2025-05-30 15:06:06,661 - INFO - Epoch [8/30] Batch [3400/4715] Loss: 0.6876\n",
      "2025-05-30 15:06:08,243 - INFO - Epoch [8/30] Batch [3410/4715] Loss: 0.7023\n",
      "2025-05-30 15:06:09,840 - INFO - Epoch [8/30] Batch [3420/4715] Loss: 0.9496\n",
      "2025-05-30 15:06:11,542 - INFO - Epoch [8/30] Batch [3430/4715] Loss: 0.6071\n",
      "2025-05-30 15:06:13,125 - INFO - Epoch [8/30] Batch [3440/4715] Loss: 0.7961\n",
      "2025-05-30 15:06:14,686 - INFO - Epoch [8/30] Batch [3450/4715] Loss: 1.1324\n",
      "2025-05-30 15:06:16,272 - INFO - Epoch [8/30] Batch [3460/4715] Loss: 0.8042\n",
      "2025-05-30 15:06:17,936 - INFO - Epoch [8/30] Batch [3470/4715] Loss: 0.8585\n",
      "2025-05-30 15:06:19,529 - INFO - Epoch [8/30] Batch [3480/4715] Loss: 0.7123\n",
      "2025-05-30 15:06:21,043 - INFO - Epoch [8/30] Batch [3490/4715] Loss: 1.0511\n",
      "2025-05-30 15:06:22,627 - INFO - Epoch [8/30] Batch [3500/4715] Loss: 0.7479\n",
      "2025-05-30 15:06:24,190 - INFO - Epoch [8/30] Batch [3510/4715] Loss: 0.9213\n",
      "2025-05-30 15:06:25,765 - INFO - Epoch [8/30] Batch [3520/4715] Loss: 0.8262\n",
      "2025-05-30 15:06:27,365 - INFO - Epoch [8/30] Batch [3530/4715] Loss: 1.0447\n",
      "2025-05-30 15:06:28,912 - INFO - Epoch [8/30] Batch [3540/4715] Loss: 0.9559\n",
      "2025-05-30 15:06:30,466 - INFO - Epoch [8/30] Batch [3550/4715] Loss: 0.7354\n",
      "2025-05-30 15:06:32,044 - INFO - Epoch [8/30] Batch [3560/4715] Loss: 0.7654\n",
      "2025-05-30 15:06:33,711 - INFO - Epoch [8/30] Batch [3570/4715] Loss: 0.6620\n",
      "2025-05-30 15:06:35,276 - INFO - Epoch [8/30] Batch [3580/4715] Loss: 0.6957\n",
      "2025-05-30 15:06:36,857 - INFO - Epoch [8/30] Batch [3590/4715] Loss: 0.7784\n",
      "2025-05-30 15:06:38,447 - INFO - Epoch [8/30] Batch [3600/4715] Loss: 0.7247\n",
      "2025-05-30 15:06:40,010 - INFO - Epoch [8/30] Batch [3610/4715] Loss: 0.6819\n",
      "2025-05-30 15:06:41,583 - INFO - Epoch [8/30] Batch [3620/4715] Loss: 0.6494\n",
      "2025-05-30 15:06:43,197 - INFO - Epoch [8/30] Batch [3630/4715] Loss: 0.6519\n",
      "2025-05-30 15:06:44,682 - INFO - Epoch [8/30] Batch [3640/4715] Loss: 0.8152\n",
      "2025-05-30 15:06:46,209 - INFO - Epoch [8/30] Batch [3650/4715] Loss: 0.7301\n",
      "2025-05-30 15:06:47,853 - INFO - Epoch [8/30] Batch [3660/4715] Loss: 0.6198\n",
      "2025-05-30 15:06:49,527 - INFO - Epoch [8/30] Batch [3670/4715] Loss: 0.6713\n",
      "2025-05-30 15:06:51,134 - INFO - Epoch [8/30] Batch [3680/4715] Loss: 0.8396\n",
      "2025-05-30 15:06:52,641 - INFO - Epoch [8/30] Batch [3690/4715] Loss: 0.8630\n",
      "2025-05-30 15:06:54,176 - INFO - Epoch [8/30] Batch [3700/4715] Loss: 0.6872\n",
      "2025-05-30 15:06:55,794 - INFO - Epoch [8/30] Batch [3710/4715] Loss: 0.9046\n",
      "2025-05-30 15:06:57,334 - INFO - Epoch [8/30] Batch [3720/4715] Loss: 0.8318\n",
      "2025-05-30 15:06:58,914 - INFO - Epoch [8/30] Batch [3730/4715] Loss: 0.9836\n",
      "2025-05-30 15:07:00,526 - INFO - Epoch [8/30] Batch [3740/4715] Loss: 0.7062\n",
      "2025-05-30 15:07:02,089 - INFO - Epoch [8/30] Batch [3750/4715] Loss: 0.8535\n",
      "2025-05-30 15:07:03,664 - INFO - Epoch [8/30] Batch [3760/4715] Loss: 0.6165\n",
      "2025-05-30 15:07:05,215 - INFO - Epoch [8/30] Batch [3770/4715] Loss: 0.6955\n",
      "2025-05-30 15:07:06,707 - INFO - Epoch [8/30] Batch [3780/4715] Loss: 1.1777\n",
      "2025-05-30 15:07:08,300 - INFO - Epoch [8/30] Batch [3790/4715] Loss: 1.1682\n",
      "2025-05-30 15:07:09,870 - INFO - Epoch [8/30] Batch [3800/4715] Loss: 1.0541\n",
      "2025-05-30 15:07:11,371 - INFO - Epoch [8/30] Batch [3810/4715] Loss: 0.8579\n",
      "2025-05-30 15:07:13,018 - INFO - Epoch [8/30] Batch [3820/4715] Loss: 0.6890\n",
      "2025-05-30 15:07:14,623 - INFO - Epoch [8/30] Batch [3830/4715] Loss: 1.0160\n",
      "2025-05-30 15:07:16,213 - INFO - Epoch [8/30] Batch [3840/4715] Loss: 0.7493\n",
      "2025-05-30 15:07:17,771 - INFO - Epoch [8/30] Batch [3850/4715] Loss: 0.9413\n",
      "2025-05-30 15:07:19,280 - INFO - Epoch [8/30] Batch [3860/4715] Loss: 0.8092\n",
      "2025-05-30 15:07:20,876 - INFO - Epoch [8/30] Batch [3870/4715] Loss: 0.7896\n",
      "2025-05-30 15:07:22,480 - INFO - Epoch [8/30] Batch [3880/4715] Loss: 0.6107\n",
      "2025-05-30 15:07:23,976 - INFO - Epoch [8/30] Batch [3890/4715] Loss: 0.7987\n",
      "2025-05-30 15:07:25,666 - INFO - Epoch [8/30] Batch [3900/4715] Loss: 0.6836\n",
      "2025-05-30 15:07:27,196 - INFO - Epoch [8/30] Batch [3910/4715] Loss: 0.6231\n",
      "2025-05-30 15:07:28,667 - INFO - Epoch [8/30] Batch [3920/4715] Loss: 0.7901\n",
      "2025-05-30 15:07:30,179 - INFO - Epoch [8/30] Batch [3930/4715] Loss: 1.2031\n",
      "2025-05-30 15:07:31,814 - INFO - Epoch [8/30] Batch [3940/4715] Loss: 0.9417\n",
      "2025-05-30 15:07:33,429 - INFO - Epoch [8/30] Batch [3950/4715] Loss: 0.8415\n",
      "2025-05-30 15:07:35,015 - INFO - Epoch [8/30] Batch [3960/4715] Loss: 1.1186\n",
      "2025-05-30 15:07:36,556 - INFO - Epoch [8/30] Batch [3970/4715] Loss: 1.0184\n",
      "2025-05-30 15:07:38,161 - INFO - Epoch [8/30] Batch [3980/4715] Loss: 0.6442\n",
      "2025-05-30 15:07:39,781 - INFO - Epoch [8/30] Batch [3990/4715] Loss: 0.9178\n",
      "2025-05-30 15:07:41,341 - INFO - Epoch [8/30] Batch [4000/4715] Loss: 0.7743\n",
      "2025-05-30 15:07:42,880 - INFO - Epoch [8/30] Batch [4010/4715] Loss: 0.8986\n",
      "2025-05-30 15:07:44,404 - INFO - Epoch [8/30] Batch [4020/4715] Loss: 0.6007\n",
      "2025-05-30 15:07:45,943 - INFO - Epoch [8/30] Batch [4030/4715] Loss: 0.5989\n",
      "2025-05-30 15:07:47,533 - INFO - Epoch [8/30] Batch [4040/4715] Loss: 1.2872\n",
      "2025-05-30 15:07:49,047 - INFO - Epoch [8/30] Batch [4050/4715] Loss: 0.9119\n",
      "2025-05-30 15:07:50,607 - INFO - Epoch [8/30] Batch [4060/4715] Loss: 0.6970\n",
      "2025-05-30 15:07:52,109 - INFO - Epoch [8/30] Batch [4070/4715] Loss: 0.8542\n",
      "2025-05-30 15:07:53,587 - INFO - Epoch [8/30] Batch [4080/4715] Loss: 0.8335\n",
      "2025-05-30 15:07:55,091 - INFO - Epoch [8/30] Batch [4090/4715] Loss: 0.8183\n",
      "2025-05-30 15:07:56,671 - INFO - Epoch [8/30] Batch [4100/4715] Loss: 0.7113\n",
      "2025-05-30 15:07:58,374 - INFO - Epoch [8/30] Batch [4110/4715] Loss: 1.0533\n",
      "2025-05-30 15:07:59,949 - INFO - Epoch [8/30] Batch [4120/4715] Loss: 0.7421\n",
      "2025-05-30 15:08:01,566 - INFO - Epoch [8/30] Batch [4130/4715] Loss: 0.8446\n",
      "2025-05-30 15:08:03,050 - INFO - Epoch [8/30] Batch [4140/4715] Loss: 1.3665\n",
      "2025-05-30 15:08:04,663 - INFO - Epoch [8/30] Batch [4150/4715] Loss: 0.8866\n",
      "2025-05-30 15:08:06,235 - INFO - Epoch [8/30] Batch [4160/4715] Loss: 0.6807\n",
      "2025-05-30 15:08:07,778 - INFO - Epoch [8/30] Batch [4170/4715] Loss: 0.5934\n",
      "2025-05-30 15:08:09,368 - INFO - Epoch [8/30] Batch [4180/4715] Loss: 0.7425\n",
      "2025-05-30 15:08:10,901 - INFO - Epoch [8/30] Batch [4190/4715] Loss: 0.7144\n",
      "2025-05-30 15:08:12,433 - INFO - Epoch [8/30] Batch [4200/4715] Loss: 1.1013\n",
      "2025-05-30 15:08:14,016 - INFO - Epoch [8/30] Batch [4210/4715] Loss: 0.8157\n",
      "2025-05-30 15:08:15,563 - INFO - Epoch [8/30] Batch [4220/4715] Loss: 0.5905\n",
      "2025-05-30 15:08:17,107 - INFO - Epoch [8/30] Batch [4230/4715] Loss: 0.8514\n",
      "2025-05-30 15:08:18,702 - INFO - Epoch [8/30] Batch [4240/4715] Loss: 1.1168\n",
      "2025-05-30 15:08:20,175 - INFO - Epoch [8/30] Batch [4250/4715] Loss: 0.8066\n",
      "2025-05-30 15:08:21,663 - INFO - Epoch [8/30] Batch [4260/4715] Loss: 1.0492\n",
      "2025-05-30 15:08:23,263 - INFO - Epoch [8/30] Batch [4270/4715] Loss: 1.1799\n",
      "2025-05-30 15:08:24,791 - INFO - Epoch [8/30] Batch [4280/4715] Loss: 0.7872\n",
      "2025-05-30 15:08:26,377 - INFO - Epoch [8/30] Batch [4290/4715] Loss: 0.8816\n",
      "2025-05-30 15:08:27,952 - INFO - Epoch [8/30] Batch [4300/4715] Loss: 0.7420\n",
      "2025-05-30 15:08:29,521 - INFO - Epoch [8/30] Batch [4310/4715] Loss: 1.0866\n",
      "2025-05-30 15:08:31,058 - INFO - Epoch [8/30] Batch [4320/4715] Loss: 0.9334\n",
      "2025-05-30 15:08:32,528 - INFO - Epoch [8/30] Batch [4330/4715] Loss: 0.7699\n",
      "2025-05-30 15:08:34,090 - INFO - Epoch [8/30] Batch [4340/4715] Loss: 0.8210\n",
      "2025-05-30 15:08:35,601 - INFO - Epoch [8/30] Batch [4350/4715] Loss: 0.6115\n",
      "2025-05-30 15:08:37,137 - INFO - Epoch [8/30] Batch [4360/4715] Loss: 0.8166\n",
      "2025-05-30 15:08:38,666 - INFO - Epoch [8/30] Batch [4370/4715] Loss: 0.6589\n",
      "2025-05-30 15:08:40,332 - INFO - Epoch [8/30] Batch [4380/4715] Loss: 0.9543\n",
      "2025-05-30 15:08:41,913 - INFO - Epoch [8/30] Batch [4390/4715] Loss: 0.8829\n",
      "2025-05-30 15:08:43,444 - INFO - Epoch [8/30] Batch [4400/4715] Loss: 0.6998\n",
      "2025-05-30 15:08:45,102 - INFO - Epoch [8/30] Batch [4410/4715] Loss: 0.8608\n",
      "2025-05-30 15:08:46,681 - INFO - Epoch [8/30] Batch [4420/4715] Loss: 0.8071\n",
      "2025-05-30 15:08:48,270 - INFO - Epoch [8/30] Batch [4430/4715] Loss: 0.8115\n",
      "2025-05-30 15:08:49,893 - INFO - Epoch [8/30] Batch [4440/4715] Loss: 0.9721\n",
      "2025-05-30 15:08:51,323 - INFO - Epoch [8/30] Batch [4450/4715] Loss: 0.8817\n",
      "2025-05-30 15:08:52,939 - INFO - Epoch [8/30] Batch [4460/4715] Loss: 0.8040\n",
      "2025-05-30 15:08:54,620 - INFO - Epoch [8/30] Batch [4470/4715] Loss: 0.9732\n",
      "2025-05-30 15:08:56,249 - INFO - Epoch [8/30] Batch [4480/4715] Loss: 1.0273\n",
      "2025-05-30 15:08:57,868 - INFO - Epoch [8/30] Batch [4490/4715] Loss: 0.6501\n",
      "2025-05-30 15:08:59,338 - INFO - Epoch [8/30] Batch [4500/4715] Loss: 0.7913\n",
      "2025-05-30 15:09:00,894 - INFO - Epoch [8/30] Batch [4510/4715] Loss: 0.7335\n",
      "2025-05-30 15:09:02,526 - INFO - Epoch [8/30] Batch [4520/4715] Loss: 0.7989\n",
      "2025-05-30 15:09:04,118 - INFO - Epoch [8/30] Batch [4530/4715] Loss: 0.7312\n",
      "2025-05-30 15:09:05,623 - INFO - Epoch [8/30] Batch [4540/4715] Loss: 0.9212\n",
      "2025-05-30 15:09:07,090 - INFO - Epoch [8/30] Batch [4550/4715] Loss: 0.8388\n",
      "2025-05-30 15:09:08,667 - INFO - Epoch [8/30] Batch [4560/4715] Loss: 0.7543\n",
      "2025-05-30 15:09:10,213 - INFO - Epoch [8/30] Batch [4570/4715] Loss: 0.6050\n",
      "2025-05-30 15:09:11,696 - INFO - Epoch [8/30] Batch [4580/4715] Loss: 0.7173\n",
      "2025-05-30 15:09:13,215 - INFO - Epoch [8/30] Batch [4590/4715] Loss: 0.9500\n",
      "2025-05-30 15:09:14,717 - INFO - Epoch [8/30] Batch [4600/4715] Loss: 0.6676\n",
      "2025-05-30 15:09:16,248 - INFO - Epoch [8/30] Batch [4610/4715] Loss: 0.7078\n",
      "2025-05-30 15:09:17,830 - INFO - Epoch [8/30] Batch [4620/4715] Loss: 0.6690\n",
      "2025-05-30 15:09:19,414 - INFO - Epoch [8/30] Batch [4630/4715] Loss: 0.7258\n",
      "2025-05-30 15:09:21,036 - INFO - Epoch [8/30] Batch [4640/4715] Loss: 1.0110\n",
      "2025-05-30 15:09:22,628 - INFO - Epoch [8/30] Batch [4650/4715] Loss: 0.9366\n",
      "2025-05-30 15:09:24,283 - INFO - Epoch [8/30] Batch [4660/4715] Loss: 0.8853\n",
      "2025-05-30 15:09:25,832 - INFO - Epoch [8/30] Batch [4670/4715] Loss: 0.9720\n",
      "2025-05-30 15:09:27,441 - INFO - Epoch [8/30] Batch [4680/4715] Loss: 1.2609\n",
      "2025-05-30 15:09:29,002 - INFO - Epoch [8/30] Batch [4690/4715] Loss: 0.9355\n",
      "2025-05-30 15:09:30,700 - INFO - Epoch [8/30] Batch [4700/4715] Loss: 0.8201\n",
      "2025-05-30 15:09:32,492 - INFO - Epoch [8/30] Batch [4710/4715] Loss: 1.0115\n",
      "2025-05-30 15:10:11,831 - INFO - \n",
      "Epoch [8/30] Time: 778.47s\n",
      "2025-05-30 15:10:11,832 - INFO - Train Loss: 0.8363, Valid Loss: 0.8255\n",
      "2025-05-30 15:10:11,832 - INFO - Valid AUC (macro): 0.7228, F1 (macro): 0.5652\n",
      "2025-05-30 15:10:12,362 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\best_model.pth\n",
      "2025-05-30 15:10:12,363 - INFO - New best model saved with AUC: 0.7228\n",
      "2025-05-30 15:10:12,885 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 15:10:12,886 - INFO - Saved checkpoint at epoch 8\n",
      "2025-05-30 15:10:13,073 - INFO - Epoch [9/30] Batch [0/4715] Loss: 0.7474\n",
      "2025-05-30 15:10:14,963 - INFO - Epoch [9/30] Batch [10/4715] Loss: 0.7643\n",
      "2025-05-30 15:10:16,789 - INFO - Epoch [9/30] Batch [20/4715] Loss: 0.5530\n",
      "2025-05-30 15:10:18,350 - INFO - Epoch [9/30] Batch [30/4715] Loss: 0.9337\n",
      "2025-05-30 15:10:19,895 - INFO - Epoch [9/30] Batch [40/4715] Loss: 0.8395\n",
      "2025-05-30 15:10:21,485 - INFO - Epoch [9/30] Batch [50/4715] Loss: 0.9659\n",
      "2025-05-30 15:10:23,009 - INFO - Epoch [9/30] Batch [60/4715] Loss: 0.7458\n",
      "2025-05-30 15:10:24,602 - INFO - Epoch [9/30] Batch [70/4715] Loss: 0.7641\n",
      "2025-05-30 15:10:26,231 - INFO - Epoch [9/30] Batch [80/4715] Loss: 0.5949\n",
      "2025-05-30 15:10:27,753 - INFO - Epoch [9/30] Batch [90/4715] Loss: 0.6840\n",
      "2025-05-30 15:10:29,266 - INFO - Epoch [9/30] Batch [100/4715] Loss: 0.9307\n",
      "2025-05-30 15:10:30,902 - INFO - Epoch [9/30] Batch [110/4715] Loss: 0.5801\n",
      "2025-05-30 15:10:32,422 - INFO - Epoch [9/30] Batch [120/4715] Loss: 0.7302\n",
      "2025-05-30 15:10:33,983 - INFO - Epoch [9/30] Batch [130/4715] Loss: 0.6524\n",
      "2025-05-30 15:10:35,554 - INFO - Epoch [9/30] Batch [140/4715] Loss: 1.0418\n",
      "2025-05-30 15:10:37,112 - INFO - Epoch [9/30] Batch [150/4715] Loss: 0.7366\n",
      "2025-05-30 15:10:38,719 - INFO - Epoch [9/30] Batch [160/4715] Loss: 0.8246\n",
      "2025-05-30 15:10:40,253 - INFO - Epoch [9/30] Batch [170/4715] Loss: 0.5601\n",
      "2025-05-30 15:10:41,844 - INFO - Epoch [9/30] Batch [180/4715] Loss: 0.7796\n",
      "2025-05-30 15:10:43,406 - INFO - Epoch [9/30] Batch [190/4715] Loss: 0.8299\n",
      "2025-05-30 15:10:44,953 - INFO - Epoch [9/30] Batch [200/4715] Loss: 0.8800\n",
      "2025-05-30 15:10:46,482 - INFO - Epoch [9/30] Batch [210/4715] Loss: 0.9293\n",
      "2025-05-30 15:10:48,107 - INFO - Epoch [9/30] Batch [220/4715] Loss: 0.5695\n",
      "2025-05-30 15:10:49,668 - INFO - Epoch [9/30] Batch [230/4715] Loss: 1.0900\n",
      "2025-05-30 15:10:51,260 - INFO - Epoch [9/30] Batch [240/4715] Loss: 0.9463\n",
      "2025-05-30 15:10:52,869 - INFO - Epoch [9/30] Batch [250/4715] Loss: 0.7218\n",
      "2025-05-30 15:10:54,462 - INFO - Epoch [9/30] Batch [260/4715] Loss: 0.8075\n",
      "2025-05-30 15:10:56,062 - INFO - Epoch [9/30] Batch [270/4715] Loss: 0.9678\n",
      "2025-05-30 15:10:57,670 - INFO - Epoch [9/30] Batch [280/4715] Loss: 0.7394\n",
      "2025-05-30 15:10:59,235 - INFO - Epoch [9/30] Batch [290/4715] Loss: 1.1619\n",
      "2025-05-30 15:11:00,827 - INFO - Epoch [9/30] Batch [300/4715] Loss: 0.8836\n",
      "2025-05-30 15:11:02,328 - INFO - Epoch [9/30] Batch [310/4715] Loss: 0.8917\n",
      "2025-05-30 15:11:03,884 - INFO - Epoch [9/30] Batch [320/4715] Loss: 0.7324\n",
      "2025-05-30 15:11:05,542 - INFO - Epoch [9/30] Batch [330/4715] Loss: 0.7668\n",
      "2025-05-30 15:11:07,154 - INFO - Epoch [9/30] Batch [340/4715] Loss: 0.7602\n",
      "2025-05-30 15:11:08,697 - INFO - Epoch [9/30] Batch [350/4715] Loss: 0.8133\n",
      "2025-05-30 15:11:10,209 - INFO - Epoch [9/30] Batch [360/4715] Loss: 0.8413\n",
      "2025-05-30 15:11:11,721 - INFO - Epoch [9/30] Batch [370/4715] Loss: 0.7399\n",
      "2025-05-30 15:11:13,249 - INFO - Epoch [9/30] Batch [380/4715] Loss: 0.8522\n",
      "2025-05-30 15:11:14,820 - INFO - Epoch [9/30] Batch [390/4715] Loss: 0.9099\n",
      "2025-05-30 15:11:16,372 - INFO - Epoch [9/30] Batch [400/4715] Loss: 0.7803\n",
      "2025-05-30 15:11:17,991 - INFO - Epoch [9/30] Batch [410/4715] Loss: 1.0573\n",
      "2025-05-30 15:11:19,560 - INFO - Epoch [9/30] Batch [420/4715] Loss: 1.0570\n",
      "2025-05-30 15:11:21,083 - INFO - Epoch [9/30] Batch [430/4715] Loss: 0.7642\n",
      "2025-05-30 15:11:22,602 - INFO - Epoch [9/30] Batch [440/4715] Loss: 0.7630\n",
      "2025-05-30 15:11:24,099 - INFO - Epoch [9/30] Batch [450/4715] Loss: 0.8905\n",
      "2025-05-30 15:11:25,592 - INFO - Epoch [9/30] Batch [460/4715] Loss: 0.7597\n",
      "2025-05-30 15:11:27,227 - INFO - Epoch [9/30] Batch [470/4715] Loss: 0.8974\n",
      "2025-05-30 15:11:28,819 - INFO - Epoch [9/30] Batch [480/4715] Loss: 0.8647\n",
      "2025-05-30 15:11:30,293 - INFO - Epoch [9/30] Batch [490/4715] Loss: 0.8555\n",
      "2025-05-30 15:11:31,841 - INFO - Epoch [9/30] Batch [500/4715] Loss: 0.9402\n",
      "2025-05-30 15:11:33,453 - INFO - Epoch [9/30] Batch [510/4715] Loss: 0.6036\n",
      "2025-05-30 15:11:34,986 - INFO - Epoch [9/30] Batch [520/4715] Loss: 0.8783\n",
      "2025-05-30 15:11:36,566 - INFO - Epoch [9/30] Batch [530/4715] Loss: 0.8493\n",
      "2025-05-30 15:11:38,064 - INFO - Epoch [9/30] Batch [540/4715] Loss: 0.7701\n",
      "2025-05-30 15:11:39,662 - INFO - Epoch [9/30] Batch [550/4715] Loss: 0.9378\n",
      "2025-05-30 15:11:41,389 - INFO - Epoch [9/30] Batch [560/4715] Loss: 0.8629\n",
      "2025-05-30 15:11:42,953 - INFO - Epoch [9/30] Batch [570/4715] Loss: 0.9511\n",
      "2025-05-30 15:11:44,502 - INFO - Epoch [9/30] Batch [580/4715] Loss: 0.7546\n",
      "2025-05-30 15:11:46,078 - INFO - Epoch [9/30] Batch [590/4715] Loss: 0.7752\n",
      "2025-05-30 15:11:47,636 - INFO - Epoch [9/30] Batch [600/4715] Loss: 0.7348\n",
      "2025-05-30 15:11:49,136 - INFO - Epoch [9/30] Batch [610/4715] Loss: 0.9098\n",
      "2025-05-30 15:11:50,677 - INFO - Epoch [9/30] Batch [620/4715] Loss: 0.5781\n",
      "2025-05-30 15:11:52,210 - INFO - Epoch [9/30] Batch [630/4715] Loss: 0.8012\n",
      "2025-05-30 15:11:53,808 - INFO - Epoch [9/30] Batch [640/4715] Loss: 0.5521\n",
      "2025-05-30 15:11:55,351 - INFO - Epoch [9/30] Batch [650/4715] Loss: 0.7451\n",
      "2025-05-30 15:11:56,903 - INFO - Epoch [9/30] Batch [660/4715] Loss: 0.8626\n",
      "2025-05-30 15:11:58,418 - INFO - Epoch [9/30] Batch [670/4715] Loss: 0.6007\n",
      "2025-05-30 15:11:59,963 - INFO - Epoch [9/30] Batch [680/4715] Loss: 0.9225\n",
      "2025-05-30 15:12:01,480 - INFO - Epoch [9/30] Batch [690/4715] Loss: 0.6950\n",
      "2025-05-30 15:12:03,097 - INFO - Epoch [9/30] Batch [700/4715] Loss: 0.8294\n",
      "2025-05-30 15:12:04,575 - INFO - Epoch [9/30] Batch [710/4715] Loss: 0.8010\n",
      "2025-05-30 15:12:06,245 - INFO - Epoch [9/30] Batch [720/4715] Loss: 0.7874\n",
      "2025-05-30 15:12:07,839 - INFO - Epoch [9/30] Batch [730/4715] Loss: 0.5941\n",
      "2025-05-30 15:12:09,547 - INFO - Epoch [9/30] Batch [740/4715] Loss: 0.6890\n",
      "2025-05-30 15:12:11,278 - INFO - Epoch [9/30] Batch [750/4715] Loss: 0.6555\n",
      "2025-05-30 15:12:12,995 - INFO - Epoch [9/30] Batch [760/4715] Loss: 0.8392\n",
      "2025-05-30 15:12:14,751 - INFO - Epoch [9/30] Batch [770/4715] Loss: 0.8421\n",
      "2025-05-30 15:12:16,291 - INFO - Epoch [9/30] Batch [780/4715] Loss: 0.8913\n",
      "2025-05-30 15:12:17,796 - INFO - Epoch [9/30] Batch [790/4715] Loss: 0.8433\n",
      "2025-05-30 15:12:19,335 - INFO - Epoch [9/30] Batch [800/4715] Loss: 0.8856\n",
      "2025-05-30 15:12:20,897 - INFO - Epoch [9/30] Batch [810/4715] Loss: 0.7713\n",
      "2025-05-30 15:12:22,468 - INFO - Epoch [9/30] Batch [820/4715] Loss: 1.0308\n",
      "2025-05-30 15:12:24,091 - INFO - Epoch [9/30] Batch [830/4715] Loss: 0.5030\n",
      "2025-05-30 15:12:25,667 - INFO - Epoch [9/30] Batch [840/4715] Loss: 1.0449\n",
      "2025-05-30 15:12:27,216 - INFO - Epoch [9/30] Batch [850/4715] Loss: 0.7267\n",
      "2025-05-30 15:12:28,784 - INFO - Epoch [9/30] Batch [860/4715] Loss: 0.9299\n",
      "2025-05-30 15:12:30,272 - INFO - Epoch [9/30] Batch [870/4715] Loss: 0.8690\n",
      "2025-05-30 15:12:31,877 - INFO - Epoch [9/30] Batch [880/4715] Loss: 0.7786\n",
      "2025-05-30 15:12:33,392 - INFO - Epoch [9/30] Batch [890/4715] Loss: 0.8102\n",
      "2025-05-30 15:12:35,005 - INFO - Epoch [9/30] Batch [900/4715] Loss: 1.1797\n",
      "2025-05-30 15:12:36,566 - INFO - Epoch [9/30] Batch [910/4715] Loss: 0.8173\n",
      "2025-05-30 15:12:38,180 - INFO - Epoch [9/30] Batch [920/4715] Loss: 0.8626\n",
      "2025-05-30 15:12:39,737 - INFO - Epoch [9/30] Batch [930/4715] Loss: 0.8245\n",
      "2025-05-30 15:12:41,236 - INFO - Epoch [9/30] Batch [940/4715] Loss: 0.7634\n",
      "2025-05-30 15:12:42,810 - INFO - Epoch [9/30] Batch [950/4715] Loss: 0.7631\n",
      "2025-05-30 15:12:44,317 - INFO - Epoch [9/30] Batch [960/4715] Loss: 0.8322\n",
      "2025-05-30 15:12:46,009 - INFO - Epoch [9/30] Batch [970/4715] Loss: 1.0274\n",
      "2025-05-30 15:12:47,524 - INFO - Epoch [9/30] Batch [980/4715] Loss: 0.5496\n",
      "2025-05-30 15:12:49,039 - INFO - Epoch [9/30] Batch [990/4715] Loss: 0.8707\n",
      "2025-05-30 15:12:50,604 - INFO - Epoch [9/30] Batch [1000/4715] Loss: 0.7563\n",
      "2025-05-30 15:12:52,144 - INFO - Epoch [9/30] Batch [1010/4715] Loss: 0.8893\n",
      "2025-05-30 15:12:53,653 - INFO - Epoch [9/30] Batch [1020/4715] Loss: 0.6382\n",
      "2025-05-30 15:12:55,213 - INFO - Epoch [9/30] Batch [1030/4715] Loss: 0.7574\n",
      "2025-05-30 15:12:56,833 - INFO - Epoch [9/30] Batch [1040/4715] Loss: 0.6871\n",
      "2025-05-30 15:12:58,364 - INFO - Epoch [9/30] Batch [1050/4715] Loss: 0.8456\n",
      "2025-05-30 15:12:59,950 - INFO - Epoch [9/30] Batch [1060/4715] Loss: 0.8374\n",
      "2025-05-30 15:13:01,488 - INFO - Epoch [9/30] Batch [1070/4715] Loss: 0.8078\n",
      "2025-05-30 15:13:03,011 - INFO - Epoch [9/30] Batch [1080/4715] Loss: 0.8827\n",
      "2025-05-30 15:13:04,568 - INFO - Epoch [9/30] Batch [1090/4715] Loss: 0.8855\n",
      "2025-05-30 15:13:06,105 - INFO - Epoch [9/30] Batch [1100/4715] Loss: 0.7265\n",
      "2025-05-30 15:13:07,696 - INFO - Epoch [9/30] Batch [1110/4715] Loss: 0.7310\n",
      "2025-05-30 15:13:09,287 - INFO - Epoch [9/30] Batch [1120/4715] Loss: 0.9004\n",
      "2025-05-30 15:13:10,908 - INFO - Epoch [9/30] Batch [1130/4715] Loss: 1.1600\n",
      "2025-05-30 15:13:12,514 - INFO - Epoch [9/30] Batch [1140/4715] Loss: 0.9396\n",
      "2025-05-30 15:13:14,158 - INFO - Epoch [9/30] Batch [1150/4715] Loss: 0.6809\n",
      "2025-05-30 15:13:15,770 - INFO - Epoch [9/30] Batch [1160/4715] Loss: 0.6948\n",
      "2025-05-30 15:13:17,302 - INFO - Epoch [9/30] Batch [1170/4715] Loss: 0.9804\n",
      "2025-05-30 15:13:18,905 - INFO - Epoch [9/30] Batch [1180/4715] Loss: 0.8652\n",
      "2025-05-30 15:13:20,511 - INFO - Epoch [9/30] Batch [1190/4715] Loss: 0.7162\n",
      "2025-05-30 15:13:22,046 - INFO - Epoch [9/30] Batch [1200/4715] Loss: 0.9392\n",
      "2025-05-30 15:13:23,586 - INFO - Epoch [9/30] Batch [1210/4715] Loss: 0.6930\n",
      "2025-05-30 15:13:25,135 - INFO - Epoch [9/30] Batch [1220/4715] Loss: 0.9354\n",
      "2025-05-30 15:13:26,635 - INFO - Epoch [9/30] Batch [1230/4715] Loss: 1.0348\n",
      "2025-05-30 15:13:28,263 - INFO - Epoch [9/30] Batch [1240/4715] Loss: 0.9349\n",
      "2025-05-30 15:13:29,933 - INFO - Epoch [9/30] Batch [1250/4715] Loss: 0.9528\n",
      "2025-05-30 15:13:31,591 - INFO - Epoch [9/30] Batch [1260/4715] Loss: 1.1291\n",
      "2025-05-30 15:13:33,176 - INFO - Epoch [9/30] Batch [1270/4715] Loss: 0.7419\n",
      "2025-05-30 15:13:34,759 - INFO - Epoch [9/30] Batch [1280/4715] Loss: 0.8320\n",
      "2025-05-30 15:13:36,272 - INFO - Epoch [9/30] Batch [1290/4715] Loss: 0.6481\n",
      "2025-05-30 15:13:37,807 - INFO - Epoch [9/30] Batch [1300/4715] Loss: 0.8716\n",
      "2025-05-30 15:13:39,342 - INFO - Epoch [9/30] Batch [1310/4715] Loss: 0.7432\n",
      "2025-05-30 15:13:40,869 - INFO - Epoch [9/30] Batch [1320/4715] Loss: 0.8828\n",
      "2025-05-30 15:13:42,448 - INFO - Epoch [9/30] Batch [1330/4715] Loss: 0.6060\n",
      "2025-05-30 15:13:44,018 - INFO - Epoch [9/30] Batch [1340/4715] Loss: 0.6578\n",
      "2025-05-30 15:13:45,546 - INFO - Epoch [9/30] Batch [1350/4715] Loss: 0.8627\n",
      "2025-05-30 15:13:47,095 - INFO - Epoch [9/30] Batch [1360/4715] Loss: 0.9842\n",
      "2025-05-30 15:13:48,564 - INFO - Epoch [9/30] Batch [1370/4715] Loss: 1.0281\n",
      "2025-05-30 15:13:50,057 - INFO - Epoch [9/30] Batch [1380/4715] Loss: 0.9788\n",
      "2025-05-30 15:13:51,611 - INFO - Epoch [9/30] Batch [1390/4715] Loss: 0.8007\n",
      "2025-05-30 15:13:53,272 - INFO - Epoch [9/30] Batch [1400/4715] Loss: 0.7776\n",
      "2025-05-30 15:13:54,841 - INFO - Epoch [9/30] Batch [1410/4715] Loss: 0.7445\n",
      "2025-05-30 15:13:56,401 - INFO - Epoch [9/30] Batch [1420/4715] Loss: 0.8702\n",
      "2025-05-30 15:13:57,926 - INFO - Epoch [9/30] Batch [1430/4715] Loss: 0.6697\n",
      "2025-05-30 15:13:59,441 - INFO - Epoch [9/30] Batch [1440/4715] Loss: 0.7867\n",
      "2025-05-30 15:14:01,009 - INFO - Epoch [9/30] Batch [1450/4715] Loss: 0.8630\n",
      "2025-05-30 15:14:02,501 - INFO - Epoch [9/30] Batch [1460/4715] Loss: 0.8419\n",
      "2025-05-30 15:14:04,069 - INFO - Epoch [9/30] Batch [1470/4715] Loss: 0.7661\n",
      "2025-05-30 15:14:05,652 - INFO - Epoch [9/30] Batch [1480/4715] Loss: 0.7844\n",
      "2025-05-30 15:14:07,181 - INFO - Epoch [9/30] Batch [1490/4715] Loss: 0.7959\n",
      "2025-05-30 15:14:08,737 - INFO - Epoch [9/30] Batch [1500/4715] Loss: 0.7098\n",
      "2025-05-30 15:14:10,266 - INFO - Epoch [9/30] Batch [1510/4715] Loss: 1.0039\n",
      "2025-05-30 15:14:11,961 - INFO - Epoch [9/30] Batch [1520/4715] Loss: 0.7438\n",
      "2025-05-30 15:14:13,509 - INFO - Epoch [9/30] Batch [1530/4715] Loss: 0.8317\n",
      "2025-05-30 15:14:15,090 - INFO - Epoch [9/30] Batch [1540/4715] Loss: 0.8249\n",
      "2025-05-30 15:14:16,668 - INFO - Epoch [9/30] Batch [1550/4715] Loss: 1.0571\n",
      "2025-05-30 15:14:18,149 - INFO - Epoch [9/30] Batch [1560/4715] Loss: 0.7577\n",
      "2025-05-30 15:14:19,770 - INFO - Epoch [9/30] Batch [1570/4715] Loss: 0.8058\n",
      "2025-05-30 15:14:21,321 - INFO - Epoch [9/30] Batch [1580/4715] Loss: 0.8445\n",
      "2025-05-30 15:14:22,861 - INFO - Epoch [9/30] Batch [1590/4715] Loss: 0.7880\n",
      "2025-05-30 15:14:24,369 - INFO - Epoch [9/30] Batch [1600/4715] Loss: 0.5837\n",
      "2025-05-30 15:14:25,843 - INFO - Epoch [9/30] Batch [1610/4715] Loss: 0.8847\n",
      "2025-05-30 15:14:27,439 - INFO - Epoch [9/30] Batch [1620/4715] Loss: 0.7357\n",
      "2025-05-30 15:14:29,033 - INFO - Epoch [9/30] Batch [1630/4715] Loss: 0.8253\n",
      "2025-05-30 15:14:30,560 - INFO - Epoch [9/30] Batch [1640/4715] Loss: 0.6648\n",
      "2025-05-30 15:14:32,143 - INFO - Epoch [9/30] Batch [1650/4715] Loss: 0.9588\n",
      "2025-05-30 15:14:33,754 - INFO - Epoch [9/30] Batch [1660/4715] Loss: 0.7280\n",
      "2025-05-30 15:14:35,329 - INFO - Epoch [9/30] Batch [1670/4715] Loss: 1.1108\n",
      "2025-05-30 15:14:36,883 - INFO - Epoch [9/30] Batch [1680/4715] Loss: 0.9402\n",
      "2025-05-30 15:14:38,492 - INFO - Epoch [9/30] Batch [1690/4715] Loss: 1.1212\n",
      "2025-05-30 15:14:40,050 - INFO - Epoch [9/30] Batch [1700/4715] Loss: 0.7073\n",
      "2025-05-30 15:14:41,616 - INFO - Epoch [9/30] Batch [1710/4715] Loss: 0.8693\n",
      "2025-05-30 15:14:43,250 - INFO - Epoch [9/30] Batch [1720/4715] Loss: 0.9495\n",
      "2025-05-30 15:14:44,892 - INFO - Epoch [9/30] Batch [1730/4715] Loss: 0.8593\n",
      "2025-05-30 15:14:46,428 - INFO - Epoch [9/30] Batch [1740/4715] Loss: 0.6797\n",
      "2025-05-30 15:14:47,940 - INFO - Epoch [9/30] Batch [1750/4715] Loss: 0.5356\n",
      "2025-05-30 15:14:49,534 - INFO - Epoch [9/30] Batch [1760/4715] Loss: 0.8027\n",
      "2025-05-30 15:14:51,066 - INFO - Epoch [9/30] Batch [1770/4715] Loss: 0.6645\n",
      "2025-05-30 15:14:52,669 - INFO - Epoch [9/30] Batch [1780/4715] Loss: 0.9100\n",
      "2025-05-30 15:14:54,225 - INFO - Epoch [9/30] Batch [1790/4715] Loss: 0.7967\n",
      "2025-05-30 15:14:55,824 - INFO - Epoch [9/30] Batch [1800/4715] Loss: 1.0966\n",
      "2025-05-30 15:14:57,428 - INFO - Epoch [9/30] Batch [1810/4715] Loss: 1.2023\n",
      "2025-05-30 15:14:58,966 - INFO - Epoch [9/30] Batch [1820/4715] Loss: 0.7525\n",
      "2025-05-30 15:15:00,530 - INFO - Epoch [9/30] Batch [1830/4715] Loss: 0.8905\n",
      "2025-05-30 15:15:02,108 - INFO - Epoch [9/30] Batch [1840/4715] Loss: 0.6355\n",
      "2025-05-30 15:15:03,629 - INFO - Epoch [9/30] Batch [1850/4715] Loss: 0.5335\n",
      "2025-05-30 15:15:05,210 - INFO - Epoch [9/30] Batch [1860/4715] Loss: 0.7154\n",
      "2025-05-30 15:15:06,758 - INFO - Epoch [9/30] Batch [1870/4715] Loss: 0.8582\n",
      "2025-05-30 15:15:08,279 - INFO - Epoch [9/30] Batch [1880/4715] Loss: 0.7381\n",
      "2025-05-30 15:15:09,991 - INFO - Epoch [9/30] Batch [1890/4715] Loss: 0.8279\n",
      "2025-05-30 15:15:11,586 - INFO - Epoch [9/30] Batch [1900/4715] Loss: 0.9260\n",
      "2025-05-30 15:15:13,154 - INFO - Epoch [9/30] Batch [1910/4715] Loss: 0.8389\n",
      "2025-05-30 15:15:14,787 - INFO - Epoch [9/30] Batch [1920/4715] Loss: 0.7263\n",
      "2025-05-30 15:15:16,304 - INFO - Epoch [9/30] Batch [1930/4715] Loss: 0.6775\n",
      "2025-05-30 15:15:17,884 - INFO - Epoch [9/30] Batch [1940/4715] Loss: 0.6352\n",
      "2025-05-30 15:15:19,398 - INFO - Epoch [9/30] Batch [1950/4715] Loss: 0.8910\n",
      "2025-05-30 15:15:20,975 - INFO - Epoch [9/30] Batch [1960/4715] Loss: 0.6440\n",
      "2025-05-30 15:15:22,481 - INFO - Epoch [9/30] Batch [1970/4715] Loss: 0.6007\n",
      "2025-05-30 15:15:24,078 - INFO - Epoch [9/30] Batch [1980/4715] Loss: 0.9700\n",
      "2025-05-30 15:15:25,565 - INFO - Epoch [9/30] Batch [1990/4715] Loss: 0.7798\n",
      "2025-05-30 15:15:27,146 - INFO - Epoch [9/30] Batch [2000/4715] Loss: 0.8013\n",
      "2025-05-30 15:15:28,720 - INFO - Epoch [9/30] Batch [2010/4715] Loss: 0.8016\n",
      "2025-05-30 15:15:30,245 - INFO - Epoch [9/30] Batch [2020/4715] Loss: 0.8965\n",
      "2025-05-30 15:15:31,745 - INFO - Epoch [9/30] Batch [2030/4715] Loss: 0.6774\n",
      "2025-05-30 15:15:33,269 - INFO - Epoch [9/30] Batch [2040/4715] Loss: 0.9021\n",
      "2025-05-30 15:15:34,862 - INFO - Epoch [9/30] Batch [2050/4715] Loss: 0.9877\n",
      "2025-05-30 15:15:36,477 - INFO - Epoch [9/30] Batch [2060/4715] Loss: 0.7566\n",
      "2025-05-30 15:15:38,054 - INFO - Epoch [9/30] Batch [2070/4715] Loss: 0.8811\n",
      "2025-05-30 15:15:39,514 - INFO - Epoch [9/30] Batch [2080/4715] Loss: 0.9392\n",
      "2025-05-30 15:15:41,057 - INFO - Epoch [9/30] Batch [2090/4715] Loss: 0.6858\n",
      "2025-05-30 15:15:42,564 - INFO - Epoch [9/30] Batch [2100/4715] Loss: 0.7406\n",
      "2025-05-30 15:15:44,170 - INFO - Epoch [9/30] Batch [2110/4715] Loss: 0.9548\n",
      "2025-05-30 15:15:45,777 - INFO - Epoch [9/30] Batch [2120/4715] Loss: 0.5615\n",
      "2025-05-30 15:15:47,265 - INFO - Epoch [9/30] Batch [2130/4715] Loss: 0.5535\n",
      "2025-05-30 15:15:48,819 - INFO - Epoch [9/30] Batch [2140/4715] Loss: 0.7838\n",
      "2025-05-30 15:15:50,331 - INFO - Epoch [9/30] Batch [2150/4715] Loss: 0.7733\n",
      "2025-05-30 15:15:51,880 - INFO - Epoch [9/30] Batch [2160/4715] Loss: 0.8403\n",
      "2025-05-30 15:15:53,408 - INFO - Epoch [9/30] Batch [2170/4715] Loss: 0.8949\n",
      "2025-05-30 15:15:55,035 - INFO - Epoch [9/30] Batch [2180/4715] Loss: 0.8315\n",
      "2025-05-30 15:15:56,621 - INFO - Epoch [9/30] Batch [2190/4715] Loss: 0.9663\n",
      "2025-05-30 15:15:58,198 - INFO - Epoch [9/30] Batch [2200/4715] Loss: 0.7537\n",
      "2025-05-30 15:15:59,738 - INFO - Epoch [9/30] Batch [2210/4715] Loss: 0.9542\n",
      "2025-05-30 15:16:01,429 - INFO - Epoch [9/30] Batch [2220/4715] Loss: 0.7677\n",
      "2025-05-30 15:16:03,119 - INFO - Epoch [9/30] Batch [2230/4715] Loss: 0.9202\n",
      "2025-05-30 15:16:04,718 - INFO - Epoch [9/30] Batch [2240/4715] Loss: 0.8512\n",
      "2025-05-30 15:16:06,266 - INFO - Epoch [9/30] Batch [2250/4715] Loss: 0.9008\n",
      "2025-05-30 15:16:07,821 - INFO - Epoch [9/30] Batch [2260/4715] Loss: 0.8191\n",
      "2025-05-30 15:16:09,440 - INFO - Epoch [9/30] Batch [2270/4715] Loss: 0.7815\n",
      "2025-05-30 15:16:10,982 - INFO - Epoch [9/30] Batch [2280/4715] Loss: 0.9578\n",
      "2025-05-30 15:16:12,501 - INFO - Epoch [9/30] Batch [2290/4715] Loss: 0.8047\n",
      "2025-05-30 15:16:14,244 - INFO - Epoch [9/30] Batch [2300/4715] Loss: 0.6494\n",
      "2025-05-30 15:16:15,752 - INFO - Epoch [9/30] Batch [2310/4715] Loss: 1.1782\n",
      "2025-05-30 15:16:17,399 - INFO - Epoch [9/30] Batch [2320/4715] Loss: 0.8934\n",
      "2025-05-30 15:16:18,903 - INFO - Epoch [9/30] Batch [2330/4715] Loss: 0.8132\n",
      "2025-05-30 15:16:20,537 - INFO - Epoch [9/30] Batch [2340/4715] Loss: 0.8849\n",
      "2025-05-30 15:16:22,032 - INFO - Epoch [9/30] Batch [2350/4715] Loss: 0.8010\n",
      "2025-05-30 15:16:23,577 - INFO - Epoch [9/30] Batch [2360/4715] Loss: 0.7731\n",
      "2025-05-30 15:16:25,120 - INFO - Epoch [9/30] Batch [2370/4715] Loss: 0.7459\n",
      "2025-05-30 15:16:26,654 - INFO - Epoch [9/30] Batch [2380/4715] Loss: 0.7257\n",
      "2025-05-30 15:16:28,124 - INFO - Epoch [9/30] Batch [2390/4715] Loss: 0.9606\n",
      "2025-05-30 15:16:29,825 - INFO - Epoch [9/30] Batch [2400/4715] Loss: 0.9168\n",
      "2025-05-30 15:16:31,372 - INFO - Epoch [9/30] Batch [2410/4715] Loss: 0.7887\n",
      "2025-05-30 15:16:32,949 - INFO - Epoch [9/30] Batch [2420/4715] Loss: 1.0470\n",
      "2025-05-30 15:16:34,593 - INFO - Epoch [9/30] Batch [2430/4715] Loss: 1.0471\n",
      "2025-05-30 15:16:36,265 - INFO - Epoch [9/30] Batch [2440/4715] Loss: 1.1339\n",
      "2025-05-30 15:16:37,805 - INFO - Epoch [9/30] Batch [2450/4715] Loss: 0.6797\n",
      "2025-05-30 15:16:39,451 - INFO - Epoch [9/30] Batch [2460/4715] Loss: 0.8978\n",
      "2025-05-30 15:16:41,050 - INFO - Epoch [9/30] Batch [2470/4715] Loss: 0.8677\n",
      "2025-05-30 15:16:42,570 - INFO - Epoch [9/30] Batch [2480/4715] Loss: 0.8157\n",
      "2025-05-30 15:16:44,163 - INFO - Epoch [9/30] Batch [2490/4715] Loss: 0.6787\n",
      "2025-05-30 15:16:45,751 - INFO - Epoch [9/30] Batch [2500/4715] Loss: 0.8299\n",
      "2025-05-30 15:16:47,394 - INFO - Epoch [9/30] Batch [2510/4715] Loss: 0.7362\n",
      "2025-05-30 15:16:48,928 - INFO - Epoch [9/30] Batch [2520/4715] Loss: 0.8803\n",
      "2025-05-30 15:16:50,453 - INFO - Epoch [9/30] Batch [2530/4715] Loss: 0.7339\n",
      "2025-05-30 15:16:52,040 - INFO - Epoch [9/30] Batch [2540/4715] Loss: 0.7401\n",
      "2025-05-30 15:16:53,628 - INFO - Epoch [9/30] Batch [2550/4715] Loss: 0.7233\n",
      "2025-05-30 15:16:55,125 - INFO - Epoch [9/30] Batch [2560/4715] Loss: 0.7719\n",
      "2025-05-30 15:16:56,658 - INFO - Epoch [9/30] Batch [2570/4715] Loss: 0.7185\n",
      "2025-05-30 15:16:58,190 - INFO - Epoch [9/30] Batch [2580/4715] Loss: 0.8644\n",
      "2025-05-30 15:16:59,844 - INFO - Epoch [9/30] Batch [2590/4715] Loss: 0.8704\n",
      "2025-05-30 15:17:01,350 - INFO - Epoch [9/30] Batch [2600/4715] Loss: 0.5982\n",
      "2025-05-30 15:17:02,907 - INFO - Epoch [9/30] Batch [2610/4715] Loss: 0.7292\n",
      "2025-05-30 15:17:04,446 - INFO - Epoch [9/30] Batch [2620/4715] Loss: 0.7556\n",
      "2025-05-30 15:17:06,074 - INFO - Epoch [9/30] Batch [2630/4715] Loss: 0.8349\n",
      "2025-05-30 15:17:07,641 - INFO - Epoch [9/30] Batch [2640/4715] Loss: 0.9040\n",
      "2025-05-30 15:17:09,158 - INFO - Epoch [9/30] Batch [2650/4715] Loss: 0.6383\n",
      "2025-05-30 15:17:10,759 - INFO - Epoch [9/30] Batch [2660/4715] Loss: 0.7953\n",
      "2025-05-30 15:17:12,382 - INFO - Epoch [9/30] Batch [2670/4715] Loss: 1.0216\n",
      "2025-05-30 15:17:14,026 - INFO - Epoch [9/30] Batch [2680/4715] Loss: 1.0083\n",
      "2025-05-30 15:17:15,567 - INFO - Epoch [9/30] Batch [2690/4715] Loss: 0.6542\n",
      "2025-05-30 15:17:17,233 - INFO - Epoch [9/30] Batch [2700/4715] Loss: 1.0155\n",
      "2025-05-30 15:17:18,774 - INFO - Epoch [9/30] Batch [2710/4715] Loss: 0.8085\n",
      "2025-05-30 15:17:20,335 - INFO - Epoch [9/30] Batch [2720/4715] Loss: 0.9751\n",
      "2025-05-30 15:17:21,849 - INFO - Epoch [9/30] Batch [2730/4715] Loss: 0.9227\n",
      "2025-05-30 15:17:23,395 - INFO - Epoch [9/30] Batch [2740/4715] Loss: 0.6411\n",
      "2025-05-30 15:17:25,012 - INFO - Epoch [9/30] Batch [2750/4715] Loss: 0.9948\n",
      "2025-05-30 15:17:26,500 - INFO - Epoch [9/30] Batch [2760/4715] Loss: 0.8442\n",
      "2025-05-30 15:17:28,030 - INFO - Epoch [9/30] Batch [2770/4715] Loss: 0.9848\n",
      "2025-05-30 15:17:29,475 - INFO - Epoch [9/30] Batch [2780/4715] Loss: 0.8556\n",
      "2025-05-30 15:17:31,050 - INFO - Epoch [9/30] Batch [2790/4715] Loss: 0.7630\n",
      "2025-05-30 15:17:32,600 - INFO - Epoch [9/30] Batch [2800/4715] Loss: 1.1478\n",
      "2025-05-30 15:17:34,154 - INFO - Epoch [9/30] Batch [2810/4715] Loss: 0.8997\n",
      "2025-05-30 15:17:35,665 - INFO - Epoch [9/30] Batch [2820/4715] Loss: 0.7759\n",
      "2025-05-30 15:17:37,182 - INFO - Epoch [9/30] Batch [2830/4715] Loss: 0.6832\n",
      "2025-05-30 15:17:38,761 - INFO - Epoch [9/30] Batch [2840/4715] Loss: 0.7998\n",
      "2025-05-30 15:17:40,400 - INFO - Epoch [9/30] Batch [2850/4715] Loss: 0.6659\n",
      "2025-05-30 15:17:41,991 - INFO - Epoch [9/30] Batch [2860/4715] Loss: 0.9615\n",
      "2025-05-30 15:17:43,619 - INFO - Epoch [9/30] Batch [2870/4715] Loss: 0.7262\n",
      "2025-05-30 15:17:45,221 - INFO - Epoch [9/30] Batch [2880/4715] Loss: 0.9485\n",
      "2025-05-30 15:17:46,829 - INFO - Epoch [9/30] Batch [2890/4715] Loss: 0.8839\n",
      "2025-05-30 15:17:48,312 - INFO - Epoch [9/30] Batch [2900/4715] Loss: 0.6312\n",
      "2025-05-30 15:17:49,896 - INFO - Epoch [9/30] Batch [2910/4715] Loss: 0.7574\n",
      "2025-05-30 15:17:51,570 - INFO - Epoch [9/30] Batch [2920/4715] Loss: 0.7690\n",
      "2025-05-30 15:17:53,088 - INFO - Epoch [9/30] Batch [2930/4715] Loss: 0.7910\n",
      "2025-05-30 15:17:54,730 - INFO - Epoch [9/30] Batch [2940/4715] Loss: 1.0369\n",
      "2025-05-30 15:17:56,363 - INFO - Epoch [9/30] Batch [2950/4715] Loss: 1.0502\n",
      "2025-05-30 15:17:57,937 - INFO - Epoch [9/30] Batch [2960/4715] Loss: 0.5718\n",
      "2025-05-30 15:17:59,606 - INFO - Epoch [9/30] Batch [2970/4715] Loss: 0.7654\n",
      "2025-05-30 15:18:01,151 - INFO - Epoch [9/30] Batch [2980/4715] Loss: 0.8146\n",
      "2025-05-30 15:18:02,737 - INFO - Epoch [9/30] Batch [2990/4715] Loss: 0.9054\n",
      "2025-05-30 15:18:04,289 - INFO - Epoch [9/30] Batch [3000/4715] Loss: 0.9941\n",
      "2025-05-30 15:18:05,936 - INFO - Epoch [9/30] Batch [3010/4715] Loss: 0.7313\n",
      "2025-05-30 15:18:07,473 - INFO - Epoch [9/30] Batch [3020/4715] Loss: 0.6929\n",
      "2025-05-30 15:18:09,017 - INFO - Epoch [9/30] Batch [3030/4715] Loss: 0.7778\n",
      "2025-05-30 15:18:10,626 - INFO - Epoch [9/30] Batch [3040/4715] Loss: 0.7000\n",
      "2025-05-30 15:18:12,155 - INFO - Epoch [9/30] Batch [3050/4715] Loss: 0.8117\n",
      "2025-05-30 15:18:13,720 - INFO - Epoch [9/30] Batch [3060/4715] Loss: 0.6952\n",
      "2025-05-30 15:18:15,245 - INFO - Epoch [9/30] Batch [3070/4715] Loss: 0.8458\n",
      "2025-05-30 15:18:16,830 - INFO - Epoch [9/30] Batch [3080/4715] Loss: 0.7315\n",
      "2025-05-30 15:18:18,322 - INFO - Epoch [9/30] Batch [3090/4715] Loss: 0.7955\n",
      "2025-05-30 15:18:19,840 - INFO - Epoch [9/30] Batch [3100/4715] Loss: 0.8233\n",
      "2025-05-30 15:18:21,416 - INFO - Epoch [9/30] Batch [3110/4715] Loss: 0.7497\n",
      "2025-05-30 15:18:22,986 - INFO - Epoch [9/30] Batch [3120/4715] Loss: 1.2068\n",
      "2025-05-30 15:18:24,582 - INFO - Epoch [9/30] Batch [3130/4715] Loss: 0.6735\n",
      "2025-05-30 15:18:26,236 - INFO - Epoch [9/30] Batch [3140/4715] Loss: 0.9248\n",
      "2025-05-30 15:18:27,798 - INFO - Epoch [9/30] Batch [3150/4715] Loss: 0.6351\n",
      "2025-05-30 15:18:29,344 - INFO - Epoch [9/30] Batch [3160/4715] Loss: 0.8600\n",
      "2025-05-30 15:18:30,867 - INFO - Epoch [9/30] Batch [3170/4715] Loss: 0.6945\n",
      "2025-05-30 15:18:32,422 - INFO - Epoch [9/30] Batch [3180/4715] Loss: 0.7781\n",
      "2025-05-30 15:18:33,942 - INFO - Epoch [9/30] Batch [3190/4715] Loss: 1.0151\n",
      "2025-05-30 15:18:35,574 - INFO - Epoch [9/30] Batch [3200/4715] Loss: 1.0052\n",
      "2025-05-30 15:18:37,131 - INFO - Epoch [9/30] Batch [3210/4715] Loss: 0.9214\n",
      "2025-05-30 15:18:38,748 - INFO - Epoch [9/30] Batch [3220/4715] Loss: 0.8524\n",
      "2025-05-30 15:18:40,345 - INFO - Epoch [9/30] Batch [3230/4715] Loss: 0.6676\n",
      "2025-05-30 15:18:41,936 - INFO - Epoch [9/30] Batch [3240/4715] Loss: 0.8552\n",
      "2025-05-30 15:18:43,506 - INFO - Epoch [9/30] Batch [3250/4715] Loss: 0.6352\n",
      "2025-05-30 15:18:44,995 - INFO - Epoch [9/30] Batch [3260/4715] Loss: 0.9100\n",
      "2025-05-30 15:18:46,546 - INFO - Epoch [9/30] Batch [3270/4715] Loss: 0.9591\n",
      "2025-05-30 15:18:48,043 - INFO - Epoch [9/30] Batch [3280/4715] Loss: 0.9804\n",
      "2025-05-30 15:18:49,517 - INFO - Epoch [9/30] Batch [3290/4715] Loss: 0.9407\n",
      "2025-05-30 15:18:51,058 - INFO - Epoch [9/30] Batch [3300/4715] Loss: 0.7886\n",
      "2025-05-30 15:18:52,641 - INFO - Epoch [9/30] Batch [3310/4715] Loss: 0.6688\n",
      "2025-05-30 15:18:54,142 - INFO - Epoch [9/30] Batch [3320/4715] Loss: 0.7668\n",
      "2025-05-30 15:18:55,608 - INFO - Epoch [9/30] Batch [3330/4715] Loss: 0.9442\n",
      "2025-05-30 15:18:57,180 - INFO - Epoch [9/30] Batch [3340/4715] Loss: 1.0499\n",
      "2025-05-30 15:18:58,804 - INFO - Epoch [9/30] Batch [3350/4715] Loss: 1.0047\n",
      "2025-05-30 15:19:00,422 - INFO - Epoch [9/30] Batch [3360/4715] Loss: 0.6949\n",
      "2025-05-30 15:19:01,956 - INFO - Epoch [9/30] Batch [3370/4715] Loss: 0.6777\n",
      "2025-05-30 15:19:03,443 - INFO - Epoch [9/30] Batch [3380/4715] Loss: 0.6486\n",
      "2025-05-30 15:19:04,964 - INFO - Epoch [9/30] Batch [3390/4715] Loss: 0.9091\n",
      "2025-05-30 15:19:06,553 - INFO - Epoch [9/30] Batch [3400/4715] Loss: 0.8541\n",
      "2025-05-30 15:19:08,027 - INFO - Epoch [9/30] Batch [3410/4715] Loss: 0.9378\n",
      "2025-05-30 15:19:09,480 - INFO - Epoch [9/30] Batch [3420/4715] Loss: 0.6294\n",
      "2025-05-30 15:19:10,999 - INFO - Epoch [9/30] Batch [3430/4715] Loss: 0.7853\n",
      "2025-05-30 15:19:12,613 - INFO - Epoch [9/30] Batch [3440/4715] Loss: 0.4693\n",
      "2025-05-30 15:19:14,257 - INFO - Epoch [9/30] Batch [3450/4715] Loss: 0.7381\n",
      "2025-05-30 15:19:15,836 - INFO - Epoch [9/30] Batch [3460/4715] Loss: 0.8329\n",
      "2025-05-30 15:19:17,460 - INFO - Epoch [9/30] Batch [3470/4715] Loss: 0.5987\n",
      "2025-05-30 15:19:19,026 - INFO - Epoch [9/30] Batch [3480/4715] Loss: 0.5740\n",
      "2025-05-30 15:19:20,610 - INFO - Epoch [9/30] Batch [3490/4715] Loss: 0.9326\n",
      "2025-05-30 15:19:22,173 - INFO - Epoch [9/30] Batch [3500/4715] Loss: 0.9166\n",
      "2025-05-30 15:19:23,814 - INFO - Epoch [9/30] Batch [3510/4715] Loss: 0.8549\n",
      "2025-05-30 15:19:25,367 - INFO - Epoch [9/30] Batch [3520/4715] Loss: 0.7025\n",
      "2025-05-30 15:19:26,942 - INFO - Epoch [9/30] Batch [3530/4715] Loss: 0.6585\n",
      "2025-05-30 15:19:28,543 - INFO - Epoch [9/30] Batch [3540/4715] Loss: 0.8236\n",
      "2025-05-30 15:19:30,255 - INFO - Epoch [9/30] Batch [3550/4715] Loss: 0.7625\n",
      "2025-05-30 15:19:31,869 - INFO - Epoch [9/30] Batch [3560/4715] Loss: 0.9985\n",
      "2025-05-30 15:19:33,451 - INFO - Epoch [9/30] Batch [3570/4715] Loss: 0.7398\n",
      "2025-05-30 15:19:34,999 - INFO - Epoch [9/30] Batch [3580/4715] Loss: 1.0403\n",
      "2025-05-30 15:19:36,495 - INFO - Epoch [9/30] Batch [3590/4715] Loss: 1.0134\n",
      "2025-05-30 15:19:38,093 - INFO - Epoch [9/30] Batch [3600/4715] Loss: 0.8462\n",
      "2025-05-30 15:19:39,612 - INFO - Epoch [9/30] Batch [3610/4715] Loss: 0.6513\n",
      "2025-05-30 15:19:41,178 - INFO - Epoch [9/30] Batch [3620/4715] Loss: 0.9181\n",
      "2025-05-30 15:19:42,752 - INFO - Epoch [9/30] Batch [3630/4715] Loss: 0.8450\n",
      "2025-05-30 15:19:44,278 - INFO - Epoch [9/30] Batch [3640/4715] Loss: 0.9290\n",
      "2025-05-30 15:19:45,909 - INFO - Epoch [9/30] Batch [3650/4715] Loss: 1.1282\n",
      "2025-05-30 15:19:47,371 - INFO - Epoch [9/30] Batch [3660/4715] Loss: 0.9715\n",
      "2025-05-30 15:19:48,938 - INFO - Epoch [9/30] Batch [3670/4715] Loss: 0.7879\n",
      "2025-05-30 15:19:50,447 - INFO - Epoch [9/30] Batch [3680/4715] Loss: 0.8975\n",
      "2025-05-30 15:19:51,996 - INFO - Epoch [9/30] Batch [3690/4715] Loss: 0.7071\n",
      "2025-05-30 15:19:53,548 - INFO - Epoch [9/30] Batch [3700/4715] Loss: 0.7460\n",
      "2025-05-30 15:19:55,100 - INFO - Epoch [9/30] Batch [3710/4715] Loss: 0.9103\n",
      "2025-05-30 15:19:56,619 - INFO - Epoch [9/30] Batch [3720/4715] Loss: 0.8299\n",
      "2025-05-30 15:19:58,250 - INFO - Epoch [9/30] Batch [3730/4715] Loss: 0.7353\n",
      "2025-05-30 15:19:59,879 - INFO - Epoch [9/30] Batch [3740/4715] Loss: 0.6307\n",
      "2025-05-30 15:20:01,489 - INFO - Epoch [9/30] Batch [3750/4715] Loss: 0.8503\n",
      "2025-05-30 15:20:03,120 - INFO - Epoch [9/30] Batch [3760/4715] Loss: 0.8792\n",
      "2025-05-30 15:20:04,710 - INFO - Epoch [9/30] Batch [3770/4715] Loss: 0.9918\n",
      "2025-05-30 15:20:06,196 - INFO - Epoch [9/30] Batch [3780/4715] Loss: 0.5438\n",
      "2025-05-30 15:20:07,774 - INFO - Epoch [9/30] Batch [3790/4715] Loss: 0.6478\n",
      "2025-05-30 15:20:09,290 - INFO - Epoch [9/30] Batch [3800/4715] Loss: 0.8119\n",
      "2025-05-30 15:20:10,847 - INFO - Epoch [9/30] Batch [3810/4715] Loss: 0.9075\n",
      "2025-05-30 15:20:12,372 - INFO - Epoch [9/30] Batch [3820/4715] Loss: 0.7465\n",
      "2025-05-30 15:20:13,969 - INFO - Epoch [9/30] Batch [3830/4715] Loss: 1.0201\n",
      "2025-05-30 15:20:15,515 - INFO - Epoch [9/30] Batch [3840/4715] Loss: 0.7977\n",
      "2025-05-30 15:20:17,096 - INFO - Epoch [9/30] Batch [3850/4715] Loss: 1.0883\n",
      "2025-05-30 15:20:18,650 - INFO - Epoch [9/30] Batch [3860/4715] Loss: 0.7831\n",
      "2025-05-30 15:20:20,249 - INFO - Epoch [9/30] Batch [3870/4715] Loss: 0.7007\n",
      "2025-05-30 15:20:21,862 - INFO - Epoch [9/30] Batch [3880/4715] Loss: 0.7894\n",
      "2025-05-30 15:20:23,500 - INFO - Epoch [9/30] Batch [3890/4715] Loss: 0.8348\n",
      "2025-05-30 15:20:25,002 - INFO - Epoch [9/30] Batch [3900/4715] Loss: 0.9338\n",
      "2025-05-30 15:20:26,638 - INFO - Epoch [9/30] Batch [3910/4715] Loss: 0.6034\n",
      "2025-05-30 15:20:28,237 - INFO - Epoch [9/30] Batch [3920/4715] Loss: 0.6618\n",
      "2025-05-30 15:20:29,960 - INFO - Epoch [9/30] Batch [3930/4715] Loss: 0.8610\n",
      "2025-05-30 15:20:31,638 - INFO - Epoch [9/30] Batch [3940/4715] Loss: 0.7989\n",
      "2025-05-30 15:20:33,328 - INFO - Epoch [9/30] Batch [3950/4715] Loss: 0.7761\n",
      "2025-05-30 15:20:34,823 - INFO - Epoch [9/30] Batch [3960/4715] Loss: 0.8591\n",
      "2025-05-30 15:20:36,395 - INFO - Epoch [9/30] Batch [3970/4715] Loss: 0.7809\n",
      "2025-05-30 15:20:38,050 - INFO - Epoch [9/30] Batch [3980/4715] Loss: 0.9245\n",
      "2025-05-30 15:20:39,657 - INFO - Epoch [9/30] Batch [3990/4715] Loss: 0.8548\n",
      "2025-05-30 15:20:41,217 - INFO - Epoch [9/30] Batch [4000/4715] Loss: 0.7170\n",
      "2025-05-30 15:20:42,841 - INFO - Epoch [9/30] Batch [4010/4715] Loss: 0.8320\n",
      "2025-05-30 15:20:44,397 - INFO - Epoch [9/30] Batch [4020/4715] Loss: 0.8043\n",
      "2025-05-30 15:20:45,900 - INFO - Epoch [9/30] Batch [4030/4715] Loss: 0.8711\n",
      "2025-05-30 15:20:47,394 - INFO - Epoch [9/30] Batch [4040/4715] Loss: 0.9348\n",
      "2025-05-30 15:20:49,054 - INFO - Epoch [9/30] Batch [4050/4715] Loss: 0.9882\n",
      "2025-05-30 15:20:50,596 - INFO - Epoch [9/30] Batch [4060/4715] Loss: 0.6606\n",
      "2025-05-30 15:20:52,126 - INFO - Epoch [9/30] Batch [4070/4715] Loss: 1.1316\n",
      "2025-05-30 15:20:53,780 - INFO - Epoch [9/30] Batch [4080/4715] Loss: 0.6179\n",
      "2025-05-30 15:20:55,297 - INFO - Epoch [9/30] Batch [4090/4715] Loss: 0.6225\n",
      "2025-05-30 15:20:56,842 - INFO - Epoch [9/30] Batch [4100/4715] Loss: 0.8685\n",
      "2025-05-30 15:20:58,493 - INFO - Epoch [9/30] Batch [4110/4715] Loss: 0.4970\n",
      "2025-05-30 15:21:00,116 - INFO - Epoch [9/30] Batch [4120/4715] Loss: 0.5900\n",
      "2025-05-30 15:21:01,825 - INFO - Epoch [9/30] Batch [4130/4715] Loss: 0.9157\n",
      "2025-05-30 15:21:03,313 - INFO - Epoch [9/30] Batch [4140/4715] Loss: 0.9303\n",
      "2025-05-30 15:21:04,868 - INFO - Epoch [9/30] Batch [4150/4715] Loss: 0.6804\n",
      "2025-05-30 15:21:06,352 - INFO - Epoch [9/30] Batch [4160/4715] Loss: 0.9970\n",
      "2025-05-30 15:21:07,935 - INFO - Epoch [9/30] Batch [4170/4715] Loss: 0.8339\n",
      "2025-05-30 15:21:09,467 - INFO - Epoch [9/30] Batch [4180/4715] Loss: 0.8535\n",
      "2025-05-30 15:21:11,008 - INFO - Epoch [9/30] Batch [4190/4715] Loss: 1.3767\n",
      "2025-05-30 15:21:12,640 - INFO - Epoch [9/30] Batch [4200/4715] Loss: 0.6846\n",
      "2025-05-30 15:21:14,166 - INFO - Epoch [9/30] Batch [4210/4715] Loss: 0.9410\n",
      "2025-05-30 15:21:15,757 - INFO - Epoch [9/30] Batch [4220/4715] Loss: 0.7127\n",
      "2025-05-30 15:21:17,301 - INFO - Epoch [9/30] Batch [4230/4715] Loss: 0.8221\n",
      "2025-05-30 15:21:18,879 - INFO - Epoch [9/30] Batch [4240/4715] Loss: 0.8473\n",
      "2025-05-30 15:21:20,398 - INFO - Epoch [9/30] Batch [4250/4715] Loss: 0.8179\n",
      "2025-05-30 15:21:21,905 - INFO - Epoch [9/30] Batch [4260/4715] Loss: 0.9673\n",
      "2025-05-30 15:21:23,439 - INFO - Epoch [9/30] Batch [4270/4715] Loss: 0.8803\n",
      "2025-05-30 15:21:25,018 - INFO - Epoch [9/30] Batch [4280/4715] Loss: 0.7073\n",
      "2025-05-30 15:21:26,574 - INFO - Epoch [9/30] Batch [4290/4715] Loss: 0.6717\n",
      "2025-05-30 15:21:28,115 - INFO - Epoch [9/30] Batch [4300/4715] Loss: 0.5072\n",
      "2025-05-30 15:21:29,721 - INFO - Epoch [9/30] Batch [4310/4715] Loss: 0.9183\n",
      "2025-05-30 15:21:31,274 - INFO - Epoch [9/30] Batch [4320/4715] Loss: 0.7933\n",
      "2025-05-30 15:21:32,839 - INFO - Epoch [9/30] Batch [4330/4715] Loss: 0.8729\n",
      "2025-05-30 15:21:34,363 - INFO - Epoch [9/30] Batch [4340/4715] Loss: 0.7932\n",
      "2025-05-30 15:21:35,946 - INFO - Epoch [9/30] Batch [4350/4715] Loss: 0.6777\n",
      "2025-05-30 15:21:37,436 - INFO - Epoch [9/30] Batch [4360/4715] Loss: 0.8837\n",
      "2025-05-30 15:21:39,073 - INFO - Epoch [9/30] Batch [4370/4715] Loss: 0.6173\n",
      "2025-05-30 15:21:40,676 - INFO - Epoch [9/30] Batch [4380/4715] Loss: 0.7826\n",
      "2025-05-30 15:21:42,238 - INFO - Epoch [9/30] Batch [4390/4715] Loss: 1.0265\n",
      "2025-05-30 15:21:43,819 - INFO - Epoch [9/30] Batch [4400/4715] Loss: 1.0512\n",
      "2025-05-30 15:21:45,495 - INFO - Epoch [9/30] Batch [4410/4715] Loss: 0.7908\n",
      "2025-05-30 15:21:47,115 - INFO - Epoch [9/30] Batch [4420/4715] Loss: 1.1282\n",
      "2025-05-30 15:21:48,692 - INFO - Epoch [9/30] Batch [4430/4715] Loss: 0.8903\n",
      "2025-05-30 15:21:50,423 - INFO - Epoch [9/30] Batch [4440/4715] Loss: 0.9164\n",
      "2025-05-30 15:21:51,980 - INFO - Epoch [9/30] Batch [4450/4715] Loss: 0.6857\n",
      "2025-05-30 15:21:53,639 - INFO - Epoch [9/30] Batch [4460/4715] Loss: 0.8803\n",
      "2025-05-30 15:21:55,120 - INFO - Epoch [9/30] Batch [4470/4715] Loss: 0.6794\n",
      "2025-05-30 15:21:56,702 - INFO - Epoch [9/30] Batch [4480/4715] Loss: 0.7889\n",
      "2025-05-30 15:21:58,266 - INFO - Epoch [9/30] Batch [4490/4715] Loss: 0.7646\n",
      "2025-05-30 15:21:59,855 - INFO - Epoch [9/30] Batch [4500/4715] Loss: 0.7764\n",
      "2025-05-30 15:22:01,490 - INFO - Epoch [9/30] Batch [4510/4715] Loss: 0.9939\n",
      "2025-05-30 15:22:03,050 - INFO - Epoch [9/30] Batch [4520/4715] Loss: 0.9413\n",
      "2025-05-30 15:22:04,600 - INFO - Epoch [9/30] Batch [4530/4715] Loss: 1.0709\n",
      "2025-05-30 15:22:06,060 - INFO - Epoch [9/30] Batch [4540/4715] Loss: 1.0166\n",
      "2025-05-30 15:22:07,708 - INFO - Epoch [9/30] Batch [4550/4715] Loss: 1.0554\n",
      "2025-05-30 15:22:09,295 - INFO - Epoch [9/30] Batch [4560/4715] Loss: 0.7878\n",
      "2025-05-30 15:22:10,865 - INFO - Epoch [9/30] Batch [4570/4715] Loss: 0.8954\n",
      "2025-05-30 15:22:12,536 - INFO - Epoch [9/30] Batch [4580/4715] Loss: 0.8396\n",
      "2025-05-30 15:22:14,063 - INFO - Epoch [9/30] Batch [4590/4715] Loss: 0.7525\n",
      "2025-05-30 15:22:15,682 - INFO - Epoch [9/30] Batch [4600/4715] Loss: 0.7405\n",
      "2025-05-30 15:22:17,228 - INFO - Epoch [9/30] Batch [4610/4715] Loss: 0.6452\n",
      "2025-05-30 15:22:18,829 - INFO - Epoch [9/30] Batch [4620/4715] Loss: 0.5343\n",
      "2025-05-30 15:22:20,306 - INFO - Epoch [9/30] Batch [4630/4715] Loss: 1.0136\n",
      "2025-05-30 15:22:21,801 - INFO - Epoch [9/30] Batch [4640/4715] Loss: 0.7557\n",
      "2025-05-30 15:22:23,407 - INFO - Epoch [9/30] Batch [4650/4715] Loss: 0.7560\n",
      "2025-05-30 15:22:24,968 - INFO - Epoch [9/30] Batch [4660/4715] Loss: 0.6994\n",
      "2025-05-30 15:22:26,569 - INFO - Epoch [9/30] Batch [4670/4715] Loss: 1.0640\n",
      "2025-05-30 15:22:28,095 - INFO - Epoch [9/30] Batch [4680/4715] Loss: 1.0818\n",
      "2025-05-30 15:22:29,684 - INFO - Epoch [9/30] Batch [4690/4715] Loss: 0.6365\n",
      "2025-05-30 15:22:31,259 - INFO - Epoch [9/30] Batch [4700/4715] Loss: 0.8457\n",
      "2025-05-30 15:22:32,847 - INFO - Epoch [9/30] Batch [4710/4715] Loss: 0.7676\n",
      "2025-05-30 15:23:12,033 - INFO - \n",
      "Epoch [9/30] Time: 779.15s\n",
      "2025-05-30 15:23:12,034 - INFO - Train Loss: 0.8288, Valid Loss: 0.8250\n",
      "2025-05-30 15:23:12,034 - INFO - Valid AUC (macro): 0.7252, F1 (macro): 0.5665\n",
      "2025-05-30 15:23:12,574 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\best_model.pth\n",
      "2025-05-30 15:23:12,575 - INFO - New best model saved with AUC: 0.7252\n",
      "2025-05-30 15:23:13,169 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 15:23:13,170 - INFO - Saved checkpoint at epoch 9\n",
      "2025-05-30 15:23:13,425 - INFO - Epoch [10/30] Batch [0/4715] Loss: 1.0511\n",
      "2025-05-30 15:23:15,301 - INFO - Epoch [10/30] Batch [10/4715] Loss: 0.7032\n",
      "2025-05-30 15:23:16,906 - INFO - Epoch [10/30] Batch [20/4715] Loss: 0.8865\n",
      "2025-05-30 15:23:18,589 - INFO - Epoch [10/30] Batch [30/4715] Loss: 1.1361\n",
      "2025-05-30 15:23:20,180 - INFO - Epoch [10/30] Batch [40/4715] Loss: 0.8819\n",
      "2025-05-30 15:23:21,783 - INFO - Epoch [10/30] Batch [50/4715] Loss: 0.4683\n",
      "2025-05-30 15:23:23,393 - INFO - Epoch [10/30] Batch [60/4715] Loss: 0.6753\n",
      "2025-05-30 15:23:24,887 - INFO - Epoch [10/30] Batch [70/4715] Loss: 0.8795\n",
      "2025-05-30 15:23:26,475 - INFO - Epoch [10/30] Batch [80/4715] Loss: 0.8453\n",
      "2025-05-30 15:23:28,024 - INFO - Epoch [10/30] Batch [90/4715] Loss: 0.8363\n",
      "2025-05-30 15:23:29,545 - INFO - Epoch [10/30] Batch [100/4715] Loss: 0.8662\n",
      "2025-05-30 15:23:31,147 - INFO - Epoch [10/30] Batch [110/4715] Loss: 0.6598\n",
      "2025-05-30 15:23:32,612 - INFO - Epoch [10/30] Batch [120/4715] Loss: 0.5967\n",
      "2025-05-30 15:23:34,182 - INFO - Epoch [10/30] Batch [130/4715] Loss: 0.6956\n",
      "2025-05-30 15:23:35,751 - INFO - Epoch [10/30] Batch [140/4715] Loss: 0.8893\n",
      "2025-05-30 15:23:37,394 - INFO - Epoch [10/30] Batch [150/4715] Loss: 1.3023\n",
      "2025-05-30 15:23:38,969 - INFO - Epoch [10/30] Batch [160/4715] Loss: 1.1404\n",
      "2025-05-30 15:23:40,542 - INFO - Epoch [10/30] Batch [170/4715] Loss: 0.7427\n",
      "2025-05-30 15:23:42,073 - INFO - Epoch [10/30] Batch [180/4715] Loss: 0.9740\n",
      "2025-05-30 15:23:43,703 - INFO - Epoch [10/30] Batch [190/4715] Loss: 0.8099\n",
      "2025-05-30 15:23:45,299 - INFO - Epoch [10/30] Batch [200/4715] Loss: 0.8175\n",
      "2025-05-30 15:23:46,791 - INFO - Epoch [10/30] Batch [210/4715] Loss: 0.8036\n",
      "2025-05-30 15:23:48,412 - INFO - Epoch [10/30] Batch [220/4715] Loss: 0.8920\n",
      "2025-05-30 15:23:50,098 - INFO - Epoch [10/30] Batch [230/4715] Loss: 0.8302\n",
      "2025-05-30 15:23:51,658 - INFO - Epoch [10/30] Batch [240/4715] Loss: 0.6748\n",
      "2025-05-30 15:23:53,284 - INFO - Epoch [10/30] Batch [250/4715] Loss: 0.9860\n",
      "2025-05-30 15:23:54,858 - INFO - Epoch [10/30] Batch [260/4715] Loss: 0.7300\n",
      "2025-05-30 15:23:56,449 - INFO - Epoch [10/30] Batch [270/4715] Loss: 1.0374\n",
      "2025-05-30 15:23:58,098 - INFO - Epoch [10/30] Batch [280/4715] Loss: 0.7324\n",
      "2025-05-30 15:23:59,626 - INFO - Epoch [10/30] Batch [290/4715] Loss: 0.6882\n",
      "2025-05-30 15:24:01,130 - INFO - Epoch [10/30] Batch [300/4715] Loss: 0.7123\n",
      "2025-05-30 15:24:02,668 - INFO - Epoch [10/30] Batch [310/4715] Loss: 0.8746\n",
      "2025-05-30 15:24:04,230 - INFO - Epoch [10/30] Batch [320/4715] Loss: 0.5631\n",
      "2025-05-30 15:24:05,759 - INFO - Epoch [10/30] Batch [330/4715] Loss: 0.7682\n",
      "2025-05-30 15:24:07,404 - INFO - Epoch [10/30] Batch [340/4715] Loss: 0.6650\n",
      "2025-05-30 15:24:08,927 - INFO - Epoch [10/30] Batch [350/4715] Loss: 0.9079\n",
      "2025-05-30 15:24:10,599 - INFO - Epoch [10/30] Batch [360/4715] Loss: 0.9228\n",
      "2025-05-30 15:24:12,208 - INFO - Epoch [10/30] Batch [370/4715] Loss: 0.8113\n",
      "2025-05-30 15:24:13,735 - INFO - Epoch [10/30] Batch [380/4715] Loss: 0.8819\n",
      "2025-05-30 15:24:15,381 - INFO - Epoch [10/30] Batch [390/4715] Loss: 0.8733\n",
      "2025-05-30 15:24:17,052 - INFO - Epoch [10/30] Batch [400/4715] Loss: 0.8289\n",
      "2025-05-30 15:24:18,605 - INFO - Epoch [10/30] Batch [410/4715] Loss: 0.8498\n",
      "2025-05-30 15:24:20,192 - INFO - Epoch [10/30] Batch [420/4715] Loss: 0.6706\n",
      "2025-05-30 15:24:21,708 - INFO - Epoch [10/30] Batch [430/4715] Loss: 0.6441\n",
      "2025-05-30 15:24:23,321 - INFO - Epoch [10/30] Batch [440/4715] Loss: 0.9669\n",
      "2025-05-30 15:24:24,976 - INFO - Epoch [10/30] Batch [450/4715] Loss: 0.5993\n",
      "2025-05-30 15:24:26,611 - INFO - Epoch [10/30] Batch [460/4715] Loss: 0.9155\n",
      "2025-05-30 15:24:28,190 - INFO - Epoch [10/30] Batch [470/4715] Loss: 0.8475\n",
      "2025-05-30 15:24:29,794 - INFO - Epoch [10/30] Batch [480/4715] Loss: 0.8372\n",
      "2025-05-30 15:24:31,376 - INFO - Epoch [10/30] Batch [490/4715] Loss: 0.8820\n",
      "2025-05-30 15:24:32,969 - INFO - Epoch [10/30] Batch [500/4715] Loss: 1.1538\n",
      "2025-05-30 15:24:34,559 - INFO - Epoch [10/30] Batch [510/4715] Loss: 0.7444\n",
      "2025-05-30 15:24:36,120 - INFO - Epoch [10/30] Batch [520/4715] Loss: 0.6032\n",
      "2025-05-30 15:24:37,717 - INFO - Epoch [10/30] Batch [530/4715] Loss: 1.0756\n",
      "2025-05-30 15:24:39,220 - INFO - Epoch [10/30] Batch [540/4715] Loss: 0.7667\n",
      "2025-05-30 15:24:40,773 - INFO - Epoch [10/30] Batch [550/4715] Loss: 0.8700\n",
      "2025-05-30 15:24:42,440 - INFO - Epoch [10/30] Batch [560/4715] Loss: 0.8613\n",
      "2025-05-30 15:24:43,976 - INFO - Epoch [10/30] Batch [570/4715] Loss: 0.6993\n",
      "2025-05-30 15:24:45,582 - INFO - Epoch [10/30] Batch [580/4715] Loss: 0.5800\n",
      "2025-05-30 15:24:47,158 - INFO - Epoch [10/30] Batch [590/4715] Loss: 0.8722\n",
      "2025-05-30 15:24:48,768 - INFO - Epoch [10/30] Batch [600/4715] Loss: 0.9332\n",
      "2025-05-30 15:24:50,269 - INFO - Epoch [10/30] Batch [610/4715] Loss: 1.1704\n",
      "2025-05-30 15:24:51,796 - INFO - Epoch [10/30] Batch [620/4715] Loss: 0.8659\n",
      "2025-05-30 15:24:53,370 - INFO - Epoch [10/30] Batch [630/4715] Loss: 0.9384\n",
      "2025-05-30 15:24:54,992 - INFO - Epoch [10/30] Batch [640/4715] Loss: 0.8820\n",
      "2025-05-30 15:24:56,511 - INFO - Epoch [10/30] Batch [650/4715] Loss: 0.8077\n",
      "2025-05-30 15:24:58,066 - INFO - Epoch [10/30] Batch [660/4715] Loss: 0.7910\n",
      "2025-05-30 15:24:59,567 - INFO - Epoch [10/30] Batch [670/4715] Loss: 0.7327\n",
      "2025-05-30 15:25:01,142 - INFO - Epoch [10/30] Batch [680/4715] Loss: 0.8619\n",
      "2025-05-30 15:25:02,713 - INFO - Epoch [10/30] Batch [690/4715] Loss: 0.9084\n",
      "2025-05-30 15:25:04,380 - INFO - Epoch [10/30] Batch [700/4715] Loss: 0.7081\n",
      "2025-05-30 15:25:05,920 - INFO - Epoch [10/30] Batch [710/4715] Loss: 1.0325\n",
      "2025-05-30 15:25:07,485 - INFO - Epoch [10/30] Batch [720/4715] Loss: 0.7902\n",
      "2025-05-30 15:25:08,967 - INFO - Epoch [10/30] Batch [730/4715] Loss: 0.6850\n",
      "2025-05-30 15:25:10,604 - INFO - Epoch [10/30] Batch [740/4715] Loss: 0.8250\n",
      "2025-05-30 15:25:12,111 - INFO - Epoch [10/30] Batch [750/4715] Loss: 0.7135\n",
      "2025-05-30 15:25:13,557 - INFO - Epoch [10/30] Batch [760/4715] Loss: 0.9103\n",
      "2025-05-30 15:25:15,178 - INFO - Epoch [10/30] Batch [770/4715] Loss: 0.6867\n",
      "2025-05-30 15:25:16,815 - INFO - Epoch [10/30] Batch [780/4715] Loss: 1.0275\n",
      "2025-05-30 15:25:18,424 - INFO - Epoch [10/30] Batch [790/4715] Loss: 1.1072\n",
      "2025-05-30 15:25:19,961 - INFO - Epoch [10/30] Batch [800/4715] Loss: 0.7507\n",
      "2025-05-30 15:25:21,524 - INFO - Epoch [10/30] Batch [810/4715] Loss: 0.9615\n",
      "2025-05-30 15:25:23,173 - INFO - Epoch [10/30] Batch [820/4715] Loss: 0.8225\n",
      "2025-05-30 15:25:24,754 - INFO - Epoch [10/30] Batch [830/4715] Loss: 1.0376\n",
      "2025-05-30 15:25:26,290 - INFO - Epoch [10/30] Batch [840/4715] Loss: 0.8646\n",
      "2025-05-30 15:25:27,833 - INFO - Epoch [10/30] Batch [850/4715] Loss: 0.8919\n",
      "2025-05-30 15:25:29,403 - INFO - Epoch [10/30] Batch [860/4715] Loss: 0.8678\n",
      "2025-05-30 15:25:31,010 - INFO - Epoch [10/30] Batch [870/4715] Loss: 0.7542\n",
      "2025-05-30 15:25:32,585 - INFO - Epoch [10/30] Batch [880/4715] Loss: 0.9240\n",
      "2025-05-30 15:25:34,138 - INFO - Epoch [10/30] Batch [890/4715] Loss: 0.8165\n",
      "2025-05-30 15:25:35,806 - INFO - Epoch [10/30] Batch [900/4715] Loss: 0.7049\n",
      "2025-05-30 15:25:37,473 - INFO - Epoch [10/30] Batch [910/4715] Loss: 0.7457\n",
      "2025-05-30 15:25:39,272 - INFO - Epoch [10/30] Batch [920/4715] Loss: 0.6455\n",
      "2025-05-30 15:25:40,824 - INFO - Epoch [10/30] Batch [930/4715] Loss: 0.6962\n",
      "2025-05-30 15:25:42,383 - INFO - Epoch [10/30] Batch [940/4715] Loss: 0.9151\n",
      "2025-05-30 15:25:44,045 - INFO - Epoch [10/30] Batch [950/4715] Loss: 0.9193\n",
      "2025-05-30 15:25:45,590 - INFO - Epoch [10/30] Batch [960/4715] Loss: 0.6535\n",
      "2025-05-30 15:25:47,137 - INFO - Epoch [10/30] Batch [970/4715] Loss: 1.2788\n",
      "2025-05-30 15:25:48,626 - INFO - Epoch [10/30] Batch [980/4715] Loss: 0.7958\n",
      "2025-05-30 15:25:50,324 - INFO - Epoch [10/30] Batch [990/4715] Loss: 0.9015\n",
      "2025-05-30 15:25:51,892 - INFO - Epoch [10/30] Batch [1000/4715] Loss: 0.8479\n",
      "2025-05-30 15:25:53,437 - INFO - Epoch [10/30] Batch [1010/4715] Loss: 0.6467\n",
      "2025-05-30 15:25:55,008 - INFO - Epoch [10/30] Batch [1020/4715] Loss: 0.6288\n",
      "2025-05-30 15:25:56,641 - INFO - Epoch [10/30] Batch [1030/4715] Loss: 0.8308\n",
      "2025-05-30 15:25:58,183 - INFO - Epoch [10/30] Batch [1040/4715] Loss: 0.8089\n",
      "2025-05-30 15:25:59,762 - INFO - Epoch [10/30] Batch [1050/4715] Loss: 0.8192\n",
      "2025-05-30 15:26:01,426 - INFO - Epoch [10/30] Batch [1060/4715] Loss: 0.9276\n",
      "2025-05-30 15:26:03,000 - INFO - Epoch [10/30] Batch [1070/4715] Loss: 0.8357\n",
      "2025-05-30 15:26:04,517 - INFO - Epoch [10/30] Batch [1080/4715] Loss: 0.7630\n",
      "2025-05-30 15:26:06,066 - INFO - Epoch [10/30] Batch [1090/4715] Loss: 0.8051\n",
      "2025-05-30 15:26:07,611 - INFO - Epoch [10/30] Batch [1100/4715] Loss: 0.9887\n",
      "2025-05-30 15:26:09,122 - INFO - Epoch [10/30] Batch [1110/4715] Loss: 1.0952\n",
      "2025-05-30 15:26:10,638 - INFO - Epoch [10/30] Batch [1120/4715] Loss: 0.9091\n",
      "2025-05-30 15:26:12,181 - INFO - Epoch [10/30] Batch [1130/4715] Loss: 0.9105\n",
      "2025-05-30 15:26:13,861 - INFO - Epoch [10/30] Batch [1140/4715] Loss: 0.8475\n",
      "2025-05-30 15:26:15,310 - INFO - Epoch [10/30] Batch [1150/4715] Loss: 0.8000\n",
      "2025-05-30 15:26:16,865 - INFO - Epoch [10/30] Batch [1160/4715] Loss: 0.6707\n",
      "2025-05-30 15:26:18,463 - INFO - Epoch [10/30] Batch [1170/4715] Loss: 0.9596\n",
      "2025-05-30 15:26:19,980 - INFO - Epoch [10/30] Batch [1180/4715] Loss: 0.9824\n",
      "2025-05-30 15:26:21,523 - INFO - Epoch [10/30] Batch [1190/4715] Loss: 0.9863\n",
      "2025-05-30 15:26:23,176 - INFO - Epoch [10/30] Batch [1200/4715] Loss: 1.0500\n",
      "2025-05-30 15:26:24,795 - INFO - Epoch [10/30] Batch [1210/4715] Loss: 0.7834\n",
      "2025-05-30 15:26:26,369 - INFO - Epoch [10/30] Batch [1220/4715] Loss: 0.7449\n",
      "2025-05-30 15:26:28,044 - INFO - Epoch [10/30] Batch [1230/4715] Loss: 1.1668\n",
      "2025-05-30 15:26:29,766 - INFO - Epoch [10/30] Batch [1240/4715] Loss: 0.9102\n",
      "2025-05-30 15:26:31,347 - INFO - Epoch [10/30] Batch [1250/4715] Loss: 0.7894\n",
      "2025-05-30 15:26:32,929 - INFO - Epoch [10/30] Batch [1260/4715] Loss: 0.9869\n",
      "2025-05-30 15:26:34,497 - INFO - Epoch [10/30] Batch [1270/4715] Loss: 0.5815\n",
      "2025-05-30 15:26:36,172 - INFO - Epoch [10/30] Batch [1280/4715] Loss: 0.6567\n",
      "2025-05-30 15:26:37,764 - INFO - Epoch [10/30] Batch [1290/4715] Loss: 0.7418\n",
      "2025-05-30 15:26:39,422 - INFO - Epoch [10/30] Batch [1300/4715] Loss: 0.7553\n",
      "2025-05-30 15:26:40,927 - INFO - Epoch [10/30] Batch [1310/4715] Loss: 0.8813\n",
      "2025-05-30 15:26:42,495 - INFO - Epoch [10/30] Batch [1320/4715] Loss: 0.9461\n",
      "2025-05-30 15:26:44,004 - INFO - Epoch [10/30] Batch [1330/4715] Loss: 0.8387\n",
      "2025-05-30 15:26:45,573 - INFO - Epoch [10/30] Batch [1340/4715] Loss: 0.6658\n",
      "2025-05-30 15:26:47,102 - INFO - Epoch [10/30] Batch [1350/4715] Loss: 1.0505\n",
      "2025-05-30 15:26:48,629 - INFO - Epoch [10/30] Batch [1360/4715] Loss: 0.6145\n",
      "2025-05-30 15:26:50,152 - INFO - Epoch [10/30] Batch [1370/4715] Loss: 1.0101\n",
      "2025-05-30 15:26:51,781 - INFO - Epoch [10/30] Batch [1380/4715] Loss: 0.7032\n",
      "2025-05-30 15:26:53,377 - INFO - Epoch [10/30] Batch [1390/4715] Loss: 0.7739\n",
      "2025-05-30 15:26:54,995 - INFO - Epoch [10/30] Batch [1400/4715] Loss: 0.8618\n",
      "2025-05-30 15:26:56,528 - INFO - Epoch [10/30] Batch [1410/4715] Loss: 0.9091\n",
      "2025-05-30 15:26:58,151 - INFO - Epoch [10/30] Batch [1420/4715] Loss: 0.8243\n",
      "2025-05-30 15:26:59,624 - INFO - Epoch [10/30] Batch [1430/4715] Loss: 0.6957\n",
      "2025-05-30 15:27:01,269 - INFO - Epoch [10/30] Batch [1440/4715] Loss: 0.8137\n",
      "2025-05-30 15:27:02,801 - INFO - Epoch [10/30] Batch [1450/4715] Loss: 0.9272\n",
      "2025-05-30 15:27:04,412 - INFO - Epoch [10/30] Batch [1460/4715] Loss: 0.7684\n",
      "2025-05-30 15:27:05,999 - INFO - Epoch [10/30] Batch [1470/4715] Loss: 0.8431\n",
      "2025-05-30 15:27:07,564 - INFO - Epoch [10/30] Batch [1480/4715] Loss: 0.7926\n",
      "2025-05-30 15:27:09,158 - INFO - Epoch [10/30] Batch [1490/4715] Loss: 0.8188\n",
      "2025-05-30 15:27:10,790 - INFO - Epoch [10/30] Batch [1500/4715] Loss: 0.7573\n",
      "2025-05-30 15:27:12,332 - INFO - Epoch [10/30] Batch [1510/4715] Loss: 0.6445\n",
      "2025-05-30 15:27:13,899 - INFO - Epoch [10/30] Batch [1520/4715] Loss: 0.8396\n",
      "2025-05-30 15:27:15,481 - INFO - Epoch [10/30] Batch [1530/4715] Loss: 0.5975\n",
      "2025-05-30 15:27:17,018 - INFO - Epoch [10/30] Batch [1540/4715] Loss: 0.9695\n",
      "2025-05-30 15:27:18,576 - INFO - Epoch [10/30] Batch [1550/4715] Loss: 0.7649\n",
      "2025-05-30 15:27:20,085 - INFO - Epoch [10/30] Batch [1560/4715] Loss: 0.6710\n",
      "2025-05-30 15:27:21,637 - INFO - Epoch [10/30] Batch [1570/4715] Loss: 0.8223\n",
      "2025-05-30 15:27:23,138 - INFO - Epoch [10/30] Batch [1580/4715] Loss: 1.0356\n",
      "2025-05-30 15:27:24,728 - INFO - Epoch [10/30] Batch [1590/4715] Loss: 1.0257\n",
      "2025-05-30 15:27:26,294 - INFO - Epoch [10/30] Batch [1600/4715] Loss: 0.6472\n",
      "2025-05-30 15:27:27,899 - INFO - Epoch [10/30] Batch [1610/4715] Loss: 0.8545\n",
      "2025-05-30 15:27:29,554 - INFO - Epoch [10/30] Batch [1620/4715] Loss: 1.1964\n",
      "2025-05-30 15:27:31,114 - INFO - Epoch [10/30] Batch [1630/4715] Loss: 1.0505\n",
      "2025-05-30 15:27:32,654 - INFO - Epoch [10/30] Batch [1640/4715] Loss: 0.7320\n",
      "2025-05-30 15:27:34,144 - INFO - Epoch [10/30] Batch [1650/4715] Loss: 0.8043\n",
      "2025-05-30 15:27:35,736 - INFO - Epoch [10/30] Batch [1660/4715] Loss: 1.0889\n",
      "2025-05-30 15:27:37,279 - INFO - Epoch [10/30] Batch [1670/4715] Loss: 0.9996\n",
      "2025-05-30 15:27:38,891 - INFO - Epoch [10/30] Batch [1680/4715] Loss: 1.0255\n",
      "2025-05-30 15:27:40,395 - INFO - Epoch [10/30] Batch [1690/4715] Loss: 0.9806\n",
      "2025-05-30 15:27:41,835 - INFO - Epoch [10/30] Batch [1700/4715] Loss: 0.8646\n",
      "2025-05-30 15:27:43,466 - INFO - Epoch [10/30] Batch [1710/4715] Loss: 0.8396\n",
      "2025-05-30 15:27:45,018 - INFO - Epoch [10/30] Batch [1720/4715] Loss: 0.6546\n",
      "2025-05-30 15:27:46,606 - INFO - Epoch [10/30] Batch [1730/4715] Loss: 0.9027\n",
      "2025-05-30 15:27:48,171 - INFO - Epoch [10/30] Batch [1740/4715] Loss: 0.7705\n",
      "2025-05-30 15:27:49,772 - INFO - Epoch [10/30] Batch [1750/4715] Loss: 0.9331\n",
      "2025-05-30 15:27:51,427 - INFO - Epoch [10/30] Batch [1760/4715] Loss: 0.7146\n",
      "2025-05-30 15:27:52,940 - INFO - Epoch [10/30] Batch [1770/4715] Loss: 1.0716\n",
      "2025-05-30 15:27:54,525 - INFO - Epoch [10/30] Batch [1780/4715] Loss: 0.9106\n",
      "2025-05-30 15:27:56,112 - INFO - Epoch [10/30] Batch [1790/4715] Loss: 0.7799\n",
      "2025-05-30 15:27:57,657 - INFO - Epoch [10/30] Batch [1800/4715] Loss: 0.9897\n",
      "2025-05-30 15:27:59,408 - INFO - Epoch [10/30] Batch [1810/4715] Loss: 0.6467\n",
      "2025-05-30 15:28:01,088 - INFO - Epoch [10/30] Batch [1820/4715] Loss: 0.9189\n",
      "2025-05-30 15:28:02,666 - INFO - Epoch [10/30] Batch [1830/4715] Loss: 1.0388\n",
      "2025-05-30 15:28:04,215 - INFO - Epoch [10/30] Batch [1840/4715] Loss: 0.6239\n",
      "2025-05-30 15:28:05,761 - INFO - Epoch [10/30] Batch [1850/4715] Loss: 0.8056\n",
      "2025-05-30 15:28:07,500 - INFO - Epoch [10/30] Batch [1860/4715] Loss: 0.8648\n",
      "2025-05-30 15:28:09,059 - INFO - Epoch [10/30] Batch [1870/4715] Loss: 0.9693\n",
      "2025-05-30 15:28:10,748 - INFO - Epoch [10/30] Batch [1880/4715] Loss: 0.6723\n",
      "2025-05-30 15:28:12,261 - INFO - Epoch [10/30] Batch [1890/4715] Loss: 0.8797\n",
      "2025-05-30 15:28:13,775 - INFO - Epoch [10/30] Batch [1900/4715] Loss: 0.6279\n",
      "2025-05-30 15:28:15,393 - INFO - Epoch [10/30] Batch [1910/4715] Loss: 1.0033\n",
      "2025-05-30 15:28:16,935 - INFO - Epoch [10/30] Batch [1920/4715] Loss: 0.6283\n",
      "2025-05-30 15:28:18,454 - INFO - Epoch [10/30] Batch [1930/4715] Loss: 0.8644\n",
      "2025-05-30 15:28:20,027 - INFO - Epoch [10/30] Batch [1940/4715] Loss: 0.6464\n",
      "2025-05-30 15:28:21,579 - INFO - Epoch [10/30] Batch [1950/4715] Loss: 0.9179\n",
      "2025-05-30 15:28:23,240 - INFO - Epoch [10/30] Batch [1960/4715] Loss: 1.1257\n",
      "2025-05-30 15:28:24,872 - INFO - Epoch [10/30] Batch [1970/4715] Loss: 0.7856\n",
      "2025-05-30 15:28:26,523 - INFO - Epoch [10/30] Batch [1980/4715] Loss: 0.8669\n",
      "2025-05-30 15:28:28,074 - INFO - Epoch [10/30] Batch [1990/4715] Loss: 0.8652\n",
      "2025-05-30 15:28:29,653 - INFO - Epoch [10/30] Batch [2000/4715] Loss: 0.8518\n",
      "2025-05-30 15:28:31,177 - INFO - Epoch [10/30] Batch [2010/4715] Loss: 0.8515\n",
      "2025-05-30 15:28:32,696 - INFO - Epoch [10/30] Batch [2020/4715] Loss: 0.8998\n",
      "2025-05-30 15:28:34,300 - INFO - Epoch [10/30] Batch [2030/4715] Loss: 0.7474\n",
      "2025-05-30 15:28:35,815 - INFO - Epoch [10/30] Batch [2040/4715] Loss: 0.9285\n",
      "2025-05-30 15:28:37,367 - INFO - Epoch [10/30] Batch [2050/4715] Loss: 0.8387\n",
      "2025-05-30 15:28:38,948 - INFO - Epoch [10/30] Batch [2060/4715] Loss: 0.7751\n",
      "2025-05-30 15:28:40,560 - INFO - Epoch [10/30] Batch [2070/4715] Loss: 0.9464\n",
      "2025-05-30 15:28:42,090 - INFO - Epoch [10/30] Batch [2080/4715] Loss: 0.6944\n",
      "2025-05-30 15:28:43,598 - INFO - Epoch [10/30] Batch [2090/4715] Loss: 0.8776\n",
      "2025-05-30 15:28:45,122 - INFO - Epoch [10/30] Batch [2100/4715] Loss: 0.8216\n",
      "2025-05-30 15:28:46,656 - INFO - Epoch [10/30] Batch [2110/4715] Loss: 0.9252\n",
      "2025-05-30 15:28:48,215 - INFO - Epoch [10/30] Batch [2120/4715] Loss: 1.0763\n",
      "2025-05-30 15:28:49,827 - INFO - Epoch [10/30] Batch [2130/4715] Loss: 0.8253\n",
      "2025-05-30 15:28:51,436 - INFO - Epoch [10/30] Batch [2140/4715] Loss: 0.7462\n",
      "2025-05-30 15:28:52,982 - INFO - Epoch [10/30] Batch [2150/4715] Loss: 0.8186\n",
      "2025-05-30 15:28:54,589 - INFO - Epoch [10/30] Batch [2160/4715] Loss: 0.5626\n",
      "2025-05-30 15:28:56,264 - INFO - Epoch [10/30] Batch [2170/4715] Loss: 1.0369\n",
      "2025-05-30 15:28:57,827 - INFO - Epoch [10/30] Batch [2180/4715] Loss: 0.7291\n",
      "2025-05-30 15:28:59,412 - INFO - Epoch [10/30] Batch [2190/4715] Loss: 1.0958\n",
      "2025-05-30 15:29:00,926 - INFO - Epoch [10/30] Batch [2200/4715] Loss: 0.8535\n",
      "2025-05-30 15:29:02,491 - INFO - Epoch [10/30] Batch [2210/4715] Loss: 0.9040\n",
      "2025-05-30 15:29:04,078 - INFO - Epoch [10/30] Batch [2220/4715] Loss: 0.7029\n",
      "2025-05-30 15:29:05,710 - INFO - Epoch [10/30] Batch [2230/4715] Loss: 0.9231\n",
      "2025-05-30 15:29:07,265 - INFO - Epoch [10/30] Batch [2240/4715] Loss: 0.6615\n",
      "2025-05-30 15:29:08,764 - INFO - Epoch [10/30] Batch [2250/4715] Loss: 0.9463\n",
      "2025-05-30 15:29:10,385 - INFO - Epoch [10/30] Batch [2260/4715] Loss: 0.7391\n",
      "2025-05-30 15:29:11,926 - INFO - Epoch [10/30] Batch [2270/4715] Loss: 0.9163\n",
      "2025-05-30 15:29:13,498 - INFO - Epoch [10/30] Batch [2280/4715] Loss: 0.5853\n",
      "2025-05-30 15:29:15,066 - INFO - Epoch [10/30] Batch [2290/4715] Loss: 1.1130\n",
      "2025-05-30 15:29:16,641 - INFO - Epoch [10/30] Batch [2300/4715] Loss: 0.5884\n",
      "2025-05-30 15:29:18,213 - INFO - Epoch [10/30] Batch [2310/4715] Loss: 0.8435\n",
      "2025-05-30 15:29:19,702 - INFO - Epoch [10/30] Batch [2320/4715] Loss: 0.7257\n",
      "2025-05-30 15:29:21,236 - INFO - Epoch [10/30] Batch [2330/4715] Loss: 0.7450\n",
      "2025-05-30 15:29:22,834 - INFO - Epoch [10/30] Batch [2340/4715] Loss: 0.8701\n",
      "2025-05-30 15:29:24,461 - INFO - Epoch [10/30] Batch [2350/4715] Loss: 0.6507\n",
      "2025-05-30 15:29:26,057 - INFO - Epoch [10/30] Batch [2360/4715] Loss: 0.8849\n",
      "2025-05-30 15:29:27,595 - INFO - Epoch [10/30] Batch [2370/4715] Loss: 1.0070\n",
      "2025-05-30 15:29:29,176 - INFO - Epoch [10/30] Batch [2380/4715] Loss: 0.6726\n",
      "2025-05-30 15:29:30,720 - INFO - Epoch [10/30] Batch [2390/4715] Loss: 0.8940\n",
      "2025-05-30 15:29:32,286 - INFO - Epoch [10/30] Batch [2400/4715] Loss: 0.8305\n",
      "2025-05-30 15:29:33,953 - INFO - Epoch [10/30] Batch [2410/4715] Loss: 1.0366\n",
      "2025-05-30 15:29:35,477 - INFO - Epoch [10/30] Batch [2420/4715] Loss: 0.9697\n",
      "2025-05-30 15:29:37,047 - INFO - Epoch [10/30] Batch [2430/4715] Loss: 0.9605\n",
      "2025-05-30 15:29:38,689 - INFO - Epoch [10/30] Batch [2440/4715] Loss: 0.8140\n",
      "2025-05-30 15:29:40,332 - INFO - Epoch [10/30] Batch [2450/4715] Loss: 0.6501\n",
      "2025-05-30 15:29:42,050 - INFO - Epoch [10/30] Batch [2460/4715] Loss: 0.7848\n",
      "2025-05-30 15:29:43,723 - INFO - Epoch [10/30] Batch [2470/4715] Loss: 0.8340\n",
      "2025-05-30 15:29:45,525 - INFO - Epoch [10/30] Batch [2480/4715] Loss: 0.9780\n",
      "2025-05-30 15:29:47,084 - INFO - Epoch [10/30] Batch [2490/4715] Loss: 0.7497\n",
      "2025-05-30 15:29:48,574 - INFO - Epoch [10/30] Batch [2500/4715] Loss: 1.1091\n",
      "2025-05-30 15:29:50,203 - INFO - Epoch [10/30] Batch [2510/4715] Loss: 0.6026\n",
      "2025-05-30 15:29:51,780 - INFO - Epoch [10/30] Batch [2520/4715] Loss: 0.7855\n",
      "2025-05-30 15:29:53,292 - INFO - Epoch [10/30] Batch [2530/4715] Loss: 1.0417\n",
      "2025-05-30 15:29:54,864 - INFO - Epoch [10/30] Batch [2540/4715] Loss: 0.5583\n",
      "2025-05-30 15:29:56,389 - INFO - Epoch [10/30] Batch [2550/4715] Loss: 1.1239\n",
      "2025-05-30 15:29:57,826 - INFO - Epoch [10/30] Batch [2560/4715] Loss: 0.6833\n",
      "2025-05-30 15:29:59,395 - INFO - Epoch [10/30] Batch [2570/4715] Loss: 0.7920\n",
      "2025-05-30 15:30:00,988 - INFO - Epoch [10/30] Batch [2580/4715] Loss: 0.8347\n",
      "2025-05-30 15:30:02,499 - INFO - Epoch [10/30] Batch [2590/4715] Loss: 0.8976\n",
      "2025-05-30 15:30:04,023 - INFO - Epoch [10/30] Batch [2600/4715] Loss: 0.8524\n",
      "2025-05-30 15:30:05,659 - INFO - Epoch [10/30] Batch [2610/4715] Loss: 1.1584\n",
      "2025-05-30 15:30:07,219 - INFO - Epoch [10/30] Batch [2620/4715] Loss: 0.6768\n",
      "2025-05-30 15:30:08,799 - INFO - Epoch [10/30] Batch [2630/4715] Loss: 1.2239\n",
      "2025-05-30 15:30:10,341 - INFO - Epoch [10/30] Batch [2640/4715] Loss: 0.7646\n",
      "2025-05-30 15:30:12,001 - INFO - Epoch [10/30] Batch [2650/4715] Loss: 0.5474\n",
      "2025-05-30 15:30:13,653 - INFO - Epoch [10/30] Batch [2660/4715] Loss: 0.8135\n",
      "2025-05-30 15:30:15,256 - INFO - Epoch [10/30] Batch [2670/4715] Loss: 1.0075\n",
      "2025-05-30 15:30:16,813 - INFO - Epoch [10/30] Batch [2680/4715] Loss: 0.6674\n",
      "2025-05-30 15:30:18,369 - INFO - Epoch [10/30] Batch [2690/4715] Loss: 0.8683\n",
      "2025-05-30 15:30:19,945 - INFO - Epoch [10/30] Batch [2700/4715] Loss: 0.9948\n",
      "2025-05-30 15:30:21,477 - INFO - Epoch [10/30] Batch [2710/4715] Loss: 0.8520\n",
      "2025-05-30 15:30:23,021 - INFO - Epoch [10/30] Batch [2720/4715] Loss: 0.9579\n",
      "2025-05-30 15:30:24,641 - INFO - Epoch [10/30] Batch [2730/4715] Loss: 0.7067\n",
      "2025-05-30 15:30:26,304 - INFO - Epoch [10/30] Batch [2740/4715] Loss: 0.9533\n",
      "2025-05-30 15:30:27,882 - INFO - Epoch [10/30] Batch [2750/4715] Loss: 0.8916\n",
      "2025-05-30 15:30:29,398 - INFO - Epoch [10/30] Batch [2760/4715] Loss: 0.8310\n",
      "2025-05-30 15:30:30,947 - INFO - Epoch [10/30] Batch [2770/4715] Loss: 0.7569\n",
      "2025-05-30 15:30:32,580 - INFO - Epoch [10/30] Batch [2780/4715] Loss: 0.8502\n",
      "2025-05-30 15:30:34,125 - INFO - Epoch [10/30] Batch [2790/4715] Loss: 0.8053\n",
      "2025-05-30 15:30:35,666 - INFO - Epoch [10/30] Batch [2800/4715] Loss: 0.7956\n",
      "2025-05-30 15:30:37,206 - INFO - Epoch [10/30] Batch [2810/4715] Loss: 1.1504\n",
      "2025-05-30 15:30:38,790 - INFO - Epoch [10/30] Batch [2820/4715] Loss: 1.0401\n",
      "2025-05-30 15:30:40,318 - INFO - Epoch [10/30] Batch [2830/4715] Loss: 0.7428\n",
      "2025-05-30 15:30:41,904 - INFO - Epoch [10/30] Batch [2840/4715] Loss: 0.7539\n",
      "2025-05-30 15:30:43,584 - INFO - Epoch [10/30] Batch [2850/4715] Loss: 0.7009\n",
      "2025-05-30 15:30:45,179 - INFO - Epoch [10/30] Batch [2860/4715] Loss: 0.8885\n",
      "2025-05-30 15:30:46,857 - INFO - Epoch [10/30] Batch [2870/4715] Loss: 0.8598\n",
      "2025-05-30 15:30:48,517 - INFO - Epoch [10/30] Batch [2880/4715] Loss: 0.8408\n",
      "2025-05-30 15:30:50,078 - INFO - Epoch [10/30] Batch [2890/4715] Loss: 0.9505\n",
      "2025-05-30 15:30:51,696 - INFO - Epoch [10/30] Batch [2900/4715] Loss: 1.0518\n",
      "2025-05-30 15:30:53,283 - INFO - Epoch [10/30] Batch [2910/4715] Loss: 0.7063\n",
      "2025-05-30 15:30:54,903 - INFO - Epoch [10/30] Batch [2920/4715] Loss: 0.6925\n",
      "2025-05-30 15:30:56,451 - INFO - Epoch [10/30] Batch [2930/4715] Loss: 0.7825\n",
      "2025-05-30 15:30:58,102 - INFO - Epoch [10/30] Batch [2940/4715] Loss: 0.5486\n",
      "2025-05-30 15:30:59,722 - INFO - Epoch [10/30] Batch [2950/4715] Loss: 0.6982\n",
      "2025-05-30 15:31:01,320 - INFO - Epoch [10/30] Batch [2960/4715] Loss: 0.7040\n",
      "2025-05-30 15:31:02,819 - INFO - Epoch [10/30] Batch [2970/4715] Loss: 0.9401\n",
      "2025-05-30 15:31:04,366 - INFO - Epoch [10/30] Batch [2980/4715] Loss: 0.9284\n",
      "2025-05-30 15:31:05,894 - INFO - Epoch [10/30] Batch [2990/4715] Loss: 0.6577\n",
      "2025-05-30 15:31:07,431 - INFO - Epoch [10/30] Batch [3000/4715] Loss: 0.8109\n",
      "2025-05-30 15:31:08,969 - INFO - Epoch [10/30] Batch [3010/4715] Loss: 0.6874\n",
      "2025-05-30 15:31:10,479 - INFO - Epoch [10/30] Batch [3020/4715] Loss: 0.6381\n",
      "2025-05-30 15:31:12,005 - INFO - Epoch [10/30] Batch [3030/4715] Loss: 0.7039\n",
      "2025-05-30 15:31:13,504 - INFO - Epoch [10/30] Batch [3040/4715] Loss: 0.7091\n",
      "2025-05-30 15:31:15,001 - INFO - Epoch [10/30] Batch [3050/4715] Loss: 0.9253\n",
      "2025-05-30 15:31:16,509 - INFO - Epoch [10/30] Batch [3060/4715] Loss: 0.9475\n",
      "2025-05-30 15:31:18,050 - INFO - Epoch [10/30] Batch [3070/4715] Loss: 0.7695\n",
      "2025-05-30 15:31:19,672 - INFO - Epoch [10/30] Batch [3080/4715] Loss: 0.8468\n",
      "2025-05-30 15:31:21,236 - INFO - Epoch [10/30] Batch [3090/4715] Loss: 0.8047\n",
      "2025-05-30 15:31:22,705 - INFO - Epoch [10/30] Batch [3100/4715] Loss: 0.6736\n",
      "2025-05-30 15:31:24,343 - INFO - Epoch [10/30] Batch [3110/4715] Loss: 0.7539\n",
      "2025-05-30 15:31:25,841 - INFO - Epoch [10/30] Batch [3120/4715] Loss: 0.8239\n",
      "2025-05-30 15:31:27,457 - INFO - Epoch [10/30] Batch [3130/4715] Loss: 0.7459\n",
      "2025-05-30 15:31:28,966 - INFO - Epoch [10/30] Batch [3140/4715] Loss: 0.4308\n",
      "2025-05-30 15:31:30,556 - INFO - Epoch [10/30] Batch [3150/4715] Loss: 0.7406\n",
      "2025-05-30 15:31:32,040 - INFO - Epoch [10/30] Batch [3160/4715] Loss: 0.5450\n",
      "2025-05-30 15:31:33,739 - INFO - Epoch [10/30] Batch [3170/4715] Loss: 0.6926\n",
      "2025-05-30 15:31:35,353 - INFO - Epoch [10/30] Batch [3180/4715] Loss: 0.6657\n",
      "2025-05-30 15:31:36,923 - INFO - Epoch [10/30] Batch [3190/4715] Loss: 0.7602\n",
      "2025-05-30 15:31:38,495 - INFO - Epoch [10/30] Batch [3200/4715] Loss: 0.6534\n",
      "2025-05-30 15:31:40,037 - INFO - Epoch [10/30] Batch [3210/4715] Loss: 0.7459\n",
      "2025-05-30 15:31:41,769 - INFO - Epoch [10/30] Batch [3220/4715] Loss: 0.8281\n",
      "2025-05-30 15:31:43,433 - INFO - Epoch [10/30] Batch [3230/4715] Loss: 0.7567\n",
      "2025-05-30 15:31:45,028 - INFO - Epoch [10/30] Batch [3240/4715] Loss: 0.7904\n",
      "2025-05-30 15:31:46,547 - INFO - Epoch [10/30] Batch [3250/4715] Loss: 0.7037\n",
      "2025-05-30 15:31:48,142 - INFO - Epoch [10/30] Batch [3260/4715] Loss: 0.8947\n",
      "2025-05-30 15:31:49,703 - INFO - Epoch [10/30] Batch [3270/4715] Loss: 0.9482\n",
      "2025-05-30 15:31:51,315 - INFO - Epoch [10/30] Batch [3280/4715] Loss: 0.8844\n",
      "2025-05-30 15:31:52,930 - INFO - Epoch [10/30] Batch [3290/4715] Loss: 0.7442\n",
      "2025-05-30 15:31:54,570 - INFO - Epoch [10/30] Batch [3300/4715] Loss: 0.6549\n",
      "2025-05-30 15:31:56,049 - INFO - Epoch [10/30] Batch [3310/4715] Loss: 0.8309\n",
      "2025-05-30 15:31:57,656 - INFO - Epoch [10/30] Batch [3320/4715] Loss: 0.8716\n",
      "2025-05-30 15:31:59,175 - INFO - Epoch [10/30] Batch [3330/4715] Loss: 1.1470\n",
      "2025-05-30 15:32:00,770 - INFO - Epoch [10/30] Batch [3340/4715] Loss: 0.9254\n",
      "2025-05-30 15:32:02,298 - INFO - Epoch [10/30] Batch [3350/4715] Loss: 0.6624\n",
      "2025-05-30 15:32:03,833 - INFO - Epoch [10/30] Batch [3360/4715] Loss: 0.9424\n",
      "2025-05-30 15:32:05,449 - INFO - Epoch [10/30] Batch [3370/4715] Loss: 0.9781\n",
      "2025-05-30 15:32:07,041 - INFO - Epoch [10/30] Batch [3380/4715] Loss: 0.7518\n",
      "2025-05-30 15:32:08,602 - INFO - Epoch [10/30] Batch [3390/4715] Loss: 0.8680\n",
      "2025-05-30 15:32:10,228 - INFO - Epoch [10/30] Batch [3400/4715] Loss: 0.7731\n",
      "2025-05-30 15:32:11,797 - INFO - Epoch [10/30] Batch [3410/4715] Loss: 0.9626\n",
      "2025-05-30 15:32:13,317 - INFO - Epoch [10/30] Batch [3420/4715] Loss: 0.9335\n",
      "2025-05-30 15:32:14,878 - INFO - Epoch [10/30] Batch [3430/4715] Loss: 0.9271\n",
      "2025-05-30 15:32:16,557 - INFO - Epoch [10/30] Batch [3440/4715] Loss: 1.0725\n",
      "2025-05-30 15:32:18,155 - INFO - Epoch [10/30] Batch [3450/4715] Loss: 0.8782\n",
      "2025-05-30 15:32:19,761 - INFO - Epoch [10/30] Batch [3460/4715] Loss: 0.7054\n",
      "2025-05-30 15:32:21,448 - INFO - Epoch [10/30] Batch [3470/4715] Loss: 0.8629\n",
      "2025-05-30 15:32:22,977 - INFO - Epoch [10/30] Batch [3480/4715] Loss: 0.9459\n",
      "2025-05-30 15:32:24,579 - INFO - Epoch [10/30] Batch [3490/4715] Loss: 0.8087\n",
      "2025-05-30 15:32:26,299 - INFO - Epoch [10/30] Batch [3500/4715] Loss: 0.7294\n",
      "2025-05-30 15:32:27,847 - INFO - Epoch [10/30] Batch [3510/4715] Loss: 0.6711\n",
      "2025-05-30 15:32:29,411 - INFO - Epoch [10/30] Batch [3520/4715] Loss: 1.1806\n",
      "2025-05-30 15:32:31,047 - INFO - Epoch [10/30] Batch [3530/4715] Loss: 0.7569\n",
      "2025-05-30 15:32:32,656 - INFO - Epoch [10/30] Batch [3540/4715] Loss: 0.8392\n",
      "2025-05-30 15:32:34,231 - INFO - Epoch [10/30] Batch [3550/4715] Loss: 0.6602\n",
      "2025-05-30 15:32:35,789 - INFO - Epoch [10/30] Batch [3560/4715] Loss: 0.6645\n",
      "2025-05-30 15:32:37,336 - INFO - Epoch [10/30] Batch [3570/4715] Loss: 0.7820\n",
      "2025-05-30 15:32:38,884 - INFO - Epoch [10/30] Batch [3580/4715] Loss: 0.9636\n",
      "2025-05-30 15:32:40,488 - INFO - Epoch [10/30] Batch [3590/4715] Loss: 0.8241\n",
      "2025-05-30 15:32:41,982 - INFO - Epoch [10/30] Batch [3600/4715] Loss: 0.6594\n",
      "2025-05-30 15:32:43,547 - INFO - Epoch [10/30] Batch [3610/4715] Loss: 0.8577\n",
      "2025-05-30 15:32:45,199 - INFO - Epoch [10/30] Batch [3620/4715] Loss: 0.8507\n",
      "2025-05-30 15:32:46,761 - INFO - Epoch [10/30] Batch [3630/4715] Loss: 1.1676\n",
      "2025-05-30 15:32:48,418 - INFO - Epoch [10/30] Batch [3640/4715] Loss: 0.8520\n",
      "2025-05-30 15:32:50,055 - INFO - Epoch [10/30] Batch [3650/4715] Loss: 0.7535\n",
      "2025-05-30 15:32:51,645 - INFO - Epoch [10/30] Batch [3660/4715] Loss: 0.7704\n",
      "2025-05-30 15:32:53,281 - INFO - Epoch [10/30] Batch [3670/4715] Loss: 0.8337\n",
      "2025-05-30 15:32:54,826 - INFO - Epoch [10/30] Batch [3680/4715] Loss: 0.9354\n",
      "2025-05-30 15:32:56,328 - INFO - Epoch [10/30] Batch [3690/4715] Loss: 0.8562\n",
      "2025-05-30 15:32:57,915 - INFO - Epoch [10/30] Batch [3700/4715] Loss: 0.7377\n",
      "2025-05-30 15:32:59,537 - INFO - Epoch [10/30] Batch [3710/4715] Loss: 0.6838\n",
      "2025-05-30 15:33:01,246 - INFO - Epoch [10/30] Batch [3720/4715] Loss: 1.0717\n",
      "2025-05-30 15:33:02,788 - INFO - Epoch [10/30] Batch [3730/4715] Loss: 0.6951\n",
      "2025-05-30 15:33:04,320 - INFO - Epoch [10/30] Batch [3740/4715] Loss: 0.8697\n",
      "2025-05-30 15:33:05,887 - INFO - Epoch [10/30] Batch [3750/4715] Loss: 0.7588\n",
      "2025-05-30 15:33:07,455 - INFO - Epoch [10/30] Batch [3760/4715] Loss: 0.9364\n",
      "2025-05-30 15:33:08,958 - INFO - Epoch [10/30] Batch [3770/4715] Loss: 0.6496\n",
      "2025-05-30 15:33:10,462 - INFO - Epoch [10/30] Batch [3780/4715] Loss: 0.6994\n",
      "2025-05-30 15:33:12,073 - INFO - Epoch [10/30] Batch [3790/4715] Loss: 0.6616\n",
      "2025-05-30 15:33:13,557 - INFO - Epoch [10/30] Batch [3800/4715] Loss: 0.8590\n",
      "2025-05-30 15:33:15,163 - INFO - Epoch [10/30] Batch [3810/4715] Loss: 0.7726\n",
      "2025-05-30 15:33:16,736 - INFO - Epoch [10/30] Batch [3820/4715] Loss: 0.7099\n",
      "2025-05-30 15:33:18,333 - INFO - Epoch [10/30] Batch [3830/4715] Loss: 0.8571\n",
      "2025-05-30 15:33:19,981 - INFO - Epoch [10/30] Batch [3840/4715] Loss: 0.8825\n",
      "2025-05-30 15:33:21,574 - INFO - Epoch [10/30] Batch [3850/4715] Loss: 0.9747\n",
      "2025-05-30 15:33:23,249 - INFO - Epoch [10/30] Batch [3860/4715] Loss: 0.8034\n",
      "2025-05-30 15:33:24,894 - INFO - Epoch [10/30] Batch [3870/4715] Loss: 0.8201\n",
      "2025-05-30 15:33:26,519 - INFO - Epoch [10/30] Batch [3880/4715] Loss: 0.9584\n",
      "2025-05-30 15:33:28,108 - INFO - Epoch [10/30] Batch [3890/4715] Loss: 0.8214\n",
      "2025-05-30 15:33:29,804 - INFO - Epoch [10/30] Batch [3900/4715] Loss: 0.9555\n",
      "2025-05-30 15:33:31,542 - INFO - Epoch [10/30] Batch [3910/4715] Loss: 0.7913\n",
      "2025-05-30 15:33:33,154 - INFO - Epoch [10/30] Batch [3920/4715] Loss: 0.7550\n",
      "2025-05-30 15:33:34,704 - INFO - Epoch [10/30] Batch [3930/4715] Loss: 0.7084\n",
      "2025-05-30 15:33:36,214 - INFO - Epoch [10/30] Batch [3940/4715] Loss: 0.9920\n",
      "2025-05-30 15:33:37,755 - INFO - Epoch [10/30] Batch [3950/4715] Loss: 0.7134\n",
      "2025-05-30 15:33:39,339 - INFO - Epoch [10/30] Batch [3960/4715] Loss: 0.7791\n",
      "2025-05-30 15:33:40,874 - INFO - Epoch [10/30] Batch [3970/4715] Loss: 0.7885\n",
      "2025-05-30 15:33:42,500 - INFO - Epoch [10/30] Batch [3980/4715] Loss: 0.8064\n",
      "2025-05-30 15:33:44,030 - INFO - Epoch [10/30] Batch [3990/4715] Loss: 0.6768\n",
      "2025-05-30 15:33:45,663 - INFO - Epoch [10/30] Batch [4000/4715] Loss: 0.6512\n",
      "2025-05-30 15:33:47,253 - INFO - Epoch [10/30] Batch [4010/4715] Loss: 0.6866\n",
      "2025-05-30 15:33:48,843 - INFO - Epoch [10/30] Batch [4020/4715] Loss: 0.8382\n",
      "2025-05-30 15:33:50,326 - INFO - Epoch [10/30] Batch [4030/4715] Loss: 0.8625\n",
      "2025-05-30 15:33:51,922 - INFO - Epoch [10/30] Batch [4040/4715] Loss: 0.8400\n",
      "2025-05-30 15:33:53,502 - INFO - Epoch [10/30] Batch [4050/4715] Loss: 1.0610\n",
      "2025-05-30 15:33:55,099 - INFO - Epoch [10/30] Batch [4060/4715] Loss: 0.8679\n",
      "2025-05-30 15:33:56,750 - INFO - Epoch [10/30] Batch [4070/4715] Loss: 0.7880\n",
      "2025-05-30 15:33:58,254 - INFO - Epoch [10/30] Batch [4080/4715] Loss: 0.6918\n",
      "2025-05-30 15:33:59,867 - INFO - Epoch [10/30] Batch [4090/4715] Loss: 1.1689\n",
      "2025-05-30 15:34:01,565 - INFO - Epoch [10/30] Batch [4100/4715] Loss: 1.1201\n",
      "2025-05-30 15:34:03,146 - INFO - Epoch [10/30] Batch [4110/4715] Loss: 0.7459\n",
      "2025-05-30 15:34:04,746 - INFO - Epoch [10/30] Batch [4120/4715] Loss: 0.6944\n",
      "2025-05-30 15:34:06,288 - INFO - Epoch [10/30] Batch [4130/4715] Loss: 0.7594\n",
      "2025-05-30 15:34:07,883 - INFO - Epoch [10/30] Batch [4140/4715] Loss: 0.7497\n",
      "2025-05-30 15:34:09,458 - INFO - Epoch [10/30] Batch [4150/4715] Loss: 0.9107\n",
      "2025-05-30 15:34:11,062 - INFO - Epoch [10/30] Batch [4160/4715] Loss: 1.0119\n",
      "2025-05-30 15:34:12,588 - INFO - Epoch [10/30] Batch [4170/4715] Loss: 0.7344\n",
      "2025-05-30 15:34:14,135 - INFO - Epoch [10/30] Batch [4180/4715] Loss: 0.6988\n",
      "2025-05-30 15:34:15,662 - INFO - Epoch [10/30] Batch [4190/4715] Loss: 0.8197\n",
      "2025-05-30 15:34:17,292 - INFO - Epoch [10/30] Batch [4200/4715] Loss: 0.7966\n",
      "2025-05-30 15:34:18,814 - INFO - Epoch [10/30] Batch [4210/4715] Loss: 0.8768\n",
      "2025-05-30 15:34:20,387 - INFO - Epoch [10/30] Batch [4220/4715] Loss: 0.7142\n",
      "2025-05-30 15:34:21,899 - INFO - Epoch [10/30] Batch [4230/4715] Loss: 0.9769\n",
      "2025-05-30 15:34:23,518 - INFO - Epoch [10/30] Batch [4240/4715] Loss: 0.9012\n",
      "2025-05-30 15:34:25,053 - INFO - Epoch [10/30] Batch [4250/4715] Loss: 0.5454\n",
      "2025-05-30 15:34:26,619 - INFO - Epoch [10/30] Batch [4260/4715] Loss: 0.7156\n",
      "2025-05-30 15:34:28,189 - INFO - Epoch [10/30] Batch [4270/4715] Loss: 0.7664\n",
      "2025-05-30 15:34:29,678 - INFO - Epoch [10/30] Batch [4280/4715] Loss: 0.7762\n",
      "2025-05-30 15:34:31,251 - INFO - Epoch [10/30] Batch [4290/4715] Loss: 0.8963\n",
      "2025-05-30 15:34:32,851 - INFO - Epoch [10/30] Batch [4300/4715] Loss: 0.9705\n",
      "2025-05-30 15:34:34,383 - INFO - Epoch [10/30] Batch [4310/4715] Loss: 0.7752\n",
      "2025-05-30 15:34:35,958 - INFO - Epoch [10/30] Batch [4320/4715] Loss: 0.9930\n",
      "2025-05-30 15:34:37,593 - INFO - Epoch [10/30] Batch [4330/4715] Loss: 0.6279\n",
      "2025-05-30 15:34:39,148 - INFO - Epoch [10/30] Batch [4340/4715] Loss: 0.7478\n",
      "2025-05-30 15:34:40,714 - INFO - Epoch [10/30] Batch [4350/4715] Loss: 0.7204\n",
      "2025-05-30 15:34:42,274 - INFO - Epoch [10/30] Batch [4360/4715] Loss: 0.7418\n",
      "2025-05-30 15:34:43,871 - INFO - Epoch [10/30] Batch [4370/4715] Loss: 0.7029\n",
      "2025-05-30 15:34:45,452 - INFO - Epoch [10/30] Batch [4380/4715] Loss: 0.7574\n",
      "2025-05-30 15:34:46,948 - INFO - Epoch [10/30] Batch [4390/4715] Loss: 0.6758\n",
      "2025-05-30 15:34:48,519 - INFO - Epoch [10/30] Batch [4400/4715] Loss: 0.8547\n",
      "2025-05-30 15:34:50,058 - INFO - Epoch [10/30] Batch [4410/4715] Loss: 0.8548\n",
      "2025-05-30 15:34:51,648 - INFO - Epoch [10/30] Batch [4420/4715] Loss: 0.6627\n",
      "2025-05-30 15:34:53,262 - INFO - Epoch [10/30] Batch [4430/4715] Loss: 0.7553\n",
      "2025-05-30 15:34:54,873 - INFO - Epoch [10/30] Batch [4440/4715] Loss: 0.8063\n",
      "2025-05-30 15:34:56,498 - INFO - Epoch [10/30] Batch [4450/4715] Loss: 0.7477\n",
      "2025-05-30 15:34:58,074 - INFO - Epoch [10/30] Batch [4460/4715] Loss: 0.7356\n",
      "2025-05-30 15:34:59,617 - INFO - Epoch [10/30] Batch [4470/4715] Loss: 0.7948\n",
      "2025-05-30 15:35:01,187 - INFO - Epoch [10/30] Batch [4480/4715] Loss: 0.9734\n",
      "2025-05-30 15:35:02,846 - INFO - Epoch [10/30] Batch [4490/4715] Loss: 0.7729\n",
      "2025-05-30 15:35:04,458 - INFO - Epoch [10/30] Batch [4500/4715] Loss: 0.6912\n",
      "2025-05-30 15:35:06,002 - INFO - Epoch [10/30] Batch [4510/4715] Loss: 0.6522\n",
      "2025-05-30 15:35:07,587 - INFO - Epoch [10/30] Batch [4520/4715] Loss: 0.6805\n",
      "2025-05-30 15:35:09,143 - INFO - Epoch [10/30] Batch [4530/4715] Loss: 0.6562\n",
      "2025-05-30 15:35:10,738 - INFO - Epoch [10/30] Batch [4540/4715] Loss: 1.0283\n",
      "2025-05-30 15:35:12,241 - INFO - Epoch [10/30] Batch [4550/4715] Loss: 0.8075\n",
      "2025-05-30 15:35:13,836 - INFO - Epoch [10/30] Batch [4560/4715] Loss: 0.8834\n",
      "2025-05-30 15:35:15,351 - INFO - Epoch [10/30] Batch [4570/4715] Loss: 0.8193\n",
      "2025-05-30 15:35:16,920 - INFO - Epoch [10/30] Batch [4580/4715] Loss: 0.7723\n",
      "2025-05-30 15:35:18,493 - INFO - Epoch [10/30] Batch [4590/4715] Loss: 0.7114\n",
      "2025-05-30 15:35:20,031 - INFO - Epoch [10/30] Batch [4600/4715] Loss: 0.6312\n",
      "2025-05-30 15:35:21,568 - INFO - Epoch [10/30] Batch [4610/4715] Loss: 0.8781\n",
      "2025-05-30 15:35:23,136 - INFO - Epoch [10/30] Batch [4620/4715] Loss: 0.8788\n",
      "2025-05-30 15:35:24,612 - INFO - Epoch [10/30] Batch [4630/4715] Loss: 0.8637\n",
      "2025-05-30 15:35:26,176 - INFO - Epoch [10/30] Batch [4640/4715] Loss: 0.7650\n",
      "2025-05-30 15:35:27,784 - INFO - Epoch [10/30] Batch [4650/4715] Loss: 0.8176\n",
      "2025-05-30 15:35:29,430 - INFO - Epoch [10/30] Batch [4660/4715] Loss: 0.7251\n",
      "2025-05-30 15:35:31,139 - INFO - Epoch [10/30] Batch [4670/4715] Loss: 1.0664\n",
      "2025-05-30 15:35:32,674 - INFO - Epoch [10/30] Batch [4680/4715] Loss: 0.7529\n",
      "2025-05-30 15:35:34,220 - INFO - Epoch [10/30] Batch [4690/4715] Loss: 0.8033\n",
      "2025-05-30 15:35:35,792 - INFO - Epoch [10/30] Batch [4700/4715] Loss: 0.7549\n",
      "2025-05-30 15:35:37,441 - INFO - Epoch [10/30] Batch [4710/4715] Loss: 0.6234\n",
      "2025-05-30 15:36:16,688 - INFO - \n",
      "Epoch [10/30] Time: 783.52s\n",
      "2025-05-30 15:36:16,688 - INFO - Train Loss: 0.8231, Valid Loss: 0.8291\n",
      "2025-05-30 15:36:16,689 - INFO - Valid AUC (macro): 0.7229, F1 (macro): 0.5486\n",
      "2025-05-30 15:36:17,234 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\checkpoint_epoch_10.pth\n",
      "2025-05-30 15:36:17,752 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 15:36:17,753 - INFO - Saved checkpoint at epoch 10\n",
      "2025-05-30 15:36:17,983 - INFO - Epoch [11/30] Batch [0/4715] Loss: 0.7260\n",
      "2025-05-30 15:36:19,794 - INFO - Epoch [11/30] Batch [10/4715] Loss: 0.7865\n",
      "2025-05-30 15:36:21,360 - INFO - Epoch [11/30] Batch [20/4715] Loss: 1.0684\n",
      "2025-05-30 15:36:22,891 - INFO - Epoch [11/30] Batch [30/4715] Loss: 0.7233\n",
      "2025-05-30 15:36:24,479 - INFO - Epoch [11/30] Batch [40/4715] Loss: 1.0578\n",
      "2025-05-30 15:36:26,016 - INFO - Epoch [11/30] Batch [50/4715] Loss: 1.3684\n",
      "2025-05-30 15:36:27,570 - INFO - Epoch [11/30] Batch [60/4715] Loss: 0.9755\n",
      "2025-05-30 15:36:29,101 - INFO - Epoch [11/30] Batch [70/4715] Loss: 0.8742\n",
      "2025-05-30 15:36:30,753 - INFO - Epoch [11/30] Batch [80/4715] Loss: 0.7641\n",
      "2025-05-30 15:36:32,351 - INFO - Epoch [11/30] Batch [90/4715] Loss: 0.6645\n",
      "2025-05-30 15:36:34,022 - INFO - Epoch [11/30] Batch [100/4715] Loss: 0.7708\n",
      "2025-05-30 15:36:35,646 - INFO - Epoch [11/30] Batch [110/4715] Loss: 0.9094\n",
      "2025-05-30 15:36:37,231 - INFO - Epoch [11/30] Batch [120/4715] Loss: 0.7870\n",
      "2025-05-30 15:36:38,816 - INFO - Epoch [11/30] Batch [130/4715] Loss: 0.7225\n",
      "2025-05-30 15:36:40,396 - INFO - Epoch [11/30] Batch [140/4715] Loss: 0.6563\n",
      "2025-05-30 15:36:42,004 - INFO - Epoch [11/30] Batch [150/4715] Loss: 0.8320\n",
      "2025-05-30 15:36:43,853 - INFO - Epoch [11/30] Batch [160/4715] Loss: 0.6684\n",
      "2025-05-30 15:36:45,485 - INFO - Epoch [11/30] Batch [170/4715] Loss: 0.6630\n",
      "2025-05-30 15:36:47,169 - INFO - Epoch [11/30] Batch [180/4715] Loss: 0.6996\n",
      "2025-05-30 15:36:48,642 - INFO - Epoch [11/30] Batch [190/4715] Loss: 0.7047\n",
      "2025-05-30 15:36:50,276 - INFO - Epoch [11/30] Batch [200/4715] Loss: 0.5811\n",
      "2025-05-30 15:36:51,871 - INFO - Epoch [11/30] Batch [210/4715] Loss: 0.9100\n",
      "2025-05-30 15:36:53,438 - INFO - Epoch [11/30] Batch [220/4715] Loss: 0.7660\n",
      "2025-05-30 15:36:55,074 - INFO - Epoch [11/30] Batch [230/4715] Loss: 0.6582\n",
      "2025-05-30 15:36:56,646 - INFO - Epoch [11/30] Batch [240/4715] Loss: 1.0995\n",
      "2025-05-30 15:36:58,211 - INFO - Epoch [11/30] Batch [250/4715] Loss: 0.8116\n",
      "2025-05-30 15:36:59,780 - INFO - Epoch [11/30] Batch [260/4715] Loss: 0.8526\n",
      "2025-05-30 15:37:01,397 - INFO - Epoch [11/30] Batch [270/4715] Loss: 1.1284\n",
      "2025-05-30 15:37:02,916 - INFO - Epoch [11/30] Batch [280/4715] Loss: 0.8895\n",
      "2025-05-30 15:37:04,449 - INFO - Epoch [11/30] Batch [290/4715] Loss: 0.6918\n",
      "2025-05-30 15:37:06,046 - INFO - Epoch [11/30] Batch [300/4715] Loss: 0.6187\n",
      "2025-05-30 15:37:07,624 - INFO - Epoch [11/30] Batch [310/4715] Loss: 0.9977\n",
      "2025-05-30 15:37:09,185 - INFO - Epoch [11/30] Batch [320/4715] Loss: 0.8696\n",
      "2025-05-30 15:37:10,838 - INFO - Epoch [11/30] Batch [330/4715] Loss: 0.8661\n",
      "2025-05-30 15:37:12,337 - INFO - Epoch [11/30] Batch [340/4715] Loss: 0.7310\n",
      "2025-05-30 15:37:13,882 - INFO - Epoch [11/30] Batch [350/4715] Loss: 0.7950\n",
      "2025-05-30 15:37:15,530 - INFO - Epoch [11/30] Batch [360/4715] Loss: 0.6913\n",
      "2025-05-30 15:37:17,168 - INFO - Epoch [11/30] Batch [370/4715] Loss: 0.8112\n",
      "2025-05-30 15:37:18,665 - INFO - Epoch [11/30] Batch [380/4715] Loss: 1.0681\n",
      "2025-05-30 15:37:20,210 - INFO - Epoch [11/30] Batch [390/4715] Loss: 0.9130\n",
      "2025-05-30 15:37:21,768 - INFO - Epoch [11/30] Batch [400/4715] Loss: 0.7255\n",
      "2025-05-30 15:37:23,272 - INFO - Epoch [11/30] Batch [410/4715] Loss: 0.6799\n",
      "2025-05-30 15:37:24,898 - INFO - Epoch [11/30] Batch [420/4715] Loss: 0.8948\n",
      "2025-05-30 15:37:26,424 - INFO - Epoch [11/30] Batch [430/4715] Loss: 0.7470\n",
      "2025-05-30 15:37:27,941 - INFO - Epoch [11/30] Batch [440/4715] Loss: 0.7188\n",
      "2025-05-30 15:37:29,465 - INFO - Epoch [11/30] Batch [450/4715] Loss: 0.6043\n",
      "2025-05-30 15:37:31,031 - INFO - Epoch [11/30] Batch [460/4715] Loss: 0.8669\n",
      "2025-05-30 15:37:32,807 - INFO - Epoch [11/30] Batch [470/4715] Loss: 0.8812\n",
      "2025-05-30 15:37:34,399 - INFO - Epoch [11/30] Batch [480/4715] Loss: 0.8996\n",
      "2025-05-30 15:37:35,923 - INFO - Epoch [11/30] Batch [490/4715] Loss: 0.8276\n",
      "2025-05-30 15:37:37,585 - INFO - Epoch [11/30] Batch [500/4715] Loss: 0.7861\n",
      "2025-05-30 15:37:39,191 - INFO - Epoch [11/30] Batch [510/4715] Loss: 0.7794\n",
      "2025-05-30 15:37:40,764 - INFO - Epoch [11/30] Batch [520/4715] Loss: 0.8463\n",
      "2025-05-30 15:37:42,329 - INFO - Epoch [11/30] Batch [530/4715] Loss: 0.7711\n",
      "2025-05-30 15:37:43,830 - INFO - Epoch [11/30] Batch [540/4715] Loss: 0.9511\n",
      "2025-05-30 15:37:45,366 - INFO - Epoch [11/30] Batch [550/4715] Loss: 0.7611\n",
      "2025-05-30 15:37:46,937 - INFO - Epoch [11/30] Batch [560/4715] Loss: 0.4850\n",
      "2025-05-30 15:37:48,512 - INFO - Epoch [11/30] Batch [570/4715] Loss: 0.6713\n",
      "2025-05-30 15:37:50,083 - INFO - Epoch [11/30] Batch [580/4715] Loss: 0.6712\n",
      "2025-05-30 15:37:51,579 - INFO - Epoch [11/30] Batch [590/4715] Loss: 0.7989\n",
      "2025-05-30 15:37:53,219 - INFO - Epoch [11/30] Batch [600/4715] Loss: 0.7222\n",
      "2025-05-30 15:37:54,726 - INFO - Epoch [11/30] Batch [610/4715] Loss: 0.8467\n",
      "2025-05-30 15:37:56,307 - INFO - Epoch [11/30] Batch [620/4715] Loss: 0.5997\n",
      "2025-05-30 15:37:57,842 - INFO - Epoch [11/30] Batch [630/4715] Loss: 0.8605\n",
      "2025-05-30 15:37:59,307 - INFO - Epoch [11/30] Batch [640/4715] Loss: 0.8794\n",
      "2025-05-30 15:38:00,768 - INFO - Epoch [11/30] Batch [650/4715] Loss: 0.8543\n",
      "2025-05-30 15:38:02,299 - INFO - Epoch [11/30] Batch [660/4715] Loss: 0.5558\n",
      "2025-05-30 15:38:03,817 - INFO - Epoch [11/30] Batch [670/4715] Loss: 1.1045\n",
      "2025-05-30 15:38:05,411 - INFO - Epoch [11/30] Batch [680/4715] Loss: 0.7574\n",
      "2025-05-30 15:38:06,914 - INFO - Epoch [11/30] Batch [690/4715] Loss: 0.8344\n",
      "2025-05-30 15:38:08,521 - INFO - Epoch [11/30] Batch [700/4715] Loss: 0.7039\n",
      "2025-05-30 15:38:10,050 - INFO - Epoch [11/30] Batch [710/4715] Loss: 0.9095\n",
      "2025-05-30 15:38:11,581 - INFO - Epoch [11/30] Batch [720/4715] Loss: 0.8905\n",
      "2025-05-30 15:38:13,070 - INFO - Epoch [11/30] Batch [730/4715] Loss: 0.6085\n",
      "2025-05-30 15:38:14,632 - INFO - Epoch [11/30] Batch [740/4715] Loss: 0.7637\n",
      "2025-05-30 15:38:16,334 - INFO - Epoch [11/30] Batch [750/4715] Loss: 0.8065\n",
      "2025-05-30 15:38:17,965 - INFO - Epoch [11/30] Batch [760/4715] Loss: 0.7168\n",
      "2025-05-30 15:38:19,455 - INFO - Epoch [11/30] Batch [770/4715] Loss: 0.8864\n",
      "2025-05-30 15:38:20,919 - INFO - Epoch [11/30] Batch [780/4715] Loss: 0.8534\n",
      "2025-05-30 15:38:22,465 - INFO - Epoch [11/30] Batch [790/4715] Loss: 0.8952\n",
      "2025-05-30 15:38:23,999 - INFO - Epoch [11/30] Batch [800/4715] Loss: 0.9760\n",
      "2025-05-30 15:38:25,578 - INFO - Epoch [11/30] Batch [810/4715] Loss: 0.8265\n",
      "2025-05-30 15:38:27,102 - INFO - Epoch [11/30] Batch [820/4715] Loss: 0.8987\n",
      "2025-05-30 15:38:28,604 - INFO - Epoch [11/30] Batch [830/4715] Loss: 1.0855\n",
      "2025-05-30 15:38:30,142 - INFO - Epoch [11/30] Batch [840/4715] Loss: 0.8482\n",
      "2025-05-30 15:38:31,632 - INFO - Epoch [11/30] Batch [850/4715] Loss: 0.8122\n",
      "2025-05-30 15:38:33,169 - INFO - Epoch [11/30] Batch [860/4715] Loss: 0.6728\n",
      "2025-05-30 15:38:34,705 - INFO - Epoch [11/30] Batch [870/4715] Loss: 0.8460\n",
      "2025-05-30 15:38:36,145 - INFO - Epoch [11/30] Batch [880/4715] Loss: 0.6825\n",
      "2025-05-30 15:38:37,736 - INFO - Epoch [11/30] Batch [890/4715] Loss: 0.7331\n",
      "2025-05-30 15:38:39,243 - INFO - Epoch [11/30] Batch [900/4715] Loss: 0.8274\n",
      "2025-05-30 15:38:40,812 - INFO - Epoch [11/30] Batch [910/4715] Loss: 0.8493\n",
      "2025-05-30 15:38:42,401 - INFO - Epoch [11/30] Batch [920/4715] Loss: 0.8962\n",
      "2025-05-30 15:38:43,965 - INFO - Epoch [11/30] Batch [930/4715] Loss: 0.7796\n",
      "2025-05-30 15:38:45,543 - INFO - Epoch [11/30] Batch [940/4715] Loss: 0.6751\n",
      "2025-05-30 15:38:47,218 - INFO - Epoch [11/30] Batch [950/4715] Loss: 1.0650\n",
      "2025-05-30 15:38:48,937 - INFO - Epoch [11/30] Batch [960/4715] Loss: 0.9395\n",
      "2025-05-30 15:38:50,486 - INFO - Epoch [11/30] Batch [970/4715] Loss: 0.7056\n",
      "2025-05-30 15:38:52,168 - INFO - Epoch [11/30] Batch [980/4715] Loss: 0.9559\n",
      "2025-05-30 15:38:53,706 - INFO - Epoch [11/30] Batch [990/4715] Loss: 0.6628\n",
      "2025-05-30 15:38:55,268 - INFO - Epoch [11/30] Batch [1000/4715] Loss: 0.9367\n",
      "2025-05-30 15:38:56,884 - INFO - Epoch [11/30] Batch [1010/4715] Loss: 0.9026\n",
      "2025-05-30 15:38:58,496 - INFO - Epoch [11/30] Batch [1020/4715] Loss: 1.0245\n",
      "2025-05-30 15:39:00,067 - INFO - Epoch [11/30] Batch [1030/4715] Loss: 0.8505\n",
      "2025-05-30 15:39:01,572 - INFO - Epoch [11/30] Batch [1040/4715] Loss: 0.7686\n",
      "2025-05-30 15:39:03,040 - INFO - Epoch [11/30] Batch [1050/4715] Loss: 0.7734\n",
      "2025-05-30 15:39:04,562 - INFO - Epoch [11/30] Batch [1060/4715] Loss: 0.7068\n",
      "2025-05-30 15:39:06,088 - INFO - Epoch [11/30] Batch [1070/4715] Loss: 0.7883\n",
      "2025-05-30 15:39:07,670 - INFO - Epoch [11/30] Batch [1080/4715] Loss: 0.9608\n",
      "2025-05-30 15:39:09,279 - INFO - Epoch [11/30] Batch [1090/4715] Loss: 0.8799\n",
      "2025-05-30 15:39:10,889 - INFO - Epoch [11/30] Batch [1100/4715] Loss: 0.8498\n",
      "2025-05-30 15:39:12,527 - INFO - Epoch [11/30] Batch [1110/4715] Loss: 0.7203\n",
      "2025-05-30 15:39:14,106 - INFO - Epoch [11/30] Batch [1120/4715] Loss: 0.7948\n",
      "2025-05-30 15:39:15,671 - INFO - Epoch [11/30] Batch [1130/4715] Loss: 0.8721\n",
      "2025-05-30 15:39:17,194 - INFO - Epoch [11/30] Batch [1140/4715] Loss: 0.7098\n",
      "2025-05-30 15:39:18,756 - INFO - Epoch [11/30] Batch [1150/4715] Loss: 0.6155\n",
      "2025-05-30 15:39:20,312 - INFO - Epoch [11/30] Batch [1160/4715] Loss: 0.8831\n",
      "2025-05-30 15:39:21,868 - INFO - Epoch [11/30] Batch [1170/4715] Loss: 0.7969\n",
      "2025-05-30 15:39:23,378 - INFO - Epoch [11/30] Batch [1180/4715] Loss: 0.8017\n",
      "2025-05-30 15:39:24,887 - INFO - Epoch [11/30] Batch [1190/4715] Loss: 1.2673\n",
      "2025-05-30 15:39:26,491 - INFO - Epoch [11/30] Batch [1200/4715] Loss: 0.8510\n",
      "2025-05-30 15:39:28,167 - INFO - Epoch [11/30] Batch [1210/4715] Loss: 0.9286\n",
      "2025-05-30 15:39:29,719 - INFO - Epoch [11/30] Batch [1220/4715] Loss: 0.8426\n",
      "2025-05-30 15:39:31,284 - INFO - Epoch [11/30] Batch [1230/4715] Loss: 0.8804\n",
      "2025-05-30 15:39:33,037 - INFO - Epoch [11/30] Batch [1240/4715] Loss: 0.7214\n",
      "2025-05-30 15:39:34,962 - INFO - Epoch [11/30] Batch [1250/4715] Loss: 0.7849\n",
      "2025-05-30 15:39:36,593 - INFO - Epoch [11/30] Batch [1260/4715] Loss: 0.6225\n",
      "2025-05-30 15:39:38,169 - INFO - Epoch [11/30] Batch [1270/4715] Loss: 0.5714\n",
      "2025-05-30 15:39:39,717 - INFO - Epoch [11/30] Batch [1280/4715] Loss: 0.8704\n",
      "2025-05-30 15:39:41,228 - INFO - Epoch [11/30] Batch [1290/4715] Loss: 0.6656\n",
      "2025-05-30 15:39:42,747 - INFO - Epoch [11/30] Batch [1300/4715] Loss: 0.9759\n",
      "2025-05-30 15:39:44,337 - INFO - Epoch [11/30] Batch [1310/4715] Loss: 0.9557\n",
      "2025-05-30 15:39:45,977 - INFO - Epoch [11/30] Batch [1320/4715] Loss: 0.6658\n",
      "2025-05-30 15:39:47,571 - INFO - Epoch [11/30] Batch [1330/4715] Loss: 1.2153\n",
      "2025-05-30 15:39:49,098 - INFO - Epoch [11/30] Batch [1340/4715] Loss: 0.7349\n",
      "2025-05-30 15:39:50,599 - INFO - Epoch [11/30] Batch [1350/4715] Loss: 0.7358\n",
      "2025-05-30 15:39:52,107 - INFO - Epoch [11/30] Batch [1360/4715] Loss: 0.9872\n",
      "2025-05-30 15:39:53,682 - INFO - Epoch [11/30] Batch [1370/4715] Loss: 0.7820\n",
      "2025-05-30 15:39:55,340 - INFO - Epoch [11/30] Batch [1380/4715] Loss: 0.6654\n",
      "2025-05-30 15:39:57,008 - INFO - Epoch [11/30] Batch [1390/4715] Loss: 0.8056\n",
      "2025-05-30 15:39:58,679 - INFO - Epoch [11/30] Batch [1400/4715] Loss: 0.9006\n",
      "2025-05-30 15:40:00,185 - INFO - Epoch [11/30] Batch [1410/4715] Loss: 0.8109\n",
      "2025-05-30 15:40:01,686 - INFO - Epoch [11/30] Batch [1420/4715] Loss: 0.8203\n",
      "2025-05-30 15:40:03,328 - INFO - Epoch [11/30] Batch [1430/4715] Loss: 0.9109\n",
      "2025-05-30 15:40:04,915 - INFO - Epoch [11/30] Batch [1440/4715] Loss: 0.9320\n",
      "2025-05-30 15:40:06,510 - INFO - Epoch [11/30] Batch [1450/4715] Loss: 0.7761\n",
      "2025-05-30 15:40:08,099 - INFO - Epoch [11/30] Batch [1460/4715] Loss: 0.7643\n",
      "2025-05-30 15:40:09,664 - INFO - Epoch [11/30] Batch [1470/4715] Loss: 0.8352\n",
      "2025-05-30 15:40:11,221 - INFO - Epoch [11/30] Batch [1480/4715] Loss: 0.6282\n",
      "2025-05-30 15:40:12,695 - INFO - Epoch [11/30] Batch [1490/4715] Loss: 1.1203\n",
      "2025-05-30 15:40:14,218 - INFO - Epoch [11/30] Batch [1500/4715] Loss: 0.6321\n",
      "2025-05-30 15:40:15,823 - INFO - Epoch [11/30] Batch [1510/4715] Loss: 0.8180\n",
      "2025-05-30 15:40:17,370 - INFO - Epoch [11/30] Batch [1520/4715] Loss: 1.0211\n",
      "2025-05-30 15:40:18,879 - INFO - Epoch [11/30] Batch [1530/4715] Loss: 0.7583\n",
      "2025-05-30 15:40:20,510 - INFO - Epoch [11/30] Batch [1540/4715] Loss: 0.7479\n",
      "2025-05-30 15:40:22,031 - INFO - Epoch [11/30] Batch [1550/4715] Loss: 0.7810\n",
      "2025-05-30 15:40:23,589 - INFO - Epoch [11/30] Batch [1560/4715] Loss: 0.6757\n",
      "2025-05-30 15:40:25,159 - INFO - Epoch [11/30] Batch [1570/4715] Loss: 0.9744\n",
      "2025-05-30 15:40:26,700 - INFO - Epoch [11/30] Batch [1580/4715] Loss: 0.7276\n",
      "2025-05-30 15:40:28,272 - INFO - Epoch [11/30] Batch [1590/4715] Loss: 0.8016\n",
      "2025-05-30 15:40:29,840 - INFO - Epoch [11/30] Batch [1600/4715] Loss: 1.4500\n",
      "2025-05-30 15:40:31,556 - INFO - Epoch [11/30] Batch [1610/4715] Loss: 0.6441\n",
      "2025-05-30 15:40:33,155 - INFO - Epoch [11/30] Batch [1620/4715] Loss: 0.6955\n",
      "2025-05-30 15:40:34,722 - INFO - Epoch [11/30] Batch [1630/4715] Loss: 0.9461\n",
      "2025-05-30 15:40:36,173 - INFO - Epoch [11/30] Batch [1640/4715] Loss: 1.1240\n",
      "2025-05-30 15:40:37,704 - INFO - Epoch [11/30] Batch [1650/4715] Loss: 0.8541\n",
      "2025-05-30 15:40:39,338 - INFO - Epoch [11/30] Batch [1660/4715] Loss: 0.8853\n",
      "2025-05-30 15:40:40,861 - INFO - Epoch [11/30] Batch [1670/4715] Loss: 0.8166\n",
      "2025-05-30 15:40:42,422 - INFO - Epoch [11/30] Batch [1680/4715] Loss: 1.0013\n",
      "2025-05-30 15:40:43,968 - INFO - Epoch [11/30] Batch [1690/4715] Loss: 0.9124\n",
      "2025-05-30 15:40:45,543 - INFO - Epoch [11/30] Batch [1700/4715] Loss: 0.7764\n",
      "2025-05-30 15:40:46,983 - INFO - Epoch [11/30] Batch [1710/4715] Loss: 0.7559\n",
      "2025-05-30 15:40:48,592 - INFO - Epoch [11/30] Batch [1720/4715] Loss: 1.0548\n",
      "2025-05-30 15:40:50,133 - INFO - Epoch [11/30] Batch [1730/4715] Loss: 0.9519\n",
      "2025-05-30 15:40:51,632 - INFO - Epoch [11/30] Batch [1740/4715] Loss: 0.8700\n",
      "2025-05-30 15:40:53,275 - INFO - Epoch [11/30] Batch [1750/4715] Loss: 1.0569\n",
      "2025-05-30 15:40:54,832 - INFO - Epoch [11/30] Batch [1760/4715] Loss: 0.7913\n",
      "2025-05-30 15:40:56,466 - INFO - Epoch [11/30] Batch [1770/4715] Loss: 0.8905\n",
      "2025-05-30 15:40:58,112 - INFO - Epoch [11/30] Batch [1780/4715] Loss: 0.7012\n",
      "2025-05-30 15:40:59,786 - INFO - Epoch [11/30] Batch [1790/4715] Loss: 0.8631\n",
      "2025-05-30 15:41:01,417 - INFO - Epoch [11/30] Batch [1800/4715] Loss: 0.6631\n",
      "2025-05-30 15:41:02,951 - INFO - Epoch [11/30] Batch [1810/4715] Loss: 0.5794\n",
      "2025-05-30 15:41:04,431 - INFO - Epoch [11/30] Batch [1820/4715] Loss: 0.8502\n",
      "2025-05-30 15:41:06,032 - INFO - Epoch [11/30] Batch [1830/4715] Loss: 1.1122\n",
      "2025-05-30 15:41:07,527 - INFO - Epoch [11/30] Batch [1840/4715] Loss: 0.7579\n",
      "2025-05-30 15:41:09,127 - INFO - Epoch [11/30] Batch [1850/4715] Loss: 0.9781\n",
      "2025-05-30 15:41:10,727 - INFO - Epoch [11/30] Batch [1860/4715] Loss: 0.7195\n",
      "2025-05-30 15:41:12,347 - INFO - Epoch [11/30] Batch [1870/4715] Loss: 0.6964\n",
      "2025-05-30 15:41:13,904 - INFO - Epoch [11/30] Batch [1880/4715] Loss: 0.8260\n",
      "2025-05-30 15:41:15,584 - INFO - Epoch [11/30] Batch [1890/4715] Loss: 0.7056\n",
      "2025-05-30 15:41:17,201 - INFO - Epoch [11/30] Batch [1900/4715] Loss: 0.6441\n",
      "2025-05-30 15:41:18,732 - INFO - Epoch [11/30] Batch [1910/4715] Loss: 0.9224\n",
      "2025-05-30 15:41:20,336 - INFO - Epoch [11/30] Batch [1920/4715] Loss: 0.7830\n",
      "2025-05-30 15:41:21,911 - INFO - Epoch [11/30] Batch [1930/4715] Loss: 1.0962\n",
      "2025-05-30 15:41:23,497 - INFO - Epoch [11/30] Batch [1940/4715] Loss: 0.6050\n",
      "2025-05-30 15:41:25,052 - INFO - Epoch [11/30] Batch [1950/4715] Loss: 0.8174\n",
      "2025-05-30 15:41:26,631 - INFO - Epoch [11/30] Batch [1960/4715] Loss: 0.7998\n",
      "2025-05-30 15:41:28,274 - INFO - Epoch [11/30] Batch [1970/4715] Loss: 0.8208\n",
      "2025-05-30 15:41:29,780 - INFO - Epoch [11/30] Batch [1980/4715] Loss: 0.9133\n",
      "2025-05-30 15:41:31,295 - INFO - Epoch [11/30] Batch [1990/4715] Loss: 0.6810\n",
      "2025-05-30 15:41:32,929 - INFO - Epoch [11/30] Batch [2000/4715] Loss: 0.8835\n",
      "2025-05-30 15:41:34,487 - INFO - Epoch [11/30] Batch [2010/4715] Loss: 0.8247\n",
      "2025-05-30 15:41:36,067 - INFO - Epoch [11/30] Batch [2020/4715] Loss: 0.7571\n",
      "2025-05-30 15:41:37,601 - INFO - Epoch [11/30] Batch [2030/4715] Loss: 0.7125\n",
      "2025-05-30 15:41:39,126 - INFO - Epoch [11/30] Batch [2040/4715] Loss: 1.0103\n",
      "2025-05-30 15:41:40,723 - INFO - Epoch [11/30] Batch [2050/4715] Loss: 0.6257\n",
      "2025-05-30 15:41:42,259 - INFO - Epoch [11/30] Batch [2060/4715] Loss: 0.9027\n",
      "2025-05-30 15:41:43,819 - INFO - Epoch [11/30] Batch [2070/4715] Loss: 0.7533\n",
      "2025-05-30 15:41:45,390 - INFO - Epoch [11/30] Batch [2080/4715] Loss: 1.1547\n",
      "2025-05-30 15:41:47,118 - INFO - Epoch [11/30] Batch [2090/4715] Loss: 0.8909\n",
      "2025-05-30 15:41:48,774 - INFO - Epoch [11/30] Batch [2100/4715] Loss: 0.7355\n",
      "2025-05-30 15:41:50,337 - INFO - Epoch [11/30] Batch [2110/4715] Loss: 0.4778\n",
      "2025-05-30 15:41:51,875 - INFO - Epoch [11/30] Batch [2120/4715] Loss: 0.8773\n",
      "2025-05-30 15:41:53,419 - INFO - Epoch [11/30] Batch [2130/4715] Loss: 0.7105\n",
      "2025-05-30 15:41:54,934 - INFO - Epoch [11/30] Batch [2140/4715] Loss: 0.9432\n",
      "2025-05-30 15:41:56,604 - INFO - Epoch [11/30] Batch [2150/4715] Loss: 0.6033\n",
      "2025-05-30 15:41:58,325 - INFO - Epoch [11/30] Batch [2160/4715] Loss: 0.8174\n",
      "2025-05-30 15:41:59,925 - INFO - Epoch [11/30] Batch [2170/4715] Loss: 1.0910\n",
      "2025-05-30 15:42:01,626 - INFO - Epoch [11/30] Batch [2180/4715] Loss: 0.7682\n",
      "2025-05-30 15:42:03,132 - INFO - Epoch [11/30] Batch [2190/4715] Loss: 0.9279\n",
      "2025-05-30 15:42:04,683 - INFO - Epoch [11/30] Batch [2200/4715] Loss: 0.7669\n",
      "2025-05-30 15:42:06,209 - INFO - Epoch [11/30] Batch [2210/4715] Loss: 0.6758\n",
      "2025-05-30 15:42:07,746 - INFO - Epoch [11/30] Batch [2220/4715] Loss: 0.8324\n",
      "2025-05-30 15:42:09,387 - INFO - Epoch [11/30] Batch [2230/4715] Loss: 1.4012\n",
      "2025-05-30 15:42:10,977 - INFO - Epoch [11/30] Batch [2240/4715] Loss: 0.8051\n",
      "2025-05-30 15:42:12,650 - INFO - Epoch [11/30] Batch [2250/4715] Loss: 0.7517\n",
      "2025-05-30 15:42:14,253 - INFO - Epoch [11/30] Batch [2260/4715] Loss: 0.7706\n",
      "2025-05-30 15:42:15,695 - INFO - Epoch [11/30] Batch [2270/4715] Loss: 0.7328\n",
      "2025-05-30 15:42:17,270 - INFO - Epoch [11/30] Batch [2280/4715] Loss: 0.8710\n",
      "2025-05-30 15:42:18,780 - INFO - Epoch [11/30] Batch [2290/4715] Loss: 0.5737\n",
      "2025-05-30 15:42:20,357 - INFO - Epoch [11/30] Batch [2300/4715] Loss: 0.8978\n",
      "2025-05-30 15:42:21,908 - INFO - Epoch [11/30] Batch [2310/4715] Loss: 0.8569\n",
      "2025-05-30 15:42:23,465 - INFO - Epoch [11/30] Batch [2320/4715] Loss: 0.7167\n",
      "2025-05-30 15:42:25,072 - INFO - Epoch [11/30] Batch [2330/4715] Loss: 0.9177\n",
      "2025-05-30 15:42:26,725 - INFO - Epoch [11/30] Batch [2340/4715] Loss: 0.8388\n",
      "2025-05-30 15:42:28,308 - INFO - Epoch [11/30] Batch [2350/4715] Loss: 0.9650\n",
      "2025-05-30 15:42:29,847 - INFO - Epoch [11/30] Batch [2360/4715] Loss: 1.0131\n",
      "2025-05-30 15:42:31,385 - INFO - Epoch [11/30] Batch [2370/4715] Loss: 1.0217\n",
      "2025-05-30 15:42:33,007 - INFO - Epoch [11/30] Batch [2380/4715] Loss: 0.7222\n",
      "2025-05-30 15:42:34,546 - INFO - Epoch [11/30] Batch [2390/4715] Loss: 0.9147\n",
      "2025-05-30 15:42:36,061 - INFO - Epoch [11/30] Batch [2400/4715] Loss: 0.7719\n",
      "2025-05-30 15:42:37,649 - INFO - Epoch [11/30] Batch [2410/4715] Loss: 0.9763\n",
      "2025-05-30 15:42:39,170 - INFO - Epoch [11/30] Batch [2420/4715] Loss: 0.8694\n",
      "2025-05-30 15:42:40,753 - INFO - Epoch [11/30] Batch [2430/4715] Loss: 0.7630\n",
      "2025-05-30 15:42:42,312 - INFO - Epoch [11/30] Batch [2440/4715] Loss: 0.6465\n",
      "2025-05-30 15:42:43,903 - INFO - Epoch [11/30] Batch [2450/4715] Loss: 0.7877\n",
      "2025-05-30 15:42:45,522 - INFO - Epoch [11/30] Batch [2460/4715] Loss: 0.5823\n",
      "2025-05-30 15:42:47,017 - INFO - Epoch [11/30] Batch [2470/4715] Loss: 0.8449\n",
      "2025-05-30 15:42:48,635 - INFO - Epoch [11/30] Batch [2480/4715] Loss: 0.8354\n",
      "2025-05-30 15:42:50,190 - INFO - Epoch [11/30] Batch [2490/4715] Loss: 0.6825\n",
      "2025-05-30 15:42:51,729 - INFO - Epoch [11/30] Batch [2500/4715] Loss: 0.7469\n",
      "2025-05-30 15:42:53,288 - INFO - Epoch [11/30] Batch [2510/4715] Loss: 0.6754\n",
      "2025-05-30 15:42:54,831 - INFO - Epoch [11/30] Batch [2520/4715] Loss: 0.9071\n",
      "2025-05-30 15:42:56,333 - INFO - Epoch [11/30] Batch [2530/4715] Loss: 0.8388\n",
      "2025-05-30 15:42:57,918 - INFO - Epoch [11/30] Batch [2540/4715] Loss: 0.7333\n",
      "2025-05-30 15:42:59,491 - INFO - Epoch [11/30] Batch [2550/4715] Loss: 0.8301\n",
      "2025-05-30 15:43:01,166 - INFO - Epoch [11/30] Batch [2560/4715] Loss: 0.8994\n",
      "2025-05-30 15:43:02,690 - INFO - Epoch [11/30] Batch [2570/4715] Loss: 0.7961\n",
      "2025-05-30 15:43:04,203 - INFO - Epoch [11/30] Batch [2580/4715] Loss: 0.8364\n",
      "2025-05-30 15:43:05,832 - INFO - Epoch [11/30] Batch [2590/4715] Loss: 0.6686\n",
      "2025-05-30 15:43:07,432 - INFO - Epoch [11/30] Batch [2600/4715] Loss: 0.5934\n",
      "2025-05-30 15:43:08,922 - INFO - Epoch [11/30] Batch [2610/4715] Loss: 0.7081\n",
      "2025-05-30 15:43:10,463 - INFO - Epoch [11/30] Batch [2620/4715] Loss: 0.7680\n",
      "2025-05-30 15:43:12,000 - INFO - Epoch [11/30] Batch [2630/4715] Loss: 0.6905\n",
      "2025-05-30 15:43:13,616 - INFO - Epoch [11/30] Batch [2640/4715] Loss: 0.8519\n",
      "2025-05-30 15:43:15,191 - INFO - Epoch [11/30] Batch [2650/4715] Loss: 1.1421\n",
      "2025-05-30 15:43:16,726 - INFO - Epoch [11/30] Batch [2660/4715] Loss: 1.1182\n",
      "2025-05-30 15:43:18,320 - INFO - Epoch [11/30] Batch [2670/4715] Loss: 0.8981\n",
      "2025-05-30 15:43:19,925 - INFO - Epoch [11/30] Batch [2680/4715] Loss: 0.9047\n",
      "2025-05-30 15:43:21,488 - INFO - Epoch [11/30] Batch [2690/4715] Loss: 0.7850\n",
      "2025-05-30 15:43:23,028 - INFO - Epoch [11/30] Batch [2700/4715] Loss: 1.1247\n",
      "2025-05-30 15:43:24,532 - INFO - Epoch [11/30] Batch [2710/4715] Loss: 0.6911\n",
      "2025-05-30 15:43:26,169 - INFO - Epoch [11/30] Batch [2720/4715] Loss: 0.7165\n",
      "2025-05-30 15:43:27,929 - INFO - Epoch [11/30] Batch [2730/4715] Loss: 0.8757\n",
      "2025-05-30 15:43:29,527 - INFO - Epoch [11/30] Batch [2740/4715] Loss: 0.9010\n",
      "2025-05-30 15:43:31,190 - INFO - Epoch [11/30] Batch [2750/4715] Loss: 0.6541\n",
      "2025-05-30 15:43:32,714 - INFO - Epoch [11/30] Batch [2760/4715] Loss: 0.7702\n",
      "2025-05-30 15:43:34,243 - INFO - Epoch [11/30] Batch [2770/4715] Loss: 0.7815\n",
      "2025-05-30 15:43:35,790 - INFO - Epoch [11/30] Batch [2780/4715] Loss: 0.7215\n",
      "2025-05-30 15:43:37,272 - INFO - Epoch [11/30] Batch [2790/4715] Loss: 0.7392\n",
      "2025-05-30 15:43:38,803 - INFO - Epoch [11/30] Batch [2800/4715] Loss: 0.7084\n",
      "2025-05-30 15:43:40,272 - INFO - Epoch [11/30] Batch [2810/4715] Loss: 0.8198\n",
      "2025-05-30 15:43:41,825 - INFO - Epoch [11/30] Batch [2820/4715] Loss: 0.7851\n",
      "2025-05-30 15:43:43,646 - INFO - Epoch [11/30] Batch [2830/4715] Loss: 0.9763\n",
      "2025-05-30 15:43:45,210 - INFO - Epoch [11/30] Batch [2840/4715] Loss: 0.9040\n",
      "2025-05-30 15:43:46,779 - INFO - Epoch [11/30] Batch [2850/4715] Loss: 0.7415\n",
      "2025-05-30 15:43:48,288 - INFO - Epoch [11/30] Batch [2860/4715] Loss: 1.0244\n",
      "2025-05-30 15:43:49,819 - INFO - Epoch [11/30] Batch [2870/4715] Loss: 0.8880\n",
      "2025-05-30 15:43:51,381 - INFO - Epoch [11/30] Batch [2880/4715] Loss: 0.8112\n",
      "2025-05-30 15:43:52,955 - INFO - Epoch [11/30] Batch [2890/4715] Loss: 0.8811\n",
      "2025-05-30 15:43:54,554 - INFO - Epoch [11/30] Batch [2900/4715] Loss: 0.9882\n",
      "2025-05-30 15:43:56,165 - INFO - Epoch [11/30] Batch [2910/4715] Loss: 0.9884\n",
      "2025-05-30 15:43:57,670 - INFO - Epoch [11/30] Batch [2920/4715] Loss: 0.6539\n",
      "2025-05-30 15:43:59,255 - INFO - Epoch [11/30] Batch [2930/4715] Loss: 0.6689\n",
      "2025-05-30 15:44:00,853 - INFO - Epoch [11/30] Batch [2940/4715] Loss: 0.8817\n",
      "2025-05-30 15:44:02,469 - INFO - Epoch [11/30] Batch [2950/4715] Loss: 0.7633\n",
      "2025-05-30 15:44:04,068 - INFO - Epoch [11/30] Batch [2960/4715] Loss: 0.7957\n",
      "2025-05-30 15:44:05,609 - INFO - Epoch [11/30] Batch [2970/4715] Loss: 0.9877\n",
      "2025-05-30 15:44:07,181 - INFO - Epoch [11/30] Batch [2980/4715] Loss: 0.7025\n",
      "2025-05-30 15:44:08,743 - INFO - Epoch [11/30] Batch [2990/4715] Loss: 0.7568\n",
      "2025-05-30 15:44:10,351 - INFO - Epoch [11/30] Batch [3000/4715] Loss: 1.0719\n",
      "2025-05-30 15:44:11,920 - INFO - Epoch [11/30] Batch [3010/4715] Loss: 0.8487\n",
      "2025-05-30 15:44:13,484 - INFO - Epoch [11/30] Batch [3020/4715] Loss: 0.7001\n",
      "2025-05-30 15:44:15,072 - INFO - Epoch [11/30] Batch [3030/4715] Loss: 1.0815\n",
      "2025-05-30 15:44:16,672 - INFO - Epoch [11/30] Batch [3040/4715] Loss: 0.6943\n",
      "2025-05-30 15:44:18,280 - INFO - Epoch [11/30] Batch [3050/4715] Loss: 0.6160\n",
      "2025-05-30 15:44:19,884 - INFO - Epoch [11/30] Batch [3060/4715] Loss: 0.8951\n",
      "2025-05-30 15:44:21,477 - INFO - Epoch [11/30] Batch [3070/4715] Loss: 0.6303\n",
      "2025-05-30 15:44:23,160 - INFO - Epoch [11/30] Batch [3080/4715] Loss: 0.9329\n",
      "2025-05-30 15:44:24,724 - INFO - Epoch [11/30] Batch [3090/4715] Loss: 0.5533\n",
      "2025-05-30 15:44:26,364 - INFO - Epoch [11/30] Batch [3100/4715] Loss: 0.6650\n",
      "2025-05-30 15:44:27,940 - INFO - Epoch [11/30] Batch [3110/4715] Loss: 0.8470\n",
      "2025-05-30 15:44:29,497 - INFO - Epoch [11/30] Batch [3120/4715] Loss: 0.8063\n",
      "2025-05-30 15:44:31,087 - INFO - Epoch [11/30] Batch [3130/4715] Loss: 0.8449\n",
      "2025-05-30 15:44:32,754 - INFO - Epoch [11/30] Batch [3140/4715] Loss: 0.9000\n",
      "2025-05-30 15:44:34,316 - INFO - Epoch [11/30] Batch [3150/4715] Loss: 0.9082\n",
      "2025-05-30 15:44:35,848 - INFO - Epoch [11/30] Batch [3160/4715] Loss: 0.8178\n",
      "2025-05-30 15:44:37,477 - INFO - Epoch [11/30] Batch [3170/4715] Loss: 0.7523\n",
      "2025-05-30 15:44:39,009 - INFO - Epoch [11/30] Batch [3180/4715] Loss: 0.7304\n",
      "2025-05-30 15:44:40,500 - INFO - Epoch [11/30] Batch [3190/4715] Loss: 0.8207\n",
      "2025-05-30 15:44:42,020 - INFO - Epoch [11/30] Batch [3200/4715] Loss: 0.9644\n",
      "2025-05-30 15:44:43,587 - INFO - Epoch [11/30] Batch [3210/4715] Loss: 0.8074\n",
      "2025-05-30 15:44:45,184 - INFO - Epoch [11/30] Batch [3220/4715] Loss: 0.8651\n",
      "2025-05-30 15:44:46,764 - INFO - Epoch [11/30] Batch [3230/4715] Loss: 0.9299\n",
      "2025-05-30 15:44:48,291 - INFO - Epoch [11/30] Batch [3240/4715] Loss: 1.0823\n",
      "2025-05-30 15:44:49,830 - INFO - Epoch [11/30] Batch [3250/4715] Loss: 1.0483\n",
      "2025-05-30 15:44:51,521 - INFO - Epoch [11/30] Batch [3260/4715] Loss: 0.9396\n",
      "2025-05-30 15:44:53,099 - INFO - Epoch [11/30] Batch [3270/4715] Loss: 0.7627\n",
      "2025-05-30 15:44:54,572 - INFO - Epoch [11/30] Batch [3280/4715] Loss: 0.8223\n",
      "2025-05-30 15:44:56,117 - INFO - Epoch [11/30] Batch [3290/4715] Loss: 0.9407\n",
      "2025-05-30 15:44:57,764 - INFO - Epoch [11/30] Batch [3300/4715] Loss: 1.1347\n",
      "2025-05-30 15:44:59,411 - INFO - Epoch [11/30] Batch [3310/4715] Loss: 0.9955\n",
      "2025-05-30 15:45:01,045 - INFO - Epoch [11/30] Batch [3320/4715] Loss: 0.8238\n",
      "2025-05-30 15:45:02,663 - INFO - Epoch [11/30] Batch [3330/4715] Loss: 0.8904\n",
      "2025-05-30 15:45:04,172 - INFO - Epoch [11/30] Batch [3340/4715] Loss: 1.0021\n",
      "2025-05-30 15:45:05,742 - INFO - Epoch [11/30] Batch [3350/4715] Loss: 0.7330\n",
      "2025-05-30 15:45:07,370 - INFO - Epoch [11/30] Batch [3360/4715] Loss: 0.9982\n",
      "2025-05-30 15:45:09,012 - INFO - Epoch [11/30] Batch [3370/4715] Loss: 0.8528\n",
      "2025-05-30 15:45:10,535 - INFO - Epoch [11/30] Batch [3380/4715] Loss: 0.8842\n",
      "2025-05-30 15:45:12,059 - INFO - Epoch [11/30] Batch [3390/4715] Loss: 0.8813\n",
      "2025-05-30 15:45:13,606 - INFO - Epoch [11/30] Batch [3400/4715] Loss: 0.9773\n",
      "2025-05-30 15:45:15,210 - INFO - Epoch [11/30] Batch [3410/4715] Loss: 0.7568\n",
      "2025-05-30 15:45:16,788 - INFO - Epoch [11/30] Batch [3420/4715] Loss: 0.8208\n",
      "2025-05-30 15:45:18,364 - INFO - Epoch [11/30] Batch [3430/4715] Loss: 0.6893\n",
      "2025-05-30 15:45:19,930 - INFO - Epoch [11/30] Batch [3440/4715] Loss: 0.9220\n",
      "2025-05-30 15:45:21,499 - INFO - Epoch [11/30] Batch [3450/4715] Loss: 0.8534\n",
      "2025-05-30 15:45:23,041 - INFO - Epoch [11/30] Batch [3460/4715] Loss: 0.8926\n",
      "2025-05-30 15:45:24,643 - INFO - Epoch [11/30] Batch [3470/4715] Loss: 0.6956\n",
      "2025-05-30 15:45:26,189 - INFO - Epoch [11/30] Batch [3480/4715] Loss: 0.7339\n",
      "2025-05-30 15:45:27,714 - INFO - Epoch [11/30] Batch [3490/4715] Loss: 0.7200\n",
      "2025-05-30 15:45:29,296 - INFO - Epoch [11/30] Batch [3500/4715] Loss: 0.7598\n",
      "2025-05-30 15:45:30,852 - INFO - Epoch [11/30] Batch [3510/4715] Loss: 0.6579\n",
      "2025-05-30 15:45:32,481 - INFO - Epoch [11/30] Batch [3520/4715] Loss: 0.5965\n",
      "2025-05-30 15:45:34,021 - INFO - Epoch [11/30] Batch [3530/4715] Loss: 0.8393\n",
      "2025-05-30 15:45:35,748 - INFO - Epoch [11/30] Batch [3540/4715] Loss: 0.7295\n",
      "2025-05-30 15:45:37,269 - INFO - Epoch [11/30] Batch [3550/4715] Loss: 1.0712\n",
      "2025-05-30 15:45:38,916 - INFO - Epoch [11/30] Batch [3560/4715] Loss: 0.8166\n",
      "2025-05-30 15:45:40,470 - INFO - Epoch [11/30] Batch [3570/4715] Loss: 0.8767\n",
      "2025-05-30 15:45:41,969 - INFO - Epoch [11/30] Batch [3580/4715] Loss: 0.8621\n",
      "2025-05-30 15:45:43,486 - INFO - Epoch [11/30] Batch [3590/4715] Loss: 0.7256\n",
      "2025-05-30 15:45:45,100 - INFO - Epoch [11/30] Batch [3600/4715] Loss: 0.9242\n",
      "2025-05-30 15:45:46,668 - INFO - Epoch [11/30] Batch [3610/4715] Loss: 0.7281\n",
      "2025-05-30 15:45:48,239 - INFO - Epoch [11/30] Batch [3620/4715] Loss: 0.7909\n",
      "2025-05-30 15:45:49,770 - INFO - Epoch [11/30] Batch [3630/4715] Loss: 1.0940\n",
      "2025-05-30 15:45:51,418 - INFO - Epoch [11/30] Batch [3640/4715] Loss: 0.6179\n",
      "2025-05-30 15:45:53,009 - INFO - Epoch [11/30] Batch [3650/4715] Loss: 0.6660\n",
      "2025-05-30 15:45:54,544 - INFO - Epoch [11/30] Batch [3660/4715] Loss: 0.8221\n",
      "2025-05-30 15:45:56,153 - INFO - Epoch [11/30] Batch [3670/4715] Loss: 0.8829\n",
      "2025-05-30 15:45:57,671 - INFO - Epoch [11/30] Batch [3680/4715] Loss: 1.1204\n",
      "2025-05-30 15:45:59,354 - INFO - Epoch [11/30] Batch [3690/4715] Loss: 0.7633\n",
      "2025-05-30 15:46:00,924 - INFO - Epoch [11/30] Batch [3700/4715] Loss: 0.9572\n",
      "2025-05-30 15:46:02,526 - INFO - Epoch [11/30] Batch [3710/4715] Loss: 0.7104\n",
      "2025-05-30 15:46:04,155 - INFO - Epoch [11/30] Batch [3720/4715] Loss: 0.7829\n",
      "2025-05-30 15:46:05,683 - INFO - Epoch [11/30] Batch [3730/4715] Loss: 0.8426\n",
      "2025-05-30 15:46:07,260 - INFO - Epoch [11/30] Batch [3740/4715] Loss: 0.7847\n",
      "2025-05-30 15:46:08,797 - INFO - Epoch [11/30] Batch [3750/4715] Loss: 0.8326\n",
      "2025-05-30 15:46:10,431 - INFO - Epoch [11/30] Batch [3760/4715] Loss: 0.8129\n",
      "2025-05-30 15:46:11,961 - INFO - Epoch [11/30] Batch [3770/4715] Loss: 0.5933\n",
      "2025-05-30 15:46:13,498 - INFO - Epoch [11/30] Batch [3780/4715] Loss: 0.5714\n",
      "2025-05-30 15:46:15,109 - INFO - Epoch [11/30] Batch [3790/4715] Loss: 0.8539\n",
      "2025-05-30 15:46:16,681 - INFO - Epoch [11/30] Batch [3800/4715] Loss: 0.8180\n",
      "2025-05-30 15:46:18,281 - INFO - Epoch [11/30] Batch [3810/4715] Loss: 0.7102\n",
      "2025-05-30 15:46:19,859 - INFO - Epoch [11/30] Batch [3820/4715] Loss: 0.7882\n",
      "2025-05-30 15:46:21,430 - INFO - Epoch [11/30] Batch [3830/4715] Loss: 0.8610\n",
      "2025-05-30 15:46:22,959 - INFO - Epoch [11/30] Batch [3840/4715] Loss: 0.7710\n",
      "2025-05-30 15:46:24,596 - INFO - Epoch [11/30] Batch [3850/4715] Loss: 0.9180\n",
      "2025-05-30 15:46:26,184 - INFO - Epoch [11/30] Batch [3860/4715] Loss: 0.9898\n",
      "2025-05-30 15:46:27,767 - INFO - Epoch [11/30] Batch [3870/4715] Loss: 0.8708\n",
      "2025-05-30 15:46:29,316 - INFO - Epoch [11/30] Batch [3880/4715] Loss: 0.7584\n",
      "2025-05-30 15:46:30,890 - INFO - Epoch [11/30] Batch [3890/4715] Loss: 0.7954\n",
      "2025-05-30 15:46:32,479 - INFO - Epoch [11/30] Batch [3900/4715] Loss: 0.7876\n",
      "2025-05-30 15:46:33,998 - INFO - Epoch [11/30] Batch [3910/4715] Loss: 0.6873\n",
      "2025-05-30 15:46:35,534 - INFO - Epoch [11/30] Batch [3920/4715] Loss: 0.8188\n",
      "2025-05-30 15:46:37,070 - INFO - Epoch [11/30] Batch [3930/4715] Loss: 0.8511\n",
      "2025-05-30 15:46:38,694 - INFO - Epoch [11/30] Batch [3940/4715] Loss: 0.5456\n",
      "2025-05-30 15:46:40,256 - INFO - Epoch [11/30] Batch [3950/4715] Loss: 0.5387\n",
      "2025-05-30 15:46:41,885 - INFO - Epoch [11/30] Batch [3960/4715] Loss: 0.5151\n",
      "2025-05-30 15:46:43,372 - INFO - Epoch [11/30] Batch [3970/4715] Loss: 0.8499\n",
      "2025-05-30 15:46:44,950 - INFO - Epoch [11/30] Batch [3980/4715] Loss: 0.8302\n",
      "2025-05-30 15:46:46,609 - INFO - Epoch [11/30] Batch [3990/4715] Loss: 0.7307\n",
      "2025-05-30 15:46:48,239 - INFO - Epoch [11/30] Batch [4000/4715] Loss: 0.8865\n",
      "2025-05-30 15:46:49,899 - INFO - Epoch [11/30] Batch [4010/4715] Loss: 0.8422\n",
      "2025-05-30 15:46:51,562 - INFO - Epoch [11/30] Batch [4020/4715] Loss: 0.8726\n",
      "2025-05-30 15:46:53,144 - INFO - Epoch [11/30] Batch [4030/4715] Loss: 0.7531\n",
      "2025-05-30 15:46:54,675 - INFO - Epoch [11/30] Batch [4040/4715] Loss: 0.8666\n",
      "2025-05-30 15:46:56,285 - INFO - Epoch [11/30] Batch [4050/4715] Loss: 1.1351\n",
      "2025-05-30 15:46:57,840 - INFO - Epoch [11/30] Batch [4060/4715] Loss: 0.8832\n",
      "2025-05-30 15:46:59,321 - INFO - Epoch [11/30] Batch [4070/4715] Loss: 0.6877\n",
      "2025-05-30 15:47:00,952 - INFO - Epoch [11/30] Batch [4080/4715] Loss: 0.7500\n",
      "2025-05-30 15:47:02,583 - INFO - Epoch [11/30] Batch [4090/4715] Loss: 0.8574\n",
      "2025-05-30 15:47:04,205 - INFO - Epoch [11/30] Batch [4100/4715] Loss: 0.8651\n",
      "2025-05-30 15:47:05,758 - INFO - Epoch [11/30] Batch [4110/4715] Loss: 0.6968\n",
      "2025-05-30 15:47:07,332 - INFO - Epoch [11/30] Batch [4120/4715] Loss: 0.8233\n",
      "2025-05-30 15:47:08,940 - INFO - Epoch [11/30] Batch [4130/4715] Loss: 0.7586\n",
      "2025-05-30 15:47:10,549 - INFO - Epoch [11/30] Batch [4140/4715] Loss: 0.7904\n",
      "2025-05-30 15:47:12,106 - INFO - Epoch [11/30] Batch [4150/4715] Loss: 0.8271\n",
      "2025-05-30 15:47:13,664 - INFO - Epoch [11/30] Batch [4160/4715] Loss: 1.0668\n",
      "2025-05-30 15:47:15,301 - INFO - Epoch [11/30] Batch [4170/4715] Loss: 0.8880\n",
      "2025-05-30 15:47:17,028 - INFO - Epoch [11/30] Batch [4180/4715] Loss: 1.0850\n",
      "2025-05-30 15:47:18,689 - INFO - Epoch [11/30] Batch [4190/4715] Loss: 0.8271\n",
      "2025-05-30 15:47:20,419 - INFO - Epoch [11/30] Batch [4200/4715] Loss: 0.8126\n",
      "2025-05-30 15:47:21,983 - INFO - Epoch [11/30] Batch [4210/4715] Loss: 0.6934\n",
      "2025-05-30 15:47:23,553 - INFO - Epoch [11/30] Batch [4220/4715] Loss: 0.7725\n",
      "2025-05-30 15:47:25,269 - INFO - Epoch [11/30] Batch [4230/4715] Loss: 0.8300\n",
      "2025-05-30 15:47:26,979 - INFO - Epoch [11/30] Batch [4240/4715] Loss: 0.6337\n",
      "2025-05-30 15:47:28,525 - INFO - Epoch [11/30] Batch [4250/4715] Loss: 0.6865\n",
      "2025-05-30 15:47:30,210 - INFO - Epoch [11/30] Batch [4260/4715] Loss: 0.7618\n",
      "2025-05-30 15:47:31,807 - INFO - Epoch [11/30] Batch [4270/4715] Loss: 0.8965\n",
      "2025-05-30 15:47:33,422 - INFO - Epoch [11/30] Batch [4280/4715] Loss: 0.8318\n",
      "2025-05-30 15:47:35,015 - INFO - Epoch [11/30] Batch [4290/4715] Loss: 0.8026\n",
      "2025-05-30 15:47:36,584 - INFO - Epoch [11/30] Batch [4300/4715] Loss: 0.8017\n",
      "2025-05-30 15:47:38,089 - INFO - Epoch [11/30] Batch [4310/4715] Loss: 0.8601\n",
      "2025-05-30 15:47:39,663 - INFO - Epoch [11/30] Batch [4320/4715] Loss: 0.8794\n",
      "2025-05-30 15:47:41,531 - INFO - Epoch [11/30] Batch [4330/4715] Loss: 0.9542\n",
      "2025-05-30 15:47:43,047 - INFO - Epoch [11/30] Batch [4340/4715] Loss: 0.6625\n",
      "2025-05-30 15:47:44,632 - INFO - Epoch [11/30] Batch [4350/4715] Loss: 0.8583\n",
      "2025-05-30 15:47:46,179 - INFO - Epoch [11/30] Batch [4360/4715] Loss: 0.8219\n",
      "2025-05-30 15:47:47,760 - INFO - Epoch [11/30] Batch [4370/4715] Loss: 0.9016\n",
      "2025-05-30 15:47:49,294 - INFO - Epoch [11/30] Batch [4380/4715] Loss: 0.9191\n",
      "2025-05-30 15:47:50,890 - INFO - Epoch [11/30] Batch [4390/4715] Loss: 0.6367\n",
      "2025-05-30 15:47:52,474 - INFO - Epoch [11/30] Batch [4400/4715] Loss: 0.6545\n",
      "2025-05-30 15:47:54,084 - INFO - Epoch [11/30] Batch [4410/4715] Loss: 0.7418\n",
      "2025-05-30 15:47:55,601 - INFO - Epoch [11/30] Batch [4420/4715] Loss: 0.9550\n",
      "2025-05-30 15:47:57,156 - INFO - Epoch [11/30] Batch [4430/4715] Loss: 0.6239\n",
      "2025-05-30 15:47:58,671 - INFO - Epoch [11/30] Batch [4440/4715] Loss: 0.9003\n",
      "2025-05-30 15:48:00,205 - INFO - Epoch [11/30] Batch [4450/4715] Loss: 0.9544\n",
      "2025-05-30 15:48:01,775 - INFO - Epoch [11/30] Batch [4460/4715] Loss: 0.6990\n",
      "2025-05-30 15:48:03,314 - INFO - Epoch [11/30] Batch [4470/4715] Loss: 0.7848\n",
      "2025-05-30 15:48:04,901 - INFO - Epoch [11/30] Batch [4480/4715] Loss: 0.8641\n",
      "2025-05-30 15:48:06,536 - INFO - Epoch [11/30] Batch [4490/4715] Loss: 0.8756\n",
      "2025-05-30 15:48:08,068 - INFO - Epoch [11/30] Batch [4500/4715] Loss: 0.9274\n",
      "2025-05-30 15:48:09,660 - INFO - Epoch [11/30] Batch [4510/4715] Loss: 0.8198\n",
      "2025-05-30 15:48:11,194 - INFO - Epoch [11/30] Batch [4520/4715] Loss: 0.6983\n",
      "2025-05-30 15:48:12,783 - INFO - Epoch [11/30] Batch [4530/4715] Loss: 0.6738\n",
      "2025-05-30 15:48:14,456 - INFO - Epoch [11/30] Batch [4540/4715] Loss: 0.8748\n",
      "2025-05-30 15:48:16,036 - INFO - Epoch [11/30] Batch [4550/4715] Loss: 1.0015\n",
      "2025-05-30 15:48:17,637 - INFO - Epoch [11/30] Batch [4560/4715] Loss: 0.7506\n",
      "2025-05-30 15:48:19,154 - INFO - Epoch [11/30] Batch [4570/4715] Loss: 0.8724\n",
      "2025-05-30 15:48:20,682 - INFO - Epoch [11/30] Batch [4580/4715] Loss: 0.7567\n",
      "2025-05-30 15:48:22,213 - INFO - Epoch [11/30] Batch [4590/4715] Loss: 0.7465\n",
      "2025-05-30 15:48:23,786 - INFO - Epoch [11/30] Batch [4600/4715] Loss: 0.8698\n",
      "2025-05-30 15:48:25,366 - INFO - Epoch [11/30] Batch [4610/4715] Loss: 0.8440\n",
      "2025-05-30 15:48:26,930 - INFO - Epoch [11/30] Batch [4620/4715] Loss: 0.7536\n",
      "2025-05-30 15:48:28,549 - INFO - Epoch [11/30] Batch [4630/4715] Loss: 0.7807\n",
      "2025-05-30 15:48:30,238 - INFO - Epoch [11/30] Batch [4640/4715] Loss: 0.8648\n",
      "2025-05-30 15:48:31,803 - INFO - Epoch [11/30] Batch [4650/4715] Loss: 0.5076\n",
      "2025-05-30 15:48:33,412 - INFO - Epoch [11/30] Batch [4660/4715] Loss: 0.7515\n",
      "2025-05-30 15:48:34,905 - INFO - Epoch [11/30] Batch [4670/4715] Loss: 0.6103\n",
      "2025-05-30 15:48:36,598 - INFO - Epoch [11/30] Batch [4680/4715] Loss: 0.9878\n",
      "2025-05-30 15:48:38,159 - INFO - Epoch [11/30] Batch [4690/4715] Loss: 0.6915\n",
      "2025-05-30 15:48:39,712 - INFO - Epoch [11/30] Batch [4700/4715] Loss: 0.9257\n",
      "2025-05-30 15:48:41,277 - INFO - Epoch [11/30] Batch [4710/4715] Loss: 0.8783\n",
      "2025-05-30 15:49:20,403 - INFO - \n",
      "Epoch [11/30] Time: 782.65s\n",
      "2025-05-30 15:49:20,404 - INFO - Train Loss: 0.8186, Valid Loss: 0.8269\n",
      "2025-05-30 15:49:20,405 - INFO - Valid AUC (macro): 0.7251, F1 (macro): 0.5549\n",
      "2025-05-30 15:49:20,943 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 15:49:20,944 - INFO - Saved checkpoint at epoch 11\n",
      "2025-05-30 15:49:21,175 - INFO - Epoch [12/30] Batch [0/4715] Loss: 0.5447\n",
      "2025-05-30 15:49:22,988 - INFO - Epoch [12/30] Batch [10/4715] Loss: 1.0017\n",
      "2025-05-30 15:49:24,597 - INFO - Epoch [12/30] Batch [20/4715] Loss: 0.7819\n",
      "2025-05-30 15:49:26,107 - INFO - Epoch [12/30] Batch [30/4715] Loss: 1.0271\n",
      "2025-05-30 15:49:27,693 - INFO - Epoch [12/30] Batch [40/4715] Loss: 0.8820\n",
      "2025-05-30 15:49:29,200 - INFO - Epoch [12/30] Batch [50/4715] Loss: 0.7375\n",
      "2025-05-30 15:49:30,849 - INFO - Epoch [12/30] Batch [60/4715] Loss: 0.8139\n",
      "2025-05-30 15:49:32,550 - INFO - Epoch [12/30] Batch [70/4715] Loss: 0.7252\n",
      "2025-05-30 15:49:34,206 - INFO - Epoch [12/30] Batch [80/4715] Loss: 0.7710\n",
      "2025-05-30 15:49:35,758 - INFO - Epoch [12/30] Batch [90/4715] Loss: 0.8043\n",
      "2025-05-30 15:49:37,274 - INFO - Epoch [12/30] Batch [100/4715] Loss: 0.7051\n",
      "2025-05-30 15:49:38,776 - INFO - Epoch [12/30] Batch [110/4715] Loss: 0.7661\n",
      "2025-05-30 15:49:40,277 - INFO - Epoch [12/30] Batch [120/4715] Loss: 0.6393\n",
      "2025-05-30 15:49:41,874 - INFO - Epoch [12/30] Batch [130/4715] Loss: 0.9561\n",
      "2025-05-30 15:49:43,486 - INFO - Epoch [12/30] Batch [140/4715] Loss: 0.8708\n",
      "2025-05-30 15:49:45,019 - INFO - Epoch [12/30] Batch [150/4715] Loss: 0.9355\n",
      "2025-05-30 15:49:46,571 - INFO - Epoch [12/30] Batch [160/4715] Loss: 0.9088\n",
      "2025-05-30 15:49:48,089 - INFO - Epoch [12/30] Batch [170/4715] Loss: 0.8227\n",
      "2025-05-30 15:49:49,782 - INFO - Epoch [12/30] Batch [180/4715] Loss: 0.6855\n",
      "2025-05-30 15:49:51,300 - INFO - Epoch [12/30] Batch [190/4715] Loss: 0.8249\n",
      "2025-05-30 15:49:52,971 - INFO - Epoch [12/30] Batch [200/4715] Loss: 0.9623\n",
      "2025-05-30 15:49:54,572 - INFO - Epoch [12/30] Batch [210/4715] Loss: 0.8933\n",
      "2025-05-30 15:49:56,130 - INFO - Epoch [12/30] Batch [220/4715] Loss: 0.7335\n",
      "2025-05-30 15:49:57,713 - INFO - Epoch [12/30] Batch [230/4715] Loss: 0.7088\n",
      "2025-05-30 15:49:59,400 - INFO - Epoch [12/30] Batch [240/4715] Loss: 0.8098\n",
      "2025-05-30 15:50:01,029 - INFO - Epoch [12/30] Batch [250/4715] Loss: 0.6641\n",
      "2025-05-30 15:50:02,664 - INFO - Epoch [12/30] Batch [260/4715] Loss: 0.6911\n",
      "2025-05-30 15:50:04,193 - INFO - Epoch [12/30] Batch [270/4715] Loss: 1.2719\n",
      "2025-05-30 15:50:05,756 - INFO - Epoch [12/30] Batch [280/4715] Loss: 0.8092\n",
      "2025-05-30 15:50:07,315 - INFO - Epoch [12/30] Batch [290/4715] Loss: 0.9020\n",
      "2025-05-30 15:50:08,943 - INFO - Epoch [12/30] Batch [300/4715] Loss: 0.8620\n",
      "2025-05-30 15:50:10,471 - INFO - Epoch [12/30] Batch [310/4715] Loss: 0.8466\n",
      "2025-05-30 15:50:12,084 - INFO - Epoch [12/30] Batch [320/4715] Loss: 0.8895\n",
      "2025-05-30 15:50:13,690 - INFO - Epoch [12/30] Batch [330/4715] Loss: 1.0779\n",
      "2025-05-30 15:50:15,172 - INFO - Epoch [12/30] Batch [340/4715] Loss: 0.9538\n",
      "2025-05-30 15:50:16,696 - INFO - Epoch [12/30] Batch [350/4715] Loss: 0.6758\n",
      "2025-05-30 15:50:18,218 - INFO - Epoch [12/30] Batch [360/4715] Loss: 0.6368\n",
      "2025-05-30 15:50:19,778 - INFO - Epoch [12/30] Batch [370/4715] Loss: 0.6438\n",
      "2025-05-30 15:50:21,360 - INFO - Epoch [12/30] Batch [380/4715] Loss: 0.7463\n",
      "2025-05-30 15:50:22,907 - INFO - Epoch [12/30] Batch [390/4715] Loss: 0.6176\n",
      "2025-05-30 15:50:24,417 - INFO - Epoch [12/30] Batch [400/4715] Loss: 0.9768\n",
      "2025-05-30 15:50:25,961 - INFO - Epoch [12/30] Batch [410/4715] Loss: 0.7941\n",
      "2025-05-30 15:50:27,458 - INFO - Epoch [12/30] Batch [420/4715] Loss: 0.7842\n",
      "2025-05-30 15:50:28,982 - INFO - Epoch [12/30] Batch [430/4715] Loss: 0.6184\n",
      "2025-05-30 15:50:30,631 - INFO - Epoch [12/30] Batch [440/4715] Loss: 0.6702\n",
      "2025-05-30 15:50:32,279 - INFO - Epoch [12/30] Batch [450/4715] Loss: 0.5720\n",
      "2025-05-30 15:50:33,821 - INFO - Epoch [12/30] Batch [460/4715] Loss: 0.8026\n",
      "2025-05-30 15:50:35,380 - INFO - Epoch [12/30] Batch [470/4715] Loss: 0.7775\n",
      "2025-05-30 15:50:36,948 - INFO - Epoch [12/30] Batch [480/4715] Loss: 0.7393\n",
      "2025-05-30 15:50:38,553 - INFO - Epoch [12/30] Batch [490/4715] Loss: 0.8083\n",
      "2025-05-30 15:50:40,163 - INFO - Epoch [12/30] Batch [500/4715] Loss: 0.8991\n",
      "2025-05-30 15:50:41,819 - INFO - Epoch [12/30] Batch [510/4715] Loss: 1.0417\n",
      "2025-05-30 15:50:43,417 - INFO - Epoch [12/30] Batch [520/4715] Loss: 1.0098\n",
      "2025-05-30 15:50:45,048 - INFO - Epoch [12/30] Batch [530/4715] Loss: 0.9164\n",
      "2025-05-30 15:50:46,602 - INFO - Epoch [12/30] Batch [540/4715] Loss: 0.8508\n",
      "2025-05-30 15:50:48,202 - INFO - Epoch [12/30] Batch [550/4715] Loss: 0.7917\n",
      "2025-05-30 15:50:49,776 - INFO - Epoch [12/30] Batch [560/4715] Loss: 0.6961\n",
      "2025-05-30 15:50:51,320 - INFO - Epoch [12/30] Batch [570/4715] Loss: 0.7414\n",
      "2025-05-30 15:50:52,872 - INFO - Epoch [12/30] Batch [580/4715] Loss: 0.6523\n",
      "2025-05-30 15:50:54,360 - INFO - Epoch [12/30] Batch [590/4715] Loss: 0.8167\n",
      "2025-05-30 15:50:55,944 - INFO - Epoch [12/30] Batch [600/4715] Loss: 0.9710\n",
      "2025-05-30 15:50:57,437 - INFO - Epoch [12/30] Batch [610/4715] Loss: 0.9055\n",
      "2025-05-30 15:50:58,942 - INFO - Epoch [12/30] Batch [620/4715] Loss: 0.6201\n",
      "2025-05-30 15:51:00,536 - INFO - Epoch [12/30] Batch [630/4715] Loss: 1.0575\n",
      "2025-05-30 15:51:02,092 - INFO - Epoch [12/30] Batch [640/4715] Loss: 0.8285\n",
      "2025-05-30 15:51:03,713 - INFO - Epoch [12/30] Batch [650/4715] Loss: 0.8063\n",
      "2025-05-30 15:51:05,379 - INFO - Epoch [12/30] Batch [660/4715] Loss: 0.8978\n",
      "2025-05-30 15:51:07,137 - INFO - Epoch [12/30] Batch [670/4715] Loss: 0.7638\n",
      "2025-05-30 15:51:08,719 - INFO - Epoch [12/30] Batch [680/4715] Loss: 1.0690\n",
      "2025-05-30 15:51:10,247 - INFO - Epoch [12/30] Batch [690/4715] Loss: 0.7129\n",
      "2025-05-30 15:51:11,898 - INFO - Epoch [12/30] Batch [700/4715] Loss: 0.8575\n",
      "2025-05-30 15:51:13,503 - INFO - Epoch [12/30] Batch [710/4715] Loss: 0.5604\n",
      "2025-05-30 15:51:15,036 - INFO - Epoch [12/30] Batch [720/4715] Loss: 0.7978\n",
      "2025-05-30 15:51:16,626 - INFO - Epoch [12/30] Batch [730/4715] Loss: 0.7580\n",
      "2025-05-30 15:51:18,360 - INFO - Epoch [12/30] Batch [740/4715] Loss: 0.7729\n",
      "2025-05-30 15:51:19,955 - INFO - Epoch [12/30] Batch [750/4715] Loss: 0.6959\n",
      "2025-05-30 15:51:21,530 - INFO - Epoch [12/30] Batch [760/4715] Loss: 0.8326\n",
      "2025-05-30 15:51:23,110 - INFO - Epoch [12/30] Batch [770/4715] Loss: 0.7013\n",
      "2025-05-30 15:51:24,621 - INFO - Epoch [12/30] Batch [780/4715] Loss: 0.7067\n",
      "2025-05-30 15:51:26,210 - INFO - Epoch [12/30] Batch [790/4715] Loss: 0.5351\n",
      "2025-05-30 15:51:27,732 - INFO - Epoch [12/30] Batch [800/4715] Loss: 0.7546\n",
      "2025-05-30 15:51:29,309 - INFO - Epoch [12/30] Batch [810/4715] Loss: 0.7221\n",
      "2025-05-30 15:51:31,098 - INFO - Epoch [12/30] Batch [820/4715] Loss: 0.8196\n",
      "2025-05-30 15:51:32,633 - INFO - Epoch [12/30] Batch [830/4715] Loss: 0.8668\n",
      "2025-05-30 15:51:34,176 - INFO - Epoch [12/30] Batch [840/4715] Loss: 0.7926\n",
      "2025-05-30 15:51:35,806 - INFO - Epoch [12/30] Batch [850/4715] Loss: 0.7284\n",
      "2025-05-30 15:51:37,447 - INFO - Epoch [12/30] Batch [860/4715] Loss: 0.6851\n",
      "2025-05-30 15:51:38,994 - INFO - Epoch [12/30] Batch [870/4715] Loss: 0.7747\n",
      "2025-05-30 15:51:40,511 - INFO - Epoch [12/30] Batch [880/4715] Loss: 0.9123\n",
      "2025-05-30 15:51:42,279 - INFO - Epoch [12/30] Batch [890/4715] Loss: 1.0663\n",
      "2025-05-30 15:51:43,923 - INFO - Epoch [12/30] Batch [900/4715] Loss: 0.8138\n",
      "2025-05-30 15:51:45,480 - INFO - Epoch [12/30] Batch [910/4715] Loss: 0.7316\n",
      "2025-05-30 15:51:47,007 - INFO - Epoch [12/30] Batch [920/4715] Loss: 0.8239\n",
      "2025-05-30 15:51:48,545 - INFO - Epoch [12/30] Batch [930/4715] Loss: 0.6900\n",
      "2025-05-30 15:51:50,084 - INFO - Epoch [12/30] Batch [940/4715] Loss: 0.7178\n",
      "2025-05-30 15:51:51,647 - INFO - Epoch [12/30] Batch [950/4715] Loss: 0.9002\n",
      "2025-05-30 15:51:53,201 - INFO - Epoch [12/30] Batch [960/4715] Loss: 0.5633\n",
      "2025-05-30 15:51:54,773 - INFO - Epoch [12/30] Batch [970/4715] Loss: 0.9031\n",
      "2025-05-30 15:51:56,365 - INFO - Epoch [12/30] Batch [980/4715] Loss: 0.9865\n",
      "2025-05-30 15:51:57,903 - INFO - Epoch [12/30] Batch [990/4715] Loss: 0.8732\n",
      "2025-05-30 15:51:59,577 - INFO - Epoch [12/30] Batch [1000/4715] Loss: 0.7274\n",
      "2025-05-30 15:52:01,100 - INFO - Epoch [12/30] Batch [1010/4715] Loss: 0.9565\n",
      "2025-05-30 15:52:02,759 - INFO - Epoch [12/30] Batch [1020/4715] Loss: 0.7276\n",
      "2025-05-30 15:52:04,359 - INFO - Epoch [12/30] Batch [1030/4715] Loss: 0.9653\n",
      "2025-05-30 15:52:05,888 - INFO - Epoch [12/30] Batch [1040/4715] Loss: 0.7988\n",
      "2025-05-30 15:52:07,470 - INFO - Epoch [12/30] Batch [1050/4715] Loss: 0.8484\n",
      "2025-05-30 15:52:09,024 - INFO - Epoch [12/30] Batch [1060/4715] Loss: 0.8715\n",
      "2025-05-30 15:52:10,566 - INFO - Epoch [12/30] Batch [1070/4715] Loss: 0.7838\n",
      "2025-05-30 15:52:12,073 - INFO - Epoch [12/30] Batch [1080/4715] Loss: 0.7889\n",
      "2025-05-30 15:52:13,622 - INFO - Epoch [12/30] Batch [1090/4715] Loss: 0.6634\n",
      "2025-05-30 15:52:15,240 - INFO - Epoch [12/30] Batch [1100/4715] Loss: 0.8335\n",
      "2025-05-30 15:52:16,788 - INFO - Epoch [12/30] Batch [1110/4715] Loss: 0.8068\n",
      "2025-05-30 15:52:18,389 - INFO - Epoch [12/30] Batch [1120/4715] Loss: 0.6825\n",
      "2025-05-30 15:52:20,059 - INFO - Epoch [12/30] Batch [1130/4715] Loss: 0.8545\n",
      "2025-05-30 15:52:21,673 - INFO - Epoch [12/30] Batch [1140/4715] Loss: 0.7897\n",
      "2025-05-30 15:52:23,213 - INFO - Epoch [12/30] Batch [1150/4715] Loss: 0.7503\n",
      "2025-05-30 15:52:24,783 - INFO - Epoch [12/30] Batch [1160/4715] Loss: 0.7642\n",
      "2025-05-30 15:52:26,381 - INFO - Epoch [12/30] Batch [1170/4715] Loss: 0.9737\n",
      "2025-05-30 15:52:28,040 - INFO - Epoch [12/30] Batch [1180/4715] Loss: 0.6476\n",
      "2025-05-30 15:52:29,629 - INFO - Epoch [12/30] Batch [1190/4715] Loss: 0.7757\n",
      "2025-05-30 15:52:31,185 - INFO - Epoch [12/30] Batch [1200/4715] Loss: 0.8533\n",
      "2025-05-30 15:52:32,706 - INFO - Epoch [12/30] Batch [1210/4715] Loss: 0.6492\n",
      "2025-05-30 15:52:34,227 - INFO - Epoch [12/30] Batch [1220/4715] Loss: 0.5224\n",
      "2025-05-30 15:52:35,728 - INFO - Epoch [12/30] Batch [1230/4715] Loss: 0.8015\n",
      "2025-05-30 15:52:37,296 - INFO - Epoch [12/30] Batch [1240/4715] Loss: 0.6771\n",
      "2025-05-30 15:52:38,949 - INFO - Epoch [12/30] Batch [1250/4715] Loss: 0.9327\n",
      "2025-05-30 15:52:40,533 - INFO - Epoch [12/30] Batch [1260/4715] Loss: 1.1824\n",
      "2025-05-30 15:52:42,075 - INFO - Epoch [12/30] Batch [1270/4715] Loss: 0.8891\n",
      "2025-05-30 15:52:43,601 - INFO - Epoch [12/30] Batch [1280/4715] Loss: 0.7197\n",
      "2025-05-30 15:52:45,164 - INFO - Epoch [12/30] Batch [1290/4715] Loss: 0.7102\n",
      "2025-05-30 15:52:46,697 - INFO - Epoch [12/30] Batch [1300/4715] Loss: 0.7983\n",
      "2025-05-30 15:52:48,321 - INFO - Epoch [12/30] Batch [1310/4715] Loss: 0.6619\n",
      "2025-05-30 15:52:49,833 - INFO - Epoch [12/30] Batch [1320/4715] Loss: 0.7451\n",
      "2025-05-30 15:52:51,397 - INFO - Epoch [12/30] Batch [1330/4715] Loss: 0.8477\n",
      "2025-05-30 15:52:52,977 - INFO - Epoch [12/30] Batch [1340/4715] Loss: 0.9814\n",
      "2025-05-30 15:52:54,600 - INFO - Epoch [12/30] Batch [1350/4715] Loss: 0.6363\n",
      "2025-05-30 15:52:56,186 - INFO - Epoch [12/30] Batch [1360/4715] Loss: 0.7978\n",
      "2025-05-30 15:52:57,759 - INFO - Epoch [12/30] Batch [1370/4715] Loss: 0.6017\n",
      "2025-05-30 15:52:59,344 - INFO - Epoch [12/30] Batch [1380/4715] Loss: 0.8489\n",
      "2025-05-30 15:53:00,884 - INFO - Epoch [12/30] Batch [1390/4715] Loss: 0.5940\n",
      "2025-05-30 15:53:02,416 - INFO - Epoch [12/30] Batch [1400/4715] Loss: 0.8494\n",
      "2025-05-30 15:53:04,024 - INFO - Epoch [12/30] Batch [1410/4715] Loss: 0.8935\n",
      "2025-05-30 15:53:05,631 - INFO - Epoch [12/30] Batch [1420/4715] Loss: 0.7141\n",
      "2025-05-30 15:53:07,270 - INFO - Epoch [12/30] Batch [1430/4715] Loss: 0.6479\n",
      "2025-05-30 15:53:08,883 - INFO - Epoch [12/30] Batch [1440/4715] Loss: 0.7607\n",
      "2025-05-30 15:53:10,442 - INFO - Epoch [12/30] Batch [1450/4715] Loss: 0.7593\n",
      "2025-05-30 15:53:12,084 - INFO - Epoch [12/30] Batch [1460/4715] Loss: 0.6984\n",
      "2025-05-30 15:53:13,693 - INFO - Epoch [12/30] Batch [1470/4715] Loss: 0.6551\n",
      "2025-05-30 15:53:15,210 - INFO - Epoch [12/30] Batch [1480/4715] Loss: 0.9610\n",
      "2025-05-30 15:53:16,742 - INFO - Epoch [12/30] Batch [1490/4715] Loss: 0.7813\n",
      "2025-05-30 15:53:18,319 - INFO - Epoch [12/30] Batch [1500/4715] Loss: 0.6861\n",
      "2025-05-30 15:53:19,859 - INFO - Epoch [12/30] Batch [1510/4715] Loss: 0.7455\n",
      "2025-05-30 15:53:21,447 - INFO - Epoch [12/30] Batch [1520/4715] Loss: 0.8168\n",
      "2025-05-30 15:53:22,975 - INFO - Epoch [12/30] Batch [1530/4715] Loss: 0.7627\n",
      "2025-05-30 15:53:24,539 - INFO - Epoch [12/30] Batch [1540/4715] Loss: 1.1889\n",
      "2025-05-30 15:53:26,091 - INFO - Epoch [12/30] Batch [1550/4715] Loss: 0.8961\n",
      "2025-05-30 15:53:27,656 - INFO - Epoch [12/30] Batch [1560/4715] Loss: 0.6629\n",
      "2025-05-30 15:53:29,235 - INFO - Epoch [12/30] Batch [1570/4715] Loss: 0.6688\n",
      "2025-05-30 15:53:30,810 - INFO - Epoch [12/30] Batch [1580/4715] Loss: 0.8213\n",
      "2025-05-30 15:53:32,383 - INFO - Epoch [12/30] Batch [1590/4715] Loss: 0.6327\n",
      "2025-05-30 15:53:33,969 - INFO - Epoch [12/30] Batch [1600/4715] Loss: 0.6772\n",
      "2025-05-30 15:53:35,514 - INFO - Epoch [12/30] Batch [1610/4715] Loss: 1.0463\n",
      "2025-05-30 15:53:37,045 - INFO - Epoch [12/30] Batch [1620/4715] Loss: 0.7692\n",
      "2025-05-30 15:53:38,560 - INFO - Epoch [12/30] Batch [1630/4715] Loss: 0.7096\n",
      "2025-05-30 15:53:40,198 - INFO - Epoch [12/30] Batch [1640/4715] Loss: 0.8415\n",
      "2025-05-30 15:53:41,803 - INFO - Epoch [12/30] Batch [1650/4715] Loss: 0.7290\n",
      "2025-05-30 15:53:43,443 - INFO - Epoch [12/30] Batch [1660/4715] Loss: 0.6954\n",
      "2025-05-30 15:53:44,980 - INFO - Epoch [12/30] Batch [1670/4715] Loss: 0.8491\n",
      "2025-05-30 15:53:46,564 - INFO - Epoch [12/30] Batch [1680/4715] Loss: 0.8032\n",
      "2025-05-30 15:53:48,102 - INFO - Epoch [12/30] Batch [1690/4715] Loss: 0.7614\n",
      "2025-05-30 15:53:49,646 - INFO - Epoch [12/30] Batch [1700/4715] Loss: 1.1385\n",
      "2025-05-30 15:53:51,204 - INFO - Epoch [12/30] Batch [1710/4715] Loss: 0.8364\n",
      "2025-05-30 15:53:52,893 - INFO - Epoch [12/30] Batch [1720/4715] Loss: 0.7274\n",
      "2025-05-30 15:53:54,434 - INFO - Epoch [12/30] Batch [1730/4715] Loss: 0.9840\n",
      "2025-05-30 15:53:55,886 - INFO - Epoch [12/30] Batch [1740/4715] Loss: 0.7063\n",
      "2025-05-30 15:53:57,568 - INFO - Epoch [12/30] Batch [1750/4715] Loss: 0.7652\n",
      "2025-05-30 15:53:59,186 - INFO - Epoch [12/30] Batch [1760/4715] Loss: 0.6362\n",
      "2025-05-30 15:54:00,844 - INFO - Epoch [12/30] Batch [1770/4715] Loss: 0.9579\n",
      "2025-05-30 15:54:02,484 - INFO - Epoch [12/30] Batch [1780/4715] Loss: 1.0114\n",
      "2025-05-30 15:54:04,063 - INFO - Epoch [12/30] Batch [1790/4715] Loss: 0.8467\n",
      "2025-05-30 15:54:05,656 - INFO - Epoch [12/30] Batch [1800/4715] Loss: 0.6130\n",
      "2025-05-30 15:54:07,150 - INFO - Epoch [12/30] Batch [1810/4715] Loss: 0.6503\n",
      "2025-05-30 15:54:08,737 - INFO - Epoch [12/30] Batch [1820/4715] Loss: 0.8086\n",
      "2025-05-30 15:54:10,311 - INFO - Epoch [12/30] Batch [1830/4715] Loss: 0.8416\n",
      "2025-05-30 15:54:11,833 - INFO - Epoch [12/30] Batch [1840/4715] Loss: 0.8103\n",
      "2025-05-30 15:54:13,373 - INFO - Epoch [12/30] Batch [1850/4715] Loss: 0.6615\n",
      "2025-05-30 15:54:14,987 - INFO - Epoch [12/30] Batch [1860/4715] Loss: 0.7436\n",
      "2025-05-30 15:54:16,533 - INFO - Epoch [12/30] Batch [1870/4715] Loss: 0.9400\n",
      "2025-05-30 15:54:18,191 - INFO - Epoch [12/30] Batch [1880/4715] Loss: 0.7449\n",
      "2025-05-30 15:54:19,715 - INFO - Epoch [12/30] Batch [1890/4715] Loss: 1.0284\n",
      "2025-05-30 15:54:21,302 - INFO - Epoch [12/30] Batch [1900/4715] Loss: 0.7592\n",
      "2025-05-30 15:54:23,001 - INFO - Epoch [12/30] Batch [1910/4715] Loss: 0.9783\n",
      "2025-05-30 15:54:24,696 - INFO - Epoch [12/30] Batch [1920/4715] Loss: 0.7650\n",
      "2025-05-30 15:54:26,271 - INFO - Epoch [12/30] Batch [1930/4715] Loss: 0.6726\n",
      "2025-05-30 15:54:27,912 - INFO - Epoch [12/30] Batch [1940/4715] Loss: 0.7983\n",
      "2025-05-30 15:54:29,467 - INFO - Epoch [12/30] Batch [1950/4715] Loss: 0.6582\n",
      "2025-05-30 15:54:31,043 - INFO - Epoch [12/30] Batch [1960/4715] Loss: 0.6512\n",
      "2025-05-30 15:54:32,678 - INFO - Epoch [12/30] Batch [1970/4715] Loss: 0.7194\n",
      "2025-05-30 15:54:34,213 - INFO - Epoch [12/30] Batch [1980/4715] Loss: 0.6225\n",
      "2025-05-30 15:54:35,701 - INFO - Epoch [12/30] Batch [1990/4715] Loss: 0.7138\n",
      "2025-05-30 15:54:37,267 - INFO - Epoch [12/30] Batch [2000/4715] Loss: 0.7744\n",
      "2025-05-30 15:54:38,738 - INFO - Epoch [12/30] Batch [2010/4715] Loss: 0.8022\n",
      "2025-05-30 15:54:40,347 - INFO - Epoch [12/30] Batch [2020/4715] Loss: 0.8203\n",
      "2025-05-30 15:54:41,876 - INFO - Epoch [12/30] Batch [2030/4715] Loss: 1.0524\n",
      "2025-05-30 15:54:43,515 - INFO - Epoch [12/30] Batch [2040/4715] Loss: 0.7617\n",
      "2025-05-30 15:54:45,091 - INFO - Epoch [12/30] Batch [2050/4715] Loss: 0.8344\n",
      "2025-05-30 15:54:46,631 - INFO - Epoch [12/30] Batch [2060/4715] Loss: 0.6628\n",
      "2025-05-30 15:54:48,118 - INFO - Epoch [12/30] Batch [2070/4715] Loss: 0.8145\n",
      "2025-05-30 15:54:49,758 - INFO - Epoch [12/30] Batch [2080/4715] Loss: 0.8302\n",
      "2025-05-30 15:54:51,398 - INFO - Epoch [12/30] Batch [2090/4715] Loss: 0.7790\n",
      "2025-05-30 15:54:52,952 - INFO - Epoch [12/30] Batch [2100/4715] Loss: 0.7199\n",
      "2025-05-30 15:54:54,500 - INFO - Epoch [12/30] Batch [2110/4715] Loss: 0.9991\n",
      "2025-05-30 15:54:56,061 - INFO - Epoch [12/30] Batch [2120/4715] Loss: 1.0121\n",
      "2025-05-30 15:54:57,660 - INFO - Epoch [12/30] Batch [2130/4715] Loss: 0.9594\n",
      "2025-05-30 15:54:59,221 - INFO - Epoch [12/30] Batch [2140/4715] Loss: 0.7749\n",
      "2025-05-30 15:55:00,821 - INFO - Epoch [12/30] Batch [2150/4715] Loss: 0.6157\n",
      "2025-05-30 15:55:02,377 - INFO - Epoch [12/30] Batch [2160/4715] Loss: 0.7498\n",
      "2025-05-30 15:55:03,987 - INFO - Epoch [12/30] Batch [2170/4715] Loss: 0.8822\n",
      "2025-05-30 15:55:05,536 - INFO - Epoch [12/30] Batch [2180/4715] Loss: 0.9751\n",
      "2025-05-30 15:55:07,106 - INFO - Epoch [12/30] Batch [2190/4715] Loss: 0.7528\n",
      "2025-05-30 15:55:08,790 - INFO - Epoch [12/30] Batch [2200/4715] Loss: 0.4822\n",
      "2025-05-30 15:55:10,318 - INFO - Epoch [12/30] Batch [2210/4715] Loss: 0.6973\n",
      "2025-05-30 15:55:12,001 - INFO - Epoch [12/30] Batch [2220/4715] Loss: 0.7894\n",
      "2025-05-30 15:55:13,520 - INFO - Epoch [12/30] Batch [2230/4715] Loss: 1.0842\n",
      "2025-05-30 15:55:15,110 - INFO - Epoch [12/30] Batch [2240/4715] Loss: 0.7748\n",
      "2025-05-30 15:55:16,678 - INFO - Epoch [12/30] Batch [2250/4715] Loss: 0.8122\n",
      "2025-05-30 15:55:18,214 - INFO - Epoch [12/30] Batch [2260/4715] Loss: 0.5623\n",
      "2025-05-30 15:55:19,770 - INFO - Epoch [12/30] Batch [2270/4715] Loss: 0.9019\n",
      "2025-05-30 15:55:21,420 - INFO - Epoch [12/30] Batch [2280/4715] Loss: 0.8033\n",
      "2025-05-30 15:55:23,014 - INFO - Epoch [12/30] Batch [2290/4715] Loss: 0.7949\n",
      "2025-05-30 15:55:24,598 - INFO - Epoch [12/30] Batch [2300/4715] Loss: 1.0325\n",
      "2025-05-30 15:55:26,192 - INFO - Epoch [12/30] Batch [2310/4715] Loss: 0.6907\n",
      "2025-05-30 15:55:27,924 - INFO - Epoch [12/30] Batch [2320/4715] Loss: 0.4493\n",
      "2025-05-30 15:55:29,575 - INFO - Epoch [12/30] Batch [2330/4715] Loss: 0.9230\n",
      "2025-05-30 15:55:31,100 - INFO - Epoch [12/30] Batch [2340/4715] Loss: 0.7532\n",
      "2025-05-30 15:55:32,709 - INFO - Epoch [12/30] Batch [2350/4715] Loss: 0.7218\n",
      "2025-05-30 15:55:34,243 - INFO - Epoch [12/30] Batch [2360/4715] Loss: 0.9465\n",
      "2025-05-30 15:55:35,825 - INFO - Epoch [12/30] Batch [2370/4715] Loss: 0.7403\n",
      "2025-05-30 15:55:37,370 - INFO - Epoch [12/30] Batch [2380/4715] Loss: 0.8176\n",
      "2025-05-30 15:55:38,949 - INFO - Epoch [12/30] Batch [2390/4715] Loss: 0.9120\n",
      "2025-05-30 15:55:40,535 - INFO - Epoch [12/30] Batch [2400/4715] Loss: 0.9053\n",
      "2025-05-30 15:55:42,178 - INFO - Epoch [12/30] Batch [2410/4715] Loss: 0.8995\n",
      "2025-05-30 15:55:43,753 - INFO - Epoch [12/30] Batch [2420/4715] Loss: 0.5950\n",
      "2025-05-30 15:55:45,289 - INFO - Epoch [12/30] Batch [2430/4715] Loss: 0.8718\n",
      "2025-05-30 15:55:46,878 - INFO - Epoch [12/30] Batch [2440/4715] Loss: 0.8865\n",
      "2025-05-30 15:55:48,411 - INFO - Epoch [12/30] Batch [2450/4715] Loss: 0.7163\n",
      "2025-05-30 15:55:49,962 - INFO - Epoch [12/30] Batch [2460/4715] Loss: 0.5877\n",
      "2025-05-30 15:55:51,532 - INFO - Epoch [12/30] Batch [2470/4715] Loss: 0.9163\n",
      "2025-05-30 15:55:53,110 - INFO - Epoch [12/30] Batch [2480/4715] Loss: 0.5983\n",
      "2025-05-30 15:55:54,698 - INFO - Epoch [12/30] Batch [2490/4715] Loss: 0.7040\n",
      "2025-05-30 15:55:56,306 - INFO - Epoch [12/30] Batch [2500/4715] Loss: 0.7304\n",
      "2025-05-30 15:55:57,978 - INFO - Epoch [12/30] Batch [2510/4715] Loss: 1.2422\n",
      "2025-05-30 15:55:59,476 - INFO - Epoch [12/30] Batch [2520/4715] Loss: 0.4335\n",
      "2025-05-30 15:56:00,942 - INFO - Epoch [12/30] Batch [2530/4715] Loss: 0.7975\n",
      "2025-05-30 15:56:02,524 - INFO - Epoch [12/30] Batch [2540/4715] Loss: 1.0423\n",
      "2025-05-30 15:56:04,102 - INFO - Epoch [12/30] Batch [2550/4715] Loss: 1.0635\n",
      "2025-05-30 15:56:05,709 - INFO - Epoch [12/30] Batch [2560/4715] Loss: 0.6948\n",
      "2025-05-30 15:56:07,285 - INFO - Epoch [12/30] Batch [2570/4715] Loss: 0.5580\n",
      "2025-05-30 15:56:08,875 - INFO - Epoch [12/30] Batch [2580/4715] Loss: 0.7857\n",
      "2025-05-30 15:56:10,449 - INFO - Epoch [12/30] Batch [2590/4715] Loss: 0.6161\n",
      "2025-05-30 15:56:12,068 - INFO - Epoch [12/30] Batch [2600/4715] Loss: 0.8041\n",
      "2025-05-30 15:56:13,591 - INFO - Epoch [12/30] Batch [2610/4715] Loss: 0.9506\n",
      "2025-05-30 15:56:15,130 - INFO - Epoch [12/30] Batch [2620/4715] Loss: 0.6191\n",
      "2025-05-30 15:56:16,773 - INFO - Epoch [12/30] Batch [2630/4715] Loss: 0.6964\n",
      "2025-05-30 15:56:18,324 - INFO - Epoch [12/30] Batch [2640/4715] Loss: 0.8395\n",
      "2025-05-30 15:56:19,946 - INFO - Epoch [12/30] Batch [2650/4715] Loss: 0.8422\n",
      "2025-05-30 15:56:21,476 - INFO - Epoch [12/30] Batch [2660/4715] Loss: 0.7738\n",
      "2025-05-30 15:56:22,945 - INFO - Epoch [12/30] Batch [2670/4715] Loss: 0.9905\n",
      "2025-05-30 15:56:24,517 - INFO - Epoch [12/30] Batch [2680/4715] Loss: 0.8034\n",
      "2025-05-30 15:56:26,036 - INFO - Epoch [12/30] Batch [2690/4715] Loss: 0.7498\n",
      "2025-05-30 15:56:27,697 - INFO - Epoch [12/30] Batch [2700/4715] Loss: 0.9079\n",
      "2025-05-30 15:56:29,381 - INFO - Epoch [12/30] Batch [2710/4715] Loss: 0.8252\n",
      "2025-05-30 15:56:31,014 - INFO - Epoch [12/30] Batch [2720/4715] Loss: 0.7607\n",
      "2025-05-30 15:56:32,659 - INFO - Epoch [12/30] Batch [2730/4715] Loss: 0.7590\n",
      "2025-05-30 15:56:34,246 - INFO - Epoch [12/30] Batch [2740/4715] Loss: 0.8132\n",
      "2025-05-30 15:56:35,775 - INFO - Epoch [12/30] Batch [2750/4715] Loss: 0.7846\n",
      "2025-05-30 15:56:37,363 - INFO - Epoch [12/30] Batch [2760/4715] Loss: 0.7064\n",
      "2025-05-30 15:56:39,005 - INFO - Epoch [12/30] Batch [2770/4715] Loss: 0.7272\n",
      "2025-05-30 15:56:40,581 - INFO - Epoch [12/30] Batch [2780/4715] Loss: 0.8629\n",
      "2025-05-30 15:56:42,101 - INFO - Epoch [12/30] Batch [2790/4715] Loss: 0.9254\n",
      "2025-05-30 15:56:43,670 - INFO - Epoch [12/30] Batch [2800/4715] Loss: 0.5025\n",
      "2025-05-30 15:56:45,178 - INFO - Epoch [12/30] Batch [2810/4715] Loss: 0.9431\n",
      "2025-05-30 15:56:46,661 - INFO - Epoch [12/30] Batch [2820/4715] Loss: 0.9421\n",
      "2025-05-30 15:56:48,203 - INFO - Epoch [12/30] Batch [2830/4715] Loss: 0.6864\n",
      "2025-05-30 15:56:49,777 - INFO - Epoch [12/30] Batch [2840/4715] Loss: 0.9041\n",
      "2025-05-30 15:56:51,381 - INFO - Epoch [12/30] Batch [2850/4715] Loss: 0.9172\n",
      "2025-05-30 15:56:52,978 - INFO - Epoch [12/30] Batch [2860/4715] Loss: 0.9777\n",
      "2025-05-30 15:56:54,532 - INFO - Epoch [12/30] Batch [2870/4715] Loss: 0.7253\n",
      "2025-05-30 15:56:56,119 - INFO - Epoch [12/30] Batch [2880/4715] Loss: 0.8649\n",
      "2025-05-30 15:56:57,692 - INFO - Epoch [12/30] Batch [2890/4715] Loss: 0.7879\n",
      "2025-05-30 15:56:59,328 - INFO - Epoch [12/30] Batch [2900/4715] Loss: 0.9921\n",
      "2025-05-30 15:57:00,812 - INFO - Epoch [12/30] Batch [2910/4715] Loss: 0.5411\n",
      "2025-05-30 15:57:02,363 - INFO - Epoch [12/30] Batch [2920/4715] Loss: 1.0392\n",
      "2025-05-30 15:57:03,895 - INFO - Epoch [12/30] Batch [2930/4715] Loss: 0.8364\n",
      "2025-05-30 15:57:05,527 - INFO - Epoch [12/30] Batch [2940/4715] Loss: 0.8643\n",
      "2025-05-30 15:57:07,143 - INFO - Epoch [12/30] Batch [2950/4715] Loss: 0.9135\n",
      "2025-05-30 15:57:08,842 - INFO - Epoch [12/30] Batch [2960/4715] Loss: 0.6473\n",
      "2025-05-30 15:57:10,361 - INFO - Epoch [12/30] Batch [2970/4715] Loss: 0.9577\n",
      "2025-05-30 15:57:11,953 - INFO - Epoch [12/30] Batch [2980/4715] Loss: 0.9515\n",
      "2025-05-30 15:57:13,479 - INFO - Epoch [12/30] Batch [2990/4715] Loss: 0.7696\n",
      "2025-05-30 15:57:15,054 - INFO - Epoch [12/30] Batch [3000/4715] Loss: 0.8430\n",
      "2025-05-30 15:57:16,605 - INFO - Epoch [12/30] Batch [3010/4715] Loss: 0.7037\n",
      "2025-05-30 15:57:18,203 - INFO - Epoch [12/30] Batch [3020/4715] Loss: 0.7043\n",
      "2025-05-30 15:57:19,722 - INFO - Epoch [12/30] Batch [3030/4715] Loss: 0.9474\n",
      "2025-05-30 15:57:21,186 - INFO - Epoch [12/30] Batch [3040/4715] Loss: 1.0951\n",
      "2025-05-30 15:57:22,715 - INFO - Epoch [12/30] Batch [3050/4715] Loss: 1.0269\n",
      "2025-05-30 15:57:24,254 - INFO - Epoch [12/30] Batch [3060/4715] Loss: 0.7126\n",
      "2025-05-30 15:57:25,829 - INFO - Epoch [12/30] Batch [3070/4715] Loss: 1.0138\n",
      "2025-05-30 15:57:27,436 - INFO - Epoch [12/30] Batch [3080/4715] Loss: 0.7619\n",
      "2025-05-30 15:57:29,139 - INFO - Epoch [12/30] Batch [3090/4715] Loss: 0.7132\n",
      "2025-05-30 15:57:30,845 - INFO - Epoch [12/30] Batch [3100/4715] Loss: 0.8813\n",
      "2025-05-30 15:57:32,371 - INFO - Epoch [12/30] Batch [3110/4715] Loss: 0.7102\n",
      "2025-05-30 15:57:33,938 - INFO - Epoch [12/30] Batch [3120/4715] Loss: 0.8183\n",
      "2025-05-30 15:57:35,404 - INFO - Epoch [12/30] Batch [3130/4715] Loss: 0.5830\n",
      "2025-05-30 15:57:36,913 - INFO - Epoch [12/30] Batch [3140/4715] Loss: 0.8723\n",
      "2025-05-30 15:57:38,458 - INFO - Epoch [12/30] Batch [3150/4715] Loss: 0.7064\n",
      "2025-05-30 15:57:40,025 - INFO - Epoch [12/30] Batch [3160/4715] Loss: 0.8346\n",
      "2025-05-30 15:57:41,591 - INFO - Epoch [12/30] Batch [3170/4715] Loss: 0.8535\n",
      "2025-05-30 15:57:43,165 - INFO - Epoch [12/30] Batch [3180/4715] Loss: 0.9324\n",
      "2025-05-30 15:57:44,811 - INFO - Epoch [12/30] Batch [3190/4715] Loss: 1.0023\n",
      "2025-05-30 15:57:46,485 - INFO - Epoch [12/30] Batch [3200/4715] Loss: 0.7120\n",
      "2025-05-30 15:57:47,990 - INFO - Epoch [12/30] Batch [3210/4715] Loss: 0.8236\n",
      "2025-05-30 15:57:49,552 - INFO - Epoch [12/30] Batch [3220/4715] Loss: 0.7067\n",
      "2025-05-30 15:57:51,142 - INFO - Epoch [12/30] Batch [3230/4715] Loss: 0.9020\n",
      "2025-05-30 15:57:52,619 - INFO - Epoch [12/30] Batch [3240/4715] Loss: 0.6822\n",
      "2025-05-30 15:57:54,178 - INFO - Epoch [12/30] Batch [3250/4715] Loss: 0.9174\n",
      "2025-05-30 15:57:55,741 - INFO - Epoch [12/30] Batch [3260/4715] Loss: 0.9450\n",
      "2025-05-30 15:57:57,242 - INFO - Epoch [12/30] Batch [3270/4715] Loss: 0.6061\n",
      "2025-05-30 15:57:58,776 - INFO - Epoch [12/30] Batch [3280/4715] Loss: 0.7537\n",
      "2025-05-30 15:58:00,261 - INFO - Epoch [12/30] Batch [3290/4715] Loss: 1.0258\n",
      "2025-05-30 15:58:01,848 - INFO - Epoch [12/30] Batch [3300/4715] Loss: 0.6718\n",
      "2025-05-30 15:58:03,374 - INFO - Epoch [12/30] Batch [3310/4715] Loss: 0.6366\n",
      "2025-05-30 15:58:04,923 - INFO - Epoch [12/30] Batch [3320/4715] Loss: 0.8606\n",
      "2025-05-30 15:58:06,500 - INFO - Epoch [12/30] Batch [3330/4715] Loss: 0.7356\n",
      "2025-05-30 15:58:08,033 - INFO - Epoch [12/30] Batch [3340/4715] Loss: 0.8978\n",
      "2025-05-30 15:58:09,578 - INFO - Epoch [12/30] Batch [3350/4715] Loss: 0.7955\n",
      "2025-05-30 15:58:11,122 - INFO - Epoch [12/30] Batch [3360/4715] Loss: 0.8023\n",
      "2025-05-30 15:58:12,699 - INFO - Epoch [12/30] Batch [3370/4715] Loss: 0.7845\n",
      "2025-05-30 15:58:14,287 - INFO - Epoch [12/30] Batch [3380/4715] Loss: 0.7943\n",
      "2025-05-30 15:58:15,897 - INFO - Epoch [12/30] Batch [3390/4715] Loss: 0.6988\n",
      "2025-05-30 15:58:17,521 - INFO - Epoch [12/30] Batch [3400/4715] Loss: 0.8345\n",
      "2025-05-30 15:58:19,045 - INFO - Epoch [12/30] Batch [3410/4715] Loss: 0.6904\n",
      "2025-05-30 15:58:20,655 - INFO - Epoch [12/30] Batch [3420/4715] Loss: 0.6262\n",
      "2025-05-30 15:58:22,167 - INFO - Epoch [12/30] Batch [3430/4715] Loss: 0.8924\n",
      "2025-05-30 15:58:23,741 - INFO - Epoch [12/30] Batch [3440/4715] Loss: 0.7987\n",
      "2025-05-30 15:58:25,291 - INFO - Epoch [12/30] Batch [3450/4715] Loss: 0.7436\n",
      "2025-05-30 15:58:26,819 - INFO - Epoch [12/30] Batch [3460/4715] Loss: 0.7780\n",
      "2025-05-30 15:58:28,339 - INFO - Epoch [12/30] Batch [3470/4715] Loss: 0.6813\n",
      "2025-05-30 15:58:29,930 - INFO - Epoch [12/30] Batch [3480/4715] Loss: 0.8040\n",
      "2025-05-30 15:58:31,533 - INFO - Epoch [12/30] Batch [3490/4715] Loss: 0.8297\n",
      "2025-05-30 15:58:33,087 - INFO - Epoch [12/30] Batch [3500/4715] Loss: 0.7125\n",
      "2025-05-30 15:58:34,707 - INFO - Epoch [12/30] Batch [3510/4715] Loss: 0.6774\n",
      "2025-05-30 15:58:36,328 - INFO - Epoch [12/30] Batch [3520/4715] Loss: 0.8193\n",
      "2025-05-30 15:58:37,900 - INFO - Epoch [12/30] Batch [3530/4715] Loss: 0.8257\n",
      "2025-05-30 15:58:39,478 - INFO - Epoch [12/30] Batch [3540/4715] Loss: 0.6697\n",
      "2025-05-30 15:58:41,087 - INFO - Epoch [12/30] Batch [3550/4715] Loss: 0.9077\n",
      "2025-05-30 15:58:42,603 - INFO - Epoch [12/30] Batch [3560/4715] Loss: 0.7973\n",
      "2025-05-30 15:58:44,102 - INFO - Epoch [12/30] Batch [3570/4715] Loss: 0.8049\n",
      "2025-05-30 15:58:45,719 - INFO - Epoch [12/30] Batch [3580/4715] Loss: 0.6584\n",
      "2025-05-30 15:58:47,287 - INFO - Epoch [12/30] Batch [3590/4715] Loss: 0.6855\n",
      "2025-05-30 15:58:48,836 - INFO - Epoch [12/30] Batch [3600/4715] Loss: 0.6555\n",
      "2025-05-30 15:58:50,412 - INFO - Epoch [12/30] Batch [3610/4715] Loss: 1.0379\n",
      "2025-05-30 15:58:51,956 - INFO - Epoch [12/30] Batch [3620/4715] Loss: 0.7663\n",
      "2025-05-30 15:58:53,466 - INFO - Epoch [12/30] Batch [3630/4715] Loss: 0.5787\n",
      "2025-05-30 15:58:54,996 - INFO - Epoch [12/30] Batch [3640/4715] Loss: 0.7904\n",
      "2025-05-30 15:58:56,603 - INFO - Epoch [12/30] Batch [3650/4715] Loss: 0.7586\n",
      "2025-05-30 15:58:58,161 - INFO - Epoch [12/30] Batch [3660/4715] Loss: 0.8260\n",
      "2025-05-30 15:58:59,761 - INFO - Epoch [12/30] Batch [3670/4715] Loss: 0.6854\n",
      "2025-05-30 15:59:01,410 - INFO - Epoch [12/30] Batch [3680/4715] Loss: 0.6479\n",
      "2025-05-30 15:59:03,017 - INFO - Epoch [12/30] Batch [3690/4715] Loss: 1.0022\n",
      "2025-05-30 15:59:04,568 - INFO - Epoch [12/30] Batch [3700/4715] Loss: 0.7678\n",
      "2025-05-30 15:59:06,098 - INFO - Epoch [12/30] Batch [3710/4715] Loss: 0.9155\n",
      "2025-05-30 15:59:07,677 - INFO - Epoch [12/30] Batch [3720/4715] Loss: 0.5703\n",
      "2025-05-30 15:59:09,178 - INFO - Epoch [12/30] Batch [3730/4715] Loss: 0.6776\n",
      "2025-05-30 15:59:10,796 - INFO - Epoch [12/30] Batch [3740/4715] Loss: 0.8042\n",
      "2025-05-30 15:59:12,282 - INFO - Epoch [12/30] Batch [3750/4715] Loss: 0.7853\n",
      "2025-05-30 15:59:13,975 - INFO - Epoch [12/30] Batch [3760/4715] Loss: 0.7003\n",
      "2025-05-30 15:59:15,579 - INFO - Epoch [12/30] Batch [3770/4715] Loss: 0.6646\n",
      "2025-05-30 15:59:17,078 - INFO - Epoch [12/30] Batch [3780/4715] Loss: 0.7505\n",
      "2025-05-30 15:59:18,617 - INFO - Epoch [12/30] Batch [3790/4715] Loss: 0.6951\n",
      "2025-05-30 15:59:20,135 - INFO - Epoch [12/30] Batch [3800/4715] Loss: 0.6400\n",
      "2025-05-30 15:59:21,694 - INFO - Epoch [12/30] Batch [3810/4715] Loss: 0.7429\n",
      "2025-05-30 15:59:23,218 - INFO - Epoch [12/30] Batch [3820/4715] Loss: 0.7398\n",
      "2025-05-30 15:59:24,817 - INFO - Epoch [12/30] Batch [3830/4715] Loss: 0.9235\n",
      "2025-05-30 15:59:26,440 - INFO - Epoch [12/30] Batch [3840/4715] Loss: 0.8833\n",
      "2025-05-30 15:59:28,039 - INFO - Epoch [12/30] Batch [3850/4715] Loss: 0.4949\n",
      "2025-05-30 15:59:29,624 - INFO - Epoch [12/30] Batch [3860/4715] Loss: 0.7082\n",
      "2025-05-30 15:59:31,168 - INFO - Epoch [12/30] Batch [3870/4715] Loss: 0.6584\n",
      "2025-05-30 15:59:32,817 - INFO - Epoch [12/30] Batch [3880/4715] Loss: 1.0591\n",
      "2025-05-30 15:59:34,369 - INFO - Epoch [12/30] Batch [3890/4715] Loss: 1.0955\n",
      "2025-05-30 15:59:35,845 - INFO - Epoch [12/30] Batch [3900/4715] Loss: 0.8884\n",
      "2025-05-30 15:59:37,330 - INFO - Epoch [12/30] Batch [3910/4715] Loss: 0.8417\n",
      "2025-05-30 15:59:38,938 - INFO - Epoch [12/30] Batch [3920/4715] Loss: 0.9672\n",
      "2025-05-30 15:59:40,414 - INFO - Epoch [12/30] Batch [3930/4715] Loss: 0.8493\n",
      "2025-05-30 15:59:42,004 - INFO - Epoch [12/30] Batch [3940/4715] Loss: 1.1032\n",
      "2025-05-30 15:59:43,581 - INFO - Epoch [12/30] Batch [3950/4715] Loss: 0.7244\n",
      "2025-05-30 15:59:45,168 - INFO - Epoch [12/30] Batch [3960/4715] Loss: 0.8312\n",
      "2025-05-30 15:59:46,725 - INFO - Epoch [12/30] Batch [3970/4715] Loss: 0.5669\n",
      "2025-05-30 15:59:48,283 - INFO - Epoch [12/30] Batch [3980/4715] Loss: 0.7088\n",
      "2025-05-30 15:59:49,861 - INFO - Epoch [12/30] Batch [3990/4715] Loss: 0.9056\n",
      "2025-05-30 15:59:51,379 - INFO - Epoch [12/30] Batch [4000/4715] Loss: 0.8055\n",
      "2025-05-30 15:59:52,968 - INFO - Epoch [12/30] Batch [4010/4715] Loss: 0.8384\n",
      "2025-05-30 15:59:54,597 - INFO - Epoch [12/30] Batch [4020/4715] Loss: 0.8706\n",
      "2025-05-30 15:59:56,212 - INFO - Epoch [12/30] Batch [4030/4715] Loss: 0.8615\n",
      "2025-05-30 15:59:57,836 - INFO - Epoch [12/30] Batch [4040/4715] Loss: 0.9440\n",
      "2025-05-30 15:59:59,409 - INFO - Epoch [12/30] Batch [4050/4715] Loss: 0.6322\n",
      "2025-05-30 16:00:00,989 - INFO - Epoch [12/30] Batch [4060/4715] Loss: 0.8606\n",
      "2025-05-30 16:00:02,617 - INFO - Epoch [12/30] Batch [4070/4715] Loss: 0.6005\n",
      "2025-05-30 16:00:04,220 - INFO - Epoch [12/30] Batch [4080/4715] Loss: 0.9325\n",
      "2025-05-30 16:00:05,819 - INFO - Epoch [12/30] Batch [4090/4715] Loss: 0.8545\n",
      "2025-05-30 16:00:07,454 - INFO - Epoch [12/30] Batch [4100/4715] Loss: 0.8413\n",
      "2025-05-30 16:00:09,048 - INFO - Epoch [12/30] Batch [4110/4715] Loss: 0.8179\n",
      "2025-05-30 16:00:10,699 - INFO - Epoch [12/30] Batch [4120/4715] Loss: 1.0226\n",
      "2025-05-30 16:00:12,251 - INFO - Epoch [12/30] Batch [4130/4715] Loss: 0.9367\n",
      "2025-05-30 16:00:13,834 - INFO - Epoch [12/30] Batch [4140/4715] Loss: 0.9492\n",
      "2025-05-30 16:00:15,448 - INFO - Epoch [12/30] Batch [4150/4715] Loss: 0.7560\n",
      "2025-05-30 16:00:17,180 - INFO - Epoch [12/30] Batch [4160/4715] Loss: 0.6276\n",
      "2025-05-30 16:00:18,740 - INFO - Epoch [12/30] Batch [4170/4715] Loss: 0.9197\n",
      "2025-05-30 16:00:20,391 - INFO - Epoch [12/30] Batch [4180/4715] Loss: 0.7730\n",
      "2025-05-30 16:00:21,883 - INFO - Epoch [12/30] Batch [4190/4715] Loss: 0.8860\n",
      "2025-05-30 16:00:23,451 - INFO - Epoch [12/30] Batch [4200/4715] Loss: 0.8510\n",
      "2025-05-30 16:00:25,031 - INFO - Epoch [12/30] Batch [4210/4715] Loss: 0.9413\n",
      "2025-05-30 16:00:26,665 - INFO - Epoch [12/30] Batch [4220/4715] Loss: 0.6971\n",
      "2025-05-30 16:00:28,170 - INFO - Epoch [12/30] Batch [4230/4715] Loss: 1.0158\n",
      "2025-05-30 16:00:29,709 - INFO - Epoch [12/30] Batch [4240/4715] Loss: 0.7283\n",
      "2025-05-30 16:00:31,247 - INFO - Epoch [12/30] Batch [4250/4715] Loss: 0.7594\n",
      "2025-05-30 16:00:32,815 - INFO - Epoch [12/30] Batch [4260/4715] Loss: 0.7643\n",
      "2025-05-30 16:00:34,376 - INFO - Epoch [12/30] Batch [4270/4715] Loss: 0.6930\n",
      "2025-05-30 16:00:35,866 - INFO - Epoch [12/30] Batch [4280/4715] Loss: 0.7280\n",
      "2025-05-30 16:00:37,539 - INFO - Epoch [12/30] Batch [4290/4715] Loss: 0.6909\n",
      "2025-05-30 16:00:39,157 - INFO - Epoch [12/30] Batch [4300/4715] Loss: 0.9177\n",
      "2025-05-30 16:00:40,651 - INFO - Epoch [12/30] Batch [4310/4715] Loss: 0.6482\n",
      "2025-05-30 16:00:42,359 - INFO - Epoch [12/30] Batch [4320/4715] Loss: 0.9490\n",
      "2025-05-30 16:00:43,831 - INFO - Epoch [12/30] Batch [4330/4715] Loss: 0.6681\n",
      "2025-05-30 16:00:45,417 - INFO - Epoch [12/30] Batch [4340/4715] Loss: 0.7690\n",
      "2025-05-30 16:00:47,064 - INFO - Epoch [12/30] Batch [4350/4715] Loss: 0.7523\n",
      "2025-05-30 16:00:48,616 - INFO - Epoch [12/30] Batch [4360/4715] Loss: 0.7261\n",
      "2025-05-30 16:00:50,125 - INFO - Epoch [12/30] Batch [4370/4715] Loss: 0.7806\n",
      "2025-05-30 16:00:51,761 - INFO - Epoch [12/30] Batch [4380/4715] Loss: 0.8678\n",
      "2025-05-30 16:00:53,380 - INFO - Epoch [12/30] Batch [4390/4715] Loss: 0.6726\n",
      "2025-05-30 16:00:54,962 - INFO - Epoch [12/30] Batch [4400/4715] Loss: 0.6778\n",
      "2025-05-30 16:00:56,509 - INFO - Epoch [12/30] Batch [4410/4715] Loss: 0.7384\n",
      "2025-05-30 16:00:58,106 - INFO - Epoch [12/30] Batch [4420/4715] Loss: 0.7333\n",
      "2025-05-30 16:00:59,656 - INFO - Epoch [12/30] Batch [4430/4715] Loss: 0.9264\n",
      "2025-05-30 16:01:01,292 - INFO - Epoch [12/30] Batch [4440/4715] Loss: 0.8169\n",
      "2025-05-30 16:01:02,856 - INFO - Epoch [12/30] Batch [4450/4715] Loss: 0.8429\n",
      "2025-05-30 16:01:04,492 - INFO - Epoch [12/30] Batch [4460/4715] Loss: 0.7181\n",
      "2025-05-30 16:01:06,055 - INFO - Epoch [12/30] Batch [4470/4715] Loss: 0.9761\n",
      "2025-05-30 16:01:07,604 - INFO - Epoch [12/30] Batch [4480/4715] Loss: 0.9744\n",
      "2025-05-30 16:01:09,171 - INFO - Epoch [12/30] Batch [4490/4715] Loss: 0.7439\n",
      "2025-05-30 16:01:10,721 - INFO - Epoch [12/30] Batch [4500/4715] Loss: 0.8334\n",
      "2025-05-30 16:01:12,242 - INFO - Epoch [12/30] Batch [4510/4715] Loss: 0.8611\n",
      "2025-05-30 16:01:13,912 - INFO - Epoch [12/30] Batch [4520/4715] Loss: 0.6762\n",
      "2025-05-30 16:01:15,463 - INFO - Epoch [12/30] Batch [4530/4715] Loss: 0.8339\n",
      "2025-05-30 16:01:17,040 - INFO - Epoch [12/30] Batch [4540/4715] Loss: 0.7723\n",
      "2025-05-30 16:01:18,647 - INFO - Epoch [12/30] Batch [4550/4715] Loss: 0.8933\n",
      "2025-05-30 16:01:20,167 - INFO - Epoch [12/30] Batch [4560/4715] Loss: 0.7353\n",
      "2025-05-30 16:01:21,733 - INFO - Epoch [12/30] Batch [4570/4715] Loss: 0.8784\n",
      "2025-05-30 16:01:23,366 - INFO - Epoch [12/30] Batch [4580/4715] Loss: 0.6830\n",
      "2025-05-30 16:01:24,925 - INFO - Epoch [12/30] Batch [4590/4715] Loss: 1.0157\n",
      "2025-05-30 16:01:26,428 - INFO - Epoch [12/30] Batch [4600/4715] Loss: 0.5857\n",
      "2025-05-30 16:01:27,993 - INFO - Epoch [12/30] Batch [4610/4715] Loss: 0.7454\n",
      "2025-05-30 16:01:29,588 - INFO - Epoch [12/30] Batch [4620/4715] Loss: 0.8113\n",
      "2025-05-30 16:01:31,175 - INFO - Epoch [12/30] Batch [4630/4715] Loss: 0.7471\n",
      "2025-05-30 16:01:32,754 - INFO - Epoch [12/30] Batch [4640/4715] Loss: 0.6167\n",
      "2025-05-30 16:01:34,393 - INFO - Epoch [12/30] Batch [4650/4715] Loss: 0.7072\n",
      "2025-05-30 16:01:35,938 - INFO - Epoch [12/30] Batch [4660/4715] Loss: 0.7788\n",
      "2025-05-30 16:01:37,450 - INFO - Epoch [12/30] Batch [4670/4715] Loss: 1.0749\n",
      "2025-05-30 16:01:38,954 - INFO - Epoch [12/30] Batch [4680/4715] Loss: 0.7892\n",
      "2025-05-30 16:01:40,572 - INFO - Epoch [12/30] Batch [4690/4715] Loss: 0.7365\n",
      "2025-05-30 16:01:42,201 - INFO - Epoch [12/30] Batch [4700/4715] Loss: 0.7551\n",
      "2025-05-30 16:01:43,737 - INFO - Epoch [12/30] Batch [4710/4715] Loss: 0.8913\n",
      "2025-05-30 16:02:22,857 - INFO - \n",
      "Epoch [12/30] Time: 781.91s\n",
      "2025-05-30 16:02:22,857 - INFO - Train Loss: 0.8120, Valid Loss: 0.8169\n",
      "2025-05-30 16:02:22,858 - INFO - Valid AUC (macro): 0.7315, F1 (macro): 0.5733\n",
      "2025-05-30 16:02:23,396 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\best_model.pth\n",
      "2025-05-30 16:02:23,397 - INFO - New best model saved with AUC: 0.7315\n",
      "2025-05-30 16:02:23,920 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 16:02:23,921 - INFO - Saved checkpoint at epoch 12\n",
      "2025-05-30 16:02:24,128 - INFO - Epoch [13/30] Batch [0/4715] Loss: 0.7126\n",
      "2025-05-30 16:02:25,919 - INFO - Epoch [13/30] Batch [10/4715] Loss: 0.9594\n",
      "2025-05-30 16:02:27,467 - INFO - Epoch [13/30] Batch [20/4715] Loss: 0.9478\n",
      "2025-05-30 16:02:29,023 - INFO - Epoch [13/30] Batch [30/4715] Loss: 0.7861\n",
      "2025-05-30 16:02:30,580 - INFO - Epoch [13/30] Batch [40/4715] Loss: 0.6462\n",
      "2025-05-30 16:02:32,154 - INFO - Epoch [13/30] Batch [50/4715] Loss: 0.6851\n",
      "2025-05-30 16:02:33,729 - INFO - Epoch [13/30] Batch [60/4715] Loss: 0.8960\n",
      "2025-05-30 16:02:35,225 - INFO - Epoch [13/30] Batch [70/4715] Loss: 0.5798\n",
      "2025-05-30 16:02:36,727 - INFO - Epoch [13/30] Batch [80/4715] Loss: 0.8696\n",
      "2025-05-30 16:02:38,340 - INFO - Epoch [13/30] Batch [90/4715] Loss: 0.8616\n",
      "2025-05-30 16:02:39,959 - INFO - Epoch [13/30] Batch [100/4715] Loss: 0.9215\n",
      "2025-05-30 16:02:41,507 - INFO - Epoch [13/30] Batch [110/4715] Loss: 0.7708\n",
      "2025-05-30 16:02:43,077 - INFO - Epoch [13/30] Batch [120/4715] Loss: 0.7783\n",
      "2025-05-30 16:02:44,597 - INFO - Epoch [13/30] Batch [130/4715] Loss: 0.7712\n",
      "2025-05-30 16:02:46,265 - INFO - Epoch [13/30] Batch [140/4715] Loss: 0.8422\n",
      "2025-05-30 16:02:47,928 - INFO - Epoch [13/30] Batch [150/4715] Loss: 1.0476\n",
      "2025-05-30 16:02:49,527 - INFO - Epoch [13/30] Batch [160/4715] Loss: 0.8116\n",
      "2025-05-30 16:02:51,037 - INFO - Epoch [13/30] Batch [170/4715] Loss: 0.7190\n",
      "2025-05-30 16:02:52,538 - INFO - Epoch [13/30] Batch [180/4715] Loss: 0.8574\n",
      "2025-05-30 16:02:54,152 - INFO - Epoch [13/30] Batch [190/4715] Loss: 1.1443\n",
      "2025-05-30 16:02:55,709 - INFO - Epoch [13/30] Batch [200/4715] Loss: 0.8988\n",
      "2025-05-30 16:02:57,309 - INFO - Epoch [13/30] Batch [210/4715] Loss: 0.7910\n",
      "2025-05-30 16:02:58,934 - INFO - Epoch [13/30] Batch [220/4715] Loss: 0.7310\n",
      "2025-05-30 16:03:00,430 - INFO - Epoch [13/30] Batch [230/4715] Loss: 0.7904\n",
      "2025-05-30 16:03:01,947 - INFO - Epoch [13/30] Batch [240/4715] Loss: 0.7964\n",
      "2025-05-30 16:03:03,488 - INFO - Epoch [13/30] Batch [250/4715] Loss: 0.6964\n",
      "2025-05-30 16:03:05,078 - INFO - Epoch [13/30] Batch [260/4715] Loss: 0.7710\n",
      "2025-05-30 16:03:06,782 - INFO - Epoch [13/30] Batch [270/4715] Loss: 0.7471\n",
      "2025-05-30 16:03:08,326 - INFO - Epoch [13/30] Batch [280/4715] Loss: 0.7125\n",
      "2025-05-30 16:03:09,963 - INFO - Epoch [13/30] Batch [290/4715] Loss: 0.8289\n",
      "2025-05-30 16:03:11,508 - INFO - Epoch [13/30] Batch [300/4715] Loss: 0.8389\n",
      "2025-05-30 16:03:13,141 - INFO - Epoch [13/30] Batch [310/4715] Loss: 0.7012\n",
      "2025-05-30 16:03:14,736 - INFO - Epoch [13/30] Batch [320/4715] Loss: 0.6516\n",
      "2025-05-30 16:03:16,302 - INFO - Epoch [13/30] Batch [330/4715] Loss: 0.9515\n",
      "2025-05-30 16:03:17,839 - INFO - Epoch [13/30] Batch [340/4715] Loss: 0.8628\n",
      "2025-05-30 16:03:19,492 - INFO - Epoch [13/30] Batch [350/4715] Loss: 0.6670\n",
      "2025-05-30 16:03:21,066 - INFO - Epoch [13/30] Batch [360/4715] Loss: 0.8612\n",
      "2025-05-30 16:03:22,562 - INFO - Epoch [13/30] Batch [370/4715] Loss: 1.0500\n",
      "2025-05-30 16:03:24,119 - INFO - Epoch [13/30] Batch [380/4715] Loss: 0.8303\n",
      "2025-05-30 16:03:25,811 - INFO - Epoch [13/30] Batch [390/4715] Loss: 0.7282\n",
      "2025-05-30 16:03:27,435 - INFO - Epoch [13/30] Batch [400/4715] Loss: 0.7011\n",
      "2025-05-30 16:03:28,943 - INFO - Epoch [13/30] Batch [410/4715] Loss: 0.8113\n",
      "2025-05-30 16:03:30,496 - INFO - Epoch [13/30] Batch [420/4715] Loss: 0.8739\n",
      "2025-05-30 16:03:32,116 - INFO - Epoch [13/30] Batch [430/4715] Loss: 0.6696\n",
      "2025-05-30 16:03:33,676 - INFO - Epoch [13/30] Batch [440/4715] Loss: 0.6726\n",
      "2025-05-30 16:03:35,196 - INFO - Epoch [13/30] Batch [450/4715] Loss: 0.6774\n",
      "2025-05-30 16:03:36,788 - INFO - Epoch [13/30] Batch [460/4715] Loss: 0.7960\n",
      "2025-05-30 16:03:38,387 - INFO - Epoch [13/30] Batch [470/4715] Loss: 0.7992\n",
      "2025-05-30 16:03:39,941 - INFO - Epoch [13/30] Batch [480/4715] Loss: 0.9284\n",
      "2025-05-30 16:03:41,435 - INFO - Epoch [13/30] Batch [490/4715] Loss: 0.6549\n",
      "2025-05-30 16:03:42,991 - INFO - Epoch [13/30] Batch [500/4715] Loss: 0.7681\n",
      "2025-05-30 16:03:44,542 - INFO - Epoch [13/30] Batch [510/4715] Loss: 1.0816\n",
      "2025-05-30 16:03:46,127 - INFO - Epoch [13/30] Batch [520/4715] Loss: 0.6711\n",
      "2025-05-30 16:03:47,671 - INFO - Epoch [13/30] Batch [530/4715] Loss: 1.0036\n",
      "2025-05-30 16:03:49,224 - INFO - Epoch [13/30] Batch [540/4715] Loss: 0.7604\n",
      "2025-05-30 16:03:50,731 - INFO - Epoch [13/30] Batch [550/4715] Loss: 0.8408\n",
      "2025-05-30 16:03:52,323 - INFO - Epoch [13/30] Batch [560/4715] Loss: 0.7623\n",
      "2025-05-30 16:03:53,877 - INFO - Epoch [13/30] Batch [570/4715] Loss: 0.7695\n",
      "2025-05-30 16:03:55,350 - INFO - Epoch [13/30] Batch [580/4715] Loss: 0.6372\n",
      "2025-05-30 16:03:56,955 - INFO - Epoch [13/30] Batch [590/4715] Loss: 0.7963\n",
      "2025-05-30 16:03:58,529 - INFO - Epoch [13/30] Batch [600/4715] Loss: 0.7061\n",
      "2025-05-30 16:04:00,011 - INFO - Epoch [13/30] Batch [610/4715] Loss: 0.8055\n",
      "2025-05-30 16:04:01,638 - INFO - Epoch [13/30] Batch [620/4715] Loss: 0.7337\n",
      "2025-05-30 16:04:03,158 - INFO - Epoch [13/30] Batch [630/4715] Loss: 0.7924\n",
      "2025-05-30 16:04:04,728 - INFO - Epoch [13/30] Batch [640/4715] Loss: 0.6521\n",
      "2025-05-30 16:04:06,301 - INFO - Epoch [13/30] Batch [650/4715] Loss: 0.7599\n",
      "2025-05-30 16:04:07,828 - INFO - Epoch [13/30] Batch [660/4715] Loss: 0.8649\n",
      "2025-05-30 16:04:09,315 - INFO - Epoch [13/30] Batch [670/4715] Loss: 1.1828\n",
      "2025-05-30 16:04:10,905 - INFO - Epoch [13/30] Batch [680/4715] Loss: 0.7363\n",
      "2025-05-30 16:04:12,512 - INFO - Epoch [13/30] Batch [690/4715] Loss: 0.7589\n",
      "2025-05-30 16:04:14,119 - INFO - Epoch [13/30] Batch [700/4715] Loss: 0.7036\n",
      "2025-05-30 16:04:15,736 - INFO - Epoch [13/30] Batch [710/4715] Loss: 0.7095\n",
      "2025-05-30 16:04:17,300 - INFO - Epoch [13/30] Batch [720/4715] Loss: 0.5892\n",
      "2025-05-30 16:04:18,799 - INFO - Epoch [13/30] Batch [730/4715] Loss: 0.7558\n",
      "2025-05-30 16:04:20,382 - INFO - Epoch [13/30] Batch [740/4715] Loss: 1.0910\n",
      "2025-05-30 16:04:21,919 - INFO - Epoch [13/30] Batch [750/4715] Loss: 1.0019\n",
      "2025-05-30 16:04:23,566 - INFO - Epoch [13/30] Batch [760/4715] Loss: 0.9137\n",
      "2025-05-30 16:04:25,068 - INFO - Epoch [13/30] Batch [770/4715] Loss: 0.8330\n",
      "2025-05-30 16:04:26,638 - INFO - Epoch [13/30] Batch [780/4715] Loss: 1.0930\n",
      "2025-05-30 16:04:28,173 - INFO - Epoch [13/30] Batch [790/4715] Loss: 0.6258\n",
      "2025-05-30 16:04:29,774 - INFO - Epoch [13/30] Batch [800/4715] Loss: 0.6996\n",
      "2025-05-30 16:04:31,396 - INFO - Epoch [13/30] Batch [810/4715] Loss: 0.7828\n",
      "2025-05-30 16:04:32,949 - INFO - Epoch [13/30] Batch [820/4715] Loss: 0.9998\n",
      "2025-05-30 16:04:34,493 - INFO - Epoch [13/30] Batch [830/4715] Loss: 0.7526\n",
      "2025-05-30 16:04:36,066 - INFO - Epoch [13/30] Batch [840/4715] Loss: 0.6459\n",
      "2025-05-30 16:04:37,624 - INFO - Epoch [13/30] Batch [850/4715] Loss: 0.6810\n",
      "2025-05-30 16:04:39,298 - INFO - Epoch [13/30] Batch [860/4715] Loss: 0.8139\n",
      "2025-05-30 16:04:40,777 - INFO - Epoch [13/30] Batch [870/4715] Loss: 0.7720\n",
      "2025-05-30 16:04:42,328 - INFO - Epoch [13/30] Batch [880/4715] Loss: 0.7378\n",
      "2025-05-30 16:04:43,879 - INFO - Epoch [13/30] Batch [890/4715] Loss: 0.8896\n",
      "2025-05-30 16:04:45,360 - INFO - Epoch [13/30] Batch [900/4715] Loss: 0.7151\n",
      "2025-05-30 16:04:46,890 - INFO - Epoch [13/30] Batch [910/4715] Loss: 0.7985\n",
      "2025-05-30 16:04:48,470 - INFO - Epoch [13/30] Batch [920/4715] Loss: 0.9679\n",
      "2025-05-30 16:04:50,086 - INFO - Epoch [13/30] Batch [930/4715] Loss: 1.0042\n",
      "2025-05-30 16:04:51,774 - INFO - Epoch [13/30] Batch [940/4715] Loss: 0.6539\n",
      "2025-05-30 16:04:53,450 - INFO - Epoch [13/30] Batch [950/4715] Loss: 0.7136\n",
      "2025-05-30 16:04:55,060 - INFO - Epoch [13/30] Batch [960/4715] Loss: 0.7647\n",
      "2025-05-30 16:04:56,683 - INFO - Epoch [13/30] Batch [970/4715] Loss: 0.8086\n",
      "2025-05-30 16:04:58,238 - INFO - Epoch [13/30] Batch [980/4715] Loss: 0.6273\n",
      "2025-05-30 16:04:59,761 - INFO - Epoch [13/30] Batch [990/4715] Loss: 0.8734\n",
      "2025-05-30 16:05:01,285 - INFO - Epoch [13/30] Batch [1000/4715] Loss: 0.7945\n",
      "2025-05-30 16:05:02,758 - INFO - Epoch [13/30] Batch [1010/4715] Loss: 0.7573\n",
      "2025-05-30 16:05:04,258 - INFO - Epoch [13/30] Batch [1020/4715] Loss: 0.8517\n",
      "2025-05-30 16:05:05,803 - INFO - Epoch [13/30] Batch [1030/4715] Loss: 0.6025\n",
      "2025-05-30 16:05:07,451 - INFO - Epoch [13/30] Batch [1040/4715] Loss: 0.7149\n",
      "2025-05-30 16:05:08,909 - INFO - Epoch [13/30] Batch [1050/4715] Loss: 0.8655\n",
      "2025-05-30 16:05:10,415 - INFO - Epoch [13/30] Batch [1060/4715] Loss: 0.7363\n",
      "2025-05-30 16:05:11,939 - INFO - Epoch [13/30] Batch [1070/4715] Loss: 0.8305\n",
      "2025-05-30 16:05:13,468 - INFO - Epoch [13/30] Batch [1080/4715] Loss: 0.8957\n",
      "2025-05-30 16:05:15,039 - INFO - Epoch [13/30] Batch [1090/4715] Loss: 0.6461\n",
      "2025-05-30 16:05:16,536 - INFO - Epoch [13/30] Batch [1100/4715] Loss: 0.8951\n",
      "2025-05-30 16:05:18,175 - INFO - Epoch [13/30] Batch [1110/4715] Loss: 1.1448\n",
      "2025-05-30 16:05:19,693 - INFO - Epoch [13/30] Batch [1120/4715] Loss: 0.7571\n",
      "2025-05-30 16:05:21,354 - INFO - Epoch [13/30] Batch [1130/4715] Loss: 1.0595\n",
      "2025-05-30 16:05:22,928 - INFO - Epoch [13/30] Batch [1140/4715] Loss: 0.7380\n",
      "2025-05-30 16:05:24,465 - INFO - Epoch [13/30] Batch [1150/4715] Loss: 1.1246\n",
      "2025-05-30 16:05:26,027 - INFO - Epoch [13/30] Batch [1160/4715] Loss: 0.6937\n",
      "2025-05-30 16:05:27,518 - INFO - Epoch [13/30] Batch [1170/4715] Loss: 0.9406\n",
      "2025-05-30 16:05:29,021 - INFO - Epoch [13/30] Batch [1180/4715] Loss: 0.6343\n",
      "2025-05-30 16:05:30,460 - INFO - Epoch [13/30] Batch [1190/4715] Loss: 0.8038\n",
      "2025-05-30 16:05:31,971 - INFO - Epoch [13/30] Batch [1200/4715] Loss: 0.7899\n",
      "2025-05-30 16:05:33,516 - INFO - Epoch [13/30] Batch [1210/4715] Loss: 0.8457\n",
      "2025-05-30 16:05:35,107 - INFO - Epoch [13/30] Batch [1220/4715] Loss: 0.5737\n",
      "2025-05-30 16:05:36,622 - INFO - Epoch [13/30] Batch [1230/4715] Loss: 0.8231\n",
      "2025-05-30 16:05:38,180 - INFO - Epoch [13/30] Batch [1240/4715] Loss: 0.5827\n",
      "2025-05-30 16:05:39,766 - INFO - Epoch [13/30] Batch [1250/4715] Loss: 0.6101\n",
      "2025-05-30 16:05:41,184 - INFO - Epoch [13/30] Batch [1260/4715] Loss: 0.9940\n",
      "2025-05-30 16:05:42,735 - INFO - Epoch [13/30] Batch [1270/4715] Loss: 0.8121\n",
      "2025-05-30 16:05:44,266 - INFO - Epoch [13/30] Batch [1280/4715] Loss: 0.6808\n",
      "2025-05-30 16:05:45,816 - INFO - Epoch [13/30] Batch [1290/4715] Loss: 0.7858\n",
      "2025-05-30 16:05:47,443 - INFO - Epoch [13/30] Batch [1300/4715] Loss: 0.8069\n",
      "2025-05-30 16:05:49,001 - INFO - Epoch [13/30] Batch [1310/4715] Loss: 0.9191\n",
      "2025-05-30 16:05:50,679 - INFO - Epoch [13/30] Batch [1320/4715] Loss: 0.6645\n",
      "2025-05-30 16:05:52,274 - INFO - Epoch [13/30] Batch [1330/4715] Loss: 0.6591\n",
      "2025-05-30 16:05:53,855 - INFO - Epoch [13/30] Batch [1340/4715] Loss: 0.8351\n",
      "2025-05-30 16:05:55,479 - INFO - Epoch [13/30] Batch [1350/4715] Loss: 0.8168\n",
      "2025-05-30 16:05:57,040 - INFO - Epoch [13/30] Batch [1360/4715] Loss: 0.6411\n",
      "2025-05-30 16:05:58,594 - INFO - Epoch [13/30] Batch [1370/4715] Loss: 0.9719\n",
      "2025-05-30 16:06:00,224 - INFO - Epoch [13/30] Batch [1380/4715] Loss: 0.6350\n",
      "2025-05-30 16:06:01,761 - INFO - Epoch [13/30] Batch [1390/4715] Loss: 0.7347\n",
      "2025-05-30 16:06:03,377 - INFO - Epoch [13/30] Batch [1400/4715] Loss: 0.7747\n",
      "2025-05-30 16:06:04,946 - INFO - Epoch [13/30] Batch [1410/4715] Loss: 0.7569\n",
      "2025-05-30 16:06:06,549 - INFO - Epoch [13/30] Batch [1420/4715] Loss: 0.9936\n",
      "2025-05-30 16:06:08,081 - INFO - Epoch [13/30] Batch [1430/4715] Loss: 1.0172\n",
      "2025-05-30 16:06:09,604 - INFO - Epoch [13/30] Batch [1440/4715] Loss: 0.8611\n",
      "2025-05-30 16:06:11,144 - INFO - Epoch [13/30] Batch [1450/4715] Loss: 0.8183\n",
      "2025-05-30 16:06:12,827 - INFO - Epoch [13/30] Batch [1460/4715] Loss: 1.0185\n",
      "2025-05-30 16:06:14,370 - INFO - Epoch [13/30] Batch [1470/4715] Loss: 0.9222\n",
      "2025-05-30 16:06:15,989 - INFO - Epoch [13/30] Batch [1480/4715] Loss: 0.4953\n",
      "2025-05-30 16:06:17,516 - INFO - Epoch [13/30] Batch [1490/4715] Loss: 0.8594\n",
      "2025-05-30 16:06:19,060 - INFO - Epoch [13/30] Batch [1500/4715] Loss: 0.6167\n",
      "2025-05-30 16:06:20,577 - INFO - Epoch [13/30] Batch [1510/4715] Loss: 0.5663\n",
      "2025-05-30 16:06:22,127 - INFO - Epoch [13/30] Batch [1520/4715] Loss: 0.9314\n",
      "2025-05-30 16:06:23,930 - INFO - Epoch [13/30] Batch [1530/4715] Loss: 0.7613\n",
      "2025-05-30 16:06:25,538 - INFO - Epoch [13/30] Batch [1540/4715] Loss: 0.8356\n",
      "2025-05-30 16:06:27,094 - INFO - Epoch [13/30] Batch [1550/4715] Loss: 0.6996\n",
      "2025-05-30 16:06:28,579 - INFO - Epoch [13/30] Batch [1560/4715] Loss: 0.9240\n",
      "2025-05-30 16:06:30,119 - INFO - Epoch [13/30] Batch [1570/4715] Loss: 0.7213\n",
      "2025-05-30 16:06:31,662 - INFO - Epoch [13/30] Batch [1580/4715] Loss: 0.8501\n",
      "2025-05-30 16:06:33,243 - INFO - Epoch [13/30] Batch [1590/4715] Loss: 0.8299\n",
      "2025-05-30 16:06:34,786 - INFO - Epoch [13/30] Batch [1600/4715] Loss: 0.8502\n",
      "2025-05-30 16:06:36,292 - INFO - Epoch [13/30] Batch [1610/4715] Loss: 0.8280\n",
      "2025-05-30 16:06:37,836 - INFO - Epoch [13/30] Batch [1620/4715] Loss: 0.6491\n",
      "2025-05-30 16:06:39,461 - INFO - Epoch [13/30] Batch [1630/4715] Loss: 0.6743\n",
      "2025-05-30 16:06:41,038 - INFO - Epoch [13/30] Batch [1640/4715] Loss: 0.8361\n",
      "2025-05-30 16:06:42,590 - INFO - Epoch [13/30] Batch [1650/4715] Loss: 0.7710\n",
      "2025-05-30 16:06:44,163 - INFO - Epoch [13/30] Batch [1660/4715] Loss: 0.9940\n",
      "2025-05-30 16:06:45,719 - INFO - Epoch [13/30] Batch [1670/4715] Loss: 0.7657\n",
      "2025-05-30 16:06:47,267 - INFO - Epoch [13/30] Batch [1680/4715] Loss: 0.6163\n",
      "2025-05-30 16:06:48,788 - INFO - Epoch [13/30] Batch [1690/4715] Loss: 0.9828\n",
      "2025-05-30 16:06:50,366 - INFO - Epoch [13/30] Batch [1700/4715] Loss: 0.6502\n",
      "2025-05-30 16:06:51,909 - INFO - Epoch [13/30] Batch [1710/4715] Loss: 0.6972\n",
      "2025-05-30 16:06:53,446 - INFO - Epoch [13/30] Batch [1720/4715] Loss: 0.5635\n",
      "2025-05-30 16:06:55,076 - INFO - Epoch [13/30] Batch [1730/4715] Loss: 0.8644\n",
      "2025-05-30 16:06:56,762 - INFO - Epoch [13/30] Batch [1740/4715] Loss: 0.9009\n",
      "2025-05-30 16:06:58,386 - INFO - Epoch [13/30] Batch [1750/4715] Loss: 0.6721\n",
      "2025-05-30 16:06:59,955 - INFO - Epoch [13/30] Batch [1760/4715] Loss: 0.6836\n",
      "2025-05-30 16:07:01,479 - INFO - Epoch [13/30] Batch [1770/4715] Loss: 0.8358\n",
      "2025-05-30 16:07:03,055 - INFO - Epoch [13/30] Batch [1780/4715] Loss: 1.4446\n",
      "2025-05-30 16:07:04,674 - INFO - Epoch [13/30] Batch [1790/4715] Loss: 0.5224\n",
      "2025-05-30 16:07:06,142 - INFO - Epoch [13/30] Batch [1800/4715] Loss: 0.9408\n",
      "2025-05-30 16:07:07,674 - INFO - Epoch [13/30] Batch [1810/4715] Loss: 0.6148\n",
      "2025-05-30 16:07:09,313 - INFO - Epoch [13/30] Batch [1820/4715] Loss: 0.8431\n",
      "2025-05-30 16:07:10,854 - INFO - Epoch [13/30] Batch [1830/4715] Loss: 0.8002\n",
      "2025-05-30 16:07:12,345 - INFO - Epoch [13/30] Batch [1840/4715] Loss: 0.7485\n",
      "2025-05-30 16:07:13,867 - INFO - Epoch [13/30] Batch [1850/4715] Loss: 0.7409\n",
      "2025-05-30 16:07:15,384 - INFO - Epoch [13/30] Batch [1860/4715] Loss: 0.7390\n",
      "2025-05-30 16:07:16,859 - INFO - Epoch [13/30] Batch [1870/4715] Loss: 0.6362\n",
      "2025-05-30 16:07:18,485 - INFO - Epoch [13/30] Batch [1880/4715] Loss: 0.8710\n",
      "2025-05-30 16:07:20,042 - INFO - Epoch [13/30] Batch [1890/4715] Loss: 0.7666\n",
      "2025-05-30 16:07:21,638 - INFO - Epoch [13/30] Batch [1900/4715] Loss: 0.6501\n",
      "2025-05-30 16:07:23,189 - INFO - Epoch [13/30] Batch [1910/4715] Loss: 0.8220\n",
      "2025-05-30 16:07:24,825 - INFO - Epoch [13/30] Batch [1920/4715] Loss: 1.1259\n",
      "2025-05-30 16:07:26,461 - INFO - Epoch [13/30] Batch [1930/4715] Loss: 1.0508\n",
      "2025-05-30 16:07:28,030 - INFO - Epoch [13/30] Batch [1940/4715] Loss: 1.0605\n",
      "2025-05-30 16:07:29,601 - INFO - Epoch [13/30] Batch [1950/4715] Loss: 0.7062\n",
      "2025-05-30 16:07:31,165 - INFO - Epoch [13/30] Batch [1960/4715] Loss: 1.0687\n",
      "2025-05-30 16:07:32,620 - INFO - Epoch [13/30] Batch [1970/4715] Loss: 0.8926\n",
      "2025-05-30 16:07:34,165 - INFO - Epoch [13/30] Batch [1980/4715] Loss: 0.9060\n",
      "2025-05-30 16:07:35,833 - INFO - Epoch [13/30] Batch [1990/4715] Loss: 0.8659\n",
      "2025-05-30 16:07:37,510 - INFO - Epoch [13/30] Batch [2000/4715] Loss: 0.7681\n",
      "2025-05-30 16:07:39,080 - INFO - Epoch [13/30] Batch [2010/4715] Loss: 0.9235\n",
      "2025-05-30 16:07:40,614 - INFO - Epoch [13/30] Batch [2020/4715] Loss: 0.7087\n",
      "2025-05-30 16:07:42,251 - INFO - Epoch [13/30] Batch [2030/4715] Loss: 0.6496\n",
      "2025-05-30 16:07:43,793 - INFO - Epoch [13/30] Batch [2040/4715] Loss: 0.8141\n",
      "2025-05-30 16:07:45,424 - INFO - Epoch [13/30] Batch [2050/4715] Loss: 0.6953\n",
      "2025-05-30 16:07:46,941 - INFO - Epoch [13/30] Batch [2060/4715] Loss: 0.8714\n",
      "2025-05-30 16:07:48,517 - INFO - Epoch [13/30] Batch [2070/4715] Loss: 0.5115\n",
      "2025-05-30 16:07:50,087 - INFO - Epoch [13/30] Batch [2080/4715] Loss: 0.6921\n",
      "2025-05-30 16:07:51,666 - INFO - Epoch [13/30] Batch [2090/4715] Loss: 1.0226\n",
      "2025-05-30 16:07:53,232 - INFO - Epoch [13/30] Batch [2100/4715] Loss: 0.9945\n",
      "2025-05-30 16:07:54,896 - INFO - Epoch [13/30] Batch [2110/4715] Loss: 0.9754\n",
      "2025-05-30 16:07:56,385 - INFO - Epoch [13/30] Batch [2120/4715] Loss: 0.7806\n",
      "2025-05-30 16:07:57,957 - INFO - Epoch [13/30] Batch [2130/4715] Loss: 0.7798\n",
      "2025-05-30 16:07:59,497 - INFO - Epoch [13/30] Batch [2140/4715] Loss: 0.6649\n",
      "2025-05-30 16:08:01,127 - INFO - Epoch [13/30] Batch [2150/4715] Loss: 0.5693\n",
      "2025-05-30 16:08:02,752 - INFO - Epoch [13/30] Batch [2160/4715] Loss: 0.5178\n",
      "2025-05-30 16:08:04,304 - INFO - Epoch [13/30] Batch [2170/4715] Loss: 0.8758\n",
      "2025-05-30 16:08:05,848 - INFO - Epoch [13/30] Batch [2180/4715] Loss: 1.0450\n",
      "2025-05-30 16:08:07,484 - INFO - Epoch [13/30] Batch [2190/4715] Loss: 0.8117\n",
      "2025-05-30 16:08:09,008 - INFO - Epoch [13/30] Batch [2200/4715] Loss: 0.7200\n",
      "2025-05-30 16:08:10,608 - INFO - Epoch [13/30] Batch [2210/4715] Loss: 1.0265\n",
      "2025-05-30 16:08:12,192 - INFO - Epoch [13/30] Batch [2220/4715] Loss: 0.8578\n",
      "2025-05-30 16:08:13,721 - INFO - Epoch [13/30] Batch [2230/4715] Loss: 0.8316\n",
      "2025-05-30 16:08:15,335 - INFO - Epoch [13/30] Batch [2240/4715] Loss: 0.8705\n",
      "2025-05-30 16:08:16,995 - INFO - Epoch [13/30] Batch [2250/4715] Loss: 0.5446\n",
      "2025-05-30 16:08:18,623 - INFO - Epoch [13/30] Batch [2260/4715] Loss: 0.6407\n",
      "2025-05-30 16:08:20,171 - INFO - Epoch [13/30] Batch [2270/4715] Loss: 0.7441\n",
      "2025-05-30 16:08:21,699 - INFO - Epoch [13/30] Batch [2280/4715] Loss: 1.0700\n",
      "2025-05-30 16:08:23,259 - INFO - Epoch [13/30] Batch [2290/4715] Loss: 0.7922\n",
      "2025-05-30 16:08:24,858 - INFO - Epoch [13/30] Batch [2300/4715] Loss: 0.6710\n",
      "2025-05-30 16:08:26,466 - INFO - Epoch [13/30] Batch [2310/4715] Loss: 0.7666\n",
      "2025-05-30 16:08:27,978 - INFO - Epoch [13/30] Batch [2320/4715] Loss: 0.7336\n",
      "2025-05-30 16:08:29,518 - INFO - Epoch [13/30] Batch [2330/4715] Loss: 0.6413\n",
      "2025-05-30 16:08:31,127 - INFO - Epoch [13/30] Batch [2340/4715] Loss: 0.8831\n",
      "2025-05-30 16:08:32,660 - INFO - Epoch [13/30] Batch [2350/4715] Loss: 1.0760\n",
      "2025-05-30 16:08:34,218 - INFO - Epoch [13/30] Batch [2360/4715] Loss: 0.7911\n",
      "2025-05-30 16:08:35,680 - INFO - Epoch [13/30] Batch [2370/4715] Loss: 0.8455\n",
      "2025-05-30 16:08:37,237 - INFO - Epoch [13/30] Batch [2380/4715] Loss: 0.9699\n",
      "2025-05-30 16:08:38,735 - INFO - Epoch [13/30] Batch [2390/4715] Loss: 0.5644\n",
      "2025-05-30 16:08:40,282 - INFO - Epoch [13/30] Batch [2400/4715] Loss: 0.9499\n",
      "2025-05-30 16:08:41,820 - INFO - Epoch [13/30] Batch [2410/4715] Loss: 0.7394\n",
      "2025-05-30 16:08:43,301 - INFO - Epoch [13/30] Batch [2420/4715] Loss: 0.6764\n",
      "2025-05-30 16:08:44,848 - INFO - Epoch [13/30] Batch [2430/4715] Loss: 0.8461\n",
      "2025-05-30 16:08:46,366 - INFO - Epoch [13/30] Batch [2440/4715] Loss: 0.7132\n",
      "2025-05-30 16:08:47,912 - INFO - Epoch [13/30] Batch [2450/4715] Loss: 0.8837\n",
      "2025-05-30 16:08:49,428 - INFO - Epoch [13/30] Batch [2460/4715] Loss: 0.8159\n",
      "2025-05-30 16:08:50,913 - INFO - Epoch [13/30] Batch [2470/4715] Loss: 1.3236\n",
      "2025-05-30 16:08:52,535 - INFO - Epoch [13/30] Batch [2480/4715] Loss: 0.9451\n",
      "2025-05-30 16:08:54,206 - INFO - Epoch [13/30] Batch [2490/4715] Loss: 0.7613\n",
      "2025-05-30 16:08:55,769 - INFO - Epoch [13/30] Batch [2500/4715] Loss: 0.6908\n",
      "2025-05-30 16:08:57,328 - INFO - Epoch [13/30] Batch [2510/4715] Loss: 0.8545\n",
      "2025-05-30 16:08:58,822 - INFO - Epoch [13/30] Batch [2520/4715] Loss: 1.0021\n",
      "2025-05-30 16:09:00,270 - INFO - Epoch [13/30] Batch [2530/4715] Loss: 0.8103\n",
      "2025-05-30 16:09:01,756 - INFO - Epoch [13/30] Batch [2540/4715] Loss: 0.6464\n",
      "2025-05-30 16:09:03,352 - INFO - Epoch [13/30] Batch [2550/4715] Loss: 0.7748\n",
      "2025-05-30 16:09:05,094 - INFO - Epoch [13/30] Batch [2560/4715] Loss: 0.9325\n",
      "2025-05-30 16:09:06,664 - INFO - Epoch [13/30] Batch [2570/4715] Loss: 0.7139\n",
      "2025-05-30 16:09:08,217 - INFO - Epoch [13/30] Batch [2580/4715] Loss: 0.8917\n",
      "2025-05-30 16:09:09,726 - INFO - Epoch [13/30] Batch [2590/4715] Loss: 0.9741\n",
      "2025-05-30 16:09:11,324 - INFO - Epoch [13/30] Batch [2600/4715] Loss: 0.9075\n",
      "2025-05-30 16:09:12,896 - INFO - Epoch [13/30] Batch [2610/4715] Loss: 0.8700\n",
      "2025-05-30 16:09:14,446 - INFO - Epoch [13/30] Batch [2620/4715] Loss: 1.2337\n",
      "2025-05-30 16:09:16,011 - INFO - Epoch [13/30] Batch [2630/4715] Loss: 0.5108\n",
      "2025-05-30 16:09:17,618 - INFO - Epoch [13/30] Batch [2640/4715] Loss: 0.8174\n",
      "2025-05-30 16:09:19,119 - INFO - Epoch [13/30] Batch [2650/4715] Loss: 0.8339\n",
      "2025-05-30 16:09:20,785 - INFO - Epoch [13/30] Batch [2660/4715] Loss: 0.8788\n",
      "2025-05-30 16:09:22,360 - INFO - Epoch [13/30] Batch [2670/4715] Loss: 0.7414\n",
      "2025-05-30 16:09:23,932 - INFO - Epoch [13/30] Batch [2680/4715] Loss: 0.6823\n",
      "2025-05-30 16:09:25,463 - INFO - Epoch [13/30] Batch [2690/4715] Loss: 0.8440\n",
      "2025-05-30 16:09:26,965 - INFO - Epoch [13/30] Batch [2700/4715] Loss: 0.9198\n",
      "2025-05-30 16:09:28,514 - INFO - Epoch [13/30] Batch [2710/4715] Loss: 0.6677\n",
      "2025-05-30 16:09:30,002 - INFO - Epoch [13/30] Batch [2720/4715] Loss: 0.8065\n",
      "2025-05-30 16:09:31,581 - INFO - Epoch [13/30] Batch [2730/4715] Loss: 0.8206\n",
      "2025-05-30 16:09:33,152 - INFO - Epoch [13/30] Batch [2740/4715] Loss: 0.7078\n",
      "2025-05-30 16:09:34,776 - INFO - Epoch [13/30] Batch [2750/4715] Loss: 0.8095\n",
      "2025-05-30 16:09:36,364 - INFO - Epoch [13/30] Batch [2760/4715] Loss: 0.8682\n",
      "2025-05-30 16:09:37,902 - INFO - Epoch [13/30] Batch [2770/4715] Loss: 0.7175\n",
      "2025-05-30 16:09:39,420 - INFO - Epoch [13/30] Batch [2780/4715] Loss: 0.6916\n",
      "2025-05-30 16:09:41,015 - INFO - Epoch [13/30] Batch [2790/4715] Loss: 0.8247\n",
      "2025-05-30 16:09:42,562 - INFO - Epoch [13/30] Batch [2800/4715] Loss: 0.8453\n",
      "2025-05-30 16:09:44,109 - INFO - Epoch [13/30] Batch [2810/4715] Loss: 0.9665\n",
      "2025-05-30 16:09:45,718 - INFO - Epoch [13/30] Batch [2820/4715] Loss: 0.7306\n",
      "2025-05-30 16:09:47,259 - INFO - Epoch [13/30] Batch [2830/4715] Loss: 0.6765\n",
      "2025-05-30 16:09:48,728 - INFO - Epoch [13/30] Batch [2840/4715] Loss: 0.9428\n",
      "2025-05-30 16:09:50,370 - INFO - Epoch [13/30] Batch [2850/4715] Loss: 0.7331\n",
      "2025-05-30 16:09:51,916 - INFO - Epoch [13/30] Batch [2860/4715] Loss: 0.7097\n",
      "2025-05-30 16:09:53,583 - INFO - Epoch [13/30] Batch [2870/4715] Loss: 0.8026\n",
      "2025-05-30 16:09:55,215 - INFO - Epoch [13/30] Batch [2880/4715] Loss: 0.7908\n",
      "2025-05-30 16:09:56,751 - INFO - Epoch [13/30] Batch [2890/4715] Loss: 0.6986\n",
      "2025-05-30 16:09:58,262 - INFO - Epoch [13/30] Batch [2900/4715] Loss: 0.9524\n",
      "2025-05-30 16:09:59,800 - INFO - Epoch [13/30] Batch [2910/4715] Loss: 0.9111\n",
      "2025-05-30 16:10:01,408 - INFO - Epoch [13/30] Batch [2920/4715] Loss: 0.7778\n",
      "2025-05-30 16:10:02,996 - INFO - Epoch [13/30] Batch [2930/4715] Loss: 0.9216\n",
      "2025-05-30 16:10:04,553 - INFO - Epoch [13/30] Batch [2940/4715] Loss: 0.7635\n",
      "2025-05-30 16:10:06,102 - INFO - Epoch [13/30] Batch [2950/4715] Loss: 0.9659\n",
      "2025-05-30 16:10:07,747 - INFO - Epoch [13/30] Batch [2960/4715] Loss: 0.7083\n",
      "2025-05-30 16:10:09,501 - INFO - Epoch [13/30] Batch [2970/4715] Loss: 0.9807\n",
      "2025-05-30 16:10:11,063 - INFO - Epoch [13/30] Batch [2980/4715] Loss: 0.8121\n",
      "2025-05-30 16:10:12,629 - INFO - Epoch [13/30] Batch [2990/4715] Loss: 0.8883\n",
      "2025-05-30 16:10:14,200 - INFO - Epoch [13/30] Batch [3000/4715] Loss: 0.9854\n",
      "2025-05-30 16:10:15,753 - INFO - Epoch [13/30] Batch [3010/4715] Loss: 0.9085\n",
      "2025-05-30 16:10:17,276 - INFO - Epoch [13/30] Batch [3020/4715] Loss: 0.7527\n",
      "2025-05-30 16:10:18,873 - INFO - Epoch [13/30] Batch [3030/4715] Loss: 0.7148\n",
      "2025-05-30 16:10:20,497 - INFO - Epoch [13/30] Batch [3040/4715] Loss: 0.7524\n",
      "2025-05-30 16:10:22,079 - INFO - Epoch [13/30] Batch [3050/4715] Loss: 0.9525\n",
      "2025-05-30 16:10:23,658 - INFO - Epoch [13/30] Batch [3060/4715] Loss: 0.8796\n",
      "2025-05-30 16:10:25,167 - INFO - Epoch [13/30] Batch [3070/4715] Loss: 0.6246\n",
      "2025-05-30 16:10:26,741 - INFO - Epoch [13/30] Batch [3080/4715] Loss: 0.7748\n",
      "2025-05-30 16:10:28,299 - INFO - Epoch [13/30] Batch [3090/4715] Loss: 0.7065\n",
      "2025-05-30 16:10:29,962 - INFO - Epoch [13/30] Batch [3100/4715] Loss: 0.9050\n",
      "2025-05-30 16:10:31,661 - INFO - Epoch [13/30] Batch [3110/4715] Loss: 0.7572\n",
      "2025-05-30 16:10:33,128 - INFO - Epoch [13/30] Batch [3120/4715] Loss: 0.6308\n",
      "2025-05-30 16:10:34,709 - INFO - Epoch [13/30] Batch [3130/4715] Loss: 0.8991\n",
      "2025-05-30 16:10:36,289 - INFO - Epoch [13/30] Batch [3140/4715] Loss: 0.7112\n",
      "2025-05-30 16:10:37,867 - INFO - Epoch [13/30] Batch [3150/4715] Loss: 0.7888\n",
      "2025-05-30 16:10:39,474 - INFO - Epoch [13/30] Batch [3160/4715] Loss: 0.6951\n",
      "2025-05-30 16:10:41,028 - INFO - Epoch [13/30] Batch [3170/4715] Loss: 0.6499\n",
      "2025-05-30 16:10:42,596 - INFO - Epoch [13/30] Batch [3180/4715] Loss: 0.7381\n",
      "2025-05-30 16:10:44,170 - INFO - Epoch [13/30] Batch [3190/4715] Loss: 0.8229\n",
      "2025-05-30 16:10:45,704 - INFO - Epoch [13/30] Batch [3200/4715] Loss: 0.9979\n",
      "2025-05-30 16:10:47,256 - INFO - Epoch [13/30] Batch [3210/4715] Loss: 0.7596\n",
      "2025-05-30 16:10:48,843 - INFO - Epoch [13/30] Batch [3220/4715] Loss: 0.6440\n",
      "2025-05-30 16:10:50,315 - INFO - Epoch [13/30] Batch [3230/4715] Loss: 0.6269\n",
      "2025-05-30 16:10:51,804 - INFO - Epoch [13/30] Batch [3240/4715] Loss: 0.8044\n",
      "2025-05-30 16:10:53,414 - INFO - Epoch [13/30] Batch [3250/4715] Loss: 0.9749\n",
      "2025-05-30 16:10:55,080 - INFO - Epoch [13/30] Batch [3260/4715] Loss: 0.8478\n",
      "2025-05-30 16:10:56,631 - INFO - Epoch [13/30] Batch [3270/4715] Loss: 0.8319\n",
      "2025-05-30 16:10:58,191 - INFO - Epoch [13/30] Batch [3280/4715] Loss: 0.6556\n",
      "2025-05-30 16:10:59,686 - INFO - Epoch [13/30] Batch [3290/4715] Loss: 0.8927\n",
      "2025-05-30 16:11:01,136 - INFO - Epoch [13/30] Batch [3300/4715] Loss: 0.8607\n",
      "2025-05-30 16:11:02,661 - INFO - Epoch [13/30] Batch [3310/4715] Loss: 0.6802\n",
      "2025-05-30 16:11:04,299 - INFO - Epoch [13/30] Batch [3320/4715] Loss: 0.8811\n",
      "2025-05-30 16:11:05,832 - INFO - Epoch [13/30] Batch [3330/4715] Loss: 0.6646\n",
      "2025-05-30 16:11:07,442 - INFO - Epoch [13/30] Batch [3340/4715] Loss: 0.9875\n",
      "2025-05-30 16:11:08,974 - INFO - Epoch [13/30] Batch [3350/4715] Loss: 0.8680\n",
      "2025-05-30 16:11:10,618 - INFO - Epoch [13/30] Batch [3360/4715] Loss: 0.6731\n",
      "2025-05-30 16:11:12,159 - INFO - Epoch [13/30] Batch [3370/4715] Loss: 1.1369\n",
      "2025-05-30 16:11:13,670 - INFO - Epoch [13/30] Batch [3380/4715] Loss: 0.9075\n",
      "2025-05-30 16:11:15,240 - INFO - Epoch [13/30] Batch [3390/4715] Loss: 0.8932\n",
      "2025-05-30 16:11:16,868 - INFO - Epoch [13/30] Batch [3400/4715] Loss: 0.7339\n",
      "2025-05-30 16:11:18,479 - INFO - Epoch [13/30] Batch [3410/4715] Loss: 0.6927\n",
      "2025-05-30 16:11:20,072 - INFO - Epoch [13/30] Batch [3420/4715] Loss: 0.8136\n",
      "2025-05-30 16:11:21,629 - INFO - Epoch [13/30] Batch [3430/4715] Loss: 0.9170\n",
      "2025-05-30 16:11:23,270 - INFO - Epoch [13/30] Batch [3440/4715] Loss: 0.7121\n",
      "2025-05-30 16:11:24,842 - INFO - Epoch [13/30] Batch [3450/4715] Loss: 1.0802\n",
      "2025-05-30 16:11:26,448 - INFO - Epoch [13/30] Batch [3460/4715] Loss: 0.6996\n",
      "2025-05-30 16:11:28,059 - INFO - Epoch [13/30] Batch [3470/4715] Loss: 1.0320\n",
      "2025-05-30 16:11:29,576 - INFO - Epoch [13/30] Batch [3480/4715] Loss: 0.6848\n",
      "2025-05-30 16:11:31,146 - INFO - Epoch [13/30] Batch [3490/4715] Loss: 0.7030\n",
      "2025-05-30 16:11:32,670 - INFO - Epoch [13/30] Batch [3500/4715] Loss: 0.5189\n",
      "2025-05-30 16:11:34,329 - INFO - Epoch [13/30] Batch [3510/4715] Loss: 0.5904\n",
      "2025-05-30 16:11:35,904 - INFO - Epoch [13/30] Batch [3520/4715] Loss: 0.7560\n",
      "2025-05-30 16:11:37,410 - INFO - Epoch [13/30] Batch [3530/4715] Loss: 0.9289\n",
      "2025-05-30 16:11:38,947 - INFO - Epoch [13/30] Batch [3540/4715] Loss: 0.7520\n",
      "2025-05-30 16:11:40,678 - INFO - Epoch [13/30] Batch [3550/4715] Loss: 0.7949\n",
      "2025-05-30 16:11:42,257 - INFO - Epoch [13/30] Batch [3560/4715] Loss: 0.7782\n",
      "2025-05-30 16:11:43,868 - INFO - Epoch [13/30] Batch [3570/4715] Loss: 0.6196\n",
      "2025-05-30 16:11:45,448 - INFO - Epoch [13/30] Batch [3580/4715] Loss: 0.9226\n",
      "2025-05-30 16:11:47,105 - INFO - Epoch [13/30] Batch [3590/4715] Loss: 0.6550\n",
      "2025-05-30 16:11:48,656 - INFO - Epoch [13/30] Batch [3600/4715] Loss: 0.7253\n",
      "2025-05-30 16:11:50,270 - INFO - Epoch [13/30] Batch [3610/4715] Loss: 0.6026\n",
      "2025-05-30 16:11:51,874 - INFO - Epoch [13/30] Batch [3620/4715] Loss: 0.9166\n",
      "2025-05-30 16:11:53,472 - INFO - Epoch [13/30] Batch [3630/4715] Loss: 1.0655\n",
      "2025-05-30 16:11:55,085 - INFO - Epoch [13/30] Batch [3640/4715] Loss: 0.7469\n",
      "2025-05-30 16:11:56,661 - INFO - Epoch [13/30] Batch [3650/4715] Loss: 0.8841\n",
      "2025-05-30 16:11:58,214 - INFO - Epoch [13/30] Batch [3660/4715] Loss: 0.7784\n",
      "2025-05-30 16:11:59,772 - INFO - Epoch [13/30] Batch [3670/4715] Loss: 0.7968\n",
      "2025-05-30 16:12:01,374 - INFO - Epoch [13/30] Batch [3680/4715] Loss: 0.6918\n",
      "2025-05-30 16:12:02,940 - INFO - Epoch [13/30] Batch [3690/4715] Loss: 0.6469\n",
      "2025-05-30 16:12:04,598 - INFO - Epoch [13/30] Batch [3700/4715] Loss: 0.9086\n",
      "2025-05-30 16:12:06,204 - INFO - Epoch [13/30] Batch [3710/4715] Loss: 0.7379\n",
      "2025-05-30 16:12:07,817 - INFO - Epoch [13/30] Batch [3720/4715] Loss: 0.6924\n",
      "2025-05-30 16:12:09,394 - INFO - Epoch [13/30] Batch [3730/4715] Loss: 0.6842\n",
      "2025-05-30 16:12:11,065 - INFO - Epoch [13/30] Batch [3740/4715] Loss: 0.7041\n",
      "2025-05-30 16:12:12,649 - INFO - Epoch [13/30] Batch [3750/4715] Loss: 0.8623\n",
      "2025-05-30 16:12:14,254 - INFO - Epoch [13/30] Batch [3760/4715] Loss: 1.0292\n",
      "2025-05-30 16:12:15,843 - INFO - Epoch [13/30] Batch [3770/4715] Loss: 0.9847\n",
      "2025-05-30 16:12:17,510 - INFO - Epoch [13/30] Batch [3780/4715] Loss: 0.9331\n",
      "2025-05-30 16:12:19,286 - INFO - Epoch [13/30] Batch [3790/4715] Loss: 0.8431\n",
      "2025-05-30 16:12:20,864 - INFO - Epoch [13/30] Batch [3800/4715] Loss: 0.7562\n",
      "2025-05-30 16:12:22,403 - INFO - Epoch [13/30] Batch [3810/4715] Loss: 0.6801\n",
      "2025-05-30 16:12:23,915 - INFO - Epoch [13/30] Batch [3820/4715] Loss: 0.8876\n",
      "2025-05-30 16:12:25,391 - INFO - Epoch [13/30] Batch [3830/4715] Loss: 0.9755\n",
      "2025-05-30 16:12:26,963 - INFO - Epoch [13/30] Batch [3840/4715] Loss: 0.6609\n",
      "2025-05-30 16:12:28,565 - INFO - Epoch [13/30] Batch [3850/4715] Loss: 0.8254\n",
      "2025-05-30 16:12:30,085 - INFO - Epoch [13/30] Batch [3860/4715] Loss: 0.7294\n",
      "2025-05-30 16:12:31,625 - INFO - Epoch [13/30] Batch [3870/4715] Loss: 0.9311\n",
      "2025-05-30 16:12:33,186 - INFO - Epoch [13/30] Batch [3880/4715] Loss: 0.9263\n",
      "2025-05-30 16:12:34,786 - INFO - Epoch [13/30] Batch [3890/4715] Loss: 0.9090\n",
      "2025-05-30 16:12:36,340 - INFO - Epoch [13/30] Batch [3900/4715] Loss: 1.0211\n",
      "2025-05-30 16:12:37,919 - INFO - Epoch [13/30] Batch [3910/4715] Loss: 0.6678\n",
      "2025-05-30 16:12:39,423 - INFO - Epoch [13/30] Batch [3920/4715] Loss: 0.8812\n",
      "2025-05-30 16:12:40,962 - INFO - Epoch [13/30] Batch [3930/4715] Loss: 0.8333\n",
      "2025-05-30 16:12:42,475 - INFO - Epoch [13/30] Batch [3940/4715] Loss: 0.9848\n",
      "2025-05-30 16:12:44,027 - INFO - Epoch [13/30] Batch [3950/4715] Loss: 1.0197\n",
      "2025-05-30 16:12:45,570 - INFO - Epoch [13/30] Batch [3960/4715] Loss: 0.7956\n",
      "2025-05-30 16:12:47,213 - INFO - Epoch [13/30] Batch [3970/4715] Loss: 0.9825\n",
      "2025-05-30 16:12:48,800 - INFO - Epoch [13/30] Batch [3980/4715] Loss: 0.8281\n",
      "2025-05-30 16:12:50,384 - INFO - Epoch [13/30] Batch [3990/4715] Loss: 0.5488\n",
      "2025-05-30 16:12:51,967 - INFO - Epoch [13/30] Batch [4000/4715] Loss: 0.9565\n",
      "2025-05-30 16:12:53,590 - INFO - Epoch [13/30] Batch [4010/4715] Loss: 0.8527\n",
      "2025-05-30 16:12:55,123 - INFO - Epoch [13/30] Batch [4020/4715] Loss: 0.7776\n",
      "2025-05-30 16:12:56,633 - INFO - Epoch [13/30] Batch [4030/4715] Loss: 0.7610\n",
      "2025-05-30 16:12:58,335 - INFO - Epoch [13/30] Batch [4040/4715] Loss: 0.5580\n",
      "2025-05-30 16:13:00,004 - INFO - Epoch [13/30] Batch [4050/4715] Loss: 0.8026\n",
      "2025-05-30 16:13:01,670 - INFO - Epoch [13/30] Batch [4060/4715] Loss: 0.8095\n",
      "2025-05-30 16:13:03,242 - INFO - Epoch [13/30] Batch [4070/4715] Loss: 0.7502\n",
      "2025-05-30 16:13:04,786 - INFO - Epoch [13/30] Batch [4080/4715] Loss: 0.7332\n",
      "2025-05-30 16:13:06,354 - INFO - Epoch [13/30] Batch [4090/4715] Loss: 1.0893\n",
      "2025-05-30 16:13:07,929 - INFO - Epoch [13/30] Batch [4100/4715] Loss: 0.8984\n",
      "2025-05-30 16:13:09,459 - INFO - Epoch [13/30] Batch [4110/4715] Loss: 1.1449\n",
      "2025-05-30 16:13:11,083 - INFO - Epoch [13/30] Batch [4120/4715] Loss: 0.7480\n",
      "2025-05-30 16:13:12,621 - INFO - Epoch [13/30] Batch [4130/4715] Loss: 0.9067\n",
      "2025-05-30 16:13:14,191 - INFO - Epoch [13/30] Batch [4140/4715] Loss: 0.9064\n",
      "2025-05-30 16:13:15,742 - INFO - Epoch [13/30] Batch [4150/4715] Loss: 0.7649\n",
      "2025-05-30 16:13:17,342 - INFO - Epoch [13/30] Batch [4160/4715] Loss: 0.9450\n",
      "2025-05-30 16:13:18,914 - INFO - Epoch [13/30] Batch [4170/4715] Loss: 0.9095\n",
      "2025-05-30 16:13:20,439 - INFO - Epoch [13/30] Batch [4180/4715] Loss: 0.7039\n",
      "2025-05-30 16:13:22,045 - INFO - Epoch [13/30] Batch [4190/4715] Loss: 0.6336\n",
      "2025-05-30 16:13:23,726 - INFO - Epoch [13/30] Batch [4200/4715] Loss: 0.6935\n",
      "2025-05-30 16:13:25,180 - INFO - Epoch [13/30] Batch [4210/4715] Loss: 0.6732\n",
      "2025-05-30 16:13:26,750 - INFO - Epoch [13/30] Batch [4220/4715] Loss: 0.6722\n",
      "2025-05-30 16:13:28,271 - INFO - Epoch [13/30] Batch [4230/4715] Loss: 1.0948\n",
      "2025-05-30 16:13:29,856 - INFO - Epoch [13/30] Batch [4240/4715] Loss: 0.6746\n",
      "2025-05-30 16:13:31,486 - INFO - Epoch [13/30] Batch [4250/4715] Loss: 0.6573\n",
      "2025-05-30 16:13:33,117 - INFO - Epoch [13/30] Batch [4260/4715] Loss: 0.7888\n",
      "2025-05-30 16:13:34,639 - INFO - Epoch [13/30] Batch [4270/4715] Loss: 0.7849\n",
      "2025-05-30 16:13:36,101 - INFO - Epoch [13/30] Batch [4280/4715] Loss: 0.7878\n",
      "2025-05-30 16:13:37,698 - INFO - Epoch [13/30] Batch [4290/4715] Loss: 1.0450\n",
      "2025-05-30 16:13:39,186 - INFO - Epoch [13/30] Batch [4300/4715] Loss: 0.7748\n",
      "2025-05-30 16:13:40,708 - INFO - Epoch [13/30] Batch [4310/4715] Loss: 0.8622\n",
      "2025-05-30 16:13:42,214 - INFO - Epoch [13/30] Batch [4320/4715] Loss: 0.7173\n",
      "2025-05-30 16:13:43,732 - INFO - Epoch [13/30] Batch [4330/4715] Loss: 0.7687\n",
      "2025-05-30 16:13:45,274 - INFO - Epoch [13/30] Batch [4340/4715] Loss: 0.9869\n",
      "2025-05-30 16:13:46,886 - INFO - Epoch [13/30] Batch [4350/4715] Loss: 0.8095\n",
      "2025-05-30 16:13:48,377 - INFO - Epoch [13/30] Batch [4360/4715] Loss: 0.7990\n",
      "2025-05-30 16:13:49,935 - INFO - Epoch [13/30] Batch [4370/4715] Loss: 0.7067\n",
      "2025-05-30 16:13:51,602 - INFO - Epoch [13/30] Batch [4380/4715] Loss: 0.7064\n",
      "2025-05-30 16:13:53,221 - INFO - Epoch [13/30] Batch [4390/4715] Loss: 0.8996\n",
      "2025-05-30 16:13:54,830 - INFO - Epoch [13/30] Batch [4400/4715] Loss: 0.6169\n",
      "2025-05-30 16:13:56,382 - INFO - Epoch [13/30] Batch [4410/4715] Loss: 0.8776\n",
      "2025-05-30 16:13:57,877 - INFO - Epoch [13/30] Batch [4420/4715] Loss: 0.6907\n",
      "2025-05-30 16:13:59,342 - INFO - Epoch [13/30] Batch [4430/4715] Loss: 0.6591\n",
      "2025-05-30 16:14:00,898 - INFO - Epoch [13/30] Batch [4440/4715] Loss: 0.8277\n",
      "2025-05-30 16:14:02,475 - INFO - Epoch [13/30] Batch [4450/4715] Loss: 1.0278\n",
      "2025-05-30 16:14:04,003 - INFO - Epoch [13/30] Batch [4460/4715] Loss: 0.7886\n",
      "2025-05-30 16:14:05,695 - INFO - Epoch [13/30] Batch [4470/4715] Loss: 0.8278\n",
      "2025-05-30 16:14:07,273 - INFO - Epoch [13/30] Batch [4480/4715] Loss: 0.6501\n",
      "2025-05-30 16:14:08,770 - INFO - Epoch [13/30] Batch [4490/4715] Loss: 0.8816\n",
      "2025-05-30 16:14:10,277 - INFO - Epoch [13/30] Batch [4500/4715] Loss: 1.0573\n",
      "2025-05-30 16:14:11,941 - INFO - Epoch [13/30] Batch [4510/4715] Loss: 0.9274\n",
      "2025-05-30 16:14:13,497 - INFO - Epoch [13/30] Batch [4520/4715] Loss: 0.5826\n",
      "2025-05-30 16:14:14,996 - INFO - Epoch [13/30] Batch [4530/4715] Loss: 0.6306\n",
      "2025-05-30 16:14:16,536 - INFO - Epoch [13/30] Batch [4540/4715] Loss: 0.8472\n",
      "2025-05-30 16:14:18,190 - INFO - Epoch [13/30] Batch [4550/4715] Loss: 0.7479\n",
      "2025-05-30 16:14:19,808 - INFO - Epoch [13/30] Batch [4560/4715] Loss: 0.9155\n",
      "2025-05-30 16:14:21,391 - INFO - Epoch [13/30] Batch [4570/4715] Loss: 0.7788\n",
      "2025-05-30 16:14:22,900 - INFO - Epoch [13/30] Batch [4580/4715] Loss: 0.8361\n",
      "2025-05-30 16:14:24,412 - INFO - Epoch [13/30] Batch [4590/4715] Loss: 0.7427\n",
      "2025-05-30 16:14:25,933 - INFO - Epoch [13/30] Batch [4600/4715] Loss: 0.7485\n",
      "2025-05-30 16:14:27,563 - INFO - Epoch [13/30] Batch [4610/4715] Loss: 0.6155\n",
      "2025-05-30 16:14:29,162 - INFO - Epoch [13/30] Batch [4620/4715] Loss: 0.6640\n",
      "2025-05-30 16:14:30,719 - INFO - Epoch [13/30] Batch [4630/4715] Loss: 0.7740\n",
      "2025-05-30 16:14:32,212 - INFO - Epoch [13/30] Batch [4640/4715] Loss: 0.6955\n",
      "2025-05-30 16:14:33,788 - INFO - Epoch [13/30] Batch [4650/4715] Loss: 0.6104\n",
      "2025-05-30 16:14:35,436 - INFO - Epoch [13/30] Batch [4660/4715] Loss: 0.7458\n",
      "2025-05-30 16:14:36,967 - INFO - Epoch [13/30] Batch [4670/4715] Loss: 0.8154\n",
      "2025-05-30 16:14:38,444 - INFO - Epoch [13/30] Batch [4680/4715] Loss: 0.7508\n",
      "2025-05-30 16:14:40,014 - INFO - Epoch [13/30] Batch [4690/4715] Loss: 0.9817\n",
      "2025-05-30 16:14:41,574 - INFO - Epoch [13/30] Batch [4700/4715] Loss: 0.6848\n",
      "2025-05-30 16:14:43,141 - INFO - Epoch [13/30] Batch [4710/4715] Loss: 0.8452\n",
      "2025-05-30 16:15:22,421 - INFO - \n",
      "Epoch [13/30] Time: 778.50s\n",
      "2025-05-30 16:15:22,421 - INFO - Train Loss: 0.8052, Valid Loss: 0.8048\n",
      "2025-05-30 16:15:22,422 - INFO - Valid AUC (macro): 0.7410, F1 (macro): 0.5812\n",
      "2025-05-30 16:15:22,955 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\best_model.pth\n",
      "2025-05-30 16:15:22,956 - INFO - New best model saved with AUC: 0.7410\n",
      "2025-05-30 16:15:23,482 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 16:15:23,483 - INFO - Saved checkpoint at epoch 13\n",
      "2025-05-30 16:15:23,690 - INFO - Epoch [14/30] Batch [0/4715] Loss: 1.0216\n",
      "2025-05-30 16:15:25,400 - INFO - Epoch [14/30] Batch [10/4715] Loss: 0.8775\n",
      "2025-05-30 16:15:26,995 - INFO - Epoch [14/30] Batch [20/4715] Loss: 0.7800\n",
      "2025-05-30 16:15:28,572 - INFO - Epoch [14/30] Batch [30/4715] Loss: 0.7248\n",
      "2025-05-30 16:15:30,120 - INFO - Epoch [14/30] Batch [40/4715] Loss: 0.8944\n",
      "2025-05-30 16:15:31,676 - INFO - Epoch [14/30] Batch [50/4715] Loss: 0.6236\n",
      "2025-05-30 16:15:33,272 - INFO - Epoch [14/30] Batch [60/4715] Loss: 0.7511\n",
      "2025-05-30 16:15:34,829 - INFO - Epoch [14/30] Batch [70/4715] Loss: 0.9126\n",
      "2025-05-30 16:15:36,391 - INFO - Epoch [14/30] Batch [80/4715] Loss: 0.7125\n",
      "2025-05-30 16:15:38,036 - INFO - Epoch [14/30] Batch [90/4715] Loss: 0.9814\n",
      "2025-05-30 16:15:39,645 - INFO - Epoch [14/30] Batch [100/4715] Loss: 0.8322\n",
      "2025-05-30 16:15:41,229 - INFO - Epoch [14/30] Batch [110/4715] Loss: 0.6644\n",
      "2025-05-30 16:15:42,774 - INFO - Epoch [14/30] Batch [120/4715] Loss: 0.9190\n",
      "2025-05-30 16:15:44,326 - INFO - Epoch [14/30] Batch [130/4715] Loss: 0.9537\n",
      "2025-05-30 16:15:45,855 - INFO - Epoch [14/30] Batch [140/4715] Loss: 0.6823\n",
      "2025-05-30 16:15:47,450 - INFO - Epoch [14/30] Batch [150/4715] Loss: 0.9902\n",
      "2025-05-30 16:15:48,991 - INFO - Epoch [14/30] Batch [160/4715] Loss: 0.9109\n",
      "2025-05-30 16:15:50,510 - INFO - Epoch [14/30] Batch [170/4715] Loss: 0.6058\n",
      "2025-05-30 16:15:52,123 - INFO - Epoch [14/30] Batch [180/4715] Loss: 0.9662\n",
      "2025-05-30 16:15:53,639 - INFO - Epoch [14/30] Batch [190/4715] Loss: 0.8386\n",
      "2025-05-30 16:15:55,153 - INFO - Epoch [14/30] Batch [200/4715] Loss: 0.7789\n",
      "2025-05-30 16:15:56,687 - INFO - Epoch [14/30] Batch [210/4715] Loss: 0.9738\n",
      "2025-05-30 16:15:58,322 - INFO - Epoch [14/30] Batch [220/4715] Loss: 0.8419\n",
      "2025-05-30 16:15:59,946 - INFO - Epoch [14/30] Batch [230/4715] Loss: 0.7173\n",
      "2025-05-30 16:16:01,456 - INFO - Epoch [14/30] Batch [240/4715] Loss: 0.7561\n",
      "2025-05-30 16:16:03,077 - INFO - Epoch [14/30] Batch [250/4715] Loss: 0.7409\n",
      "2025-05-30 16:16:04,597 - INFO - Epoch [14/30] Batch [260/4715] Loss: 1.2005\n",
      "2025-05-30 16:16:06,101 - INFO - Epoch [14/30] Batch [270/4715] Loss: 1.0666\n",
      "2025-05-30 16:16:07,663 - INFO - Epoch [14/30] Batch [280/4715] Loss: 0.8364\n",
      "2025-05-30 16:16:09,233 - INFO - Epoch [14/30] Batch [290/4715] Loss: 0.7630\n",
      "2025-05-30 16:16:10,808 - INFO - Epoch [14/30] Batch [300/4715] Loss: 0.7203\n",
      "2025-05-30 16:16:12,344 - INFO - Epoch [14/30] Batch [310/4715] Loss: 0.7108\n",
      "2025-05-30 16:16:13,898 - INFO - Epoch [14/30] Batch [320/4715] Loss: 0.7503\n",
      "2025-05-30 16:16:15,439 - INFO - Epoch [14/30] Batch [330/4715] Loss: 0.7147\n",
      "2025-05-30 16:16:16,927 - INFO - Epoch [14/30] Batch [340/4715] Loss: 0.8052\n",
      "2025-05-30 16:16:18,516 - INFO - Epoch [14/30] Batch [350/4715] Loss: 0.7041\n",
      "2025-05-30 16:16:20,093 - INFO - Epoch [14/30] Batch [360/4715] Loss: 1.0262\n",
      "2025-05-30 16:16:21,623 - INFO - Epoch [14/30] Batch [370/4715] Loss: 0.8575\n",
      "2025-05-30 16:16:23,171 - INFO - Epoch [14/30] Batch [380/4715] Loss: 0.5911\n",
      "2025-05-30 16:16:24,762 - INFO - Epoch [14/30] Batch [390/4715] Loss: 0.6864\n",
      "2025-05-30 16:16:26,293 - INFO - Epoch [14/30] Batch [400/4715] Loss: 0.6797\n",
      "2025-05-30 16:16:27,869 - INFO - Epoch [14/30] Batch [410/4715] Loss: 0.9593\n",
      "2025-05-30 16:16:29,465 - INFO - Epoch [14/30] Batch [420/4715] Loss: 0.9503\n",
      "2025-05-30 16:16:31,037 - INFO - Epoch [14/30] Batch [430/4715] Loss: 0.9571\n",
      "2025-05-30 16:16:32,556 - INFO - Epoch [14/30] Batch [440/4715] Loss: 0.7921\n",
      "2025-05-30 16:16:34,141 - INFO - Epoch [14/30] Batch [450/4715] Loss: 1.1292\n",
      "2025-05-30 16:16:35,757 - INFO - Epoch [14/30] Batch [460/4715] Loss: 0.6634\n",
      "2025-05-30 16:16:37,301 - INFO - Epoch [14/30] Batch [470/4715] Loss: 1.0352\n",
      "2025-05-30 16:16:38,867 - INFO - Epoch [14/30] Batch [480/4715] Loss: 1.0149\n",
      "2025-05-30 16:16:40,394 - INFO - Epoch [14/30] Batch [490/4715] Loss: 0.5318\n",
      "2025-05-30 16:16:41,975 - INFO - Epoch [14/30] Batch [500/4715] Loss: 0.8427\n",
      "2025-05-30 16:16:43,491 - INFO - Epoch [14/30] Batch [510/4715] Loss: 0.6604\n",
      "2025-05-30 16:16:45,140 - INFO - Epoch [14/30] Batch [520/4715] Loss: 0.9545\n",
      "2025-05-30 16:16:46,676 - INFO - Epoch [14/30] Batch [530/4715] Loss: 0.7300\n",
      "2025-05-30 16:16:48,249 - INFO - Epoch [14/30] Batch [540/4715] Loss: 0.9679\n",
      "2025-05-30 16:16:49,889 - INFO - Epoch [14/30] Batch [550/4715] Loss: 0.8612\n",
      "2025-05-30 16:16:51,463 - INFO - Epoch [14/30] Batch [560/4715] Loss: 0.7037\n",
      "2025-05-30 16:16:53,026 - INFO - Epoch [14/30] Batch [570/4715] Loss: 0.8517\n",
      "2025-05-30 16:16:54,622 - INFO - Epoch [14/30] Batch [580/4715] Loss: 0.7044\n",
      "2025-05-30 16:16:56,138 - INFO - Epoch [14/30] Batch [590/4715] Loss: 0.7554\n",
      "2025-05-30 16:16:57,692 - INFO - Epoch [14/30] Batch [600/4715] Loss: 0.8567\n",
      "2025-05-30 16:16:59,224 - INFO - Epoch [14/30] Batch [610/4715] Loss: 0.9758\n",
      "2025-05-30 16:17:00,748 - INFO - Epoch [14/30] Batch [620/4715] Loss: 0.9765\n",
      "2025-05-30 16:17:02,303 - INFO - Epoch [14/30] Batch [630/4715] Loss: 0.6965\n",
      "2025-05-30 16:17:03,844 - INFO - Epoch [14/30] Batch [640/4715] Loss: 0.7344\n",
      "2025-05-30 16:17:05,337 - INFO - Epoch [14/30] Batch [650/4715] Loss: 0.6288\n",
      "2025-05-30 16:17:06,975 - INFO - Epoch [14/30] Batch [660/4715] Loss: 0.5946\n",
      "2025-05-30 16:17:08,560 - INFO - Epoch [14/30] Batch [670/4715] Loss: 0.6794\n",
      "2025-05-30 16:17:10,143 - INFO - Epoch [14/30] Batch [680/4715] Loss: 0.9179\n",
      "2025-05-30 16:17:11,871 - INFO - Epoch [14/30] Batch [690/4715] Loss: 0.9294\n",
      "2025-05-30 16:17:13,408 - INFO - Epoch [14/30] Batch [700/4715] Loss: 0.8528\n",
      "2025-05-30 16:17:15,030 - INFO - Epoch [14/30] Batch [710/4715] Loss: 0.8048\n",
      "2025-05-30 16:17:16,547 - INFO - Epoch [14/30] Batch [720/4715] Loss: 0.7454\n",
      "2025-05-30 16:17:18,097 - INFO - Epoch [14/30] Batch [730/4715] Loss: 0.5491\n",
      "2025-05-30 16:17:19,688 - INFO - Epoch [14/30] Batch [740/4715] Loss: 0.7428\n",
      "2025-05-30 16:17:21,303 - INFO - Epoch [14/30] Batch [750/4715] Loss: 0.6944\n",
      "2025-05-30 16:17:22,861 - INFO - Epoch [14/30] Batch [760/4715] Loss: 0.8330\n",
      "2025-05-30 16:17:24,410 - INFO - Epoch [14/30] Batch [770/4715] Loss: 0.7098\n",
      "2025-05-30 16:17:25,999 - INFO - Epoch [14/30] Batch [780/4715] Loss: 0.6440\n",
      "2025-05-30 16:17:27,540 - INFO - Epoch [14/30] Batch [790/4715] Loss: 0.8854\n",
      "2025-05-30 16:17:29,098 - INFO - Epoch [14/30] Batch [800/4715] Loss: 0.7779\n",
      "2025-05-30 16:17:30,623 - INFO - Epoch [14/30] Batch [810/4715] Loss: 0.7146\n",
      "2025-05-30 16:17:32,164 - INFO - Epoch [14/30] Batch [820/4715] Loss: 0.8377\n",
      "2025-05-30 16:17:33,726 - INFO - Epoch [14/30] Batch [830/4715] Loss: 0.6151\n",
      "2025-05-30 16:17:35,374 - INFO - Epoch [14/30] Batch [840/4715] Loss: 0.8226\n",
      "2025-05-30 16:17:36,905 - INFO - Epoch [14/30] Batch [850/4715] Loss: 0.9187\n",
      "2025-05-30 16:17:38,516 - INFO - Epoch [14/30] Batch [860/4715] Loss: 0.6244\n",
      "2025-05-30 16:17:40,086 - INFO - Epoch [14/30] Batch [870/4715] Loss: 0.5724\n",
      "2025-05-30 16:17:41,545 - INFO - Epoch [14/30] Batch [880/4715] Loss: 0.8689\n",
      "2025-05-30 16:17:43,103 - INFO - Epoch [14/30] Batch [890/4715] Loss: 0.8336\n",
      "2025-05-30 16:17:44,646 - INFO - Epoch [14/30] Batch [900/4715] Loss: 0.8136\n",
      "2025-05-30 16:17:46,133 - INFO - Epoch [14/30] Batch [910/4715] Loss: 0.7033\n",
      "2025-05-30 16:17:47,713 - INFO - Epoch [14/30] Batch [920/4715] Loss: 0.8625\n",
      "2025-05-30 16:17:49,348 - INFO - Epoch [14/30] Batch [930/4715] Loss: 0.8538\n",
      "2025-05-30 16:17:50,936 - INFO - Epoch [14/30] Batch [940/4715] Loss: 0.8457\n",
      "2025-05-30 16:17:52,648 - INFO - Epoch [14/30] Batch [950/4715] Loss: 0.7677\n",
      "2025-05-30 16:17:54,269 - INFO - Epoch [14/30] Batch [960/4715] Loss: 1.0911\n",
      "2025-05-30 16:17:55,838 - INFO - Epoch [14/30] Batch [970/4715] Loss: 0.8452\n",
      "2025-05-30 16:17:57,359 - INFO - Epoch [14/30] Batch [980/4715] Loss: 0.8285\n",
      "2025-05-30 16:17:58,877 - INFO - Epoch [14/30] Batch [990/4715] Loss: 0.6485\n",
      "2025-05-30 16:18:00,441 - INFO - Epoch [14/30] Batch [1000/4715] Loss: 0.6000\n",
      "2025-05-30 16:18:01,986 - INFO - Epoch [14/30] Batch [1010/4715] Loss: 0.9452\n",
      "2025-05-30 16:18:03,543 - INFO - Epoch [14/30] Batch [1020/4715] Loss: 0.8198\n",
      "2025-05-30 16:18:05,136 - INFO - Epoch [14/30] Batch [1030/4715] Loss: 0.6384\n",
      "2025-05-30 16:18:06,703 - INFO - Epoch [14/30] Batch [1040/4715] Loss: 1.1372\n",
      "2025-05-30 16:18:08,235 - INFO - Epoch [14/30] Batch [1050/4715] Loss: 0.8543\n",
      "2025-05-30 16:18:09,750 - INFO - Epoch [14/30] Batch [1060/4715] Loss: 0.8228\n",
      "2025-05-30 16:18:11,252 - INFO - Epoch [14/30] Batch [1070/4715] Loss: 0.6054\n",
      "2025-05-30 16:18:12,872 - INFO - Epoch [14/30] Batch [1080/4715] Loss: 0.9126\n",
      "2025-05-30 16:18:14,378 - INFO - Epoch [14/30] Batch [1090/4715] Loss: 0.6699\n",
      "2025-05-30 16:18:16,066 - INFO - Epoch [14/30] Batch [1100/4715] Loss: 0.8045\n",
      "2025-05-30 16:18:17,660 - INFO - Epoch [14/30] Batch [1110/4715] Loss: 0.8666\n",
      "2025-05-30 16:18:19,195 - INFO - Epoch [14/30] Batch [1120/4715] Loss: 0.4792\n",
      "2025-05-30 16:18:20,821 - INFO - Epoch [14/30] Batch [1130/4715] Loss: 0.7106\n",
      "2025-05-30 16:18:22,459 - INFO - Epoch [14/30] Batch [1140/4715] Loss: 0.6688\n",
      "2025-05-30 16:18:24,017 - INFO - Epoch [14/30] Batch [1150/4715] Loss: 0.6409\n",
      "2025-05-30 16:18:25,638 - INFO - Epoch [14/30] Batch [1160/4715] Loss: 0.8512\n",
      "2025-05-30 16:18:27,239 - INFO - Epoch [14/30] Batch [1170/4715] Loss: 0.8200\n",
      "2025-05-30 16:18:28,751 - INFO - Epoch [14/30] Batch [1180/4715] Loss: 0.8626\n",
      "2025-05-30 16:18:30,298 - INFO - Epoch [14/30] Batch [1190/4715] Loss: 0.9478\n",
      "2025-05-30 16:18:31,866 - INFO - Epoch [14/30] Batch [1200/4715] Loss: 0.7103\n",
      "2025-05-30 16:18:33,441 - INFO - Epoch [14/30] Batch [1210/4715] Loss: 0.7389\n",
      "2025-05-30 16:18:34,957 - INFO - Epoch [14/30] Batch [1220/4715] Loss: 0.5981\n",
      "2025-05-30 16:18:36,501 - INFO - Epoch [14/30] Batch [1230/4715] Loss: 0.8751\n",
      "2025-05-30 16:18:38,099 - INFO - Epoch [14/30] Batch [1240/4715] Loss: 0.9062\n",
      "2025-05-30 16:18:39,576 - INFO - Epoch [14/30] Batch [1250/4715] Loss: 0.7751\n",
      "2025-05-30 16:18:41,097 - INFO - Epoch [14/30] Batch [1260/4715] Loss: 1.0393\n",
      "2025-05-30 16:18:42,735 - INFO - Epoch [14/30] Batch [1270/4715] Loss: 0.8736\n",
      "2025-05-30 16:18:44,278 - INFO - Epoch [14/30] Batch [1280/4715] Loss: 0.9629\n",
      "2025-05-30 16:18:45,899 - INFO - Epoch [14/30] Batch [1290/4715] Loss: 0.8245\n",
      "2025-05-30 16:18:47,406 - INFO - Epoch [14/30] Batch [1300/4715] Loss: 0.7722\n",
      "2025-05-30 16:18:48,934 - INFO - Epoch [14/30] Batch [1310/4715] Loss: 0.8331\n",
      "2025-05-30 16:18:50,601 - INFO - Epoch [14/30] Batch [1320/4715] Loss: 0.5739\n",
      "2025-05-30 16:18:52,126 - INFO - Epoch [14/30] Batch [1330/4715] Loss: 0.6655\n",
      "2025-05-30 16:18:53,655 - INFO - Epoch [14/30] Batch [1340/4715] Loss: 0.5953\n",
      "2025-05-30 16:18:55,183 - INFO - Epoch [14/30] Batch [1350/4715] Loss: 0.7879\n",
      "2025-05-30 16:18:56,781 - INFO - Epoch [14/30] Batch [1360/4715] Loss: 0.9255\n",
      "2025-05-30 16:18:58,332 - INFO - Epoch [14/30] Batch [1370/4715] Loss: 0.6076\n",
      "2025-05-30 16:19:00,031 - INFO - Epoch [14/30] Batch [1380/4715] Loss: 0.7504\n",
      "2025-05-30 16:19:01,671 - INFO - Epoch [14/30] Batch [1390/4715] Loss: 0.6612\n",
      "2025-05-30 16:19:03,256 - INFO - Epoch [14/30] Batch [1400/4715] Loss: 0.8312\n",
      "2025-05-30 16:19:04,833 - INFO - Epoch [14/30] Batch [1410/4715] Loss: 0.5816\n",
      "2025-05-30 16:19:06,494 - INFO - Epoch [14/30] Batch [1420/4715] Loss: 0.7904\n",
      "2025-05-30 16:19:08,146 - INFO - Epoch [14/30] Batch [1430/4715] Loss: 0.7597\n",
      "2025-05-30 16:19:09,705 - INFO - Epoch [14/30] Batch [1440/4715] Loss: 1.0325\n",
      "2025-05-30 16:19:11,339 - INFO - Epoch [14/30] Batch [1450/4715] Loss: 0.7409\n",
      "2025-05-30 16:19:12,954 - INFO - Epoch [14/30] Batch [1460/4715] Loss: 0.7945\n",
      "2025-05-30 16:19:14,487 - INFO - Epoch [14/30] Batch [1470/4715] Loss: 0.8770\n",
      "2025-05-30 16:19:15,977 - INFO - Epoch [14/30] Batch [1480/4715] Loss: 0.7340\n",
      "2025-05-30 16:19:17,511 - INFO - Epoch [14/30] Batch [1490/4715] Loss: 0.8719\n",
      "2025-05-30 16:19:19,078 - INFO - Epoch [14/30] Batch [1500/4715] Loss: 0.6921\n",
      "2025-05-30 16:19:20,706 - INFO - Epoch [14/30] Batch [1510/4715] Loss: 0.9547\n",
      "2025-05-30 16:19:22,196 - INFO - Epoch [14/30] Batch [1520/4715] Loss: 0.7914\n",
      "2025-05-30 16:19:23,830 - INFO - Epoch [14/30] Batch [1530/4715] Loss: 0.8466\n",
      "2025-05-30 16:19:25,369 - INFO - Epoch [14/30] Batch [1540/4715] Loss: 0.4954\n",
      "2025-05-30 16:19:27,010 - INFO - Epoch [14/30] Batch [1550/4715] Loss: 0.9566\n",
      "2025-05-30 16:19:28,581 - INFO - Epoch [14/30] Batch [1560/4715] Loss: 0.6290\n",
      "2025-05-30 16:19:30,218 - INFO - Epoch [14/30] Batch [1570/4715] Loss: 0.5844\n",
      "2025-05-30 16:19:31,778 - INFO - Epoch [14/30] Batch [1580/4715] Loss: 0.7265\n",
      "2025-05-30 16:19:33,299 - INFO - Epoch [14/30] Batch [1590/4715] Loss: 0.9686\n",
      "2025-05-30 16:19:34,836 - INFO - Epoch [14/30] Batch [1600/4715] Loss: 0.7527\n",
      "2025-05-30 16:19:36,380 - INFO - Epoch [14/30] Batch [1610/4715] Loss: 0.9972\n",
      "2025-05-30 16:19:38,019 - INFO - Epoch [14/30] Batch [1620/4715] Loss: 0.8564\n",
      "2025-05-30 16:19:39,595 - INFO - Epoch [14/30] Batch [1630/4715] Loss: 0.6697\n",
      "2025-05-30 16:19:41,085 - INFO - Epoch [14/30] Batch [1640/4715] Loss: 0.7114\n",
      "2025-05-30 16:19:42,651 - INFO - Epoch [14/30] Batch [1650/4715] Loss: 0.8094\n",
      "2025-05-30 16:19:44,252 - INFO - Epoch [14/30] Batch [1660/4715] Loss: 0.8424\n",
      "2025-05-30 16:19:45,815 - INFO - Epoch [14/30] Batch [1670/4715] Loss: 0.5513\n",
      "2025-05-30 16:19:47,308 - INFO - Epoch [14/30] Batch [1680/4715] Loss: 0.8343\n",
      "2025-05-30 16:19:48,994 - INFO - Epoch [14/30] Batch [1690/4715] Loss: 0.7412\n",
      "2025-05-30 16:19:50,703 - INFO - Epoch [14/30] Batch [1700/4715] Loss: 0.8261\n",
      "2025-05-30 16:19:52,268 - INFO - Epoch [14/30] Batch [1710/4715] Loss: 0.6914\n",
      "2025-05-30 16:19:53,832 - INFO - Epoch [14/30] Batch [1720/4715] Loss: 0.7537\n",
      "2025-05-30 16:19:55,443 - INFO - Epoch [14/30] Batch [1730/4715] Loss: 0.7017\n",
      "2025-05-30 16:19:57,005 - INFO - Epoch [14/30] Batch [1740/4715] Loss: 1.0546\n",
      "2025-05-30 16:19:58,620 - INFO - Epoch [14/30] Batch [1750/4715] Loss: 0.9199\n",
      "2025-05-30 16:20:00,159 - INFO - Epoch [14/30] Batch [1760/4715] Loss: 0.8591\n",
      "2025-05-30 16:20:01,769 - INFO - Epoch [14/30] Batch [1770/4715] Loss: 0.7995\n",
      "2025-05-30 16:20:03,306 - INFO - Epoch [14/30] Batch [1780/4715] Loss: 0.7451\n",
      "2025-05-30 16:20:04,903 - INFO - Epoch [14/30] Batch [1790/4715] Loss: 0.8246\n",
      "2025-05-30 16:20:06,561 - INFO - Epoch [14/30] Batch [1800/4715] Loss: 0.6047\n",
      "2025-05-30 16:20:08,125 - INFO - Epoch [14/30] Batch [1810/4715] Loss: 0.9977\n",
      "2025-05-30 16:20:09,721 - INFO - Epoch [14/30] Batch [1820/4715] Loss: 0.9082\n",
      "2025-05-30 16:20:11,269 - INFO - Epoch [14/30] Batch [1830/4715] Loss: 0.7221\n",
      "2025-05-30 16:20:12,875 - INFO - Epoch [14/30] Batch [1840/4715] Loss: 0.7829\n",
      "2025-05-30 16:20:14,420 - INFO - Epoch [14/30] Batch [1850/4715] Loss: 0.6297\n",
      "2025-05-30 16:20:15,991 - INFO - Epoch [14/30] Batch [1860/4715] Loss: 0.5937\n",
      "2025-05-30 16:20:17,505 - INFO - Epoch [14/30] Batch [1870/4715] Loss: 0.8925\n",
      "2025-05-30 16:20:19,062 - INFO - Epoch [14/30] Batch [1880/4715] Loss: 0.8041\n",
      "2025-05-30 16:20:20,639 - INFO - Epoch [14/30] Batch [1890/4715] Loss: 0.7200\n",
      "2025-05-30 16:20:22,197 - INFO - Epoch [14/30] Batch [1900/4715] Loss: 1.0226\n",
      "2025-05-30 16:20:23,855 - INFO - Epoch [14/30] Batch [1910/4715] Loss: 0.6271\n",
      "2025-05-30 16:20:25,409 - INFO - Epoch [14/30] Batch [1920/4715] Loss: 0.8422\n",
      "2025-05-30 16:20:26,946 - INFO - Epoch [14/30] Batch [1930/4715] Loss: 0.6057\n",
      "2025-05-30 16:20:28,540 - INFO - Epoch [14/30] Batch [1940/4715] Loss: 0.6874\n",
      "2025-05-30 16:20:30,152 - INFO - Epoch [14/30] Batch [1950/4715] Loss: 0.4230\n",
      "2025-05-30 16:20:31,721 - INFO - Epoch [14/30] Batch [1960/4715] Loss: 0.6771\n",
      "2025-05-30 16:20:33,211 - INFO - Epoch [14/30] Batch [1970/4715] Loss: 0.8793\n",
      "2025-05-30 16:20:34,634 - INFO - Epoch [14/30] Batch [1980/4715] Loss: 0.8925\n",
      "2025-05-30 16:20:36,154 - INFO - Epoch [14/30] Batch [1990/4715] Loss: 0.9497\n",
      "2025-05-30 16:20:37,773 - INFO - Epoch [14/30] Batch [2000/4715] Loss: 0.8908\n",
      "2025-05-30 16:20:39,307 - INFO - Epoch [14/30] Batch [2010/4715] Loss: 0.8193\n",
      "2025-05-30 16:20:40,813 - INFO - Epoch [14/30] Batch [2020/4715] Loss: 0.8401\n",
      "2025-05-30 16:20:42,406 - INFO - Epoch [14/30] Batch [2030/4715] Loss: 0.8256\n",
      "2025-05-30 16:20:44,015 - INFO - Epoch [14/30] Batch [2040/4715] Loss: 0.5741\n",
      "2025-05-30 16:20:45,569 - INFO - Epoch [14/30] Batch [2050/4715] Loss: 0.8221\n",
      "2025-05-30 16:20:47,328 - INFO - Epoch [14/30] Batch [2060/4715] Loss: 0.7275\n",
      "2025-05-30 16:20:48,995 - INFO - Epoch [14/30] Batch [2070/4715] Loss: 0.9043\n",
      "2025-05-30 16:20:50,567 - INFO - Epoch [14/30] Batch [2080/4715] Loss: 0.5580\n",
      "2025-05-30 16:20:52,067 - INFO - Epoch [14/30] Batch [2090/4715] Loss: 0.8379\n",
      "2025-05-30 16:20:53,628 - INFO - Epoch [14/30] Batch [2100/4715] Loss: 0.8340\n",
      "2025-05-30 16:20:55,183 - INFO - Epoch [14/30] Batch [2110/4715] Loss: 0.6816\n",
      "2025-05-30 16:20:56,674 - INFO - Epoch [14/30] Batch [2120/4715] Loss: 1.1136\n",
      "2025-05-30 16:20:58,218 - INFO - Epoch [14/30] Batch [2130/4715] Loss: 1.0408\n",
      "2025-05-30 16:20:59,822 - INFO - Epoch [14/30] Batch [2140/4715] Loss: 0.7517\n",
      "2025-05-30 16:21:01,344 - INFO - Epoch [14/30] Batch [2150/4715] Loss: 0.6051\n",
      "2025-05-30 16:21:02,838 - INFO - Epoch [14/30] Batch [2160/4715] Loss: 0.7526\n",
      "2025-05-30 16:21:04,381 - INFO - Epoch [14/30] Batch [2170/4715] Loss: 0.9083\n",
      "2025-05-30 16:21:05,876 - INFO - Epoch [14/30] Batch [2180/4715] Loss: 0.7016\n",
      "2025-05-30 16:21:07,481 - INFO - Epoch [14/30] Batch [2190/4715] Loss: 0.9760\n",
      "2025-05-30 16:21:09,203 - INFO - Epoch [14/30] Batch [2200/4715] Loss: 0.8320\n",
      "2025-05-30 16:21:10,686 - INFO - Epoch [14/30] Batch [2210/4715] Loss: 0.6082\n",
      "2025-05-30 16:21:12,215 - INFO - Epoch [14/30] Batch [2220/4715] Loss: 0.4680\n",
      "2025-05-30 16:21:13,767 - INFO - Epoch [14/30] Batch [2230/4715] Loss: 0.5719\n",
      "2025-05-30 16:21:15,275 - INFO - Epoch [14/30] Batch [2240/4715] Loss: 0.6566\n",
      "2025-05-30 16:21:16,862 - INFO - Epoch [14/30] Batch [2250/4715] Loss: 0.7957\n",
      "2025-05-30 16:21:18,471 - INFO - Epoch [14/30] Batch [2260/4715] Loss: 0.7771\n",
      "2025-05-30 16:21:20,073 - INFO - Epoch [14/30] Batch [2270/4715] Loss: 0.8121\n",
      "2025-05-30 16:21:21,710 - INFO - Epoch [14/30] Batch [2280/4715] Loss: 0.8966\n",
      "2025-05-30 16:21:23,294 - INFO - Epoch [14/30] Batch [2290/4715] Loss: 0.7507\n",
      "2025-05-30 16:21:24,922 - INFO - Epoch [14/30] Batch [2300/4715] Loss: 1.0226\n",
      "2025-05-30 16:21:26,466 - INFO - Epoch [14/30] Batch [2310/4715] Loss: 0.8222\n",
      "2025-05-30 16:21:28,026 - INFO - Epoch [14/30] Batch [2320/4715] Loss: 1.0024\n",
      "2025-05-30 16:21:29,642 - INFO - Epoch [14/30] Batch [2330/4715] Loss: 0.7865\n",
      "2025-05-30 16:21:31,247 - INFO - Epoch [14/30] Batch [2340/4715] Loss: 0.8854\n",
      "2025-05-30 16:21:32,800 - INFO - Epoch [14/30] Batch [2350/4715] Loss: 0.7767\n",
      "2025-05-30 16:21:34,344 - INFO - Epoch [14/30] Batch [2360/4715] Loss: 0.7518\n",
      "2025-05-30 16:21:35,981 - INFO - Epoch [14/30] Batch [2370/4715] Loss: 0.9800\n",
      "2025-05-30 16:21:37,519 - INFO - Epoch [14/30] Batch [2380/4715] Loss: 0.6798\n",
      "2025-05-30 16:21:39,103 - INFO - Epoch [14/30] Batch [2390/4715] Loss: 0.9343\n",
      "2025-05-30 16:21:40,670 - INFO - Epoch [14/30] Batch [2400/4715] Loss: 0.9283\n",
      "2025-05-30 16:21:42,319 - INFO - Epoch [14/30] Batch [2410/4715] Loss: 0.6990\n",
      "2025-05-30 16:21:43,918 - INFO - Epoch [14/30] Batch [2420/4715] Loss: 0.6923\n",
      "2025-05-30 16:21:45,458 - INFO - Epoch [14/30] Batch [2430/4715] Loss: 0.5992\n",
      "2025-05-30 16:21:46,968 - INFO - Epoch [14/30] Batch [2440/4715] Loss: 1.0206\n",
      "2025-05-30 16:21:48,518 - INFO - Epoch [14/30] Batch [2450/4715] Loss: 0.6391\n",
      "2025-05-30 16:21:50,077 - INFO - Epoch [14/30] Batch [2460/4715] Loss: 1.1162\n",
      "2025-05-30 16:21:51,633 - INFO - Epoch [14/30] Batch [2470/4715] Loss: 0.7459\n",
      "2025-05-30 16:21:53,183 - INFO - Epoch [14/30] Batch [2480/4715] Loss: 0.7705\n",
      "2025-05-30 16:21:54,772 - INFO - Epoch [14/30] Batch [2490/4715] Loss: 0.8656\n",
      "2025-05-30 16:21:56,407 - INFO - Epoch [14/30] Batch [2500/4715] Loss: 1.0907\n",
      "2025-05-30 16:21:57,981 - INFO - Epoch [14/30] Batch [2510/4715] Loss: 0.8257\n",
      "2025-05-30 16:21:59,517 - INFO - Epoch [14/30] Batch [2520/4715] Loss: 0.9321\n",
      "2025-05-30 16:22:01,058 - INFO - Epoch [14/30] Batch [2530/4715] Loss: 0.7618\n",
      "2025-05-30 16:22:02,631 - INFO - Epoch [14/30] Batch [2540/4715] Loss: 1.0497\n",
      "2025-05-30 16:22:04,116 - INFO - Epoch [14/30] Batch [2550/4715] Loss: 0.9428\n",
      "2025-05-30 16:22:05,590 - INFO - Epoch [14/30] Batch [2560/4715] Loss: 0.7541\n",
      "2025-05-30 16:22:07,116 - INFO - Epoch [14/30] Batch [2570/4715] Loss: 0.8421\n",
      "2025-05-30 16:22:08,659 - INFO - Epoch [14/30] Batch [2580/4715] Loss: 0.8919\n",
      "2025-05-30 16:22:10,282 - INFO - Epoch [14/30] Batch [2590/4715] Loss: 0.8345\n",
      "2025-05-30 16:22:11,868 - INFO - Epoch [14/30] Batch [2600/4715] Loss: 0.8358\n",
      "2025-05-30 16:22:13,398 - INFO - Epoch [14/30] Batch [2610/4715] Loss: 0.9519\n",
      "2025-05-30 16:22:14,999 - INFO - Epoch [14/30] Batch [2620/4715] Loss: 0.7182\n",
      "2025-05-30 16:22:16,470 - INFO - Epoch [14/30] Batch [2630/4715] Loss: 0.8177\n",
      "2025-05-30 16:22:18,029 - INFO - Epoch [14/30] Batch [2640/4715] Loss: 0.8836\n",
      "2025-05-30 16:22:19,563 - INFO - Epoch [14/30] Batch [2650/4715] Loss: 0.8979\n",
      "2025-05-30 16:22:21,096 - INFO - Epoch [14/30] Batch [2660/4715] Loss: 0.7299\n",
      "2025-05-30 16:22:22,606 - INFO - Epoch [14/30] Batch [2670/4715] Loss: 1.3471\n",
      "2025-05-30 16:22:24,165 - INFO - Epoch [14/30] Batch [2680/4715] Loss: 1.0191\n",
      "2025-05-30 16:22:25,715 - INFO - Epoch [14/30] Batch [2690/4715] Loss: 0.7209\n",
      "2025-05-30 16:22:27,219 - INFO - Epoch [14/30] Batch [2700/4715] Loss: 0.9237\n",
      "2025-05-30 16:22:28,789 - INFO - Epoch [14/30] Batch [2710/4715] Loss: 0.4844\n",
      "2025-05-30 16:22:30,355 - INFO - Epoch [14/30] Batch [2720/4715] Loss: 0.8474\n",
      "2025-05-30 16:22:31,930 - INFO - Epoch [14/30] Batch [2730/4715] Loss: 0.8440\n",
      "2025-05-30 16:22:33,568 - INFO - Epoch [14/30] Batch [2740/4715] Loss: 0.7145\n",
      "2025-05-30 16:22:35,150 - INFO - Epoch [14/30] Batch [2750/4715] Loss: 0.6922\n",
      "2025-05-30 16:22:36,706 - INFO - Epoch [14/30] Batch [2760/4715] Loss: 0.6306\n",
      "2025-05-30 16:22:38,257 - INFO - Epoch [14/30] Batch [2770/4715] Loss: 0.7756\n",
      "2025-05-30 16:22:39,793 - INFO - Epoch [14/30] Batch [2780/4715] Loss: 0.7976\n",
      "2025-05-30 16:22:41,271 - INFO - Epoch [14/30] Batch [2790/4715] Loss: 0.7898\n",
      "2025-05-30 16:22:42,828 - INFO - Epoch [14/30] Batch [2800/4715] Loss: 0.7560\n",
      "2025-05-30 16:22:44,392 - INFO - Epoch [14/30] Batch [2810/4715] Loss: 0.5921\n",
      "2025-05-30 16:22:45,996 - INFO - Epoch [14/30] Batch [2820/4715] Loss: 0.9713\n",
      "2025-05-30 16:22:47,516 - INFO - Epoch [14/30] Batch [2830/4715] Loss: 1.1878\n",
      "2025-05-30 16:22:49,088 - INFO - Epoch [14/30] Batch [2840/4715] Loss: 0.6448\n",
      "2025-05-30 16:22:50,689 - INFO - Epoch [14/30] Batch [2850/4715] Loss: 0.7115\n",
      "2025-05-30 16:22:52,187 - INFO - Epoch [14/30] Batch [2860/4715] Loss: 0.7570\n",
      "2025-05-30 16:22:53,730 - INFO - Epoch [14/30] Batch [2870/4715] Loss: 0.8788\n",
      "2025-05-30 16:22:55,303 - INFO - Epoch [14/30] Batch [2880/4715] Loss: 0.9195\n",
      "2025-05-30 16:22:56,887 - INFO - Epoch [14/30] Batch [2890/4715] Loss: 0.7580\n",
      "2025-05-30 16:22:58,468 - INFO - Epoch [14/30] Batch [2900/4715] Loss: 0.8551\n",
      "2025-05-30 16:23:00,001 - INFO - Epoch [14/30] Batch [2910/4715] Loss: 0.6574\n",
      "2025-05-30 16:23:01,565 - INFO - Epoch [14/30] Batch [2920/4715] Loss: 0.7812\n",
      "2025-05-30 16:23:03,071 - INFO - Epoch [14/30] Batch [2930/4715] Loss: 0.8914\n",
      "2025-05-30 16:23:04,534 - INFO - Epoch [14/30] Batch [2940/4715] Loss: 0.6601\n",
      "2025-05-30 16:23:06,097 - INFO - Epoch [14/30] Batch [2950/4715] Loss: 0.9068\n",
      "2025-05-30 16:23:07,691 - INFO - Epoch [14/30] Batch [2960/4715] Loss: 0.8056\n",
      "2025-05-30 16:23:09,275 - INFO - Epoch [14/30] Batch [2970/4715] Loss: 0.9276\n",
      "2025-05-30 16:23:10,758 - INFO - Epoch [14/30] Batch [2980/4715] Loss: 0.6534\n",
      "2025-05-30 16:23:12,326 - INFO - Epoch [14/30] Batch [2990/4715] Loss: 0.9130\n",
      "2025-05-30 16:23:13,885 - INFO - Epoch [14/30] Batch [3000/4715] Loss: 0.8463\n",
      "2025-05-30 16:23:15,472 - INFO - Epoch [14/30] Batch [3010/4715] Loss: 0.7952\n",
      "2025-05-30 16:23:17,046 - INFO - Epoch [14/30] Batch [3020/4715] Loss: 0.7677\n",
      "2025-05-30 16:23:18,520 - INFO - Epoch [14/30] Batch [3030/4715] Loss: 0.6365\n",
      "2025-05-30 16:23:20,077 - INFO - Epoch [14/30] Batch [3040/4715] Loss: 0.9228\n",
      "2025-05-30 16:23:21,777 - INFO - Epoch [14/30] Batch [3050/4715] Loss: 0.9115\n",
      "2025-05-30 16:23:23,295 - INFO - Epoch [14/30] Batch [3060/4715] Loss: 0.8998\n",
      "2025-05-30 16:23:24,842 - INFO - Epoch [14/30] Batch [3070/4715] Loss: 0.9576\n",
      "2025-05-30 16:23:26,400 - INFO - Epoch [14/30] Batch [3080/4715] Loss: 0.8898\n",
      "2025-05-30 16:23:27,897 - INFO - Epoch [14/30] Batch [3090/4715] Loss: 1.0186\n",
      "2025-05-30 16:23:29,618 - INFO - Epoch [14/30] Batch [3100/4715] Loss: 0.8420\n",
      "2025-05-30 16:23:31,181 - INFO - Epoch [14/30] Batch [3110/4715] Loss: 0.6029\n",
      "2025-05-30 16:23:32,833 - INFO - Epoch [14/30] Batch [3120/4715] Loss: 0.6069\n",
      "2025-05-30 16:23:34,377 - INFO - Epoch [14/30] Batch [3130/4715] Loss: 0.9239\n",
      "2025-05-30 16:23:35,991 - INFO - Epoch [14/30] Batch [3140/4715] Loss: 0.6478\n",
      "2025-05-30 16:23:37,457 - INFO - Epoch [14/30] Batch [3150/4715] Loss: 0.7527\n",
      "2025-05-30 16:23:39,062 - INFO - Epoch [14/30] Batch [3160/4715] Loss: 0.6132\n",
      "2025-05-30 16:23:40,664 - INFO - Epoch [14/30] Batch [3170/4715] Loss: 0.8066\n",
      "2025-05-30 16:23:42,221 - INFO - Epoch [14/30] Batch [3180/4715] Loss: 0.8150\n",
      "2025-05-30 16:23:43,732 - INFO - Epoch [14/30] Batch [3190/4715] Loss: 0.7054\n",
      "2025-05-30 16:23:45,274 - INFO - Epoch [14/30] Batch [3200/4715] Loss: 0.7780\n",
      "2025-05-30 16:23:46,746 - INFO - Epoch [14/30] Batch [3210/4715] Loss: 1.2670\n",
      "2025-05-30 16:23:48,410 - INFO - Epoch [14/30] Batch [3220/4715] Loss: 0.7325\n",
      "2025-05-30 16:23:50,155 - INFO - Epoch [14/30] Batch [3230/4715] Loss: 1.0208\n",
      "2025-05-30 16:23:51,744 - INFO - Epoch [14/30] Batch [3240/4715] Loss: 0.7902\n",
      "2025-05-30 16:23:53,294 - INFO - Epoch [14/30] Batch [3250/4715] Loss: 0.9012\n",
      "2025-05-30 16:23:54,837 - INFO - Epoch [14/30] Batch [3260/4715] Loss: 0.5872\n",
      "2025-05-30 16:23:56,435 - INFO - Epoch [14/30] Batch [3270/4715] Loss: 0.8918\n",
      "2025-05-30 16:23:58,011 - INFO - Epoch [14/30] Batch [3280/4715] Loss: 0.8879\n",
      "2025-05-30 16:23:59,604 - INFO - Epoch [14/30] Batch [3290/4715] Loss: 0.6548\n",
      "2025-05-30 16:24:01,188 - INFO - Epoch [14/30] Batch [3300/4715] Loss: 0.6324\n",
      "2025-05-30 16:24:02,752 - INFO - Epoch [14/30] Batch [3310/4715] Loss: 0.6819\n",
      "2025-05-30 16:24:04,261 - INFO - Epoch [14/30] Batch [3320/4715] Loss: 0.8537\n",
      "2025-05-30 16:24:05,758 - INFO - Epoch [14/30] Batch [3330/4715] Loss: 0.6896\n",
      "2025-05-30 16:24:07,295 - INFO - Epoch [14/30] Batch [3340/4715] Loss: 0.7341\n",
      "2025-05-30 16:24:08,816 - INFO - Epoch [14/30] Batch [3350/4715] Loss: 0.8820\n",
      "2025-05-30 16:24:10,420 - INFO - Epoch [14/30] Batch [3360/4715] Loss: 0.8450\n",
      "2025-05-30 16:24:12,006 - INFO - Epoch [14/30] Batch [3370/4715] Loss: 0.7524\n",
      "2025-05-30 16:24:13,627 - INFO - Epoch [14/30] Batch [3380/4715] Loss: 0.6983\n",
      "2025-05-30 16:24:15,098 - INFO - Epoch [14/30] Batch [3390/4715] Loss: 0.5936\n",
      "2025-05-30 16:24:16,691 - INFO - Epoch [14/30] Batch [3400/4715] Loss: 0.8307\n",
      "2025-05-30 16:24:18,216 - INFO - Epoch [14/30] Batch [3410/4715] Loss: 0.5991\n",
      "2025-05-30 16:24:19,717 - INFO - Epoch [14/30] Batch [3420/4715] Loss: 0.8064\n",
      "2025-05-30 16:24:21,288 - INFO - Epoch [14/30] Batch [3430/4715] Loss: 0.6951\n",
      "2025-05-30 16:24:22,855 - INFO - Epoch [14/30] Batch [3440/4715] Loss: 0.9884\n",
      "2025-05-30 16:24:24,413 - INFO - Epoch [14/30] Batch [3450/4715] Loss: 0.7670\n",
      "2025-05-30 16:24:25,929 - INFO - Epoch [14/30] Batch [3460/4715] Loss: 0.9771\n",
      "2025-05-30 16:24:27,513 - INFO - Epoch [14/30] Batch [3470/4715] Loss: 0.7532\n",
      "2025-05-30 16:24:28,999 - INFO - Epoch [14/30] Batch [3480/4715] Loss: 0.8488\n",
      "2025-05-30 16:24:30,570 - INFO - Epoch [14/30] Batch [3490/4715] Loss: 0.8087\n",
      "2025-05-30 16:24:32,098 - INFO - Epoch [14/30] Batch [3500/4715] Loss: 0.8380\n",
      "2025-05-30 16:24:33,650 - INFO - Epoch [14/30] Batch [3510/4715] Loss: 0.6427\n",
      "2025-05-30 16:24:35,197 - INFO - Epoch [14/30] Batch [3520/4715] Loss: 0.8017\n",
      "2025-05-30 16:24:36,685 - INFO - Epoch [14/30] Batch [3530/4715] Loss: 0.8292\n",
      "2025-05-30 16:24:38,329 - INFO - Epoch [14/30] Batch [3540/4715] Loss: 0.6860\n",
      "2025-05-30 16:24:39,897 - INFO - Epoch [14/30] Batch [3550/4715] Loss: 0.7831\n",
      "2025-05-30 16:24:41,440 - INFO - Epoch [14/30] Batch [3560/4715] Loss: 0.7247\n",
      "2025-05-30 16:24:43,150 - INFO - Epoch [14/30] Batch [3570/4715] Loss: 0.8122\n",
      "2025-05-30 16:24:44,670 - INFO - Epoch [14/30] Batch [3580/4715] Loss: 0.5817\n",
      "2025-05-30 16:24:46,183 - INFO - Epoch [14/30] Batch [3590/4715] Loss: 0.8679\n",
      "2025-05-30 16:24:47,792 - INFO - Epoch [14/30] Batch [3600/4715] Loss: 0.7072\n",
      "2025-05-30 16:24:49,330 - INFO - Epoch [14/30] Batch [3610/4715] Loss: 1.0209\n",
      "2025-05-30 16:24:50,871 - INFO - Epoch [14/30] Batch [3620/4715] Loss: 0.7325\n",
      "2025-05-30 16:24:52,445 - INFO - Epoch [14/30] Batch [3630/4715] Loss: 0.9997\n",
      "2025-05-30 16:24:53,992 - INFO - Epoch [14/30] Batch [3640/4715] Loss: 0.6815\n",
      "2025-05-30 16:24:55,511 - INFO - Epoch [14/30] Batch [3650/4715] Loss: 1.2668\n",
      "2025-05-30 16:24:57,024 - INFO - Epoch [14/30] Batch [3660/4715] Loss: 0.6536\n",
      "2025-05-30 16:24:58,632 - INFO - Epoch [14/30] Batch [3670/4715] Loss: 0.6892\n",
      "2025-05-30 16:25:00,190 - INFO - Epoch [14/30] Batch [3680/4715] Loss: 0.8959\n",
      "2025-05-30 16:25:01,705 - INFO - Epoch [14/30] Batch [3690/4715] Loss: 0.5413\n",
      "2025-05-30 16:25:03,224 - INFO - Epoch [14/30] Batch [3700/4715] Loss: 0.8341\n",
      "2025-05-30 16:25:04,825 - INFO - Epoch [14/30] Batch [3710/4715] Loss: 0.5858\n",
      "2025-05-30 16:25:06,359 - INFO - Epoch [14/30] Batch [3720/4715] Loss: 0.7666\n",
      "2025-05-30 16:25:07,978 - INFO - Epoch [14/30] Batch [3730/4715] Loss: 0.9307\n",
      "2025-05-30 16:25:09,528 - INFO - Epoch [14/30] Batch [3740/4715] Loss: 0.5911\n",
      "2025-05-30 16:25:11,048 - INFO - Epoch [14/30] Batch [3750/4715] Loss: 0.7447\n",
      "2025-05-30 16:25:12,559 - INFO - Epoch [14/30] Batch [3760/4715] Loss: 0.7966\n",
      "2025-05-30 16:25:14,045 - INFO - Epoch [14/30] Batch [3770/4715] Loss: 0.5420\n",
      "2025-05-30 16:25:15,641 - INFO - Epoch [14/30] Batch [3780/4715] Loss: 0.5865\n",
      "2025-05-30 16:25:17,204 - INFO - Epoch [14/30] Batch [3790/4715] Loss: 0.6866\n",
      "2025-05-30 16:25:18,768 - INFO - Epoch [14/30] Batch [3800/4715] Loss: 0.8051\n",
      "2025-05-30 16:25:20,431 - INFO - Epoch [14/30] Batch [3810/4715] Loss: 0.6528\n",
      "2025-05-30 16:25:22,056 - INFO - Epoch [14/30] Batch [3820/4715] Loss: 0.9663\n",
      "2025-05-30 16:25:23,652 - INFO - Epoch [14/30] Batch [3830/4715] Loss: 0.8631\n",
      "2025-05-30 16:25:25,145 - INFO - Epoch [14/30] Batch [3840/4715] Loss: 0.6676\n",
      "2025-05-30 16:25:26,633 - INFO - Epoch [14/30] Batch [3850/4715] Loss: 0.8889\n",
      "2025-05-30 16:25:28,263 - INFO - Epoch [14/30] Batch [3860/4715] Loss: 0.6959\n",
      "2025-05-30 16:25:29,901 - INFO - Epoch [14/30] Batch [3870/4715] Loss: 0.5262\n",
      "2025-05-30 16:25:31,414 - INFO - Epoch [14/30] Batch [3880/4715] Loss: 0.7730\n",
      "2025-05-30 16:25:33,010 - INFO - Epoch [14/30] Batch [3890/4715] Loss: 0.7457\n",
      "2025-05-30 16:25:34,565 - INFO - Epoch [14/30] Batch [3900/4715] Loss: 0.6719\n",
      "2025-05-30 16:25:36,140 - INFO - Epoch [14/30] Batch [3910/4715] Loss: 0.8029\n",
      "2025-05-30 16:25:37,744 - INFO - Epoch [14/30] Batch [3920/4715] Loss: 0.8260\n",
      "2025-05-30 16:25:39,313 - INFO - Epoch [14/30] Batch [3930/4715] Loss: 0.7601\n",
      "2025-05-30 16:25:40,879 - INFO - Epoch [14/30] Batch [3940/4715] Loss: 0.9254\n",
      "2025-05-30 16:25:42,434 - INFO - Epoch [14/30] Batch [3950/4715] Loss: 0.7257\n",
      "2025-05-30 16:25:44,006 - INFO - Epoch [14/30] Batch [3960/4715] Loss: 0.6781\n",
      "2025-05-30 16:25:45,554 - INFO - Epoch [14/30] Batch [3970/4715] Loss: 0.7464\n",
      "2025-05-30 16:25:47,100 - INFO - Epoch [14/30] Batch [3980/4715] Loss: 0.7457\n",
      "2025-05-30 16:25:48,742 - INFO - Epoch [14/30] Batch [3990/4715] Loss: 0.6155\n",
      "2025-05-30 16:25:50,398 - INFO - Epoch [14/30] Batch [4000/4715] Loss: 0.6573\n",
      "2025-05-30 16:25:51,927 - INFO - Epoch [14/30] Batch [4010/4715] Loss: 0.7009\n",
      "2025-05-30 16:25:53,474 - INFO - Epoch [14/30] Batch [4020/4715] Loss: 0.6914\n",
      "2025-05-30 16:25:55,126 - INFO - Epoch [14/30] Batch [4030/4715] Loss: 1.0602\n",
      "2025-05-30 16:25:56,682 - INFO - Epoch [14/30] Batch [4040/4715] Loss: 0.7667\n",
      "2025-05-30 16:25:58,280 - INFO - Epoch [14/30] Batch [4050/4715] Loss: 0.7811\n",
      "2025-05-30 16:25:59,818 - INFO - Epoch [14/30] Batch [4060/4715] Loss: 0.7326\n",
      "2025-05-30 16:26:01,427 - INFO - Epoch [14/30] Batch [4070/4715] Loss: 0.8092\n",
      "2025-05-30 16:26:03,033 - INFO - Epoch [14/30] Batch [4080/4715] Loss: 0.7501\n",
      "2025-05-30 16:26:04,620 - INFO - Epoch [14/30] Batch [4090/4715] Loss: 0.7434\n",
      "2025-05-30 16:26:06,222 - INFO - Epoch [14/30] Batch [4100/4715] Loss: 0.7706\n",
      "2025-05-30 16:26:07,802 - INFO - Epoch [14/30] Batch [4110/4715] Loss: 0.8375\n",
      "2025-05-30 16:26:09,365 - INFO - Epoch [14/30] Batch [4120/4715] Loss: 0.7512\n",
      "2025-05-30 16:26:10,884 - INFO - Epoch [14/30] Batch [4130/4715] Loss: 1.0697\n",
      "2025-05-30 16:26:12,424 - INFO - Epoch [14/30] Batch [4140/4715] Loss: 0.9531\n",
      "2025-05-30 16:26:14,016 - INFO - Epoch [14/30] Batch [4150/4715] Loss: 0.4766\n",
      "2025-05-30 16:26:15,619 - INFO - Epoch [14/30] Batch [4160/4715] Loss: 0.7491\n",
      "2025-05-30 16:26:17,233 - INFO - Epoch [14/30] Batch [4170/4715] Loss: 0.6521\n",
      "2025-05-30 16:26:18,730 - INFO - Epoch [14/30] Batch [4180/4715] Loss: 0.9192\n",
      "2025-05-30 16:26:20,273 - INFO - Epoch [14/30] Batch [4190/4715] Loss: 0.7734\n",
      "2025-05-30 16:26:21,858 - INFO - Epoch [14/30] Batch [4200/4715] Loss: 0.8540\n",
      "2025-05-30 16:26:23,391 - INFO - Epoch [14/30] Batch [4210/4715] Loss: 0.6934\n",
      "2025-05-30 16:26:25,068 - INFO - Epoch [14/30] Batch [4220/4715] Loss: 0.7170\n",
      "2025-05-30 16:26:26,640 - INFO - Epoch [14/30] Batch [4230/4715] Loss: 0.6315\n",
      "2025-05-30 16:26:28,161 - INFO - Epoch [14/30] Batch [4240/4715] Loss: 0.8901\n",
      "2025-05-30 16:26:29,741 - INFO - Epoch [14/30] Batch [4250/4715] Loss: 1.0087\n",
      "2025-05-30 16:26:31,473 - INFO - Epoch [14/30] Batch [4260/4715] Loss: 0.7030\n",
      "2025-05-30 16:26:33,042 - INFO - Epoch [14/30] Batch [4270/4715] Loss: 0.6567\n",
      "2025-05-30 16:26:34,605 - INFO - Epoch [14/30] Batch [4280/4715] Loss: 0.6038\n",
      "2025-05-30 16:26:36,050 - INFO - Epoch [14/30] Batch [4290/4715] Loss: 0.7837\n",
      "2025-05-30 16:26:37,510 - INFO - Epoch [14/30] Batch [4300/4715] Loss: 0.8868\n",
      "2025-05-30 16:26:39,100 - INFO - Epoch [14/30] Batch [4310/4715] Loss: 0.7394\n",
      "2025-05-30 16:26:40,576 - INFO - Epoch [14/30] Batch [4320/4715] Loss: 0.8453\n",
      "2025-05-30 16:26:42,109 - INFO - Epoch [14/30] Batch [4330/4715] Loss: 0.8697\n",
      "2025-05-30 16:26:43,715 - INFO - Epoch [14/30] Batch [4340/4715] Loss: 0.8929\n",
      "2025-05-30 16:26:45,299 - INFO - Epoch [14/30] Batch [4350/4715] Loss: 0.5531\n",
      "2025-05-30 16:26:46,880 - INFO - Epoch [14/30] Batch [4360/4715] Loss: 0.6770\n",
      "2025-05-30 16:26:48,397 - INFO - Epoch [14/30] Batch [4370/4715] Loss: 0.8339\n",
      "2025-05-30 16:26:49,903 - INFO - Epoch [14/30] Batch [4380/4715] Loss: 0.7948\n",
      "2025-05-30 16:26:51,447 - INFO - Epoch [14/30] Batch [4390/4715] Loss: 0.8463\n",
      "2025-05-30 16:26:53,032 - INFO - Epoch [14/30] Batch [4400/4715] Loss: 0.7367\n",
      "2025-05-30 16:26:54,533 - INFO - Epoch [14/30] Batch [4410/4715] Loss: 0.8820\n",
      "2025-05-30 16:26:56,024 - INFO - Epoch [14/30] Batch [4420/4715] Loss: 1.0387\n",
      "2025-05-30 16:26:57,592 - INFO - Epoch [14/30] Batch [4430/4715] Loss: 0.5388\n",
      "2025-05-30 16:26:59,247 - INFO - Epoch [14/30] Batch [4440/4715] Loss: 0.8024\n",
      "2025-05-30 16:27:00,777 - INFO - Epoch [14/30] Batch [4450/4715] Loss: 0.8364\n",
      "2025-05-30 16:27:02,341 - INFO - Epoch [14/30] Batch [4460/4715] Loss: 0.9192\n",
      "2025-05-30 16:27:03,884 - INFO - Epoch [14/30] Batch [4470/4715] Loss: 0.8054\n",
      "2025-05-30 16:27:05,428 - INFO - Epoch [14/30] Batch [4480/4715] Loss: 0.8807\n",
      "2025-05-30 16:27:07,027 - INFO - Epoch [14/30] Batch [4490/4715] Loss: 0.8216\n",
      "2025-05-30 16:27:08,627 - INFO - Epoch [14/30] Batch [4500/4715] Loss: 0.9976\n",
      "2025-05-30 16:27:10,184 - INFO - Epoch [14/30] Batch [4510/4715] Loss: 0.6184\n",
      "2025-05-30 16:27:11,738 - INFO - Epoch [14/30] Batch [4520/4715] Loss: 0.7672\n",
      "2025-05-30 16:27:13,242 - INFO - Epoch [14/30] Batch [4530/4715] Loss: 0.7477\n",
      "2025-05-30 16:27:14,816 - INFO - Epoch [14/30] Batch [4540/4715] Loss: 0.9525\n",
      "2025-05-30 16:27:16,320 - INFO - Epoch [14/30] Batch [4550/4715] Loss: 0.6266\n",
      "2025-05-30 16:27:17,878 - INFO - Epoch [14/30] Batch [4560/4715] Loss: 0.7097\n",
      "2025-05-30 16:27:19,456 - INFO - Epoch [14/30] Batch [4570/4715] Loss: 0.7761\n",
      "2025-05-30 16:27:20,998 - INFO - Epoch [14/30] Batch [4580/4715] Loss: 0.7257\n",
      "2025-05-30 16:27:22,643 - INFO - Epoch [14/30] Batch [4590/4715] Loss: 0.9330\n",
      "2025-05-30 16:27:24,249 - INFO - Epoch [14/30] Batch [4600/4715] Loss: 0.7792\n",
      "2025-05-30 16:27:25,789 - INFO - Epoch [14/30] Batch [4610/4715] Loss: 0.5970\n",
      "2025-05-30 16:27:27,366 - INFO - Epoch [14/30] Batch [4620/4715] Loss: 0.8376\n",
      "2025-05-30 16:27:28,880 - INFO - Epoch [14/30] Batch [4630/4715] Loss: 0.6960\n",
      "2025-05-30 16:27:30,433 - INFO - Epoch [14/30] Batch [4640/4715] Loss: 0.6616\n",
      "2025-05-30 16:27:31,950 - INFO - Epoch [14/30] Batch [4650/4715] Loss: 0.7432\n",
      "2025-05-30 16:27:33,489 - INFO - Epoch [14/30] Batch [4660/4715] Loss: 0.9700\n",
      "2025-05-30 16:27:35,059 - INFO - Epoch [14/30] Batch [4670/4715] Loss: 0.8899\n",
      "2025-05-30 16:27:36,648 - INFO - Epoch [14/30] Batch [4680/4715] Loss: 0.7053\n",
      "2025-05-30 16:27:38,191 - INFO - Epoch [14/30] Batch [4690/4715] Loss: 0.7822\n",
      "2025-05-30 16:27:39,769 - INFO - Epoch [14/30] Batch [4700/4715] Loss: 0.7159\n",
      "2025-05-30 16:27:41,332 - INFO - Epoch [14/30] Batch [4710/4715] Loss: 1.0708\n",
      "2025-05-30 16:28:20,448 - INFO - \n",
      "Epoch [14/30] Time: 776.96s\n",
      "2025-05-30 16:28:20,449 - INFO - Train Loss: 0.7956, Valid Loss: 0.8096\n",
      "2025-05-30 16:28:20,449 - INFO - Valid AUC (macro): 0.7400, F1 (macro): 0.5818\n",
      "2025-05-30 16:28:21,001 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 16:28:21,002 - INFO - Saved checkpoint at epoch 14\n",
      "2025-05-30 16:28:21,186 - INFO - Epoch [15/30] Batch [0/4715] Loss: 0.8786\n",
      "2025-05-30 16:28:22,964 - INFO - Epoch [15/30] Batch [10/4715] Loss: 0.7690\n",
      "2025-05-30 16:28:24,509 - INFO - Epoch [15/30] Batch [20/4715] Loss: 0.6884\n",
      "2025-05-30 16:28:25,999 - INFO - Epoch [15/30] Batch [30/4715] Loss: 0.8766\n",
      "2025-05-30 16:28:27,614 - INFO - Epoch [15/30] Batch [40/4715] Loss: 0.8353\n",
      "2025-05-30 16:28:29,155 - INFO - Epoch [15/30] Batch [50/4715] Loss: 0.5051\n",
      "2025-05-30 16:28:30,737 - INFO - Epoch [15/30] Batch [60/4715] Loss: 0.6106\n",
      "2025-05-30 16:28:32,240 - INFO - Epoch [15/30] Batch [70/4715] Loss: 0.7730\n",
      "2025-05-30 16:28:33,898 - INFO - Epoch [15/30] Batch [80/4715] Loss: 0.6517\n",
      "2025-05-30 16:28:35,638 - INFO - Epoch [15/30] Batch [90/4715] Loss: 0.7131\n",
      "2025-05-30 16:28:37,244 - INFO - Epoch [15/30] Batch [100/4715] Loss: 0.7967\n",
      "2025-05-30 16:28:38,934 - INFO - Epoch [15/30] Batch [110/4715] Loss: 1.1143\n",
      "2025-05-30 16:28:40,526 - INFO - Epoch [15/30] Batch [120/4715] Loss: 0.8411\n",
      "2025-05-30 16:28:42,101 - INFO - Epoch [15/30] Batch [130/4715] Loss: 0.5770\n",
      "2025-05-30 16:28:43,586 - INFO - Epoch [15/30] Batch [140/4715] Loss: 0.6426\n",
      "2025-05-30 16:28:45,207 - INFO - Epoch [15/30] Batch [150/4715] Loss: 0.8241\n",
      "2025-05-30 16:28:46,789 - INFO - Epoch [15/30] Batch [160/4715] Loss: 0.8515\n",
      "2025-05-30 16:28:48,399 - INFO - Epoch [15/30] Batch [170/4715] Loss: 0.7926\n",
      "2025-05-30 16:28:49,923 - INFO - Epoch [15/30] Batch [180/4715] Loss: 0.7064\n",
      "2025-05-30 16:28:51,427 - INFO - Epoch [15/30] Batch [190/4715] Loss: 0.6389\n",
      "2025-05-30 16:28:52,950 - INFO - Epoch [15/30] Batch [200/4715] Loss: 0.9323\n",
      "2025-05-30 16:28:54,609 - INFO - Epoch [15/30] Batch [210/4715] Loss: 0.7924\n",
      "2025-05-30 16:28:56,153 - INFO - Epoch [15/30] Batch [220/4715] Loss: 0.6649\n",
      "2025-05-30 16:28:57,665 - INFO - Epoch [15/30] Batch [230/4715] Loss: 0.9027\n",
      "2025-05-30 16:28:59,218 - INFO - Epoch [15/30] Batch [240/4715] Loss: 0.8029\n",
      "2025-05-30 16:29:00,822 - INFO - Epoch [15/30] Batch [250/4715] Loss: 0.8593\n",
      "2025-05-30 16:29:02,295 - INFO - Epoch [15/30] Batch [260/4715] Loss: 0.7570\n",
      "2025-05-30 16:29:03,880 - INFO - Epoch [15/30] Batch [270/4715] Loss: 0.7679\n",
      "2025-05-30 16:29:05,426 - INFO - Epoch [15/30] Batch [280/4715] Loss: 0.9119\n",
      "2025-05-30 16:29:06,985 - INFO - Epoch [15/30] Batch [290/4715] Loss: 0.9204\n",
      "2025-05-30 16:29:08,625 - INFO - Epoch [15/30] Batch [300/4715] Loss: 0.6608\n",
      "2025-05-30 16:29:10,137 - INFO - Epoch [15/30] Batch [310/4715] Loss: 0.8680\n",
      "2025-05-30 16:29:11,680 - INFO - Epoch [15/30] Batch [320/4715] Loss: 0.8829\n",
      "2025-05-30 16:29:13,190 - INFO - Epoch [15/30] Batch [330/4715] Loss: 0.7138\n",
      "2025-05-30 16:29:14,716 - INFO - Epoch [15/30] Batch [340/4715] Loss: 0.5554\n",
      "2025-05-30 16:29:16,325 - INFO - Epoch [15/30] Batch [350/4715] Loss: 0.7703\n",
      "2025-05-30 16:29:17,912 - INFO - Epoch [15/30] Batch [360/4715] Loss: 1.0264\n",
      "2025-05-30 16:29:19,486 - INFO - Epoch [15/30] Batch [370/4715] Loss: 0.8653\n",
      "2025-05-30 16:29:21,041 - INFO - Epoch [15/30] Batch [380/4715] Loss: 1.0336\n",
      "2025-05-30 16:29:22,644 - INFO - Epoch [15/30] Batch [390/4715] Loss: 0.6855\n",
      "2025-05-30 16:29:24,230 - INFO - Epoch [15/30] Batch [400/4715] Loss: 0.8588\n",
      "2025-05-30 16:29:25,813 - INFO - Epoch [15/30] Batch [410/4715] Loss: 0.7689\n",
      "2025-05-30 16:29:27,374 - INFO - Epoch [15/30] Batch [420/4715] Loss: 0.7676\n",
      "2025-05-30 16:29:28,909 - INFO - Epoch [15/30] Batch [430/4715] Loss: 0.8593\n",
      "2025-05-30 16:29:30,477 - INFO - Epoch [15/30] Batch [440/4715] Loss: 0.9124\n",
      "2025-05-30 16:29:32,042 - INFO - Epoch [15/30] Batch [450/4715] Loss: 0.6658\n",
      "2025-05-30 16:29:33,670 - INFO - Epoch [15/30] Batch [460/4715] Loss: 0.7467\n",
      "2025-05-30 16:29:35,179 - INFO - Epoch [15/30] Batch [470/4715] Loss: 0.9465\n",
      "2025-05-30 16:29:36,700 - INFO - Epoch [15/30] Batch [480/4715] Loss: 0.7857\n",
      "2025-05-30 16:29:38,179 - INFO - Epoch [15/30] Batch [490/4715] Loss: 1.0010\n",
      "2025-05-30 16:29:39,695 - INFO - Epoch [15/30] Batch [500/4715] Loss: 0.8759\n",
      "2025-05-30 16:29:41,322 - INFO - Epoch [15/30] Batch [510/4715] Loss: 0.8916\n",
      "2025-05-30 16:29:42,829 - INFO - Epoch [15/30] Batch [520/4715] Loss: 0.8134\n",
      "2025-05-30 16:29:44,425 - INFO - Epoch [15/30] Batch [530/4715] Loss: 0.6321\n",
      "2025-05-30 16:29:45,974 - INFO - Epoch [15/30] Batch [540/4715] Loss: 0.7394\n",
      "2025-05-30 16:29:47,483 - INFO - Epoch [15/30] Batch [550/4715] Loss: 0.6520\n",
      "2025-05-30 16:29:49,084 - INFO - Epoch [15/30] Batch [560/4715] Loss: 0.8455\n",
      "2025-05-30 16:29:50,649 - INFO - Epoch [15/30] Batch [570/4715] Loss: 0.8991\n",
      "2025-05-30 16:29:52,244 - INFO - Epoch [15/30] Batch [580/4715] Loss: 0.5896\n",
      "2025-05-30 16:29:53,816 - INFO - Epoch [15/30] Batch [590/4715] Loss: 1.1969\n",
      "2025-05-30 16:29:55,392 - INFO - Epoch [15/30] Batch [600/4715] Loss: 0.7764\n",
      "2025-05-30 16:29:56,894 - INFO - Epoch [15/30] Batch [610/4715] Loss: 0.7192\n",
      "2025-05-30 16:29:58,557 - INFO - Epoch [15/30] Batch [620/4715] Loss: 0.8351\n",
      "2025-05-30 16:30:00,269 - INFO - Epoch [15/30] Batch [630/4715] Loss: 1.2573\n",
      "2025-05-30 16:30:01,887 - INFO - Epoch [15/30] Batch [640/4715] Loss: 0.7682\n",
      "2025-05-30 16:30:03,474 - INFO - Epoch [15/30] Batch [650/4715] Loss: 0.6984\n",
      "2025-05-30 16:30:05,166 - INFO - Epoch [15/30] Batch [660/4715] Loss: 0.8682\n",
      "2025-05-30 16:30:06,777 - INFO - Epoch [15/30] Batch [670/4715] Loss: 0.7284\n",
      "2025-05-30 16:30:08,334 - INFO - Epoch [15/30] Batch [680/4715] Loss: 0.7929\n",
      "2025-05-30 16:30:09,797 - INFO - Epoch [15/30] Batch [690/4715] Loss: 0.7265\n",
      "2025-05-30 16:30:11,374 - INFO - Epoch [15/30] Batch [700/4715] Loss: 1.0562\n",
      "2025-05-30 16:30:12,951 - INFO - Epoch [15/30] Batch [710/4715] Loss: 1.0885\n",
      "2025-05-30 16:30:14,505 - INFO - Epoch [15/30] Batch [720/4715] Loss: 0.6168\n",
      "2025-05-30 16:30:16,038 - INFO - Epoch [15/30] Batch [730/4715] Loss: 1.1449\n",
      "2025-05-30 16:30:17,643 - INFO - Epoch [15/30] Batch [740/4715] Loss: 1.0162\n",
      "2025-05-30 16:30:19,230 - INFO - Epoch [15/30] Batch [750/4715] Loss: 0.8617\n",
      "2025-05-30 16:30:20,738 - INFO - Epoch [15/30] Batch [760/4715] Loss: 0.8192\n",
      "2025-05-30 16:30:22,303 - INFO - Epoch [15/30] Batch [770/4715] Loss: 0.9313\n",
      "2025-05-30 16:30:23,860 - INFO - Epoch [15/30] Batch [780/4715] Loss: 0.8795\n",
      "2025-05-30 16:30:25,450 - INFO - Epoch [15/30] Batch [790/4715] Loss: 0.9502\n",
      "2025-05-30 16:30:27,034 - INFO - Epoch [15/30] Batch [800/4715] Loss: 0.8060\n",
      "2025-05-30 16:30:28,596 - INFO - Epoch [15/30] Batch [810/4715] Loss: 0.5289\n",
      "2025-05-30 16:30:30,183 - INFO - Epoch [15/30] Batch [820/4715] Loss: 0.6942\n",
      "2025-05-30 16:30:31,740 - INFO - Epoch [15/30] Batch [830/4715] Loss: 0.8428\n",
      "2025-05-30 16:30:33,267 - INFO - Epoch [15/30] Batch [840/4715] Loss: 0.8163\n",
      "2025-05-30 16:30:34,888 - INFO - Epoch [15/30] Batch [850/4715] Loss: 1.0751\n",
      "2025-05-30 16:30:36,340 - INFO - Epoch [15/30] Batch [860/4715] Loss: 0.9649\n",
      "2025-05-30 16:30:37,883 - INFO - Epoch [15/30] Batch [870/4715] Loss: 0.8487\n",
      "2025-05-30 16:30:39,393 - INFO - Epoch [15/30] Batch [880/4715] Loss: 0.8699\n",
      "2025-05-30 16:30:40,891 - INFO - Epoch [15/30] Batch [890/4715] Loss: 1.0628\n",
      "2025-05-30 16:30:42,465 - INFO - Epoch [15/30] Batch [900/4715] Loss: 0.7037\n",
      "2025-05-30 16:30:44,008 - INFO - Epoch [15/30] Batch [910/4715] Loss: 0.7263\n",
      "2025-05-30 16:30:45,515 - INFO - Epoch [15/30] Batch [920/4715] Loss: 0.6717\n",
      "2025-05-30 16:30:47,066 - INFO - Epoch [15/30] Batch [930/4715] Loss: 0.7841\n",
      "2025-05-30 16:30:48,535 - INFO - Epoch [15/30] Batch [940/4715] Loss: 0.7884\n",
      "2025-05-30 16:30:50,176 - INFO - Epoch [15/30] Batch [950/4715] Loss: 0.9343\n",
      "2025-05-30 16:30:51,787 - INFO - Epoch [15/30] Batch [960/4715] Loss: 0.7590\n",
      "2025-05-30 16:30:53,418 - INFO - Epoch [15/30] Batch [970/4715] Loss: 0.7593\n",
      "2025-05-30 16:30:54,981 - INFO - Epoch [15/30] Batch [980/4715] Loss: 0.7697\n",
      "2025-05-30 16:30:56,530 - INFO - Epoch [15/30] Batch [990/4715] Loss: 0.5898\n",
      "2025-05-30 16:30:58,222 - INFO - Epoch [15/30] Batch [1000/4715] Loss: 1.0446\n",
      "2025-05-30 16:30:59,786 - INFO - Epoch [15/30] Batch [1010/4715] Loss: 0.7874\n",
      "2025-05-30 16:31:01,454 - INFO - Epoch [15/30] Batch [1020/4715] Loss: 0.6767\n",
      "2025-05-30 16:31:02,988 - INFO - Epoch [15/30] Batch [1030/4715] Loss: 1.3154\n",
      "2025-05-30 16:31:04,632 - INFO - Epoch [15/30] Batch [1040/4715] Loss: 0.8678\n",
      "2025-05-30 16:31:06,139 - INFO - Epoch [15/30] Batch [1050/4715] Loss: 0.6081\n",
      "2025-05-30 16:31:07,663 - INFO - Epoch [15/30] Batch [1060/4715] Loss: 1.1245\n",
      "2025-05-30 16:31:09,269 - INFO - Epoch [15/30] Batch [1070/4715] Loss: 1.0301\n",
      "2025-05-30 16:31:10,823 - INFO - Epoch [15/30] Batch [1080/4715] Loss: 0.7071\n",
      "2025-05-30 16:31:12,327 - INFO - Epoch [15/30] Batch [1090/4715] Loss: 0.6336\n",
      "2025-05-30 16:31:13,972 - INFO - Epoch [15/30] Batch [1100/4715] Loss: 0.7985\n",
      "2025-05-30 16:31:15,501 - INFO - Epoch [15/30] Batch [1110/4715] Loss: 0.6990\n",
      "2025-05-30 16:31:17,054 - INFO - Epoch [15/30] Batch [1120/4715] Loss: 0.7774\n",
      "2025-05-30 16:31:18,591 - INFO - Epoch [15/30] Batch [1130/4715] Loss: 0.8408\n",
      "2025-05-30 16:31:20,173 - INFO - Epoch [15/30] Batch [1140/4715] Loss: 0.8787\n",
      "2025-05-30 16:31:21,858 - INFO - Epoch [15/30] Batch [1150/4715] Loss: 1.0057\n",
      "2025-05-30 16:31:23,439 - INFO - Epoch [15/30] Batch [1160/4715] Loss: 1.1393\n",
      "2025-05-30 16:31:24,945 - INFO - Epoch [15/30] Batch [1170/4715] Loss: 0.6081\n",
      "2025-05-30 16:31:26,483 - INFO - Epoch [15/30] Batch [1180/4715] Loss: 0.6041\n",
      "2025-05-30 16:31:28,063 - INFO - Epoch [15/30] Batch [1190/4715] Loss: 0.6045\n",
      "2025-05-30 16:31:29,622 - INFO - Epoch [15/30] Batch [1200/4715] Loss: 0.7668\n",
      "2025-05-30 16:31:31,167 - INFO - Epoch [15/30] Batch [1210/4715] Loss: 0.7677\n",
      "2025-05-30 16:31:32,823 - INFO - Epoch [15/30] Batch [1220/4715] Loss: 0.6885\n",
      "2025-05-30 16:31:34,570 - INFO - Epoch [15/30] Batch [1230/4715] Loss: 0.9648\n",
      "2025-05-30 16:31:36,224 - INFO - Epoch [15/30] Batch [1240/4715] Loss: 0.5007\n",
      "2025-05-30 16:31:37,813 - INFO - Epoch [15/30] Batch [1250/4715] Loss: 0.7319\n",
      "2025-05-30 16:31:39,408 - INFO - Epoch [15/30] Batch [1260/4715] Loss: 0.7462\n",
      "2025-05-30 16:31:40,943 - INFO - Epoch [15/30] Batch [1270/4715] Loss: 0.8470\n",
      "2025-05-30 16:31:42,523 - INFO - Epoch [15/30] Batch [1280/4715] Loss: 0.9239\n",
      "2025-05-30 16:31:44,016 - INFO - Epoch [15/30] Batch [1290/4715] Loss: 0.6654\n",
      "2025-05-30 16:31:45,561 - INFO - Epoch [15/30] Batch [1300/4715] Loss: 0.9128\n",
      "2025-05-30 16:31:47,061 - INFO - Epoch [15/30] Batch [1310/4715] Loss: 0.6621\n",
      "2025-05-30 16:31:48,589 - INFO - Epoch [15/30] Batch [1320/4715] Loss: 0.7812\n",
      "2025-05-30 16:31:50,321 - INFO - Epoch [15/30] Batch [1330/4715] Loss: 0.6709\n",
      "2025-05-30 16:31:51,911 - INFO - Epoch [15/30] Batch [1340/4715] Loss: 0.7101\n",
      "2025-05-30 16:31:53,452 - INFO - Epoch [15/30] Batch [1350/4715] Loss: 0.8634\n",
      "2025-05-30 16:31:55,120 - INFO - Epoch [15/30] Batch [1360/4715] Loss: 0.9538\n",
      "2025-05-30 16:31:56,657 - INFO - Epoch [15/30] Batch [1370/4715] Loss: 0.8195\n",
      "2025-05-30 16:31:58,233 - INFO - Epoch [15/30] Batch [1380/4715] Loss: 1.0772\n",
      "2025-05-30 16:31:59,989 - INFO - Epoch [15/30] Batch [1390/4715] Loss: 0.6410\n",
      "2025-05-30 16:32:01,682 - INFO - Epoch [15/30] Batch [1400/4715] Loss: 0.6489\n",
      "2025-05-30 16:32:03,335 - INFO - Epoch [15/30] Batch [1410/4715] Loss: 0.7330\n",
      "2025-05-30 16:32:04,925 - INFO - Epoch [15/30] Batch [1420/4715] Loss: 0.7111\n",
      "2025-05-30 16:32:06,445 - INFO - Epoch [15/30] Batch [1430/4715] Loss: 0.9247\n",
      "2025-05-30 16:32:08,006 - INFO - Epoch [15/30] Batch [1440/4715] Loss: 0.6150\n",
      "2025-05-30 16:32:09,525 - INFO - Epoch [15/30] Batch [1450/4715] Loss: 0.8490\n",
      "2025-05-30 16:32:11,126 - INFO - Epoch [15/30] Batch [1460/4715] Loss: 0.9896\n",
      "2025-05-30 16:32:12,682 - INFO - Epoch [15/30] Batch [1470/4715] Loss: 1.0040\n",
      "2025-05-30 16:32:14,205 - INFO - Epoch [15/30] Batch [1480/4715] Loss: 0.9383\n",
      "2025-05-30 16:32:15,768 - INFO - Epoch [15/30] Batch [1490/4715] Loss: 1.1408\n",
      "2025-05-30 16:32:17,314 - INFO - Epoch [15/30] Batch [1500/4715] Loss: 0.8949\n",
      "2025-05-30 16:32:18,961 - INFO - Epoch [15/30] Batch [1510/4715] Loss: 0.7519\n",
      "2025-05-30 16:32:20,556 - INFO - Epoch [15/30] Batch [1520/4715] Loss: 0.6884\n",
      "2025-05-30 16:32:22,091 - INFO - Epoch [15/30] Batch [1530/4715] Loss: 0.8491\n",
      "2025-05-30 16:32:23,614 - INFO - Epoch [15/30] Batch [1540/4715] Loss: 1.1351\n",
      "2025-05-30 16:32:25,188 - INFO - Epoch [15/30] Batch [1550/4715] Loss: 0.6564\n",
      "2025-05-30 16:32:26,705 - INFO - Epoch [15/30] Batch [1560/4715] Loss: 0.8072\n",
      "2025-05-30 16:32:28,305 - INFO - Epoch [15/30] Batch [1570/4715] Loss: 0.5123\n",
      "2025-05-30 16:32:29,874 - INFO - Epoch [15/30] Batch [1580/4715] Loss: 0.8216\n",
      "2025-05-30 16:32:31,452 - INFO - Epoch [15/30] Batch [1590/4715] Loss: 0.7918\n",
      "2025-05-30 16:32:32,971 - INFO - Epoch [15/30] Batch [1600/4715] Loss: 0.8882\n",
      "2025-05-30 16:32:34,487 - INFO - Epoch [15/30] Batch [1610/4715] Loss: 0.7730\n",
      "2025-05-30 16:32:35,977 - INFO - Epoch [15/30] Batch [1620/4715] Loss: 0.5554\n",
      "2025-05-30 16:32:37,616 - INFO - Epoch [15/30] Batch [1630/4715] Loss: 0.6066\n",
      "2025-05-30 16:32:39,226 - INFO - Epoch [15/30] Batch [1640/4715] Loss: 0.8385\n",
      "2025-05-30 16:32:40,750 - INFO - Epoch [15/30] Batch [1650/4715] Loss: 0.7149\n",
      "2025-05-30 16:32:42,314 - INFO - Epoch [15/30] Batch [1660/4715] Loss: 0.9437\n",
      "2025-05-30 16:32:43,926 - INFO - Epoch [15/30] Batch [1670/4715] Loss: 0.7708\n",
      "2025-05-30 16:32:45,435 - INFO - Epoch [15/30] Batch [1680/4715] Loss: 0.5918\n",
      "2025-05-30 16:32:46,986 - INFO - Epoch [15/30] Batch [1690/4715] Loss: 1.1251\n",
      "2025-05-30 16:32:48,453 - INFO - Epoch [15/30] Batch [1700/4715] Loss: 0.9565\n",
      "2025-05-30 16:32:50,009 - INFO - Epoch [15/30] Batch [1710/4715] Loss: 1.1323\n",
      "2025-05-30 16:32:51,611 - INFO - Epoch [15/30] Batch [1720/4715] Loss: 0.8322\n",
      "2025-05-30 16:32:53,254 - INFO - Epoch [15/30] Batch [1730/4715] Loss: 0.6773\n",
      "2025-05-30 16:32:54,814 - INFO - Epoch [15/30] Batch [1740/4715] Loss: 0.8985\n",
      "2025-05-30 16:32:56,266 - INFO - Epoch [15/30] Batch [1750/4715] Loss: 0.8523\n",
      "2025-05-30 16:32:57,787 - INFO - Epoch [15/30] Batch [1760/4715] Loss: 1.2714\n",
      "2025-05-30 16:32:59,266 - INFO - Epoch [15/30] Batch [1770/4715] Loss: 0.7501\n",
      "2025-05-30 16:33:00,837 - INFO - Epoch [15/30] Batch [1780/4715] Loss: 0.7591\n",
      "2025-05-30 16:33:02,341 - INFO - Epoch [15/30] Batch [1790/4715] Loss: 0.8313\n",
      "2025-05-30 16:33:03,847 - INFO - Epoch [15/30] Batch [1800/4715] Loss: 0.7734\n",
      "2025-05-30 16:33:05,370 - INFO - Epoch [15/30] Batch [1810/4715] Loss: 0.8004\n",
      "2025-05-30 16:33:06,911 - INFO - Epoch [15/30] Batch [1820/4715] Loss: 0.8600\n",
      "2025-05-30 16:33:08,390 - INFO - Epoch [15/30] Batch [1830/4715] Loss: 0.7275\n",
      "2025-05-30 16:33:10,017 - INFO - Epoch [15/30] Batch [1840/4715] Loss: 0.4898\n",
      "2025-05-30 16:33:11,590 - INFO - Epoch [15/30] Batch [1850/4715] Loss: 0.6537\n",
      "2025-05-30 16:33:13,225 - INFO - Epoch [15/30] Batch [1860/4715] Loss: 0.7087\n",
      "2025-05-30 16:33:14,770 - INFO - Epoch [15/30] Batch [1870/4715] Loss: 0.7600\n",
      "2025-05-30 16:33:16,337 - INFO - Epoch [15/30] Batch [1880/4715] Loss: 1.0061\n",
      "2025-05-30 16:33:17,952 - INFO - Epoch [15/30] Batch [1890/4715] Loss: 0.9256\n",
      "2025-05-30 16:33:19,571 - INFO - Epoch [15/30] Batch [1900/4715] Loss: 0.6694\n",
      "2025-05-30 16:33:21,118 - INFO - Epoch [15/30] Batch [1910/4715] Loss: 0.5441\n",
      "2025-05-30 16:33:22,679 - INFO - Epoch [15/30] Batch [1920/4715] Loss: 0.7594\n",
      "2025-05-30 16:33:24,271 - INFO - Epoch [15/30] Batch [1930/4715] Loss: 0.8845\n",
      "2025-05-30 16:33:25,869 - INFO - Epoch [15/30] Batch [1940/4715] Loss: 0.7558\n",
      "2025-05-30 16:33:27,406 - INFO - Epoch [15/30] Batch [1950/4715] Loss: 0.7995\n",
      "2025-05-30 16:33:28,984 - INFO - Epoch [15/30] Batch [1960/4715] Loss: 0.8367\n",
      "2025-05-30 16:33:30,609 - INFO - Epoch [15/30] Batch [1970/4715] Loss: 0.9750\n",
      "2025-05-30 16:33:32,211 - INFO - Epoch [15/30] Batch [1980/4715] Loss: 0.9112\n",
      "2025-05-30 16:33:33,758 - INFO - Epoch [15/30] Batch [1990/4715] Loss: 0.8388\n",
      "2025-05-30 16:33:35,251 - INFO - Epoch [15/30] Batch [2000/4715] Loss: 1.0289\n",
      "2025-05-30 16:33:36,829 - INFO - Epoch [15/30] Batch [2010/4715] Loss: 0.8009\n",
      "2025-05-30 16:33:38,401 - INFO - Epoch [15/30] Batch [2020/4715] Loss: 0.7843\n",
      "2025-05-30 16:33:39,962 - INFO - Epoch [15/30] Batch [2030/4715] Loss: 0.8989\n",
      "2025-05-30 16:33:41,682 - INFO - Epoch [15/30] Batch [2040/4715] Loss: 0.8139\n",
      "2025-05-30 16:33:43,291 - INFO - Epoch [15/30] Batch [2050/4715] Loss: 0.5529\n",
      "2025-05-30 16:33:44,870 - INFO - Epoch [15/30] Batch [2060/4715] Loss: 0.6185\n",
      "2025-05-30 16:33:46,400 - INFO - Epoch [15/30] Batch [2070/4715] Loss: 0.6875\n",
      "2025-05-30 16:33:48,034 - INFO - Epoch [15/30] Batch [2080/4715] Loss: 0.9149\n",
      "2025-05-30 16:33:49,613 - INFO - Epoch [15/30] Batch [2090/4715] Loss: 0.9087\n",
      "2025-05-30 16:33:51,217 - INFO - Epoch [15/30] Batch [2100/4715] Loss: 0.7467\n",
      "2025-05-30 16:33:52,770 - INFO - Epoch [15/30] Batch [2110/4715] Loss: 0.8174\n",
      "2025-05-30 16:33:54,371 - INFO - Epoch [15/30] Batch [2120/4715] Loss: 0.8421\n",
      "2025-05-30 16:33:55,937 - INFO - Epoch [15/30] Batch [2130/4715] Loss: 0.6407\n",
      "2025-05-30 16:33:57,411 - INFO - Epoch [15/30] Batch [2140/4715] Loss: 0.6930\n",
      "2025-05-30 16:33:58,950 - INFO - Epoch [15/30] Batch [2150/4715] Loss: 0.8049\n",
      "2025-05-30 16:34:00,480 - INFO - Epoch [15/30] Batch [2160/4715] Loss: 0.7738\n",
      "2025-05-30 16:34:02,025 - INFO - Epoch [15/30] Batch [2170/4715] Loss: 0.8278\n",
      "2025-05-30 16:34:03,661 - INFO - Epoch [15/30] Batch [2180/4715] Loss: 0.8697\n",
      "2025-05-30 16:34:05,237 - INFO - Epoch [15/30] Batch [2190/4715] Loss: 0.9030\n",
      "2025-05-30 16:34:06,863 - INFO - Epoch [15/30] Batch [2200/4715] Loss: 0.9972\n",
      "2025-05-30 16:34:08,409 - INFO - Epoch [15/30] Batch [2210/4715] Loss: 0.5048\n",
      "2025-05-30 16:34:09,929 - INFO - Epoch [15/30] Batch [2220/4715] Loss: 0.8371\n",
      "2025-05-30 16:34:11,444 - INFO - Epoch [15/30] Batch [2230/4715] Loss: 0.6139\n",
      "2025-05-30 16:34:13,002 - INFO - Epoch [15/30] Batch [2240/4715] Loss: 0.9535\n",
      "2025-05-30 16:34:14,611 - INFO - Epoch [15/30] Batch [2250/4715] Loss: 1.1529\n",
      "2025-05-30 16:34:16,267 - INFO - Epoch [15/30] Batch [2260/4715] Loss: 0.7732\n",
      "2025-05-30 16:34:17,813 - INFO - Epoch [15/30] Batch [2270/4715] Loss: 0.9817\n",
      "2025-05-30 16:34:19,380 - INFO - Epoch [15/30] Batch [2280/4715] Loss: 0.7350\n",
      "2025-05-30 16:34:20,939 - INFO - Epoch [15/30] Batch [2290/4715] Loss: 0.9627\n",
      "2025-05-30 16:34:22,448 - INFO - Epoch [15/30] Batch [2300/4715] Loss: 0.9158\n",
      "2025-05-30 16:34:23,956 - INFO - Epoch [15/30] Batch [2310/4715] Loss: 0.6733\n",
      "2025-05-30 16:34:25,563 - INFO - Epoch [15/30] Batch [2320/4715] Loss: 0.7365\n",
      "2025-05-30 16:34:27,005 - INFO - Epoch [15/30] Batch [2330/4715] Loss: 0.6176\n",
      "2025-05-30 16:34:28,546 - INFO - Epoch [15/30] Batch [2340/4715] Loss: 0.5206\n",
      "2025-05-30 16:34:30,148 - INFO - Epoch [15/30] Batch [2350/4715] Loss: 0.9012\n",
      "2025-05-30 16:34:31,693 - INFO - Epoch [15/30] Batch [2360/4715] Loss: 0.9169\n",
      "2025-05-30 16:34:33,184 - INFO - Epoch [15/30] Batch [2370/4715] Loss: 0.5887\n",
      "2025-05-30 16:34:34,712 - INFO - Epoch [15/30] Batch [2380/4715] Loss: 0.6907\n",
      "2025-05-30 16:34:36,198 - INFO - Epoch [15/30] Batch [2390/4715] Loss: 0.7423\n",
      "2025-05-30 16:34:37,728 - INFO - Epoch [15/30] Batch [2400/4715] Loss: 0.8245\n",
      "2025-05-30 16:34:39,322 - INFO - Epoch [15/30] Batch [2410/4715] Loss: 0.6846\n",
      "2025-05-30 16:34:40,901 - INFO - Epoch [15/30] Batch [2420/4715] Loss: 0.4316\n",
      "2025-05-30 16:34:42,421 - INFO - Epoch [15/30] Batch [2430/4715] Loss: 0.6755\n",
      "2025-05-30 16:34:44,043 - INFO - Epoch [15/30] Batch [2440/4715] Loss: 0.9047\n",
      "2025-05-30 16:34:45,607 - INFO - Epoch [15/30] Batch [2450/4715] Loss: 0.9947\n",
      "2025-05-30 16:34:47,226 - INFO - Epoch [15/30] Batch [2460/4715] Loss: 0.8455\n",
      "2025-05-30 16:34:48,726 - INFO - Epoch [15/30] Batch [2470/4715] Loss: 0.8943\n",
      "2025-05-30 16:34:50,342 - INFO - Epoch [15/30] Batch [2480/4715] Loss: 1.0868\n",
      "2025-05-30 16:34:51,888 - INFO - Epoch [15/30] Batch [2490/4715] Loss: 0.7115\n",
      "2025-05-30 16:34:53,508 - INFO - Epoch [15/30] Batch [2500/4715] Loss: 0.6549\n",
      "2025-05-30 16:34:55,119 - INFO - Epoch [15/30] Batch [2510/4715] Loss: 1.0472\n",
      "2025-05-30 16:34:56,599 - INFO - Epoch [15/30] Batch [2520/4715] Loss: 0.7020\n",
      "2025-05-30 16:34:58,079 - INFO - Epoch [15/30] Batch [2530/4715] Loss: 0.8968\n",
      "2025-05-30 16:34:59,690 - INFO - Epoch [15/30] Batch [2540/4715] Loss: 0.9542\n",
      "2025-05-30 16:35:01,328 - INFO - Epoch [15/30] Batch [2550/4715] Loss: 0.9040\n",
      "2025-05-30 16:35:02,970 - INFO - Epoch [15/30] Batch [2560/4715] Loss: 0.7056\n",
      "2025-05-30 16:35:04,581 - INFO - Epoch [15/30] Batch [2570/4715] Loss: 0.8938\n",
      "2025-05-30 16:35:06,158 - INFO - Epoch [15/30] Batch [2580/4715] Loss: 0.6746\n",
      "2025-05-30 16:35:07,730 - INFO - Epoch [15/30] Batch [2590/4715] Loss: 0.8378\n",
      "2025-05-30 16:35:09,284 - INFO - Epoch [15/30] Batch [2600/4715] Loss: 0.8205\n",
      "2025-05-30 16:35:10,872 - INFO - Epoch [15/30] Batch [2610/4715] Loss: 0.9195\n",
      "2025-05-30 16:35:12,357 - INFO - Epoch [15/30] Batch [2620/4715] Loss: 0.6981\n",
      "2025-05-30 16:35:13,876 - INFO - Epoch [15/30] Batch [2630/4715] Loss: 0.6578\n",
      "2025-05-30 16:35:15,419 - INFO - Epoch [15/30] Batch [2640/4715] Loss: 0.7437\n",
      "2025-05-30 16:35:17,134 - INFO - Epoch [15/30] Batch [2650/4715] Loss: 0.6463\n",
      "2025-05-30 16:35:18,717 - INFO - Epoch [15/30] Batch [2660/4715] Loss: 0.9850\n",
      "2025-05-30 16:35:20,272 - INFO - Epoch [15/30] Batch [2670/4715] Loss: 0.9701\n",
      "2025-05-30 16:35:21,874 - INFO - Epoch [15/30] Batch [2680/4715] Loss: 0.5915\n",
      "2025-05-30 16:35:23,501 - INFO - Epoch [15/30] Batch [2690/4715] Loss: 0.6314\n",
      "2025-05-30 16:35:25,151 - INFO - Epoch [15/30] Batch [2700/4715] Loss: 0.7838\n",
      "2025-05-30 16:35:26,727 - INFO - Epoch [15/30] Batch [2710/4715] Loss: 0.8441\n",
      "2025-05-30 16:35:28,350 - INFO - Epoch [15/30] Batch [2720/4715] Loss: 0.8894\n",
      "2025-05-30 16:35:29,936 - INFO - Epoch [15/30] Batch [2730/4715] Loss: 0.9846\n",
      "2025-05-30 16:35:31,505 - INFO - Epoch [15/30] Batch [2740/4715] Loss: 0.7469\n",
      "2025-05-30 16:35:33,042 - INFO - Epoch [15/30] Batch [2750/4715] Loss: 0.7075\n",
      "2025-05-30 16:35:34,572 - INFO - Epoch [15/30] Batch [2760/4715] Loss: 0.8366\n",
      "2025-05-30 16:35:36,064 - INFO - Epoch [15/30] Batch [2770/4715] Loss: 0.7323\n",
      "2025-05-30 16:35:37,623 - INFO - Epoch [15/30] Batch [2780/4715] Loss: 0.7220\n",
      "2025-05-30 16:35:39,157 - INFO - Epoch [15/30] Batch [2790/4715] Loss: 0.7549\n",
      "2025-05-30 16:35:40,780 - INFO - Epoch [15/30] Batch [2800/4715] Loss: 0.7353\n",
      "2025-05-30 16:35:42,334 - INFO - Epoch [15/30] Batch [2810/4715] Loss: 0.8274\n",
      "2025-05-30 16:35:43,836 - INFO - Epoch [15/30] Batch [2820/4715] Loss: 0.5509\n",
      "2025-05-30 16:35:45,361 - INFO - Epoch [15/30] Batch [2830/4715] Loss: 0.7891\n",
      "2025-05-30 16:35:46,944 - INFO - Epoch [15/30] Batch [2840/4715] Loss: 0.7792\n",
      "2025-05-30 16:35:48,480 - INFO - Epoch [15/30] Batch [2850/4715] Loss: 0.8479\n",
      "2025-05-30 16:35:50,051 - INFO - Epoch [15/30] Batch [2860/4715] Loss: 0.8820\n",
      "2025-05-30 16:35:51,573 - INFO - Epoch [15/30] Batch [2870/4715] Loss: 0.5042\n",
      "2025-05-30 16:35:53,148 - INFO - Epoch [15/30] Batch [2880/4715] Loss: 1.1902\n",
      "2025-05-30 16:35:54,671 - INFO - Epoch [15/30] Batch [2890/4715] Loss: 0.8253\n",
      "2025-05-30 16:35:56,169 - INFO - Epoch [15/30] Batch [2900/4715] Loss: 0.9228\n",
      "2025-05-30 16:35:57,757 - INFO - Epoch [15/30] Batch [2910/4715] Loss: 0.5302\n",
      "2025-05-30 16:35:59,341 - INFO - Epoch [15/30] Batch [2920/4715] Loss: 0.7123\n",
      "2025-05-30 16:36:00,851 - INFO - Epoch [15/30] Batch [2930/4715] Loss: 0.5437\n",
      "2025-05-30 16:36:02,403 - INFO - Epoch [15/30] Batch [2940/4715] Loss: 1.0183\n",
      "2025-05-30 16:36:04,017 - INFO - Epoch [15/30] Batch [2950/4715] Loss: 0.8943\n",
      "2025-05-30 16:36:05,643 - INFO - Epoch [15/30] Batch [2960/4715] Loss: 0.8234\n",
      "2025-05-30 16:36:07,183 - INFO - Epoch [15/30] Batch [2970/4715] Loss: 0.6177\n",
      "2025-05-30 16:36:08,854 - INFO - Epoch [15/30] Batch [2980/4715] Loss: 0.6450\n",
      "2025-05-30 16:36:10,498 - INFO - Epoch [15/30] Batch [2990/4715] Loss: 0.9388\n",
      "2025-05-30 16:36:11,995 - INFO - Epoch [15/30] Batch [3000/4715] Loss: 0.6612\n",
      "2025-05-30 16:36:13,518 - INFO - Epoch [15/30] Batch [3010/4715] Loss: 0.9384\n",
      "2025-05-30 16:36:15,120 - INFO - Epoch [15/30] Batch [3020/4715] Loss: 0.8332\n",
      "2025-05-30 16:36:16,720 - INFO - Epoch [15/30] Batch [3030/4715] Loss: 0.8086\n",
      "2025-05-30 16:36:18,245 - INFO - Epoch [15/30] Batch [3040/4715] Loss: 0.6882\n",
      "2025-05-30 16:36:19,772 - INFO - Epoch [15/30] Batch [3050/4715] Loss: 0.8895\n",
      "2025-05-30 16:36:21,380 - INFO - Epoch [15/30] Batch [3060/4715] Loss: 0.8083\n",
      "2025-05-30 16:36:22,981 - INFO - Epoch [15/30] Batch [3070/4715] Loss: 0.6276\n",
      "2025-05-30 16:36:24,562 - INFO - Epoch [15/30] Batch [3080/4715] Loss: 0.7842\n",
      "2025-05-30 16:36:26,319 - INFO - Epoch [15/30] Batch [3090/4715] Loss: 0.7583\n",
      "2025-05-30 16:36:27,914 - INFO - Epoch [15/30] Batch [3100/4715] Loss: 0.8919\n",
      "2025-05-30 16:36:29,579 - INFO - Epoch [15/30] Batch [3110/4715] Loss: 0.9172\n",
      "2025-05-30 16:36:31,092 - INFO - Epoch [15/30] Batch [3120/4715] Loss: 0.5695\n",
      "2025-05-30 16:36:32,649 - INFO - Epoch [15/30] Batch [3130/4715] Loss: 0.5607\n",
      "2025-05-30 16:36:34,145 - INFO - Epoch [15/30] Batch [3140/4715] Loss: 0.9999\n",
      "2025-05-30 16:36:35,713 - INFO - Epoch [15/30] Batch [3150/4715] Loss: 0.6618\n",
      "2025-05-30 16:36:37,316 - INFO - Epoch [15/30] Batch [3160/4715] Loss: 0.6415\n",
      "2025-05-30 16:36:38,906 - INFO - Epoch [15/30] Batch [3170/4715] Loss: 0.6568\n",
      "2025-05-30 16:36:40,464 - INFO - Epoch [15/30] Batch [3180/4715] Loss: 0.8408\n",
      "2025-05-30 16:36:42,009 - INFO - Epoch [15/30] Batch [3190/4715] Loss: 0.7598\n",
      "2025-05-30 16:36:43,494 - INFO - Epoch [15/30] Batch [3200/4715] Loss: 0.6625\n",
      "2025-05-30 16:36:44,946 - INFO - Epoch [15/30] Batch [3210/4715] Loss: 0.6770\n",
      "2025-05-30 16:36:46,461 - INFO - Epoch [15/30] Batch [3220/4715] Loss: 0.7661\n",
      "2025-05-30 16:36:47,957 - INFO - Epoch [15/30] Batch [3230/4715] Loss: 0.9252\n",
      "2025-05-30 16:36:49,575 - INFO - Epoch [15/30] Batch [3240/4715] Loss: 0.9673\n",
      "2025-05-30 16:36:51,068 - INFO - Epoch [15/30] Batch [3250/4715] Loss: 0.8554\n",
      "2025-05-30 16:36:52,599 - INFO - Epoch [15/30] Batch [3260/4715] Loss: 0.7289\n",
      "2025-05-30 16:36:54,127 - INFO - Epoch [15/30] Batch [3270/4715] Loss: 0.6843\n",
      "2025-05-30 16:36:55,678 - INFO - Epoch [15/30] Batch [3280/4715] Loss: 0.7827\n",
      "2025-05-30 16:36:57,431 - INFO - Epoch [15/30] Batch [3290/4715] Loss: 0.7746\n",
      "2025-05-30 16:36:59,002 - INFO - Epoch [15/30] Batch [3300/4715] Loss: 0.6580\n",
      "2025-05-30 16:37:00,568 - INFO - Epoch [15/30] Batch [3310/4715] Loss: 0.8376\n",
      "2025-05-30 16:37:02,199 - INFO - Epoch [15/30] Batch [3320/4715] Loss: 0.7880\n",
      "2025-05-30 16:37:03,918 - INFO - Epoch [15/30] Batch [3330/4715] Loss: 0.6025\n",
      "2025-05-30 16:37:05,466 - INFO - Epoch [15/30] Batch [3340/4715] Loss: 0.7873\n",
      "2025-05-30 16:37:07,029 - INFO - Epoch [15/30] Batch [3350/4715] Loss: 0.8729\n",
      "2025-05-30 16:37:08,577 - INFO - Epoch [15/30] Batch [3360/4715] Loss: 0.7150\n",
      "2025-05-30 16:37:10,244 - INFO - Epoch [15/30] Batch [3370/4715] Loss: 0.7448\n",
      "2025-05-30 16:37:11,991 - INFO - Epoch [15/30] Batch [3380/4715] Loss: 0.9824\n",
      "2025-05-30 16:37:13,580 - INFO - Epoch [15/30] Batch [3390/4715] Loss: 0.6629\n",
      "2025-05-30 16:37:15,270 - INFO - Epoch [15/30] Batch [3400/4715] Loss: 0.6448\n",
      "2025-05-30 16:37:16,830 - INFO - Epoch [15/30] Batch [3410/4715] Loss: 0.6189\n",
      "2025-05-30 16:37:18,323 - INFO - Epoch [15/30] Batch [3420/4715] Loss: 0.7519\n",
      "2025-05-30 16:37:19,819 - INFO - Epoch [15/30] Batch [3430/4715] Loss: 0.8775\n",
      "2025-05-30 16:37:21,321 - INFO - Epoch [15/30] Batch [3440/4715] Loss: 0.6860\n",
      "2025-05-30 16:37:22,796 - INFO - Epoch [15/30] Batch [3450/4715] Loss: 0.5396\n",
      "2025-05-30 16:37:24,429 - INFO - Epoch [15/30] Batch [3460/4715] Loss: 0.8023\n",
      "2025-05-30 16:37:25,993 - INFO - Epoch [15/30] Batch [3470/4715] Loss: 0.7709\n",
      "2025-05-30 16:37:27,666 - INFO - Epoch [15/30] Batch [3480/4715] Loss: 0.9014\n",
      "2025-05-30 16:37:29,304 - INFO - Epoch [15/30] Batch [3490/4715] Loss: 0.6804\n",
      "2025-05-30 16:37:30,981 - INFO - Epoch [15/30] Batch [3500/4715] Loss: 0.8363\n",
      "2025-05-30 16:37:32,579 - INFO - Epoch [15/30] Batch [3510/4715] Loss: 0.6680\n",
      "2025-05-30 16:37:34,156 - INFO - Epoch [15/30] Batch [3520/4715] Loss: 0.9877\n",
      "2025-05-30 16:37:35,739 - INFO - Epoch [15/30] Batch [3530/4715] Loss: 0.6881\n",
      "2025-05-30 16:37:37,295 - INFO - Epoch [15/30] Batch [3540/4715] Loss: 0.6050\n",
      "2025-05-30 16:37:38,872 - INFO - Epoch [15/30] Batch [3550/4715] Loss: 0.7430\n",
      "2025-05-30 16:37:40,350 - INFO - Epoch [15/30] Batch [3560/4715] Loss: 0.6167\n",
      "2025-05-30 16:37:41,885 - INFO - Epoch [15/30] Batch [3570/4715] Loss: 0.9275\n",
      "2025-05-30 16:37:43,478 - INFO - Epoch [15/30] Batch [3580/4715] Loss: 0.9453\n",
      "2025-05-30 16:37:45,060 - INFO - Epoch [15/30] Batch [3590/4715] Loss: 0.6914\n",
      "2025-05-30 16:37:46,639 - INFO - Epoch [15/30] Batch [3600/4715] Loss: 0.7915\n",
      "2025-05-30 16:37:48,110 - INFO - Epoch [15/30] Batch [3610/4715] Loss: 0.8103\n",
      "2025-05-30 16:37:49,661 - INFO - Epoch [15/30] Batch [3620/4715] Loss: 0.7522\n",
      "2025-05-30 16:37:51,285 - INFO - Epoch [15/30] Batch [3630/4715] Loss: 0.9269\n",
      "2025-05-30 16:37:52,912 - INFO - Epoch [15/30] Batch [3640/4715] Loss: 0.9122\n",
      "2025-05-30 16:37:54,418 - INFO - Epoch [15/30] Batch [3650/4715] Loss: 0.6308\n",
      "2025-05-30 16:37:55,969 - INFO - Epoch [15/30] Batch [3660/4715] Loss: 0.7377\n",
      "2025-05-30 16:37:57,562 - INFO - Epoch [15/30] Batch [3670/4715] Loss: 0.9215\n",
      "2025-05-30 16:37:59,120 - INFO - Epoch [15/30] Batch [3680/4715] Loss: 0.6218\n",
      "2025-05-30 16:38:00,682 - INFO - Epoch [15/30] Batch [3690/4715] Loss: 0.6334\n",
      "2025-05-30 16:38:02,200 - INFO - Epoch [15/30] Batch [3700/4715] Loss: 0.6422\n",
      "2025-05-30 16:38:03,737 - INFO - Epoch [15/30] Batch [3710/4715] Loss: 0.5680\n",
      "2025-05-30 16:38:05,389 - INFO - Epoch [15/30] Batch [3720/4715] Loss: 0.8093\n",
      "2025-05-30 16:38:06,952 - INFO - Epoch [15/30] Batch [3730/4715] Loss: 0.9193\n",
      "2025-05-30 16:38:08,491 - INFO - Epoch [15/30] Batch [3740/4715] Loss: 1.0817\n",
      "2025-05-30 16:38:09,993 - INFO - Epoch [15/30] Batch [3750/4715] Loss: 0.6708\n",
      "2025-05-30 16:38:11,456 - INFO - Epoch [15/30] Batch [3760/4715] Loss: 0.8029\n",
      "2025-05-30 16:38:13,079 - INFO - Epoch [15/30] Batch [3770/4715] Loss: 0.8906\n",
      "2025-05-30 16:38:14,641 - INFO - Epoch [15/30] Batch [3780/4715] Loss: 0.6137\n",
      "2025-05-30 16:38:16,158 - INFO - Epoch [15/30] Batch [3790/4715] Loss: 0.7912\n",
      "2025-05-30 16:38:17,679 - INFO - Epoch [15/30] Batch [3800/4715] Loss: 0.7802\n",
      "2025-05-30 16:38:19,213 - INFO - Epoch [15/30] Batch [3810/4715] Loss: 0.8013\n",
      "2025-05-30 16:38:20,832 - INFO - Epoch [15/30] Batch [3820/4715] Loss: 0.5737\n",
      "2025-05-30 16:38:22,399 - INFO - Epoch [15/30] Batch [3830/4715] Loss: 0.6318\n",
      "2025-05-30 16:38:23,938 - INFO - Epoch [15/30] Batch [3840/4715] Loss: 0.6774\n",
      "2025-05-30 16:38:25,435 - INFO - Epoch [15/30] Batch [3850/4715] Loss: 0.8950\n",
      "2025-05-30 16:38:26,974 - INFO - Epoch [15/30] Batch [3860/4715] Loss: 0.6245\n",
      "2025-05-30 16:38:28,452 - INFO - Epoch [15/30] Batch [3870/4715] Loss: 1.0276\n",
      "2025-05-30 16:38:30,013 - INFO - Epoch [15/30] Batch [3880/4715] Loss: 0.9432\n",
      "2025-05-30 16:38:31,605 - INFO - Epoch [15/30] Batch [3890/4715] Loss: 0.6907\n",
      "2025-05-30 16:38:33,163 - INFO - Epoch [15/30] Batch [3900/4715] Loss: 0.6945\n",
      "2025-05-30 16:38:34,739 - INFO - Epoch [15/30] Batch [3910/4715] Loss: 0.7024\n",
      "2025-05-30 16:38:36,399 - INFO - Epoch [15/30] Batch [3920/4715] Loss: 0.7468\n",
      "2025-05-30 16:38:38,125 - INFO - Epoch [15/30] Batch [3930/4715] Loss: 0.6841\n",
      "2025-05-30 16:38:39,728 - INFO - Epoch [15/30] Batch [3940/4715] Loss: 0.7388\n",
      "2025-05-30 16:38:41,308 - INFO - Epoch [15/30] Batch [3950/4715] Loss: 0.6304\n",
      "2025-05-30 16:38:42,904 - INFO - Epoch [15/30] Batch [3960/4715] Loss: 0.7503\n",
      "2025-05-30 16:38:44,532 - INFO - Epoch [15/30] Batch [3970/4715] Loss: 0.8126\n",
      "2025-05-30 16:38:46,160 - INFO - Epoch [15/30] Batch [3980/4715] Loss: 0.9615\n",
      "2025-05-30 16:38:47,691 - INFO - Epoch [15/30] Batch [3990/4715] Loss: 1.2271\n",
      "2025-05-30 16:38:49,334 - INFO - Epoch [15/30] Batch [4000/4715] Loss: 0.8864\n",
      "2025-05-30 16:38:50,829 - INFO - Epoch [15/30] Batch [4010/4715] Loss: 1.0274\n",
      "2025-05-30 16:38:52,385 - INFO - Epoch [15/30] Batch [4020/4715] Loss: 1.0234\n",
      "2025-05-30 16:38:54,002 - INFO - Epoch [15/30] Batch [4030/4715] Loss: 0.6423\n",
      "2025-05-30 16:38:55,578 - INFO - Epoch [15/30] Batch [4040/4715] Loss: 0.6976\n",
      "2025-05-30 16:38:57,221 - INFO - Epoch [15/30] Batch [4050/4715] Loss: 0.8163\n",
      "2025-05-30 16:38:58,736 - INFO - Epoch [15/30] Batch [4060/4715] Loss: 0.8743\n",
      "2025-05-30 16:39:00,282 - INFO - Epoch [15/30] Batch [4070/4715] Loss: 0.7151\n",
      "2025-05-30 16:39:01,799 - INFO - Epoch [15/30] Batch [4080/4715] Loss: 0.8303\n",
      "2025-05-30 16:39:03,437 - INFO - Epoch [15/30] Batch [4090/4715] Loss: 0.8025\n",
      "2025-05-30 16:39:05,073 - INFO - Epoch [15/30] Batch [4100/4715] Loss: 0.6679\n",
      "2025-05-30 16:39:06,742 - INFO - Epoch [15/30] Batch [4110/4715] Loss: 0.7512\n",
      "2025-05-30 16:39:08,417 - INFO - Epoch [15/30] Batch [4120/4715] Loss: 0.6588\n",
      "2025-05-30 16:39:09,969 - INFO - Epoch [15/30] Batch [4130/4715] Loss: 0.5528\n",
      "2025-05-30 16:39:11,577 - INFO - Epoch [15/30] Batch [4140/4715] Loss: 0.6736\n",
      "2025-05-30 16:39:13,164 - INFO - Epoch [15/30] Batch [4150/4715] Loss: 0.7516\n",
      "2025-05-30 16:39:14,646 - INFO - Epoch [15/30] Batch [4160/4715] Loss: 0.4706\n",
      "2025-05-30 16:39:16,282 - INFO - Epoch [15/30] Batch [4170/4715] Loss: 0.7980\n",
      "2025-05-30 16:39:17,949 - INFO - Epoch [15/30] Batch [4180/4715] Loss: 0.6241\n",
      "2025-05-30 16:39:19,530 - INFO - Epoch [15/30] Batch [4190/4715] Loss: 0.8832\n",
      "2025-05-30 16:39:21,037 - INFO - Epoch [15/30] Batch [4200/4715] Loss: 0.7856\n",
      "2025-05-30 16:39:22,553 - INFO - Epoch [15/30] Batch [4210/4715] Loss: 0.7491\n",
      "2025-05-30 16:39:24,098 - INFO - Epoch [15/30] Batch [4220/4715] Loss: 0.7824\n",
      "2025-05-30 16:39:25,663 - INFO - Epoch [15/30] Batch [4230/4715] Loss: 0.5166\n",
      "2025-05-30 16:39:27,277 - INFO - Epoch [15/30] Batch [4240/4715] Loss: 1.0524\n",
      "2025-05-30 16:39:28,863 - INFO - Epoch [15/30] Batch [4250/4715] Loss: 0.9444\n",
      "2025-05-30 16:39:30,394 - INFO - Epoch [15/30] Batch [4260/4715] Loss: 1.0060\n",
      "2025-05-30 16:39:31,890 - INFO - Epoch [15/30] Batch [4270/4715] Loss: 0.7580\n",
      "2025-05-30 16:39:33,459 - INFO - Epoch [15/30] Batch [4280/4715] Loss: 0.6471\n",
      "2025-05-30 16:39:34,961 - INFO - Epoch [15/30] Batch [4290/4715] Loss: 0.7125\n",
      "2025-05-30 16:39:36,491 - INFO - Epoch [15/30] Batch [4300/4715] Loss: 0.8628\n",
      "2025-05-30 16:39:38,101 - INFO - Epoch [15/30] Batch [4310/4715] Loss: 0.9030\n",
      "2025-05-30 16:39:39,641 - INFO - Epoch [15/30] Batch [4320/4715] Loss: 0.7406\n",
      "2025-05-30 16:39:41,189 - INFO - Epoch [15/30] Batch [4330/4715] Loss: 0.7713\n",
      "2025-05-30 16:39:42,721 - INFO - Epoch [15/30] Batch [4340/4715] Loss: 0.4264\n",
      "2025-05-30 16:39:44,266 - INFO - Epoch [15/30] Batch [4350/4715] Loss: 0.6431\n",
      "2025-05-30 16:39:45,804 - INFO - Epoch [15/30] Batch [4360/4715] Loss: 0.7830\n",
      "2025-05-30 16:39:47,292 - INFO - Epoch [15/30] Batch [4370/4715] Loss: 1.0542\n",
      "2025-05-30 16:39:48,881 - INFO - Epoch [15/30] Batch [4380/4715] Loss: 0.6375\n",
      "2025-05-30 16:39:50,431 - INFO - Epoch [15/30] Batch [4390/4715] Loss: 0.9002\n",
      "2025-05-30 16:39:52,036 - INFO - Epoch [15/30] Batch [4400/4715] Loss: 1.0453\n",
      "2025-05-30 16:39:53,578 - INFO - Epoch [15/30] Batch [4410/4715] Loss: 0.6954\n",
      "2025-05-30 16:39:55,167 - INFO - Epoch [15/30] Batch [4420/4715] Loss: 0.7747\n",
      "2025-05-30 16:39:56,798 - INFO - Epoch [15/30] Batch [4430/4715] Loss: 0.7695\n",
      "2025-05-30 16:39:58,369 - INFO - Epoch [15/30] Batch [4440/4715] Loss: 0.9710\n",
      "2025-05-30 16:39:59,897 - INFO - Epoch [15/30] Batch [4450/4715] Loss: 0.8997\n",
      "2025-05-30 16:40:01,452 - INFO - Epoch [15/30] Batch [4460/4715] Loss: 0.7798\n",
      "2025-05-30 16:40:02,962 - INFO - Epoch [15/30] Batch [4470/4715] Loss: 1.1277\n",
      "2025-05-30 16:40:04,516 - INFO - Epoch [15/30] Batch [4480/4715] Loss: 0.9604\n",
      "2025-05-30 16:40:06,113 - INFO - Epoch [15/30] Batch [4490/4715] Loss: 0.9831\n",
      "2025-05-30 16:40:07,648 - INFO - Epoch [15/30] Batch [4500/4715] Loss: 0.7205\n",
      "2025-05-30 16:40:09,258 - INFO - Epoch [15/30] Batch [4510/4715] Loss: 0.6819\n",
      "2025-05-30 16:40:10,768 - INFO - Epoch [15/30] Batch [4520/4715] Loss: 0.6857\n",
      "2025-05-30 16:40:12,349 - INFO - Epoch [15/30] Batch [4530/4715] Loss: 0.7072\n",
      "2025-05-30 16:40:13,887 - INFO - Epoch [15/30] Batch [4540/4715] Loss: 0.8089\n",
      "2025-05-30 16:40:15,420 - INFO - Epoch [15/30] Batch [4550/4715] Loss: 0.8447\n",
      "2025-05-30 16:40:17,003 - INFO - Epoch [15/30] Batch [4560/4715] Loss: 1.0413\n",
      "2025-05-30 16:40:18,565 - INFO - Epoch [15/30] Batch [4570/4715] Loss: 0.5741\n",
      "2025-05-30 16:40:20,102 - INFO - Epoch [15/30] Batch [4580/4715] Loss: 0.6817\n",
      "2025-05-30 16:40:21,675 - INFO - Epoch [15/30] Batch [4590/4715] Loss: 0.7146\n",
      "2025-05-30 16:40:23,342 - INFO - Epoch [15/30] Batch [4600/4715] Loss: 0.7047\n",
      "2025-05-30 16:40:24,869 - INFO - Epoch [15/30] Batch [4610/4715] Loss: 0.7357\n",
      "2025-05-30 16:40:26,367 - INFO - Epoch [15/30] Batch [4620/4715] Loss: 0.8763\n",
      "2025-05-30 16:40:27,959 - INFO - Epoch [15/30] Batch [4630/4715] Loss: 0.7945\n",
      "2025-05-30 16:40:29,549 - INFO - Epoch [15/30] Batch [4640/4715] Loss: 0.7420\n",
      "2025-05-30 16:40:31,031 - INFO - Epoch [15/30] Batch [4650/4715] Loss: 0.7886\n",
      "2025-05-30 16:40:32,551 - INFO - Epoch [15/30] Batch [4660/4715] Loss: 0.8042\n",
      "2025-05-30 16:40:34,164 - INFO - Epoch [15/30] Batch [4670/4715] Loss: 0.9221\n",
      "2025-05-30 16:40:35,781 - INFO - Epoch [15/30] Batch [4680/4715] Loss: 0.8806\n",
      "2025-05-30 16:40:37,362 - INFO - Epoch [15/30] Batch [4690/4715] Loss: 0.8245\n",
      "2025-05-30 16:40:38,985 - INFO - Epoch [15/30] Batch [4700/4715] Loss: 0.6732\n",
      "2025-05-30 16:40:40,632 - INFO - Epoch [15/30] Batch [4710/4715] Loss: 0.9295\n",
      "2025-05-30 16:41:19,762 - INFO - \n",
      "Epoch [15/30] Time: 778.76s\n",
      "2025-05-30 16:41:19,762 - INFO - Train Loss: 0.7871, Valid Loss: 0.8130\n",
      "2025-05-30 16:41:19,763 - INFO - Valid AUC (macro): 0.7411, F1 (macro): 0.5728\n",
      "2025-05-30 16:41:20,295 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\best_model.pth\n",
      "2025-05-30 16:41:20,296 - INFO - New best model saved with AUC: 0.7411\n",
      "2025-05-30 16:41:20,928 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\checkpoint_epoch_15.pth\n",
      "2025-05-30 16:41:21,459 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 16:41:21,460 - INFO - Saved checkpoint at epoch 15\n",
      "2025-05-30 16:41:21,793 - INFO - Epoch [16/30] Batch [0/4715] Loss: 0.8875\n",
      "2025-05-30 16:41:23,386 - INFO - Epoch [16/30] Batch [10/4715] Loss: 0.8933\n",
      "2025-05-30 16:41:24,941 - INFO - Epoch [16/30] Batch [20/4715] Loss: 0.5387\n",
      "2025-05-30 16:41:26,516 - INFO - Epoch [16/30] Batch [30/4715] Loss: 0.9813\n",
      "2025-05-30 16:41:28,058 - INFO - Epoch [16/30] Batch [40/4715] Loss: 0.8507\n",
      "2025-05-30 16:41:29,557 - INFO - Epoch [16/30] Batch [50/4715] Loss: 0.9995\n",
      "2025-05-30 16:41:31,147 - INFO - Epoch [16/30] Batch [60/4715] Loss: 0.7921\n",
      "2025-05-30 16:41:32,745 - INFO - Epoch [16/30] Batch [70/4715] Loss: 0.9346\n",
      "2025-05-30 16:41:34,263 - INFO - Epoch [16/30] Batch [80/4715] Loss: 1.0633\n",
      "2025-05-30 16:41:35,897 - INFO - Epoch [16/30] Batch [90/4715] Loss: 0.9066\n",
      "2025-05-30 16:41:37,446 - INFO - Epoch [16/30] Batch [100/4715] Loss: 0.6401\n",
      "2025-05-30 16:41:38,929 - INFO - Epoch [16/30] Batch [110/4715] Loss: 0.9818\n",
      "2025-05-30 16:41:40,476 - INFO - Epoch [16/30] Batch [120/4715] Loss: 0.5960\n",
      "2025-05-30 16:41:41,982 - INFO - Epoch [16/30] Batch [130/4715] Loss: 0.6808\n",
      "2025-05-30 16:41:43,536 - INFO - Epoch [16/30] Batch [140/4715] Loss: 0.6005\n",
      "2025-05-30 16:41:45,162 - INFO - Epoch [16/30] Batch [150/4715] Loss: 0.8223\n",
      "2025-05-30 16:41:46,730 - INFO - Epoch [16/30] Batch [160/4715] Loss: 0.6143\n",
      "2025-05-30 16:41:48,344 - INFO - Epoch [16/30] Batch [170/4715] Loss: 0.9198\n",
      "2025-05-30 16:41:49,896 - INFO - Epoch [16/30] Batch [180/4715] Loss: 0.8525\n",
      "2025-05-30 16:41:51,477 - INFO - Epoch [16/30] Batch [190/4715] Loss: 0.7915\n",
      "2025-05-30 16:41:52,988 - INFO - Epoch [16/30] Batch [200/4715] Loss: 0.8282\n",
      "2025-05-30 16:41:54,572 - INFO - Epoch [16/30] Batch [210/4715] Loss: 0.6259\n",
      "2025-05-30 16:41:56,204 - INFO - Epoch [16/30] Batch [220/4715] Loss: 0.7079\n",
      "2025-05-30 16:41:57,708 - INFO - Epoch [16/30] Batch [230/4715] Loss: 0.9922\n",
      "2025-05-30 16:41:59,250 - INFO - Epoch [16/30] Batch [240/4715] Loss: 0.9090\n",
      "2025-05-30 16:42:00,831 - INFO - Epoch [16/30] Batch [250/4715] Loss: 0.8482\n",
      "2025-05-30 16:42:02,337 - INFO - Epoch [16/30] Batch [260/4715] Loss: 0.9429\n",
      "2025-05-30 16:42:03,852 - INFO - Epoch [16/30] Batch [270/4715] Loss: 0.8098\n",
      "2025-05-30 16:42:05,406 - INFO - Epoch [16/30] Batch [280/4715] Loss: 0.6104\n",
      "2025-05-30 16:42:06,865 - INFO - Epoch [16/30] Batch [290/4715] Loss: 0.9669\n",
      "2025-05-30 16:42:08,365 - INFO - Epoch [16/30] Batch [300/4715] Loss: 0.8029\n",
      "2025-05-30 16:42:09,991 - INFO - Epoch [16/30] Batch [310/4715] Loss: 0.6821\n",
      "2025-05-30 16:42:11,537 - INFO - Epoch [16/30] Batch [320/4715] Loss: 0.9880\n",
      "2025-05-30 16:42:13,158 - INFO - Epoch [16/30] Batch [330/4715] Loss: 0.7309\n",
      "2025-05-30 16:42:14,665 - INFO - Epoch [16/30] Batch [340/4715] Loss: 0.8318\n",
      "2025-05-30 16:42:16,228 - INFO - Epoch [16/30] Batch [350/4715] Loss: 0.7249\n",
      "2025-05-30 16:42:17,869 - INFO - Epoch [16/30] Batch [360/4715] Loss: 0.8177\n",
      "2025-05-30 16:42:19,549 - INFO - Epoch [16/30] Batch [370/4715] Loss: 0.6749\n",
      "2025-05-30 16:42:21,151 - INFO - Epoch [16/30] Batch [380/4715] Loss: 0.7069\n",
      "2025-05-30 16:42:22,727 - INFO - Epoch [16/30] Batch [390/4715] Loss: 0.9459\n",
      "2025-05-30 16:42:24,285 - INFO - Epoch [16/30] Batch [400/4715] Loss: 0.7192\n",
      "2025-05-30 16:42:25,777 - INFO - Epoch [16/30] Batch [410/4715] Loss: 0.8303\n",
      "2025-05-30 16:42:27,420 - INFO - Epoch [16/30] Batch [420/4715] Loss: 0.8900\n",
      "2025-05-30 16:42:28,938 - INFO - Epoch [16/30] Batch [430/4715] Loss: 0.8570\n",
      "2025-05-30 16:42:30,450 - INFO - Epoch [16/30] Batch [440/4715] Loss: 0.5692\n",
      "2025-05-30 16:42:32,034 - INFO - Epoch [16/30] Batch [450/4715] Loss: 0.9477\n",
      "2025-05-30 16:42:33,529 - INFO - Epoch [16/30] Batch [460/4715] Loss: 0.8438\n",
      "2025-05-30 16:42:35,102 - INFO - Epoch [16/30] Batch [470/4715] Loss: 0.5664\n",
      "2025-05-30 16:42:36,706 - INFO - Epoch [16/30] Batch [480/4715] Loss: 1.2407\n",
      "2025-05-30 16:42:38,270 - INFO - Epoch [16/30] Batch [490/4715] Loss: 0.6486\n",
      "2025-05-30 16:42:39,796 - INFO - Epoch [16/30] Batch [500/4715] Loss: 0.8614\n",
      "2025-05-30 16:42:41,363 - INFO - Epoch [16/30] Batch [510/4715] Loss: 0.7048\n",
      "2025-05-30 16:42:42,943 - INFO - Epoch [16/30] Batch [520/4715] Loss: 0.5936\n",
      "2025-05-30 16:42:44,470 - INFO - Epoch [16/30] Batch [530/4715] Loss: 0.6934\n",
      "2025-05-30 16:42:46,030 - INFO - Epoch [16/30] Batch [540/4715] Loss: 0.7209\n",
      "2025-05-30 16:42:47,563 - INFO - Epoch [16/30] Batch [550/4715] Loss: 0.8276\n",
      "2025-05-30 16:42:49,029 - INFO - Epoch [16/30] Batch [560/4715] Loss: 0.7042\n",
      "2025-05-30 16:42:50,609 - INFO - Epoch [16/30] Batch [570/4715] Loss: 0.9496\n",
      "2025-05-30 16:42:52,172 - INFO - Epoch [16/30] Batch [580/4715] Loss: 0.5646\n",
      "2025-05-30 16:42:53,726 - INFO - Epoch [16/30] Batch [590/4715] Loss: 0.6125\n",
      "2025-05-30 16:42:55,307 - INFO - Epoch [16/30] Batch [600/4715] Loss: 0.5390\n",
      "2025-05-30 16:42:56,929 - INFO - Epoch [16/30] Batch [610/4715] Loss: 0.9391\n",
      "2025-05-30 16:42:58,490 - INFO - Epoch [16/30] Batch [620/4715] Loss: 0.6474\n",
      "2025-05-30 16:43:00,135 - INFO - Epoch [16/30] Batch [630/4715] Loss: 0.8568\n",
      "2025-05-30 16:43:01,723 - INFO - Epoch [16/30] Batch [640/4715] Loss: 0.7918\n",
      "2025-05-30 16:43:03,278 - INFO - Epoch [16/30] Batch [650/4715] Loss: 0.6943\n",
      "2025-05-30 16:43:04,779 - INFO - Epoch [16/30] Batch [660/4715] Loss: 0.5333\n",
      "2025-05-30 16:43:06,345 - INFO - Epoch [16/30] Batch [670/4715] Loss: 0.6308\n",
      "2025-05-30 16:43:07,883 - INFO - Epoch [16/30] Batch [680/4715] Loss: 1.1088\n",
      "2025-05-30 16:43:09,445 - INFO - Epoch [16/30] Batch [690/4715] Loss: 0.6234\n",
      "2025-05-30 16:43:11,046 - INFO - Epoch [16/30] Batch [700/4715] Loss: 0.4997\n",
      "2025-05-30 16:43:12,636 - INFO - Epoch [16/30] Batch [710/4715] Loss: 0.6753\n",
      "2025-05-30 16:43:14,225 - INFO - Epoch [16/30] Batch [720/4715] Loss: 0.8840\n",
      "2025-05-30 16:43:15,799 - INFO - Epoch [16/30] Batch [730/4715] Loss: 0.7798\n",
      "2025-05-30 16:43:17,335 - INFO - Epoch [16/30] Batch [740/4715] Loss: 0.7590\n",
      "2025-05-30 16:43:18,892 - INFO - Epoch [16/30] Batch [750/4715] Loss: 0.7751\n",
      "2025-05-30 16:43:20,413 - INFO - Epoch [16/30] Batch [760/4715] Loss: 0.6287\n",
      "2025-05-30 16:43:21,973 - INFO - Epoch [16/30] Batch [770/4715] Loss: 0.8960\n",
      "2025-05-30 16:43:23,528 - INFO - Epoch [16/30] Batch [780/4715] Loss: 0.6434\n",
      "2025-05-30 16:43:25,078 - INFO - Epoch [16/30] Batch [790/4715] Loss: 0.6946\n",
      "2025-05-30 16:43:26,675 - INFO - Epoch [16/30] Batch [800/4715] Loss: 0.6027\n",
      "2025-05-30 16:43:28,242 - INFO - Epoch [16/30] Batch [810/4715] Loss: 0.3889\n",
      "2025-05-30 16:43:29,761 - INFO - Epoch [16/30] Batch [820/4715] Loss: 0.8794\n",
      "2025-05-30 16:43:31,273 - INFO - Epoch [16/30] Batch [830/4715] Loss: 0.9077\n",
      "2025-05-30 16:43:32,818 - INFO - Epoch [16/30] Batch [840/4715] Loss: 0.7966\n",
      "2025-05-30 16:43:34,315 - INFO - Epoch [16/30] Batch [850/4715] Loss: 0.7692\n",
      "2025-05-30 16:43:35,916 - INFO - Epoch [16/30] Batch [860/4715] Loss: 0.7410\n",
      "2025-05-30 16:43:37,428 - INFO - Epoch [16/30] Batch [870/4715] Loss: 0.7622\n",
      "2025-05-30 16:43:38,965 - INFO - Epoch [16/30] Batch [880/4715] Loss: 0.8372\n",
      "2025-05-30 16:43:40,463 - INFO - Epoch [16/30] Batch [890/4715] Loss: 0.8224\n",
      "2025-05-30 16:43:42,089 - INFO - Epoch [16/30] Batch [900/4715] Loss: 0.9302\n",
      "2025-05-30 16:43:43,761 - INFO - Epoch [16/30] Batch [910/4715] Loss: 0.9927\n",
      "2025-05-30 16:43:45,283 - INFO - Epoch [16/30] Batch [920/4715] Loss: 0.5184\n",
      "2025-05-30 16:43:46,820 - INFO - Epoch [16/30] Batch [930/4715] Loss: 0.8506\n",
      "2025-05-30 16:43:48,437 - INFO - Epoch [16/30] Batch [940/4715] Loss: 0.6106\n",
      "2025-05-30 16:43:50,013 - INFO - Epoch [16/30] Batch [950/4715] Loss: 0.6728\n",
      "2025-05-30 16:43:51,587 - INFO - Epoch [16/30] Batch [960/4715] Loss: 0.9864\n",
      "2025-05-30 16:43:53,146 - INFO - Epoch [16/30] Batch [970/4715] Loss: 0.7107\n",
      "2025-05-30 16:43:54,703 - INFO - Epoch [16/30] Batch [980/4715] Loss: 0.6362\n",
      "2025-05-30 16:43:56,375 - INFO - Epoch [16/30] Batch [990/4715] Loss: 0.8432\n",
      "2025-05-30 16:43:57,918 - INFO - Epoch [16/30] Batch [1000/4715] Loss: 0.8244\n",
      "2025-05-30 16:43:59,445 - INFO - Epoch [16/30] Batch [1010/4715] Loss: 0.7582\n",
      "2025-05-30 16:44:01,160 - INFO - Epoch [16/30] Batch [1020/4715] Loss: 0.5051\n",
      "2025-05-30 16:44:02,763 - INFO - Epoch [16/30] Batch [1030/4715] Loss: 0.7831\n",
      "2025-05-30 16:44:04,308 - INFO - Epoch [16/30] Batch [1040/4715] Loss: 0.8898\n",
      "2025-05-30 16:44:05,938 - INFO - Epoch [16/30] Batch [1050/4715] Loss: 0.6116\n",
      "2025-05-30 16:44:07,513 - INFO - Epoch [16/30] Batch [1060/4715] Loss: 0.6844\n",
      "2025-05-30 16:44:09,044 - INFO - Epoch [16/30] Batch [1070/4715] Loss: 0.8980\n",
      "2025-05-30 16:44:10,559 - INFO - Epoch [16/30] Batch [1080/4715] Loss: 0.7278\n",
      "2025-05-30 16:44:12,075 - INFO - Epoch [16/30] Batch [1090/4715] Loss: 0.8799\n",
      "2025-05-30 16:44:13,687 - INFO - Epoch [16/30] Batch [1100/4715] Loss: 0.7850\n",
      "2025-05-30 16:44:15,216 - INFO - Epoch [16/30] Batch [1110/4715] Loss: 0.5269\n",
      "2025-05-30 16:44:16,676 - INFO - Epoch [16/30] Batch [1120/4715] Loss: 0.9166\n",
      "2025-05-30 16:44:18,317 - INFO - Epoch [16/30] Batch [1130/4715] Loss: 0.8839\n",
      "2025-05-30 16:44:19,925 - INFO - Epoch [16/30] Batch [1140/4715] Loss: 0.7590\n",
      "2025-05-30 16:44:21,460 - INFO - Epoch [16/30] Batch [1150/4715] Loss: 0.7598\n",
      "2025-05-30 16:44:22,945 - INFO - Epoch [16/30] Batch [1160/4715] Loss: 1.0477\n",
      "2025-05-30 16:44:24,515 - INFO - Epoch [16/30] Batch [1170/4715] Loss: 0.9112\n",
      "2025-05-30 16:44:26,153 - INFO - Epoch [16/30] Batch [1180/4715] Loss: 0.8499\n",
      "2025-05-30 16:44:27,724 - INFO - Epoch [16/30] Batch [1190/4715] Loss: 0.8604\n",
      "2025-05-30 16:44:29,253 - INFO - Epoch [16/30] Batch [1200/4715] Loss: 1.0357\n",
      "2025-05-30 16:44:30,745 - INFO - Epoch [16/30] Batch [1210/4715] Loss: 0.5971\n",
      "2025-05-30 16:44:32,325 - INFO - Epoch [16/30] Batch [1220/4715] Loss: 0.9958\n",
      "2025-05-30 16:44:33,924 - INFO - Epoch [16/30] Batch [1230/4715] Loss: 0.6193\n",
      "2025-05-30 16:44:35,522 - INFO - Epoch [16/30] Batch [1240/4715] Loss: 0.6448\n",
      "2025-05-30 16:44:37,102 - INFO - Epoch [16/30] Batch [1250/4715] Loss: 0.6628\n",
      "2025-05-30 16:44:38,587 - INFO - Epoch [16/30] Batch [1260/4715] Loss: 0.8389\n",
      "2025-05-30 16:44:40,113 - INFO - Epoch [16/30] Batch [1270/4715] Loss: 0.8908\n",
      "2025-05-30 16:44:41,643 - INFO - Epoch [16/30] Batch [1280/4715] Loss: 0.8784\n",
      "2025-05-30 16:44:43,156 - INFO - Epoch [16/30] Batch [1290/4715] Loss: 0.8923\n",
      "2025-05-30 16:44:44,672 - INFO - Epoch [16/30] Batch [1300/4715] Loss: 0.7646\n",
      "2025-05-30 16:44:46,244 - INFO - Epoch [16/30] Batch [1310/4715] Loss: 0.7052\n",
      "2025-05-30 16:44:47,740 - INFO - Epoch [16/30] Batch [1320/4715] Loss: 1.0090\n",
      "2025-05-30 16:44:49,227 - INFO - Epoch [16/30] Batch [1330/4715] Loss: 0.7146\n",
      "2025-05-30 16:44:50,846 - INFO - Epoch [16/30] Batch [1340/4715] Loss: 0.6704\n",
      "2025-05-30 16:44:52,416 - INFO - Epoch [16/30] Batch [1350/4715] Loss: 0.8419\n",
      "2025-05-30 16:44:53,954 - INFO - Epoch [16/30] Batch [1360/4715] Loss: 0.6430\n",
      "2025-05-30 16:44:55,546 - INFO - Epoch [16/30] Batch [1370/4715] Loss: 0.6119\n",
      "2025-05-30 16:44:57,189 - INFO - Epoch [16/30] Batch [1380/4715] Loss: 0.8254\n",
      "2025-05-30 16:44:58,759 - INFO - Epoch [16/30] Batch [1390/4715] Loss: 0.7642\n",
      "2025-05-30 16:45:00,281 - INFO - Epoch [16/30] Batch [1400/4715] Loss: 1.0713\n",
      "2025-05-30 16:45:01,884 - INFO - Epoch [16/30] Batch [1410/4715] Loss: 0.8135\n",
      "2025-05-30 16:45:03,537 - INFO - Epoch [16/30] Batch [1420/4715] Loss: 0.5746\n",
      "2025-05-30 16:45:05,035 - INFO - Epoch [16/30] Batch [1430/4715] Loss: 0.7272\n",
      "2025-05-30 16:45:06,606 - INFO - Epoch [16/30] Batch [1440/4715] Loss: 0.6686\n",
      "2025-05-30 16:45:08,219 - INFO - Epoch [16/30] Batch [1450/4715] Loss: 0.9488\n",
      "2025-05-30 16:45:09,778 - INFO - Epoch [16/30] Batch [1460/4715] Loss: 0.7465\n",
      "2025-05-30 16:45:11,540 - INFO - Epoch [16/30] Batch [1470/4715] Loss: 1.0089\n",
      "2025-05-30 16:45:13,163 - INFO - Epoch [16/30] Batch [1480/4715] Loss: 0.7732\n",
      "2025-05-30 16:45:14,717 - INFO - Epoch [16/30] Batch [1490/4715] Loss: 0.6740\n",
      "2025-05-30 16:45:16,313 - INFO - Epoch [16/30] Batch [1500/4715] Loss: 0.7697\n",
      "2025-05-30 16:45:17,916 - INFO - Epoch [16/30] Batch [1510/4715] Loss: 0.7150\n",
      "2025-05-30 16:45:19,552 - INFO - Epoch [16/30] Batch [1520/4715] Loss: 0.5837\n",
      "2025-05-30 16:45:21,028 - INFO - Epoch [16/30] Batch [1530/4715] Loss: 0.8347\n",
      "2025-05-30 16:45:22,518 - INFO - Epoch [16/30] Batch [1540/4715] Loss: 0.6744\n",
      "2025-05-30 16:45:24,136 - INFO - Epoch [16/30] Batch [1550/4715] Loss: 0.5675\n",
      "2025-05-30 16:45:25,674 - INFO - Epoch [16/30] Batch [1560/4715] Loss: 0.9579\n",
      "2025-05-30 16:45:27,161 - INFO - Epoch [16/30] Batch [1570/4715] Loss: 0.7015\n",
      "2025-05-30 16:45:28,705 - INFO - Epoch [16/30] Batch [1580/4715] Loss: 0.7943\n",
      "2025-05-30 16:45:30,225 - INFO - Epoch [16/30] Batch [1590/4715] Loss: 0.9405\n",
      "2025-05-30 16:45:31,814 - INFO - Epoch [16/30] Batch [1600/4715] Loss: 0.9341\n",
      "2025-05-30 16:45:33,415 - INFO - Epoch [16/30] Batch [1610/4715] Loss: 0.9914\n",
      "2025-05-30 16:45:34,910 - INFO - Epoch [16/30] Batch [1620/4715] Loss: 0.8406\n",
      "2025-05-30 16:45:36,423 - INFO - Epoch [16/30] Batch [1630/4715] Loss: 0.7509\n",
      "2025-05-30 16:45:37,993 - INFO - Epoch [16/30] Batch [1640/4715] Loss: 0.5800\n",
      "2025-05-30 16:45:39,568 - INFO - Epoch [16/30] Batch [1650/4715] Loss: 0.7129\n",
      "2025-05-30 16:45:41,272 - INFO - Epoch [16/30] Batch [1660/4715] Loss: 0.7205\n",
      "2025-05-30 16:45:42,793 - INFO - Epoch [16/30] Batch [1670/4715] Loss: 0.7611\n",
      "2025-05-30 16:45:44,392 - INFO - Epoch [16/30] Batch [1680/4715] Loss: 0.8162\n",
      "2025-05-30 16:45:45,885 - INFO - Epoch [16/30] Batch [1690/4715] Loss: 0.7712\n",
      "2025-05-30 16:45:47,463 - INFO - Epoch [16/30] Batch [1700/4715] Loss: 0.4870\n",
      "2025-05-30 16:45:49,030 - INFO - Epoch [16/30] Batch [1710/4715] Loss: 0.7943\n",
      "2025-05-30 16:45:50,609 - INFO - Epoch [16/30] Batch [1720/4715] Loss: 0.8289\n",
      "2025-05-30 16:45:52,189 - INFO - Epoch [16/30] Batch [1730/4715] Loss: 0.9460\n",
      "2025-05-30 16:45:53,695 - INFO - Epoch [16/30] Batch [1740/4715] Loss: 0.7682\n",
      "2025-05-30 16:45:55,206 - INFO - Epoch [16/30] Batch [1750/4715] Loss: 0.6685\n",
      "2025-05-30 16:45:56,744 - INFO - Epoch [16/30] Batch [1760/4715] Loss: 0.9493\n",
      "2025-05-30 16:45:58,233 - INFO - Epoch [16/30] Batch [1770/4715] Loss: 0.7938\n",
      "2025-05-30 16:45:59,754 - INFO - Epoch [16/30] Batch [1780/4715] Loss: 0.7838\n",
      "2025-05-30 16:46:01,342 - INFO - Epoch [16/30] Batch [1790/4715] Loss: 0.9502\n",
      "2025-05-30 16:46:02,886 - INFO - Epoch [16/30] Batch [1800/4715] Loss: 0.7592\n",
      "2025-05-30 16:46:04,441 - INFO - Epoch [16/30] Batch [1810/4715] Loss: 0.9207\n",
      "2025-05-30 16:46:06,013 - INFO - Epoch [16/30] Batch [1820/4715] Loss: 0.7701\n",
      "2025-05-30 16:46:07,589 - INFO - Epoch [16/30] Batch [1830/4715] Loss: 0.6230\n",
      "2025-05-30 16:46:09,215 - INFO - Epoch [16/30] Batch [1840/4715] Loss: 0.7030\n",
      "2025-05-30 16:46:10,761 - INFO - Epoch [16/30] Batch [1850/4715] Loss: 0.4781\n",
      "2025-05-30 16:46:12,427 - INFO - Epoch [16/30] Batch [1860/4715] Loss: 0.6730\n",
      "2025-05-30 16:46:14,049 - INFO - Epoch [16/30] Batch [1870/4715] Loss: 0.7840\n",
      "2025-05-30 16:46:15,617 - INFO - Epoch [16/30] Batch [1880/4715] Loss: 1.2311\n",
      "2025-05-30 16:46:17,169 - INFO - Epoch [16/30] Batch [1890/4715] Loss: 0.6734\n",
      "2025-05-30 16:46:18,754 - INFO - Epoch [16/30] Batch [1900/4715] Loss: 0.8672\n",
      "2025-05-30 16:46:20,198 - INFO - Epoch [16/30] Batch [1910/4715] Loss: 0.7130\n",
      "2025-05-30 16:46:21,762 - INFO - Epoch [16/30] Batch [1920/4715] Loss: 0.8534\n",
      "2025-05-30 16:46:23,371 - INFO - Epoch [16/30] Batch [1930/4715] Loss: 0.8182\n",
      "2025-05-30 16:46:25,041 - INFO - Epoch [16/30] Batch [1940/4715] Loss: 0.6749\n",
      "2025-05-30 16:46:26,622 - INFO - Epoch [16/30] Batch [1950/4715] Loss: 0.6995\n",
      "2025-05-30 16:46:28,184 - INFO - Epoch [16/30] Batch [1960/4715] Loss: 0.8866\n",
      "2025-05-30 16:46:29,806 - INFO - Epoch [16/30] Batch [1970/4715] Loss: 0.8245\n",
      "2025-05-30 16:46:31,385 - INFO - Epoch [16/30] Batch [1980/4715] Loss: 0.7980\n",
      "2025-05-30 16:46:32,898 - INFO - Epoch [16/30] Batch [1990/4715] Loss: 0.5997\n",
      "2025-05-30 16:46:34,560 - INFO - Epoch [16/30] Batch [2000/4715] Loss: 0.7140\n",
      "2025-05-30 16:46:36,135 - INFO - Epoch [16/30] Batch [2010/4715] Loss: 0.7795\n",
      "2025-05-30 16:46:37,777 - INFO - Epoch [16/30] Batch [2020/4715] Loss: 0.6877\n",
      "2025-05-30 16:46:39,362 - INFO - Epoch [16/30] Batch [2030/4715] Loss: 0.8598\n",
      "2025-05-30 16:46:40,877 - INFO - Epoch [16/30] Batch [2040/4715] Loss: 0.8746\n",
      "2025-05-30 16:46:42,495 - INFO - Epoch [16/30] Batch [2050/4715] Loss: 0.8954\n",
      "2025-05-30 16:46:44,094 - INFO - Epoch [16/30] Batch [2060/4715] Loss: 0.8902\n",
      "2025-05-30 16:46:45,631 - INFO - Epoch [16/30] Batch [2070/4715] Loss: 0.9002\n",
      "2025-05-30 16:46:47,229 - INFO - Epoch [16/30] Batch [2080/4715] Loss: 0.6969\n",
      "2025-05-30 16:46:48,845 - INFO - Epoch [16/30] Batch [2090/4715] Loss: 0.6898\n",
      "2025-05-30 16:46:50,502 - INFO - Epoch [16/30] Batch [2100/4715] Loss: 0.7889\n",
      "2025-05-30 16:46:52,142 - INFO - Epoch [16/30] Batch [2110/4715] Loss: 0.7334\n",
      "2025-05-30 16:46:53,753 - INFO - Epoch [16/30] Batch [2120/4715] Loss: 0.7386\n",
      "2025-05-30 16:46:55,297 - INFO - Epoch [16/30] Batch [2130/4715] Loss: 0.8822\n",
      "2025-05-30 16:46:56,901 - INFO - Epoch [16/30] Batch [2140/4715] Loss: 0.7705\n",
      "2025-05-30 16:46:58,497 - INFO - Epoch [16/30] Batch [2150/4715] Loss: 0.8221\n",
      "2025-05-30 16:47:00,146 - INFO - Epoch [16/30] Batch [2160/4715] Loss: 0.8365\n",
      "2025-05-30 16:47:01,803 - INFO - Epoch [16/30] Batch [2170/4715] Loss: 0.9436\n",
      "2025-05-30 16:47:03,336 - INFO - Epoch [16/30] Batch [2180/4715] Loss: 0.7588\n",
      "2025-05-30 16:47:04,903 - INFO - Epoch [16/30] Batch [2190/4715] Loss: 0.6327\n",
      "2025-05-30 16:47:06,474 - INFO - Epoch [16/30] Batch [2200/4715] Loss: 0.9306\n",
      "2025-05-30 16:47:08,072 - INFO - Epoch [16/30] Batch [2210/4715] Loss: 0.7179\n",
      "2025-05-30 16:47:09,600 - INFO - Epoch [16/30] Batch [2220/4715] Loss: 0.7688\n",
      "2025-05-30 16:47:11,140 - INFO - Epoch [16/30] Batch [2230/4715] Loss: 0.7081\n",
      "2025-05-30 16:47:12,704 - INFO - Epoch [16/30] Batch [2240/4715] Loss: 0.9002\n",
      "2025-05-30 16:47:14,325 - INFO - Epoch [16/30] Batch [2250/4715] Loss: 0.5512\n",
      "2025-05-30 16:47:15,893 - INFO - Epoch [16/30] Batch [2260/4715] Loss: 0.6863\n",
      "2025-05-30 16:47:17,442 - INFO - Epoch [16/30] Batch [2270/4715] Loss: 0.5471\n",
      "2025-05-30 16:47:18,981 - INFO - Epoch [16/30] Batch [2280/4715] Loss: 0.7825\n",
      "2025-05-30 16:47:20,482 - INFO - Epoch [16/30] Batch [2290/4715] Loss: 0.9261\n",
      "2025-05-30 16:47:21,958 - INFO - Epoch [16/30] Batch [2300/4715] Loss: 0.8137\n",
      "2025-05-30 16:47:23,500 - INFO - Epoch [16/30] Batch [2310/4715] Loss: 0.7362\n",
      "2025-05-30 16:47:25,053 - INFO - Epoch [16/30] Batch [2320/4715] Loss: 0.7229\n",
      "2025-05-30 16:47:26,568 - INFO - Epoch [16/30] Batch [2330/4715] Loss: 0.7851\n",
      "2025-05-30 16:47:28,238 - INFO - Epoch [16/30] Batch [2340/4715] Loss: 0.8393\n",
      "2025-05-30 16:47:29,826 - INFO - Epoch [16/30] Batch [2350/4715] Loss: 0.9657\n",
      "2025-05-30 16:47:31,465 - INFO - Epoch [16/30] Batch [2360/4715] Loss: 0.6055\n",
      "2025-05-30 16:47:33,039 - INFO - Epoch [16/30] Batch [2370/4715] Loss: 0.8551\n",
      "2025-05-30 16:47:34,590 - INFO - Epoch [16/30] Batch [2380/4715] Loss: 0.6552\n",
      "2025-05-30 16:47:36,176 - INFO - Epoch [16/30] Batch [2390/4715] Loss: 0.9573\n",
      "2025-05-30 16:47:37,721 - INFO - Epoch [16/30] Batch [2400/4715] Loss: 0.6580\n",
      "2025-05-30 16:47:39,201 - INFO - Epoch [16/30] Batch [2410/4715] Loss: 1.0255\n",
      "2025-05-30 16:47:40,791 - INFO - Epoch [16/30] Batch [2420/4715] Loss: 0.6466\n",
      "2025-05-30 16:47:42,339 - INFO - Epoch [16/30] Batch [2430/4715] Loss: 0.8313\n",
      "2025-05-30 16:47:43,824 - INFO - Epoch [16/30] Batch [2440/4715] Loss: 0.6785\n",
      "2025-05-30 16:47:45,352 - INFO - Epoch [16/30] Batch [2450/4715] Loss: 0.6522\n",
      "2025-05-30 16:47:46,944 - INFO - Epoch [16/30] Batch [2460/4715] Loss: 0.9190\n",
      "2025-05-30 16:47:48,426 - INFO - Epoch [16/30] Batch [2470/4715] Loss: 0.9418\n",
      "2025-05-30 16:47:49,896 - INFO - Epoch [16/30] Batch [2480/4715] Loss: 1.0160\n",
      "2025-05-30 16:47:51,463 - INFO - Epoch [16/30] Batch [2490/4715] Loss: 0.8894\n",
      "2025-05-30 16:47:53,053 - INFO - Epoch [16/30] Batch [2500/4715] Loss: 0.7957\n",
      "2025-05-30 16:47:54,556 - INFO - Epoch [16/30] Batch [2510/4715] Loss: 0.6369\n",
      "2025-05-30 16:47:56,085 - INFO - Epoch [16/30] Batch [2520/4715] Loss: 0.8529\n",
      "2025-05-30 16:47:57,566 - INFO - Epoch [16/30] Batch [2530/4715] Loss: 0.7531\n",
      "2025-05-30 16:47:59,174 - INFO - Epoch [16/30] Batch [2540/4715] Loss: 0.6990\n",
      "2025-05-30 16:48:00,760 - INFO - Epoch [16/30] Batch [2550/4715] Loss: 0.8049\n",
      "2025-05-30 16:48:02,360 - INFO - Epoch [16/30] Batch [2560/4715] Loss: 0.7385\n",
      "2025-05-30 16:48:03,923 - INFO - Epoch [16/30] Batch [2570/4715] Loss: 0.8503\n",
      "2025-05-30 16:48:05,602 - INFO - Epoch [16/30] Batch [2580/4715] Loss: 0.7428\n",
      "2025-05-30 16:48:07,166 - INFO - Epoch [16/30] Batch [2590/4715] Loss: 0.6818\n",
      "2025-05-30 16:48:08,738 - INFO - Epoch [16/30] Batch [2600/4715] Loss: 0.8863\n",
      "2025-05-30 16:48:10,296 - INFO - Epoch [16/30] Batch [2610/4715] Loss: 0.5566\n",
      "2025-05-30 16:48:11,868 - INFO - Epoch [16/30] Batch [2620/4715] Loss: 0.8282\n",
      "2025-05-30 16:48:13,473 - INFO - Epoch [16/30] Batch [2630/4715] Loss: 0.7908\n",
      "2025-05-30 16:48:15,093 - INFO - Epoch [16/30] Batch [2640/4715] Loss: 1.1179\n",
      "2025-05-30 16:48:16,684 - INFO - Epoch [16/30] Batch [2650/4715] Loss: 0.6336\n",
      "2025-05-30 16:48:18,183 - INFO - Epoch [16/30] Batch [2660/4715] Loss: 0.7331\n",
      "2025-05-30 16:48:19,689 - INFO - Epoch [16/30] Batch [2670/4715] Loss: 0.8637\n",
      "2025-05-30 16:48:21,232 - INFO - Epoch [16/30] Batch [2680/4715] Loss: 0.5849\n",
      "2025-05-30 16:48:22,758 - INFO - Epoch [16/30] Batch [2690/4715] Loss: 1.1348\n",
      "2025-05-30 16:48:24,297 - INFO - Epoch [16/30] Batch [2700/4715] Loss: 1.1073\n",
      "2025-05-30 16:48:25,797 - INFO - Epoch [16/30] Batch [2710/4715] Loss: 0.5672\n",
      "2025-05-30 16:48:27,410 - INFO - Epoch [16/30] Batch [2720/4715] Loss: 0.7108\n",
      "2025-05-30 16:48:28,969 - INFO - Epoch [16/30] Batch [2730/4715] Loss: 0.4785\n",
      "2025-05-30 16:48:30,624 - INFO - Epoch [16/30] Batch [2740/4715] Loss: 0.5519\n",
      "2025-05-30 16:48:32,141 - INFO - Epoch [16/30] Batch [2750/4715] Loss: 0.6439\n",
      "2025-05-30 16:48:33,766 - INFO - Epoch [16/30] Batch [2760/4715] Loss: 0.6539\n",
      "2025-05-30 16:48:35,411 - INFO - Epoch [16/30] Batch [2770/4715] Loss: 0.7454\n",
      "2025-05-30 16:48:37,029 - INFO - Epoch [16/30] Batch [2780/4715] Loss: 0.7762\n",
      "2025-05-30 16:48:38,665 - INFO - Epoch [16/30] Batch [2790/4715] Loss: 0.7262\n",
      "2025-05-30 16:48:40,136 - INFO - Epoch [16/30] Batch [2800/4715] Loss: 0.7559\n",
      "2025-05-30 16:48:41,854 - INFO - Epoch [16/30] Batch [2810/4715] Loss: 0.8111\n",
      "2025-05-30 16:48:43,486 - INFO - Epoch [16/30] Batch [2820/4715] Loss: 0.6305\n",
      "2025-05-30 16:48:45,058 - INFO - Epoch [16/30] Batch [2830/4715] Loss: 1.1651\n",
      "2025-05-30 16:48:46,697 - INFO - Epoch [16/30] Batch [2840/4715] Loss: 0.8570\n",
      "2025-05-30 16:48:48,259 - INFO - Epoch [16/30] Batch [2850/4715] Loss: 0.6342\n",
      "2025-05-30 16:48:49,815 - INFO - Epoch [16/30] Batch [2860/4715] Loss: 1.0189\n",
      "2025-05-30 16:48:51,368 - INFO - Epoch [16/30] Batch [2870/4715] Loss: 0.7384\n",
      "2025-05-30 16:48:52,885 - INFO - Epoch [16/30] Batch [2880/4715] Loss: 0.8522\n",
      "2025-05-30 16:48:54,512 - INFO - Epoch [16/30] Batch [2890/4715] Loss: 0.8632\n",
      "2025-05-30 16:48:56,104 - INFO - Epoch [16/30] Batch [2900/4715] Loss: 1.0565\n",
      "2025-05-30 16:48:57,704 - INFO - Epoch [16/30] Batch [2910/4715] Loss: 0.7243\n",
      "2025-05-30 16:48:59,288 - INFO - Epoch [16/30] Batch [2920/4715] Loss: 0.7128\n",
      "2025-05-30 16:49:00,848 - INFO - Epoch [16/30] Batch [2930/4715] Loss: 0.7525\n",
      "2025-05-30 16:49:02,513 - INFO - Epoch [16/30] Batch [2940/4715] Loss: 0.5602\n",
      "2025-05-30 16:49:04,169 - INFO - Epoch [16/30] Batch [2950/4715] Loss: 0.5776\n",
      "2025-05-30 16:49:05,702 - INFO - Epoch [16/30] Batch [2960/4715] Loss: 0.7758\n",
      "2025-05-30 16:49:07,278 - INFO - Epoch [16/30] Batch [2970/4715] Loss: 1.0613\n",
      "2025-05-30 16:49:08,838 - INFO - Epoch [16/30] Batch [2980/4715] Loss: 0.8355\n",
      "2025-05-30 16:49:10,423 - INFO - Epoch [16/30] Batch [2990/4715] Loss: 0.7005\n",
      "2025-05-30 16:49:11,988 - INFO - Epoch [16/30] Batch [3000/4715] Loss: 0.6271\n",
      "2025-05-30 16:49:13,534 - INFO - Epoch [16/30] Batch [3010/4715] Loss: 0.7559\n",
      "2025-05-30 16:49:15,061 - INFO - Epoch [16/30] Batch [3020/4715] Loss: 0.9204\n",
      "2025-05-30 16:49:16,568 - INFO - Epoch [16/30] Batch [3030/4715] Loss: 0.7018\n",
      "2025-05-30 16:49:18,122 - INFO - Epoch [16/30] Batch [3040/4715] Loss: 0.9137\n",
      "2025-05-30 16:49:19,648 - INFO - Epoch [16/30] Batch [3050/4715] Loss: 0.9039\n",
      "2025-05-30 16:49:21,169 - INFO - Epoch [16/30] Batch [3060/4715] Loss: 0.7488\n",
      "2025-05-30 16:49:22,799 - INFO - Epoch [16/30] Batch [3070/4715] Loss: 0.8913\n",
      "2025-05-30 16:49:24,396 - INFO - Epoch [16/30] Batch [3080/4715] Loss: 0.9651\n",
      "2025-05-30 16:49:26,007 - INFO - Epoch [16/30] Batch [3090/4715] Loss: 0.6996\n",
      "2025-05-30 16:49:27,699 - INFO - Epoch [16/30] Batch [3100/4715] Loss: 0.9193\n",
      "2025-05-30 16:49:29,296 - INFO - Epoch [16/30] Batch [3110/4715] Loss: 0.8503\n",
      "2025-05-30 16:49:30,850 - INFO - Epoch [16/30] Batch [3120/4715] Loss: 0.8189\n",
      "2025-05-30 16:49:32,398 - INFO - Epoch [16/30] Batch [3130/4715] Loss: 1.0040\n",
      "2025-05-30 16:49:34,018 - INFO - Epoch [16/30] Batch [3140/4715] Loss: 0.8222\n",
      "2025-05-30 16:49:35,558 - INFO - Epoch [16/30] Batch [3150/4715] Loss: 0.6242\n",
      "2025-05-30 16:49:37,107 - INFO - Epoch [16/30] Batch [3160/4715] Loss: 0.6100\n",
      "2025-05-30 16:49:38,626 - INFO - Epoch [16/30] Batch [3170/4715] Loss: 0.7560\n",
      "2025-05-30 16:49:40,214 - INFO - Epoch [16/30] Batch [3180/4715] Loss: 0.9890\n",
      "2025-05-30 16:49:41,849 - INFO - Epoch [16/30] Batch [3190/4715] Loss: 0.8365\n",
      "2025-05-30 16:49:43,388 - INFO - Epoch [16/30] Batch [3200/4715] Loss: 0.8448\n",
      "2025-05-30 16:49:45,023 - INFO - Epoch [16/30] Batch [3210/4715] Loss: 0.6532\n",
      "2025-05-30 16:49:46,567 - INFO - Epoch [16/30] Batch [3220/4715] Loss: 0.8921\n",
      "2025-05-30 16:49:48,164 - INFO - Epoch [16/30] Batch [3230/4715] Loss: 0.8740\n",
      "2025-05-30 16:49:49,683 - INFO - Epoch [16/30] Batch [3240/4715] Loss: 0.6019\n",
      "2025-05-30 16:49:51,330 - INFO - Epoch [16/30] Batch [3250/4715] Loss: 0.8678\n",
      "2025-05-30 16:49:52,907 - INFO - Epoch [16/30] Batch [3260/4715] Loss: 0.7425\n",
      "2025-05-30 16:49:54,381 - INFO - Epoch [16/30] Batch [3270/4715] Loss: 0.9125\n",
      "2025-05-30 16:49:56,039 - INFO - Epoch [16/30] Batch [3280/4715] Loss: 0.7379\n",
      "2025-05-30 16:49:57,678 - INFO - Epoch [16/30] Batch [3290/4715] Loss: 0.8154\n",
      "2025-05-30 16:49:59,216 - INFO - Epoch [16/30] Batch [3300/4715] Loss: 0.9235\n",
      "2025-05-30 16:50:00,783 - INFO - Epoch [16/30] Batch [3310/4715] Loss: 0.6624\n",
      "2025-05-30 16:50:02,224 - INFO - Epoch [16/30] Batch [3320/4715] Loss: 0.5091\n",
      "2025-05-30 16:50:03,807 - INFO - Epoch [16/30] Batch [3330/4715] Loss: 0.6536\n",
      "2025-05-30 16:50:05,371 - INFO - Epoch [16/30] Batch [3340/4715] Loss: 0.6620\n",
      "2025-05-30 16:50:06,872 - INFO - Epoch [16/30] Batch [3350/4715] Loss: 0.8014\n",
      "2025-05-30 16:50:08,391 - INFO - Epoch [16/30] Batch [3360/4715] Loss: 0.7159\n",
      "2025-05-30 16:50:10,011 - INFO - Epoch [16/30] Batch [3370/4715] Loss: 0.7151\n",
      "2025-05-30 16:50:11,614 - INFO - Epoch [16/30] Batch [3380/4715] Loss: 0.7302\n",
      "2025-05-30 16:50:13,164 - INFO - Epoch [16/30] Batch [3390/4715] Loss: 0.8671\n",
      "2025-05-30 16:50:14,708 - INFO - Epoch [16/30] Batch [3400/4715] Loss: 0.6578\n",
      "2025-05-30 16:50:16,233 - INFO - Epoch [16/30] Batch [3410/4715] Loss: 0.9456\n",
      "2025-05-30 16:50:17,747 - INFO - Epoch [16/30] Batch [3420/4715] Loss: 0.9132\n",
      "2025-05-30 16:50:19,285 - INFO - Epoch [16/30] Batch [3430/4715] Loss: 0.6120\n",
      "2025-05-30 16:50:20,820 - INFO - Epoch [16/30] Batch [3440/4715] Loss: 0.7226\n",
      "2025-05-30 16:50:22,371 - INFO - Epoch [16/30] Batch [3450/4715] Loss: 0.5289\n",
      "2025-05-30 16:50:23,906 - INFO - Epoch [16/30] Batch [3460/4715] Loss: 0.7905\n",
      "2025-05-30 16:50:25,462 - INFO - Epoch [16/30] Batch [3470/4715] Loss: 0.5638\n",
      "2025-05-30 16:50:27,132 - INFO - Epoch [16/30] Batch [3480/4715] Loss: 0.9103\n",
      "2025-05-30 16:50:28,650 - INFO - Epoch [16/30] Batch [3490/4715] Loss: 0.7104\n",
      "2025-05-30 16:50:30,167 - INFO - Epoch [16/30] Batch [3500/4715] Loss: 0.7883\n",
      "2025-05-30 16:50:31,665 - INFO - Epoch [16/30] Batch [3510/4715] Loss: 0.9098\n",
      "2025-05-30 16:50:33,216 - INFO - Epoch [16/30] Batch [3520/4715] Loss: 0.6512\n",
      "2025-05-30 16:50:34,701 - INFO - Epoch [16/30] Batch [3530/4715] Loss: 0.6471\n",
      "2025-05-30 16:50:36,294 - INFO - Epoch [16/30] Batch [3540/4715] Loss: 0.9072\n",
      "2025-05-30 16:50:37,846 - INFO - Epoch [16/30] Batch [3550/4715] Loss: 0.5531\n",
      "2025-05-30 16:50:39,490 - INFO - Epoch [16/30] Batch [3560/4715] Loss: 0.7154\n",
      "2025-05-30 16:50:41,022 - INFO - Epoch [16/30] Batch [3570/4715] Loss: 0.7315\n",
      "2025-05-30 16:50:42,741 - INFO - Epoch [16/30] Batch [3580/4715] Loss: 0.6807\n",
      "2025-05-30 16:50:44,381 - INFO - Epoch [16/30] Batch [3590/4715] Loss: 0.7975\n",
      "2025-05-30 16:50:45,876 - INFO - Epoch [16/30] Batch [3600/4715] Loss: 0.6562\n",
      "2025-05-30 16:50:47,382 - INFO - Epoch [16/30] Batch [3610/4715] Loss: 0.8427\n",
      "2025-05-30 16:50:48,922 - INFO - Epoch [16/30] Batch [3620/4715] Loss: 0.6888\n",
      "2025-05-30 16:50:50,449 - INFO - Epoch [16/30] Batch [3630/4715] Loss: 0.8052\n",
      "2025-05-30 16:50:52,027 - INFO - Epoch [16/30] Batch [3640/4715] Loss: 1.0357\n",
      "2025-05-30 16:50:53,701 - INFO - Epoch [16/30] Batch [3650/4715] Loss: 0.9473\n",
      "2025-05-30 16:50:55,258 - INFO - Epoch [16/30] Batch [3660/4715] Loss: 0.8377\n",
      "2025-05-30 16:50:56,749 - INFO - Epoch [16/30] Batch [3670/4715] Loss: 0.7911\n",
      "2025-05-30 16:50:58,369 - INFO - Epoch [16/30] Batch [3680/4715] Loss: 0.8027\n",
      "2025-05-30 16:50:59,962 - INFO - Epoch [16/30] Batch [3690/4715] Loss: 0.6914\n",
      "2025-05-30 16:51:01,531 - INFO - Epoch [16/30] Batch [3700/4715] Loss: 0.8673\n",
      "2025-05-30 16:51:03,083 - INFO - Epoch [16/30] Batch [3710/4715] Loss: 0.8570\n",
      "2025-05-30 16:51:04,569 - INFO - Epoch [16/30] Batch [3720/4715] Loss: 0.7167\n",
      "2025-05-30 16:51:06,084 - INFO - Epoch [16/30] Batch [3730/4715] Loss: 0.8206\n",
      "2025-05-30 16:51:07,675 - INFO - Epoch [16/30] Batch [3740/4715] Loss: 0.8830\n",
      "2025-05-30 16:51:09,233 - INFO - Epoch [16/30] Batch [3750/4715] Loss: 0.6974\n",
      "2025-05-30 16:51:10,815 - INFO - Epoch [16/30] Batch [3760/4715] Loss: 0.7450\n",
      "2025-05-30 16:51:12,299 - INFO - Epoch [16/30] Batch [3770/4715] Loss: 0.6961\n",
      "2025-05-30 16:51:13,798 - INFO - Epoch [16/30] Batch [3780/4715] Loss: 0.6595\n",
      "2025-05-30 16:51:15,277 - INFO - Epoch [16/30] Batch [3790/4715] Loss: 0.5685\n",
      "2025-05-30 16:51:16,886 - INFO - Epoch [16/30] Batch [3800/4715] Loss: 0.9466\n",
      "2025-05-30 16:51:18,381 - INFO - Epoch [16/30] Batch [3810/4715] Loss: 0.6962\n",
      "2025-05-30 16:51:19,947 - INFO - Epoch [16/30] Batch [3820/4715] Loss: 1.0631\n",
      "2025-05-30 16:51:21,519 - INFO - Epoch [16/30] Batch [3830/4715] Loss: 0.7869\n",
      "2025-05-30 16:51:23,053 - INFO - Epoch [16/30] Batch [3840/4715] Loss: 0.8006\n",
      "2025-05-30 16:51:24,530 - INFO - Epoch [16/30] Batch [3850/4715] Loss: 0.7981\n",
      "2025-05-30 16:51:26,077 - INFO - Epoch [16/30] Batch [3860/4715] Loss: 0.9505\n",
      "2025-05-30 16:51:27,611 - INFO - Epoch [16/30] Batch [3870/4715] Loss: 0.9357\n",
      "2025-05-30 16:51:29,188 - INFO - Epoch [16/30] Batch [3880/4715] Loss: 1.1349\n",
      "2025-05-30 16:51:30,763 - INFO - Epoch [16/30] Batch [3890/4715] Loss: 0.7303\n",
      "2025-05-30 16:51:32,377 - INFO - Epoch [16/30] Batch [3900/4715] Loss: 0.8459\n",
      "2025-05-30 16:51:33,880 - INFO - Epoch [16/30] Batch [3910/4715] Loss: 0.5779\n",
      "2025-05-30 16:51:35,484 - INFO - Epoch [16/30] Batch [3920/4715] Loss: 0.8243\n",
      "2025-05-30 16:51:37,086 - INFO - Epoch [16/30] Batch [3930/4715] Loss: 0.4864\n",
      "2025-05-30 16:51:38,650 - INFO - Epoch [16/30] Batch [3940/4715] Loss: 0.7610\n",
      "2025-05-30 16:51:40,214 - INFO - Epoch [16/30] Batch [3950/4715] Loss: 0.7882\n",
      "2025-05-30 16:51:41,824 - INFO - Epoch [16/30] Batch [3960/4715] Loss: 0.8044\n",
      "2025-05-30 16:51:43,393 - INFO - Epoch [16/30] Batch [3970/4715] Loss: 0.4811\n",
      "2025-05-30 16:51:44,926 - INFO - Epoch [16/30] Batch [3980/4715] Loss: 0.8645\n",
      "2025-05-30 16:51:46,466 - INFO - Epoch [16/30] Batch [3990/4715] Loss: 1.1661\n",
      "2025-05-30 16:51:48,077 - INFO - Epoch [16/30] Batch [4000/4715] Loss: 0.8396\n",
      "2025-05-30 16:51:49,525 - INFO - Epoch [16/30] Batch [4010/4715] Loss: 0.7697\n",
      "2025-05-30 16:51:51,153 - INFO - Epoch [16/30] Batch [4020/4715] Loss: 0.6485\n",
      "2025-05-30 16:51:52,732 - INFO - Epoch [16/30] Batch [4030/4715] Loss: 0.6299\n",
      "2025-05-30 16:51:54,266 - INFO - Epoch [16/30] Batch [4040/4715] Loss: 1.0936\n",
      "2025-05-30 16:51:55,862 - INFO - Epoch [16/30] Batch [4050/4715] Loss: 0.6231\n",
      "2025-05-30 16:51:57,422 - INFO - Epoch [16/30] Batch [4060/4715] Loss: 0.8985\n",
      "2025-05-30 16:51:58,951 - INFO - Epoch [16/30] Batch [4070/4715] Loss: 0.5613\n",
      "2025-05-30 16:52:00,629 - INFO - Epoch [16/30] Batch [4080/4715] Loss: 0.6994\n",
      "2025-05-30 16:52:02,152 - INFO - Epoch [16/30] Batch [4090/4715] Loss: 1.0637\n",
      "2025-05-30 16:52:03,773 - INFO - Epoch [16/30] Batch [4100/4715] Loss: 0.8586\n",
      "2025-05-30 16:52:05,326 - INFO - Epoch [16/30] Batch [4110/4715] Loss: 0.6794\n",
      "2025-05-30 16:52:06,935 - INFO - Epoch [16/30] Batch [4120/4715] Loss: 0.7478\n",
      "2025-05-30 16:52:08,481 - INFO - Epoch [16/30] Batch [4130/4715] Loss: 0.9793\n",
      "2025-05-30 16:52:10,128 - INFO - Epoch [16/30] Batch [4140/4715] Loss: 0.9261\n",
      "2025-05-30 16:52:11,659 - INFO - Epoch [16/30] Batch [4150/4715] Loss: 0.8846\n",
      "2025-05-30 16:52:13,241 - INFO - Epoch [16/30] Batch [4160/4715] Loss: 0.9069\n",
      "2025-05-30 16:52:14,804 - INFO - Epoch [16/30] Batch [4170/4715] Loss: 0.5402\n",
      "2025-05-30 16:52:16,453 - INFO - Epoch [16/30] Batch [4180/4715] Loss: 1.0337\n",
      "2025-05-30 16:52:18,006 - INFO - Epoch [16/30] Batch [4190/4715] Loss: 1.0320\n",
      "2025-05-30 16:52:19,496 - INFO - Epoch [16/30] Batch [4200/4715] Loss: 0.6990\n",
      "2025-05-30 16:52:21,067 - INFO - Epoch [16/30] Batch [4210/4715] Loss: 0.5152\n",
      "2025-05-30 16:52:22,566 - INFO - Epoch [16/30] Batch [4220/4715] Loss: 0.8405\n",
      "2025-05-30 16:52:24,151 - INFO - Epoch [16/30] Batch [4230/4715] Loss: 0.6243\n",
      "2025-05-30 16:52:25,776 - INFO - Epoch [16/30] Batch [4240/4715] Loss: 0.5855\n",
      "2025-05-30 16:52:27,261 - INFO - Epoch [16/30] Batch [4250/4715] Loss: 0.9472\n",
      "2025-05-30 16:52:28,900 - INFO - Epoch [16/30] Batch [4260/4715] Loss: 1.0738\n",
      "2025-05-30 16:52:30,457 - INFO - Epoch [16/30] Batch [4270/4715] Loss: 0.7487\n",
      "2025-05-30 16:52:32,097 - INFO - Epoch [16/30] Batch [4280/4715] Loss: 1.1086\n",
      "2025-05-30 16:52:33,656 - INFO - Epoch [16/30] Batch [4290/4715] Loss: 0.7471\n",
      "2025-05-30 16:52:35,176 - INFO - Epoch [16/30] Batch [4300/4715] Loss: 0.7374\n",
      "2025-05-30 16:52:36,731 - INFO - Epoch [16/30] Batch [4310/4715] Loss: 0.6575\n",
      "2025-05-30 16:52:38,376 - INFO - Epoch [16/30] Batch [4320/4715] Loss: 0.6280\n",
      "2025-05-30 16:52:39,987 - INFO - Epoch [16/30] Batch [4330/4715] Loss: 0.9138\n",
      "2025-05-30 16:52:41,555 - INFO - Epoch [16/30] Batch [4340/4715] Loss: 0.7265\n",
      "2025-05-30 16:52:43,104 - INFO - Epoch [16/30] Batch [4350/4715] Loss: 0.7447\n",
      "2025-05-30 16:52:44,663 - INFO - Epoch [16/30] Batch [4360/4715] Loss: 0.7971\n",
      "2025-05-30 16:52:46,283 - INFO - Epoch [16/30] Batch [4370/4715] Loss: 0.6662\n",
      "2025-05-30 16:52:47,791 - INFO - Epoch [16/30] Batch [4380/4715] Loss: 0.8259\n",
      "2025-05-30 16:52:49,424 - INFO - Epoch [16/30] Batch [4390/4715] Loss: 0.7095\n",
      "2025-05-30 16:52:50,921 - INFO - Epoch [16/30] Batch [4400/4715] Loss: 0.9042\n",
      "2025-05-30 16:52:52,473 - INFO - Epoch [16/30] Batch [4410/4715] Loss: 0.8074\n",
      "2025-05-30 16:52:53,989 - INFO - Epoch [16/30] Batch [4420/4715] Loss: 0.7632\n",
      "2025-05-30 16:52:55,603 - INFO - Epoch [16/30] Batch [4430/4715] Loss: 0.5624\n",
      "2025-05-30 16:52:57,185 - INFO - Epoch [16/30] Batch [4440/4715] Loss: 0.6577\n",
      "2025-05-30 16:52:58,743 - INFO - Epoch [16/30] Batch [4450/4715] Loss: 0.5366\n",
      "2025-05-30 16:53:00,322 - INFO - Epoch [16/30] Batch [4460/4715] Loss: 0.9163\n",
      "2025-05-30 16:53:01,851 - INFO - Epoch [16/30] Batch [4470/4715] Loss: 0.5433\n",
      "2025-05-30 16:53:03,381 - INFO - Epoch [16/30] Batch [4480/4715] Loss: 1.0030\n",
      "2025-05-30 16:53:04,989 - INFO - Epoch [16/30] Batch [4490/4715] Loss: 0.6906\n",
      "2025-05-30 16:53:06,617 - INFO - Epoch [16/30] Batch [4500/4715] Loss: 0.8421\n",
      "2025-05-30 16:53:08,159 - INFO - Epoch [16/30] Batch [4510/4715] Loss: 0.6583\n",
      "2025-05-30 16:53:09,706 - INFO - Epoch [16/30] Batch [4520/4715] Loss: 0.7341\n",
      "2025-05-30 16:53:11,389 - INFO - Epoch [16/30] Batch [4530/4715] Loss: 1.0712\n",
      "2025-05-30 16:53:12,941 - INFO - Epoch [16/30] Batch [4540/4715] Loss: 0.7321\n",
      "2025-05-30 16:53:14,541 - INFO - Epoch [16/30] Batch [4550/4715] Loss: 0.5069\n",
      "2025-05-30 16:53:16,170 - INFO - Epoch [16/30] Batch [4560/4715] Loss: 0.6837\n",
      "2025-05-30 16:53:17,751 - INFO - Epoch [16/30] Batch [4570/4715] Loss: 0.8042\n",
      "2025-05-30 16:53:19,355 - INFO - Epoch [16/30] Batch [4580/4715] Loss: 0.7876\n",
      "2025-05-30 16:53:20,916 - INFO - Epoch [16/30] Batch [4590/4715] Loss: 0.4512\n",
      "2025-05-30 16:53:22,453 - INFO - Epoch [16/30] Batch [4600/4715] Loss: 0.6162\n",
      "2025-05-30 16:53:24,099 - INFO - Epoch [16/30] Batch [4610/4715] Loss: 0.6571\n",
      "2025-05-30 16:53:25,692 - INFO - Epoch [16/30] Batch [4620/4715] Loss: 1.0486\n",
      "2025-05-30 16:53:27,250 - INFO - Epoch [16/30] Batch [4630/4715] Loss: 0.7738\n",
      "2025-05-30 16:53:28,793 - INFO - Epoch [16/30] Batch [4640/4715] Loss: 0.7280\n",
      "2025-05-30 16:53:30,332 - INFO - Epoch [16/30] Batch [4650/4715] Loss: 0.6095\n",
      "2025-05-30 16:53:31,880 - INFO - Epoch [16/30] Batch [4660/4715] Loss: 1.0843\n",
      "2025-05-30 16:53:33,449 - INFO - Epoch [16/30] Batch [4670/4715] Loss: 0.9103\n",
      "2025-05-30 16:53:35,033 - INFO - Epoch [16/30] Batch [4680/4715] Loss: 0.8075\n",
      "2025-05-30 16:53:36,682 - INFO - Epoch [16/30] Batch [4690/4715] Loss: 0.6978\n",
      "2025-05-30 16:53:38,249 - INFO - Epoch [16/30] Batch [4700/4715] Loss: 0.9057\n",
      "2025-05-30 16:53:39,782 - INFO - Epoch [16/30] Batch [4710/4715] Loss: 0.5670\n",
      "2025-05-30 16:54:18,984 - INFO - \n",
      "Epoch [16/30] Time: 777.52s\n",
      "2025-05-30 16:54:18,985 - INFO - Train Loss: 0.7812, Valid Loss: 0.8127\n",
      "2025-05-30 16:54:18,986 - INFO - Valid AUC (macro): 0.7382, F1 (macro): 0.5773\n",
      "2025-05-30 16:54:19,514 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 16:54:19,515 - INFO - Saved checkpoint at epoch 16\n",
      "2025-05-30 16:54:19,717 - INFO - Epoch [17/30] Batch [0/4715] Loss: 0.9160\n",
      "2025-05-30 16:54:21,603 - INFO - Epoch [17/30] Batch [10/4715] Loss: 0.7376\n",
      "2025-05-30 16:54:23,222 - INFO - Epoch [17/30] Batch [20/4715] Loss: 0.6342\n",
      "2025-05-30 16:54:24,772 - INFO - Epoch [17/30] Batch [30/4715] Loss: 0.7261\n",
      "2025-05-30 16:54:26,318 - INFO - Epoch [17/30] Batch [40/4715] Loss: 0.9099\n",
      "2025-05-30 16:54:27,872 - INFO - Epoch [17/30] Batch [50/4715] Loss: 0.7323\n",
      "2025-05-30 16:54:29,451 - INFO - Epoch [17/30] Batch [60/4715] Loss: 0.7029\n",
      "2025-05-30 16:54:30,967 - INFO - Epoch [17/30] Batch [70/4715] Loss: 1.0050\n",
      "2025-05-30 16:54:32,529 - INFO - Epoch [17/30] Batch [80/4715] Loss: 0.8826\n",
      "2025-05-30 16:54:34,063 - INFO - Epoch [17/30] Batch [90/4715] Loss: 0.7260\n",
      "2025-05-30 16:54:35,636 - INFO - Epoch [17/30] Batch [100/4715] Loss: 0.8175\n",
      "2025-05-30 16:54:37,273 - INFO - Epoch [17/30] Batch [110/4715] Loss: 0.7627\n",
      "2025-05-30 16:54:38,924 - INFO - Epoch [17/30] Batch [120/4715] Loss: 1.0031\n",
      "2025-05-30 16:54:40,469 - INFO - Epoch [17/30] Batch [130/4715] Loss: 0.9172\n",
      "2025-05-30 16:54:42,049 - INFO - Epoch [17/30] Batch [140/4715] Loss: 0.9765\n",
      "2025-05-30 16:54:43,716 - INFO - Epoch [17/30] Batch [150/4715] Loss: 0.7703\n",
      "2025-05-30 16:54:45,213 - INFO - Epoch [17/30] Batch [160/4715] Loss: 0.8415\n",
      "2025-05-30 16:54:46,741 - INFO - Epoch [17/30] Batch [170/4715] Loss: 0.6799\n",
      "2025-05-30 16:54:48,442 - INFO - Epoch [17/30] Batch [180/4715] Loss: 0.8175\n",
      "2025-05-30 16:54:50,093 - INFO - Epoch [17/30] Batch [190/4715] Loss: 0.7197\n",
      "2025-05-30 16:54:51,768 - INFO - Epoch [17/30] Batch [200/4715] Loss: 1.0173\n",
      "2025-05-30 16:54:53,389 - INFO - Epoch [17/30] Batch [210/4715] Loss: 0.8675\n",
      "2025-05-30 16:54:54,946 - INFO - Epoch [17/30] Batch [220/4715] Loss: 0.6160\n",
      "2025-05-30 16:54:56,605 - INFO - Epoch [17/30] Batch [230/4715] Loss: 0.5706\n",
      "2025-05-30 16:54:58,182 - INFO - Epoch [17/30] Batch [240/4715] Loss: 0.7150\n",
      "2025-05-30 16:54:59,738 - INFO - Epoch [17/30] Batch [250/4715] Loss: 1.0166\n",
      "2025-05-30 16:55:01,339 - INFO - Epoch [17/30] Batch [260/4715] Loss: 0.8394\n",
      "2025-05-30 16:55:02,797 - INFO - Epoch [17/30] Batch [270/4715] Loss: 0.7152\n",
      "2025-05-30 16:55:04,359 - INFO - Epoch [17/30] Batch [280/4715] Loss: 0.6717\n",
      "2025-05-30 16:55:05,917 - INFO - Epoch [17/30] Batch [290/4715] Loss: 0.7237\n",
      "2025-05-30 16:55:07,441 - INFO - Epoch [17/30] Batch [300/4715] Loss: 0.9085\n",
      "2025-05-30 16:55:09,004 - INFO - Epoch [17/30] Batch [310/4715] Loss: 0.7486\n",
      "2025-05-30 16:55:10,535 - INFO - Epoch [17/30] Batch [320/4715] Loss: 0.8442\n",
      "2025-05-30 16:55:12,094 - INFO - Epoch [17/30] Batch [330/4715] Loss: 0.5642\n",
      "2025-05-30 16:55:13,682 - INFO - Epoch [17/30] Batch [340/4715] Loss: 1.0982\n",
      "2025-05-30 16:55:15,246 - INFO - Epoch [17/30] Batch [350/4715] Loss: 0.9072\n",
      "2025-05-30 16:55:16,812 - INFO - Epoch [17/30] Batch [360/4715] Loss: 0.7434\n",
      "2025-05-30 16:55:18,328 - INFO - Epoch [17/30] Batch [370/4715] Loss: 0.9491\n",
      "2025-05-30 16:55:19,923 - INFO - Epoch [17/30] Batch [380/4715] Loss: 0.5994\n",
      "2025-05-30 16:55:21,401 - INFO - Epoch [17/30] Batch [390/4715] Loss: 0.8944\n",
      "2025-05-30 16:55:22,975 - INFO - Epoch [17/30] Batch [400/4715] Loss: 0.5856\n",
      "2025-05-30 16:55:24,543 - INFO - Epoch [17/30] Batch [410/4715] Loss: 0.9246\n",
      "2025-05-30 16:55:26,185 - INFO - Epoch [17/30] Batch [420/4715] Loss: 0.7470\n",
      "2025-05-30 16:55:27,712 - INFO - Epoch [17/30] Batch [430/4715] Loss: 1.0779\n",
      "2025-05-30 16:55:29,325 - INFO - Epoch [17/30] Batch [440/4715] Loss: 0.6402\n",
      "2025-05-30 16:55:30,887 - INFO - Epoch [17/30] Batch [450/4715] Loss: 1.1252\n",
      "2025-05-30 16:55:32,453 - INFO - Epoch [17/30] Batch [460/4715] Loss: 0.8871\n",
      "2025-05-30 16:55:33,980 - INFO - Epoch [17/30] Batch [470/4715] Loss: 0.6454\n",
      "2025-05-30 16:55:35,464 - INFO - Epoch [17/30] Batch [480/4715] Loss: 1.0442\n",
      "2025-05-30 16:55:36,992 - INFO - Epoch [17/30] Batch [490/4715] Loss: 0.8560\n",
      "2025-05-30 16:55:38,555 - INFO - Epoch [17/30] Batch [500/4715] Loss: 0.7230\n",
      "2025-05-30 16:55:40,226 - INFO - Epoch [17/30] Batch [510/4715] Loss: 0.7526\n",
      "2025-05-30 16:55:41,790 - INFO - Epoch [17/30] Batch [520/4715] Loss: 0.8617\n",
      "2025-05-30 16:55:43,421 - INFO - Epoch [17/30] Batch [530/4715] Loss: 0.6499\n",
      "2025-05-30 16:55:45,045 - INFO - Epoch [17/30] Batch [540/4715] Loss: 0.8263\n",
      "2025-05-30 16:55:46,622 - INFO - Epoch [17/30] Batch [550/4715] Loss: 0.8761\n",
      "2025-05-30 16:55:48,271 - INFO - Epoch [17/30] Batch [560/4715] Loss: 0.6867\n",
      "2025-05-30 16:55:49,853 - INFO - Epoch [17/30] Batch [570/4715] Loss: 0.6614\n",
      "2025-05-30 16:55:51,401 - INFO - Epoch [17/30] Batch [580/4715] Loss: 0.6567\n",
      "2025-05-30 16:55:53,092 - INFO - Epoch [17/30] Batch [590/4715] Loss: 0.9025\n",
      "2025-05-30 16:55:54,613 - INFO - Epoch [17/30] Batch [600/4715] Loss: 0.6207\n",
      "2025-05-30 16:55:56,282 - INFO - Epoch [17/30] Batch [610/4715] Loss: 0.5888\n",
      "2025-05-30 16:55:57,862 - INFO - Epoch [17/30] Batch [620/4715] Loss: 0.6346\n",
      "2025-05-30 16:55:59,391 - INFO - Epoch [17/30] Batch [630/4715] Loss: 0.8431\n",
      "2025-05-30 16:56:00,939 - INFO - Epoch [17/30] Batch [640/4715] Loss: 0.6073\n",
      "2025-05-30 16:56:02,460 - INFO - Epoch [17/30] Batch [650/4715] Loss: 0.8843\n",
      "2025-05-30 16:56:04,012 - INFO - Epoch [17/30] Batch [660/4715] Loss: 0.6185\n",
      "2025-05-30 16:56:05,556 - INFO - Epoch [17/30] Batch [670/4715] Loss: 0.7740\n",
      "2025-05-30 16:56:07,047 - INFO - Epoch [17/30] Batch [680/4715] Loss: 0.7844\n",
      "2025-05-30 16:56:08,509 - INFO - Epoch [17/30] Batch [690/4715] Loss: 0.7711\n",
      "2025-05-30 16:56:10,047 - INFO - Epoch [17/30] Batch [700/4715] Loss: 0.6483\n",
      "2025-05-30 16:56:11,625 - INFO - Epoch [17/30] Batch [710/4715] Loss: 0.9228\n",
      "2025-05-30 16:56:13,326 - INFO - Epoch [17/30] Batch [720/4715] Loss: 0.3661\n",
      "2025-05-30 16:56:14,957 - INFO - Epoch [17/30] Batch [730/4715] Loss: 0.8976\n",
      "2025-05-30 16:56:16,469 - INFO - Epoch [17/30] Batch [740/4715] Loss: 0.4716\n",
      "2025-05-30 16:56:17,992 - INFO - Epoch [17/30] Batch [750/4715] Loss: 0.6992\n",
      "2025-05-30 16:56:19,489 - INFO - Epoch [17/30] Batch [760/4715] Loss: 0.7425\n",
      "2025-05-30 16:56:21,006 - INFO - Epoch [17/30] Batch [770/4715] Loss: 0.9569\n",
      "2025-05-30 16:56:22,568 - INFO - Epoch [17/30] Batch [780/4715] Loss: 0.9127\n",
      "2025-05-30 16:56:24,091 - INFO - Epoch [17/30] Batch [790/4715] Loss: 0.5143\n",
      "2025-05-30 16:56:25,683 - INFO - Epoch [17/30] Batch [800/4715] Loss: 0.6792\n",
      "2025-05-30 16:56:27,228 - INFO - Epoch [17/30] Batch [810/4715] Loss: 0.5920\n",
      "2025-05-30 16:56:28,822 - INFO - Epoch [17/30] Batch [820/4715] Loss: 0.7819\n",
      "2025-05-30 16:56:30,292 - INFO - Epoch [17/30] Batch [830/4715] Loss: 0.7134\n",
      "2025-05-30 16:56:31,823 - INFO - Epoch [17/30] Batch [840/4715] Loss: 0.8576\n",
      "2025-05-30 16:56:33,443 - INFO - Epoch [17/30] Batch [850/4715] Loss: 0.9039\n",
      "2025-05-30 16:56:34,988 - INFO - Epoch [17/30] Batch [860/4715] Loss: 0.6685\n",
      "2025-05-30 16:56:36,531 - INFO - Epoch [17/30] Batch [870/4715] Loss: 0.5365\n",
      "2025-05-30 16:56:38,162 - INFO - Epoch [17/30] Batch [880/4715] Loss: 0.7232\n",
      "2025-05-30 16:56:39,746 - INFO - Epoch [17/30] Batch [890/4715] Loss: 0.5884\n",
      "2025-05-30 16:56:41,327 - INFO - Epoch [17/30] Batch [900/4715] Loss: 0.7493\n",
      "2025-05-30 16:56:42,962 - INFO - Epoch [17/30] Batch [910/4715] Loss: 0.8559\n",
      "2025-05-30 16:56:44,503 - INFO - Epoch [17/30] Batch [920/4715] Loss: 1.1614\n",
      "2025-05-30 16:56:46,046 - INFO - Epoch [17/30] Batch [930/4715] Loss: 0.8010\n",
      "2025-05-30 16:56:47,586 - INFO - Epoch [17/30] Batch [940/4715] Loss: 0.7758\n",
      "2025-05-30 16:56:49,221 - INFO - Epoch [17/30] Batch [950/4715] Loss: 0.6267\n",
      "2025-05-30 16:56:50,870 - INFO - Epoch [17/30] Batch [960/4715] Loss: 0.6201\n",
      "2025-05-30 16:56:52,461 - INFO - Epoch [17/30] Batch [970/4715] Loss: 0.7211\n",
      "2025-05-30 16:56:54,066 - INFO - Epoch [17/30] Batch [980/4715] Loss: 0.8276\n",
      "2025-05-30 16:56:55,593 - INFO - Epoch [17/30] Batch [990/4715] Loss: 0.7474\n",
      "2025-05-30 16:56:57,210 - INFO - Epoch [17/30] Batch [1000/4715] Loss: 0.9519\n",
      "2025-05-30 16:56:58,738 - INFO - Epoch [17/30] Batch [1010/4715] Loss: 0.6689\n",
      "2025-05-30 16:57:00,292 - INFO - Epoch [17/30] Batch [1020/4715] Loss: 0.6523\n",
      "2025-05-30 16:57:01,881 - INFO - Epoch [17/30] Batch [1030/4715] Loss: 0.9315\n",
      "2025-05-30 16:57:03,454 - INFO - Epoch [17/30] Batch [1040/4715] Loss: 0.6531\n",
      "2025-05-30 16:57:05,051 - INFO - Epoch [17/30] Batch [1050/4715] Loss: 0.7595\n",
      "2025-05-30 16:57:06,628 - INFO - Epoch [17/30] Batch [1060/4715] Loss: 0.6571\n",
      "2025-05-30 16:57:08,400 - INFO - Epoch [17/30] Batch [1070/4715] Loss: 0.7321\n",
      "2025-05-30 16:57:10,047 - INFO - Epoch [17/30] Batch [1080/4715] Loss: 0.9558\n",
      "2025-05-30 16:57:11,618 - INFO - Epoch [17/30] Batch [1090/4715] Loss: 0.8609\n",
      "2025-05-30 16:57:13,274 - INFO - Epoch [17/30] Batch [1100/4715] Loss: 0.6874\n",
      "2025-05-30 16:57:14,905 - INFO - Epoch [17/30] Batch [1110/4715] Loss: 0.7102\n",
      "2025-05-30 16:57:16,567 - INFO - Epoch [17/30] Batch [1120/4715] Loss: 0.7260\n",
      "2025-05-30 16:57:18,081 - INFO - Epoch [17/30] Batch [1130/4715] Loss: 0.8795\n",
      "2025-05-30 16:57:19,592 - INFO - Epoch [17/30] Batch [1140/4715] Loss: 0.7878\n",
      "2025-05-30 16:57:21,122 - INFO - Epoch [17/30] Batch [1150/4715] Loss: 0.5087\n",
      "2025-05-30 16:57:22,769 - INFO - Epoch [17/30] Batch [1160/4715] Loss: 0.8486\n",
      "2025-05-30 16:57:24,282 - INFO - Epoch [17/30] Batch [1170/4715] Loss: 0.9542\n",
      "2025-05-30 16:57:25,813 - INFO - Epoch [17/30] Batch [1180/4715] Loss: 0.8562\n",
      "2025-05-30 16:57:27,356 - INFO - Epoch [17/30] Batch [1190/4715] Loss: 0.7256\n",
      "2025-05-30 16:57:28,925 - INFO - Epoch [17/30] Batch [1200/4715] Loss: 1.0406\n",
      "2025-05-30 16:57:30,491 - INFO - Epoch [17/30] Batch [1210/4715] Loss: 0.7119\n",
      "2025-05-30 16:57:32,092 - INFO - Epoch [17/30] Batch [1220/4715] Loss: 0.6384\n",
      "2025-05-30 16:57:33,678 - INFO - Epoch [17/30] Batch [1230/4715] Loss: 0.6612\n",
      "2025-05-30 16:57:35,272 - INFO - Epoch [17/30] Batch [1240/4715] Loss: 0.6386\n",
      "2025-05-30 16:57:36,803 - INFO - Epoch [17/30] Batch [1250/4715] Loss: 0.5978\n",
      "2025-05-30 16:57:38,375 - INFO - Epoch [17/30] Batch [1260/4715] Loss: 0.6945\n",
      "2025-05-30 16:57:39,879 - INFO - Epoch [17/30] Batch [1270/4715] Loss: 0.7088\n",
      "2025-05-30 16:57:41,459 - INFO - Epoch [17/30] Batch [1280/4715] Loss: 0.7613\n",
      "2025-05-30 16:57:42,988 - INFO - Epoch [17/30] Batch [1290/4715] Loss: 0.8755\n",
      "2025-05-30 16:57:44,573 - INFO - Epoch [17/30] Batch [1300/4715] Loss: 0.7671\n",
      "2025-05-30 16:57:46,087 - INFO - Epoch [17/30] Batch [1310/4715] Loss: 0.7279\n",
      "2025-05-30 16:57:47,646 - INFO - Epoch [17/30] Batch [1320/4715] Loss: 0.7266\n",
      "2025-05-30 16:57:49,221 - INFO - Epoch [17/30] Batch [1330/4715] Loss: 0.6098\n",
      "2025-05-30 16:57:50,831 - INFO - Epoch [17/30] Batch [1340/4715] Loss: 0.7809\n",
      "2025-05-30 16:57:52,413 - INFO - Epoch [17/30] Batch [1350/4715] Loss: 0.7697\n",
      "2025-05-30 16:57:54,012 - INFO - Epoch [17/30] Batch [1360/4715] Loss: 0.6114\n",
      "2025-05-30 16:57:55,560 - INFO - Epoch [17/30] Batch [1370/4715] Loss: 0.8599\n",
      "2025-05-30 16:57:57,070 - INFO - Epoch [17/30] Batch [1380/4715] Loss: 0.9362\n",
      "2025-05-30 16:57:58,607 - INFO - Epoch [17/30] Batch [1390/4715] Loss: 0.6390\n",
      "2025-05-30 16:58:00,221 - INFO - Epoch [17/30] Batch [1400/4715] Loss: 0.5617\n",
      "2025-05-30 16:58:01,788 - INFO - Epoch [17/30] Batch [1410/4715] Loss: 0.6246\n",
      "2025-05-30 16:58:03,357 - INFO - Epoch [17/30] Batch [1420/4715] Loss: 0.6879\n",
      "2025-05-30 16:58:04,845 - INFO - Epoch [17/30] Batch [1430/4715] Loss: 0.9224\n",
      "2025-05-30 16:58:06,352 - INFO - Epoch [17/30] Batch [1440/4715] Loss: 0.7537\n",
      "2025-05-30 16:58:07,953 - INFO - Epoch [17/30] Batch [1450/4715] Loss: 0.7663\n",
      "2025-05-30 16:58:09,584 - INFO - Epoch [17/30] Batch [1460/4715] Loss: 0.9135\n",
      "2025-05-30 16:58:11,060 - INFO - Epoch [17/30] Batch [1470/4715] Loss: 0.7786\n",
      "2025-05-30 16:58:12,603 - INFO - Epoch [17/30] Batch [1480/4715] Loss: 0.8034\n",
      "2025-05-30 16:58:14,250 - INFO - Epoch [17/30] Batch [1490/4715] Loss: 0.6179\n",
      "2025-05-30 16:58:15,851 - INFO - Epoch [17/30] Batch [1500/4715] Loss: 0.6645\n",
      "2025-05-30 16:58:17,455 - INFO - Epoch [17/30] Batch [1510/4715] Loss: 1.0911\n",
      "2025-05-30 16:58:18,987 - INFO - Epoch [17/30] Batch [1520/4715] Loss: 0.7554\n",
      "2025-05-30 16:58:20,563 - INFO - Epoch [17/30] Batch [1530/4715] Loss: 0.4143\n",
      "2025-05-30 16:58:22,224 - INFO - Epoch [17/30] Batch [1540/4715] Loss: 0.9079\n",
      "2025-05-30 16:58:23,746 - INFO - Epoch [17/30] Batch [1550/4715] Loss: 0.9978\n",
      "2025-05-30 16:58:25,281 - INFO - Epoch [17/30] Batch [1560/4715] Loss: 0.6872\n",
      "2025-05-30 16:58:26,844 - INFO - Epoch [17/30] Batch [1570/4715] Loss: 0.9232\n",
      "2025-05-30 16:58:28,547 - INFO - Epoch [17/30] Batch [1580/4715] Loss: 0.9065\n",
      "2025-05-30 16:58:30,091 - INFO - Epoch [17/30] Batch [1590/4715] Loss: 0.6991\n",
      "2025-05-30 16:58:31,653 - INFO - Epoch [17/30] Batch [1600/4715] Loss: 0.6655\n",
      "2025-05-30 16:58:33,191 - INFO - Epoch [17/30] Batch [1610/4715] Loss: 0.8636\n",
      "2025-05-30 16:58:34,715 - INFO - Epoch [17/30] Batch [1620/4715] Loss: 0.7360\n",
      "2025-05-30 16:58:36,250 - INFO - Epoch [17/30] Batch [1630/4715] Loss: 0.7414\n",
      "2025-05-30 16:58:37,868 - INFO - Epoch [17/30] Batch [1640/4715] Loss: 0.7247\n",
      "2025-05-30 16:58:39,435 - INFO - Epoch [17/30] Batch [1650/4715] Loss: 0.8346\n",
      "2025-05-30 16:58:40,982 - INFO - Epoch [17/30] Batch [1660/4715] Loss: 0.8019\n",
      "2025-05-30 16:58:42,529 - INFO - Epoch [17/30] Batch [1670/4715] Loss: 0.7114\n",
      "2025-05-30 16:58:44,103 - INFO - Epoch [17/30] Batch [1680/4715] Loss: 0.6969\n",
      "2025-05-30 16:58:45,681 - INFO - Epoch [17/30] Batch [1690/4715] Loss: 0.8391\n",
      "2025-05-30 16:58:47,254 - INFO - Epoch [17/30] Batch [1700/4715] Loss: 0.8283\n",
      "2025-05-30 16:58:48,827 - INFO - Epoch [17/30] Batch [1710/4715] Loss: 0.7664\n",
      "2025-05-30 16:58:50,462 - INFO - Epoch [17/30] Batch [1720/4715] Loss: 0.7230\n",
      "2025-05-30 16:58:52,119 - INFO - Epoch [17/30] Batch [1730/4715] Loss: 0.8459\n",
      "2025-05-30 16:58:53,746 - INFO - Epoch [17/30] Batch [1740/4715] Loss: 0.7455\n",
      "2025-05-30 16:58:55,322 - INFO - Epoch [17/30] Batch [1750/4715] Loss: 0.9353\n",
      "2025-05-30 16:58:56,957 - INFO - Epoch [17/30] Batch [1760/4715] Loss: 0.4373\n",
      "2025-05-30 16:58:58,430 - INFO - Epoch [17/30] Batch [1770/4715] Loss: 0.9140\n",
      "2025-05-30 16:58:59,983 - INFO - Epoch [17/30] Batch [1780/4715] Loss: 0.6369\n",
      "2025-05-30 16:59:01,655 - INFO - Epoch [17/30] Batch [1790/4715] Loss: 0.7562\n",
      "2025-05-30 16:59:03,186 - INFO - Epoch [17/30] Batch [1800/4715] Loss: 0.9444\n",
      "2025-05-30 16:59:04,700 - INFO - Epoch [17/30] Batch [1810/4715] Loss: 0.7308\n",
      "2025-05-30 16:59:06,295 - INFO - Epoch [17/30] Batch [1820/4715] Loss: 0.4915\n",
      "2025-05-30 16:59:07,862 - INFO - Epoch [17/30] Batch [1830/4715] Loss: 0.8600\n",
      "2025-05-30 16:59:09,466 - INFO - Epoch [17/30] Batch [1840/4715] Loss: 1.1321\n",
      "2025-05-30 16:59:11,067 - INFO - Epoch [17/30] Batch [1850/4715] Loss: 0.6830\n",
      "2025-05-30 16:59:12,648 - INFO - Epoch [17/30] Batch [1860/4715] Loss: 0.9773\n",
      "2025-05-30 16:59:14,171 - INFO - Epoch [17/30] Batch [1870/4715] Loss: 0.8510\n",
      "2025-05-30 16:59:15,687 - INFO - Epoch [17/30] Batch [1880/4715] Loss: 0.7067\n",
      "2025-05-30 16:59:17,258 - INFO - Epoch [17/30] Batch [1890/4715] Loss: 0.6544\n",
      "2025-05-30 16:59:18,791 - INFO - Epoch [17/30] Batch [1900/4715] Loss: 0.7011\n",
      "2025-05-30 16:59:20,489 - INFO - Epoch [17/30] Batch [1910/4715] Loss: 0.8174\n",
      "2025-05-30 16:59:22,008 - INFO - Epoch [17/30] Batch [1920/4715] Loss: 0.6148\n",
      "2025-05-30 16:59:23,651 - INFO - Epoch [17/30] Batch [1930/4715] Loss: 1.0973\n",
      "2025-05-30 16:59:25,235 - INFO - Epoch [17/30] Batch [1940/4715] Loss: 0.6252\n",
      "2025-05-30 16:59:27,000 - INFO - Epoch [17/30] Batch [1950/4715] Loss: 0.8557\n",
      "2025-05-30 16:59:28,654 - INFO - Epoch [17/30] Batch [1960/4715] Loss: 0.8157\n",
      "2025-05-30 16:59:30,313 - INFO - Epoch [17/30] Batch [1970/4715] Loss: 0.7528\n",
      "2025-05-30 16:59:31,919 - INFO - Epoch [17/30] Batch [1980/4715] Loss: 0.7307\n",
      "2025-05-30 16:59:33,535 - INFO - Epoch [17/30] Batch [1990/4715] Loss: 0.5910\n",
      "2025-05-30 16:59:35,119 - INFO - Epoch [17/30] Batch [2000/4715] Loss: 0.7695\n",
      "2025-05-30 16:59:36,638 - INFO - Epoch [17/30] Batch [2010/4715] Loss: 0.7659\n",
      "2025-05-30 16:59:38,242 - INFO - Epoch [17/30] Batch [2020/4715] Loss: 0.7124\n",
      "2025-05-30 16:59:39,791 - INFO - Epoch [17/30] Batch [2030/4715] Loss: 0.6200\n",
      "2025-05-30 16:59:41,296 - INFO - Epoch [17/30] Batch [2040/4715] Loss: 0.5759\n",
      "2025-05-30 16:59:42,923 - INFO - Epoch [17/30] Batch [2050/4715] Loss: 0.7847\n",
      "2025-05-30 16:59:44,464 - INFO - Epoch [17/30] Batch [2060/4715] Loss: 0.5774\n",
      "2025-05-30 16:59:46,163 - INFO - Epoch [17/30] Batch [2070/4715] Loss: 0.6928\n",
      "2025-05-30 16:59:47,899 - INFO - Epoch [17/30] Batch [2080/4715] Loss: 0.8863\n",
      "2025-05-30 16:59:49,541 - INFO - Epoch [17/30] Batch [2090/4715] Loss: 0.7540\n",
      "2025-05-30 16:59:51,063 - INFO - Epoch [17/30] Batch [2100/4715] Loss: 0.6422\n",
      "2025-05-30 16:59:52,645 - INFO - Epoch [17/30] Batch [2110/4715] Loss: 0.7733\n",
      "2025-05-30 16:59:54,229 - INFO - Epoch [17/30] Batch [2120/4715] Loss: 0.8164\n",
      "2025-05-30 16:59:55,782 - INFO - Epoch [17/30] Batch [2130/4715] Loss: 0.7770\n",
      "2025-05-30 16:59:57,503 - INFO - Epoch [17/30] Batch [2140/4715] Loss: 1.0827\n",
      "2025-05-30 16:59:59,221 - INFO - Epoch [17/30] Batch [2150/4715] Loss: 0.6208\n",
      "2025-05-30 17:00:00,858 - INFO - Epoch [17/30] Batch [2160/4715] Loss: 0.9220\n",
      "2025-05-30 17:00:02,605 - INFO - Epoch [17/30] Batch [2170/4715] Loss: 0.7705\n",
      "2025-05-30 17:00:04,190 - INFO - Epoch [17/30] Batch [2180/4715] Loss: 0.7125\n",
      "2025-05-30 17:00:05,725 - INFO - Epoch [17/30] Batch [2190/4715] Loss: 0.8578\n",
      "2025-05-30 17:00:07,335 - INFO - Epoch [17/30] Batch [2200/4715] Loss: 0.7793\n",
      "2025-05-30 17:00:09,007 - INFO - Epoch [17/30] Batch [2210/4715] Loss: 0.6818\n",
      "2025-05-30 17:00:10,609 - INFO - Epoch [17/30] Batch [2220/4715] Loss: 0.7928\n",
      "2025-05-30 17:00:12,183 - INFO - Epoch [17/30] Batch [2230/4715] Loss: 0.8606\n",
      "2025-05-30 17:00:13,702 - INFO - Epoch [17/30] Batch [2240/4715] Loss: 0.8062\n",
      "2025-05-30 17:00:15,217 - INFO - Epoch [17/30] Batch [2250/4715] Loss: 0.7416\n",
      "2025-05-30 17:00:16,739 - INFO - Epoch [17/30] Batch [2260/4715] Loss: 0.8206\n",
      "2025-05-30 17:00:18,315 - INFO - Epoch [17/30] Batch [2270/4715] Loss: 0.8542\n",
      "2025-05-30 17:00:19,818 - INFO - Epoch [17/30] Batch [2280/4715] Loss: 0.9267\n",
      "2025-05-30 17:00:21,375 - INFO - Epoch [17/30] Batch [2290/4715] Loss: 0.7907\n",
      "2025-05-30 17:00:22,919 - INFO - Epoch [17/30] Batch [2300/4715] Loss: 0.6350\n",
      "2025-05-30 17:00:24,508 - INFO - Epoch [17/30] Batch [2310/4715] Loss: 1.1444\n",
      "2025-05-30 17:00:26,070 - INFO - Epoch [17/30] Batch [2320/4715] Loss: 0.6593\n",
      "2025-05-30 17:00:27,599 - INFO - Epoch [17/30] Batch [2330/4715] Loss: 0.9153\n",
      "2025-05-30 17:00:29,159 - INFO - Epoch [17/30] Batch [2340/4715] Loss: 0.6811\n",
      "2025-05-30 17:00:30,788 - INFO - Epoch [17/30] Batch [2350/4715] Loss: 0.8019\n",
      "2025-05-30 17:00:32,303 - INFO - Epoch [17/30] Batch [2360/4715] Loss: 0.5598\n",
      "2025-05-30 17:00:33,911 - INFO - Epoch [17/30] Batch [2370/4715] Loss: 0.7709\n",
      "2025-05-30 17:00:35,442 - INFO - Epoch [17/30] Batch [2380/4715] Loss: 0.5754\n",
      "2025-05-30 17:00:36,995 - INFO - Epoch [17/30] Batch [2390/4715] Loss: 0.5648\n",
      "2025-05-30 17:00:38,604 - INFO - Epoch [17/30] Batch [2400/4715] Loss: 1.0071\n",
      "2025-05-30 17:00:40,228 - INFO - Epoch [17/30] Batch [2410/4715] Loss: 0.8856\n",
      "2025-05-30 17:00:41,828 - INFO - Epoch [17/30] Batch [2420/4715] Loss: 0.7019\n",
      "2025-05-30 17:00:43,393 - INFO - Epoch [17/30] Batch [2430/4715] Loss: 0.8378\n",
      "2025-05-30 17:00:44,983 - INFO - Epoch [17/30] Batch [2440/4715] Loss: 0.9272\n",
      "2025-05-30 17:00:46,547 - INFO - Epoch [17/30] Batch [2450/4715] Loss: 0.6874\n",
      "2025-05-30 17:00:48,128 - INFO - Epoch [17/30] Batch [2460/4715] Loss: 0.7510\n",
      "2025-05-30 17:00:49,701 - INFO - Epoch [17/30] Batch [2470/4715] Loss: 0.6250\n",
      "2025-05-30 17:00:51,287 - INFO - Epoch [17/30] Batch [2480/4715] Loss: 0.8342\n",
      "2025-05-30 17:00:52,928 - INFO - Epoch [17/30] Batch [2490/4715] Loss: 0.6228\n",
      "2025-05-30 17:00:54,493 - INFO - Epoch [17/30] Batch [2500/4715] Loss: 0.9473\n",
      "2025-05-30 17:00:56,047 - INFO - Epoch [17/30] Batch [2510/4715] Loss: 1.0180\n",
      "2025-05-30 17:00:57,633 - INFO - Epoch [17/30] Batch [2520/4715] Loss: 0.8601\n",
      "2025-05-30 17:00:59,200 - INFO - Epoch [17/30] Batch [2530/4715] Loss: 0.9515\n",
      "2025-05-30 17:01:00,826 - INFO - Epoch [17/30] Batch [2540/4715] Loss: 0.5716\n",
      "2025-05-30 17:01:02,397 - INFO - Epoch [17/30] Batch [2550/4715] Loss: 1.0578\n",
      "2025-05-30 17:01:04,084 - INFO - Epoch [17/30] Batch [2560/4715] Loss: 0.8188\n",
      "2025-05-30 17:01:05,681 - INFO - Epoch [17/30] Batch [2570/4715] Loss: 0.6072\n",
      "2025-05-30 17:01:07,289 - INFO - Epoch [17/30] Batch [2580/4715] Loss: 0.7499\n",
      "2025-05-30 17:01:08,902 - INFO - Epoch [17/30] Batch [2590/4715] Loss: 0.6031\n",
      "2025-05-30 17:01:10,541 - INFO - Epoch [17/30] Batch [2600/4715] Loss: 0.5559\n",
      "2025-05-30 17:01:12,171 - INFO - Epoch [17/30] Batch [2610/4715] Loss: 0.8669\n",
      "2025-05-30 17:01:13,865 - INFO - Epoch [17/30] Batch [2620/4715] Loss: 0.6077\n",
      "2025-05-30 17:01:15,463 - INFO - Epoch [17/30] Batch [2630/4715] Loss: 0.9245\n",
      "2025-05-30 17:01:16,950 - INFO - Epoch [17/30] Batch [2640/4715] Loss: 0.6618\n",
      "2025-05-30 17:01:18,490 - INFO - Epoch [17/30] Batch [2650/4715] Loss: 0.9881\n",
      "2025-05-30 17:01:19,997 - INFO - Epoch [17/30] Batch [2660/4715] Loss: 0.8878\n",
      "2025-05-30 17:01:21,542 - INFO - Epoch [17/30] Batch [2670/4715] Loss: 0.7341\n",
      "2025-05-30 17:01:23,101 - INFO - Epoch [17/30] Batch [2680/4715] Loss: 0.6232\n",
      "2025-05-30 17:01:24,631 - INFO - Epoch [17/30] Batch [2690/4715] Loss: 0.6207\n",
      "2025-05-30 17:01:26,186 - INFO - Epoch [17/30] Batch [2700/4715] Loss: 0.8368\n",
      "2025-05-30 17:01:27,828 - INFO - Epoch [17/30] Batch [2710/4715] Loss: 0.6238\n",
      "2025-05-30 17:01:29,450 - INFO - Epoch [17/30] Batch [2720/4715] Loss: 0.8856\n",
      "2025-05-30 17:01:31,035 - INFO - Epoch [17/30] Batch [2730/4715] Loss: 0.4415\n",
      "2025-05-30 17:01:32,724 - INFO - Epoch [17/30] Batch [2740/4715] Loss: 0.8703\n",
      "2025-05-30 17:01:34,342 - INFO - Epoch [17/30] Batch [2750/4715] Loss: 0.6694\n",
      "2025-05-30 17:01:35,861 - INFO - Epoch [17/30] Batch [2760/4715] Loss: 0.9895\n",
      "2025-05-30 17:01:37,351 - INFO - Epoch [17/30] Batch [2770/4715] Loss: 0.6091\n",
      "2025-05-30 17:01:38,970 - INFO - Epoch [17/30] Batch [2780/4715] Loss: 0.9112\n",
      "2025-05-30 17:01:40,550 - INFO - Epoch [17/30] Batch [2790/4715] Loss: 0.6556\n",
      "2025-05-30 17:01:42,081 - INFO - Epoch [17/30] Batch [2800/4715] Loss: 0.7687\n",
      "2025-05-30 17:01:43,832 - INFO - Epoch [17/30] Batch [2810/4715] Loss: 0.7346\n",
      "2025-05-30 17:01:45,386 - INFO - Epoch [17/30] Batch [2820/4715] Loss: 0.8320\n",
      "2025-05-30 17:01:46,942 - INFO - Epoch [17/30] Batch [2830/4715] Loss: 0.6542\n",
      "2025-05-30 17:01:48,550 - INFO - Epoch [17/30] Batch [2840/4715] Loss: 0.8543\n",
      "2025-05-30 17:01:50,109 - INFO - Epoch [17/30] Batch [2850/4715] Loss: 0.9276\n",
      "2025-05-30 17:01:51,684 - INFO - Epoch [17/30] Batch [2860/4715] Loss: 0.5953\n",
      "2025-05-30 17:01:53,251 - INFO - Epoch [17/30] Batch [2870/4715] Loss: 0.8441\n",
      "2025-05-30 17:01:55,075 - INFO - Epoch [17/30] Batch [2880/4715] Loss: 0.8027\n",
      "2025-05-30 17:01:56,728 - INFO - Epoch [17/30] Batch [2890/4715] Loss: 0.9932\n",
      "2025-05-30 17:01:58,284 - INFO - Epoch [17/30] Batch [2900/4715] Loss: 0.6026\n",
      "2025-05-30 17:01:59,886 - INFO - Epoch [17/30] Batch [2910/4715] Loss: 0.5980\n",
      "2025-05-30 17:02:01,440 - INFO - Epoch [17/30] Batch [2920/4715] Loss: 0.7172\n",
      "2025-05-30 17:02:02,990 - INFO - Epoch [17/30] Batch [2930/4715] Loss: 0.9818\n",
      "2025-05-30 17:02:04,494 - INFO - Epoch [17/30] Batch [2940/4715] Loss: 0.7874\n",
      "2025-05-30 17:02:06,048 - INFO - Epoch [17/30] Batch [2950/4715] Loss: 0.6002\n",
      "2025-05-30 17:02:07,624 - INFO - Epoch [17/30] Batch [2960/4715] Loss: 0.6152\n",
      "2025-05-30 17:02:09,219 - INFO - Epoch [17/30] Batch [2970/4715] Loss: 0.9580\n",
      "2025-05-30 17:02:10,803 - INFO - Epoch [17/30] Batch [2980/4715] Loss: 0.8173\n",
      "2025-05-30 17:02:12,405 - INFO - Epoch [17/30] Batch [2990/4715] Loss: 0.7465\n",
      "2025-05-30 17:02:14,010 - INFO - Epoch [17/30] Batch [3000/4715] Loss: 0.8642\n",
      "2025-05-30 17:02:15,545 - INFO - Epoch [17/30] Batch [3010/4715] Loss: 0.9287\n",
      "2025-05-30 17:02:17,166 - INFO - Epoch [17/30] Batch [3020/4715] Loss: 0.8672\n",
      "2025-05-30 17:02:18,752 - INFO - Epoch [17/30] Batch [3030/4715] Loss: 0.7686\n",
      "2025-05-30 17:02:20,389 - INFO - Epoch [17/30] Batch [3040/4715] Loss: 0.6921\n",
      "2025-05-30 17:02:21,913 - INFO - Epoch [17/30] Batch [3050/4715] Loss: 0.9357\n",
      "2025-05-30 17:02:23,516 - INFO - Epoch [17/30] Batch [3060/4715] Loss: 0.5514\n",
      "2025-05-30 17:02:25,054 - INFO - Epoch [17/30] Batch [3070/4715] Loss: 0.7022\n",
      "2025-05-30 17:02:26,630 - INFO - Epoch [17/30] Batch [3080/4715] Loss: 0.8079\n",
      "2025-05-30 17:02:28,130 - INFO - Epoch [17/30] Batch [3090/4715] Loss: 0.6173\n",
      "2025-05-30 17:02:29,649 - INFO - Epoch [17/30] Batch [3100/4715] Loss: 0.6618\n",
      "2025-05-30 17:02:31,231 - INFO - Epoch [17/30] Batch [3110/4715] Loss: 1.1072\n",
      "2025-05-30 17:02:32,824 - INFO - Epoch [17/30] Batch [3120/4715] Loss: 0.8140\n",
      "2025-05-30 17:02:34,359 - INFO - Epoch [17/30] Batch [3130/4715] Loss: 0.6573\n",
      "2025-05-30 17:02:35,903 - INFO - Epoch [17/30] Batch [3140/4715] Loss: 0.6280\n",
      "2025-05-30 17:02:37,435 - INFO - Epoch [17/30] Batch [3150/4715] Loss: 0.8936\n",
      "2025-05-30 17:02:38,976 - INFO - Epoch [17/30] Batch [3160/4715] Loss: 0.7340\n",
      "2025-05-30 17:02:40,500 - INFO - Epoch [17/30] Batch [3170/4715] Loss: 0.8495\n",
      "2025-05-30 17:02:42,020 - INFO - Epoch [17/30] Batch [3180/4715] Loss: 0.6965\n",
      "2025-05-30 17:02:43,516 - INFO - Epoch [17/30] Batch [3190/4715] Loss: 0.7465\n",
      "2025-05-30 17:02:45,122 - INFO - Epoch [17/30] Batch [3200/4715] Loss: 0.8587\n",
      "2025-05-30 17:02:46,694 - INFO - Epoch [17/30] Batch [3210/4715] Loss: 0.8769\n",
      "2025-05-30 17:02:48,255 - INFO - Epoch [17/30] Batch [3220/4715] Loss: 0.8194\n",
      "2025-05-30 17:02:49,726 - INFO - Epoch [17/30] Batch [3230/4715] Loss: 0.7313\n",
      "2025-05-30 17:02:51,245 - INFO - Epoch [17/30] Batch [3240/4715] Loss: 0.7651\n",
      "2025-05-30 17:02:52,820 - INFO - Epoch [17/30] Batch [3250/4715] Loss: 0.7479\n",
      "2025-05-30 17:02:54,351 - INFO - Epoch [17/30] Batch [3260/4715] Loss: 0.6713\n",
      "2025-05-30 17:02:55,976 - INFO - Epoch [17/30] Batch [3270/4715] Loss: 0.7091\n",
      "2025-05-30 17:02:57,622 - INFO - Epoch [17/30] Batch [3280/4715] Loss: 1.0411\n",
      "2025-05-30 17:02:59,177 - INFO - Epoch [17/30] Batch [3290/4715] Loss: 0.6625\n",
      "2025-05-30 17:03:00,832 - INFO - Epoch [17/30] Batch [3300/4715] Loss: 0.7058\n",
      "2025-05-30 17:03:02,364 - INFO - Epoch [17/30] Batch [3310/4715] Loss: 0.7629\n",
      "2025-05-30 17:03:03,859 - INFO - Epoch [17/30] Batch [3320/4715] Loss: 0.6971\n",
      "2025-05-30 17:03:05,410 - INFO - Epoch [17/30] Batch [3330/4715] Loss: 0.7527\n",
      "2025-05-30 17:03:06,905 - INFO - Epoch [17/30] Batch [3340/4715] Loss: 0.8121\n",
      "2025-05-30 17:03:08,476 - INFO - Epoch [17/30] Batch [3350/4715] Loss: 0.6562\n",
      "2025-05-30 17:03:10,110 - INFO - Epoch [17/30] Batch [3360/4715] Loss: 0.8340\n",
      "2025-05-30 17:03:11,637 - INFO - Epoch [17/30] Batch [3370/4715] Loss: 0.8217\n",
      "2025-05-30 17:03:13,183 - INFO - Epoch [17/30] Batch [3380/4715] Loss: 0.7915\n",
      "2025-05-30 17:03:14,738 - INFO - Epoch [17/30] Batch [3390/4715] Loss: 0.8318\n",
      "2025-05-30 17:03:16,204 - INFO - Epoch [17/30] Batch [3400/4715] Loss: 0.8053\n",
      "2025-05-30 17:03:17,766 - INFO - Epoch [17/30] Batch [3410/4715] Loss: 0.7645\n",
      "2025-05-30 17:03:19,406 - INFO - Epoch [17/30] Batch [3420/4715] Loss: 0.9526\n",
      "2025-05-30 17:03:20,954 - INFO - Epoch [17/30] Batch [3430/4715] Loss: 1.1015\n",
      "2025-05-30 17:03:22,578 - INFO - Epoch [17/30] Batch [3440/4715] Loss: 0.8035\n",
      "2025-05-30 17:03:24,145 - INFO - Epoch [17/30] Batch [3450/4715] Loss: 0.8935\n",
      "2025-05-30 17:03:25,648 - INFO - Epoch [17/30] Batch [3460/4715] Loss: 0.8598\n",
      "2025-05-30 17:03:27,225 - INFO - Epoch [17/30] Batch [3470/4715] Loss: 0.8130\n",
      "2025-05-30 17:03:28,817 - INFO - Epoch [17/30] Batch [3480/4715] Loss: 0.9550\n",
      "2025-05-30 17:03:30,393 - INFO - Epoch [17/30] Batch [3490/4715] Loss: 0.6257\n",
      "2025-05-30 17:03:31,948 - INFO - Epoch [17/30] Batch [3500/4715] Loss: 0.5900\n",
      "2025-05-30 17:03:33,515 - INFO - Epoch [17/30] Batch [3510/4715] Loss: 0.6918\n",
      "2025-05-30 17:03:35,093 - INFO - Epoch [17/30] Batch [3520/4715] Loss: 0.6913\n",
      "2025-05-30 17:03:36,604 - INFO - Epoch [17/30] Batch [3530/4715] Loss: 1.0546\n",
      "2025-05-30 17:03:38,127 - INFO - Epoch [17/30] Batch [3540/4715] Loss: 0.7470\n",
      "2025-05-30 17:03:39,738 - INFO - Epoch [17/30] Batch [3550/4715] Loss: 0.9138\n",
      "2025-05-30 17:03:41,367 - INFO - Epoch [17/30] Batch [3560/4715] Loss: 0.4967\n",
      "2025-05-30 17:03:42,910 - INFO - Epoch [17/30] Batch [3570/4715] Loss: 0.8447\n",
      "2025-05-30 17:03:44,423 - INFO - Epoch [17/30] Batch [3580/4715] Loss: 0.8553\n",
      "2025-05-30 17:03:46,007 - INFO - Epoch [17/30] Batch [3590/4715] Loss: 0.8848\n",
      "2025-05-30 17:03:47,547 - INFO - Epoch [17/30] Batch [3600/4715] Loss: 0.6135\n",
      "2025-05-30 17:03:49,119 - INFO - Epoch [17/30] Batch [3610/4715] Loss: 0.7197\n",
      "2025-05-30 17:03:50,637 - INFO - Epoch [17/30] Batch [3620/4715] Loss: 0.4834\n",
      "2025-05-30 17:03:52,338 - INFO - Epoch [17/30] Batch [3630/4715] Loss: 0.6991\n",
      "2025-05-30 17:03:53,936 - INFO - Epoch [17/30] Batch [3640/4715] Loss: 0.7165\n",
      "2025-05-30 17:03:55,471 - INFO - Epoch [17/30] Batch [3650/4715] Loss: 0.5870\n",
      "2025-05-30 17:03:57,075 - INFO - Epoch [17/30] Batch [3660/4715] Loss: 0.6045\n",
      "2025-05-30 17:03:58,697 - INFO - Epoch [17/30] Batch [3670/4715] Loss: 0.7579\n",
      "2025-05-30 17:04:00,365 - INFO - Epoch [17/30] Batch [3680/4715] Loss: 0.7691\n",
      "2025-05-30 17:04:01,986 - INFO - Epoch [17/30] Batch [3690/4715] Loss: 0.9369\n",
      "2025-05-30 17:04:03,620 - INFO - Epoch [17/30] Batch [3700/4715] Loss: 0.7395\n",
      "2025-05-30 17:04:05,164 - INFO - Epoch [17/30] Batch [3710/4715] Loss: 0.8542\n",
      "2025-05-30 17:04:06,749 - INFO - Epoch [17/30] Batch [3720/4715] Loss: 0.6518\n",
      "2025-05-30 17:04:08,357 - INFO - Epoch [17/30] Batch [3730/4715] Loss: 0.9133\n",
      "2025-05-30 17:04:09,971 - INFO - Epoch [17/30] Batch [3740/4715] Loss: 0.8049\n",
      "2025-05-30 17:04:11,598 - INFO - Epoch [17/30] Batch [3750/4715] Loss: 0.8589\n",
      "2025-05-30 17:04:13,273 - INFO - Epoch [17/30] Batch [3760/4715] Loss: 0.5665\n",
      "2025-05-30 17:04:14,828 - INFO - Epoch [17/30] Batch [3770/4715] Loss: 0.7694\n",
      "2025-05-30 17:04:16,319 - INFO - Epoch [17/30] Batch [3780/4715] Loss: 0.9715\n",
      "2025-05-30 17:04:17,853 - INFO - Epoch [17/30] Batch [3790/4715] Loss: 0.9524\n",
      "2025-05-30 17:04:19,455 - INFO - Epoch [17/30] Batch [3800/4715] Loss: 0.7312\n",
      "2025-05-30 17:04:21,006 - INFO - Epoch [17/30] Batch [3810/4715] Loss: 0.6919\n",
      "2025-05-30 17:04:22,535 - INFO - Epoch [17/30] Batch [3820/4715] Loss: 0.8046\n",
      "2025-05-30 17:04:24,100 - INFO - Epoch [17/30] Batch [3830/4715] Loss: 0.6005\n",
      "2025-05-30 17:04:25,596 - INFO - Epoch [17/30] Batch [3840/4715] Loss: 0.7242\n",
      "2025-05-30 17:04:27,184 - INFO - Epoch [17/30] Batch [3850/4715] Loss: 0.6761\n",
      "2025-05-30 17:04:28,746 - INFO - Epoch [17/30] Batch [3860/4715] Loss: 0.6686\n",
      "2025-05-30 17:04:30,309 - INFO - Epoch [17/30] Batch [3870/4715] Loss: 0.5766\n",
      "2025-05-30 17:04:31,884 - INFO - Epoch [17/30] Batch [3880/4715] Loss: 0.9385\n",
      "2025-05-30 17:04:33,449 - INFO - Epoch [17/30] Batch [3890/4715] Loss: 0.5178\n",
      "2025-05-30 17:04:34,968 - INFO - Epoch [17/30] Batch [3900/4715] Loss: 1.0085\n",
      "2025-05-30 17:04:36,454 - INFO - Epoch [17/30] Batch [3910/4715] Loss: 0.8112\n",
      "2025-05-30 17:04:38,115 - INFO - Epoch [17/30] Batch [3920/4715] Loss: 0.8996\n",
      "2025-05-30 17:04:39,654 - INFO - Epoch [17/30] Batch [3930/4715] Loss: 0.8695\n",
      "2025-05-30 17:04:41,295 - INFO - Epoch [17/30] Batch [3940/4715] Loss: 0.7167\n",
      "2025-05-30 17:04:42,890 - INFO - Epoch [17/30] Batch [3950/4715] Loss: 0.8596\n",
      "2025-05-30 17:04:44,449 - INFO - Epoch [17/30] Batch [3960/4715] Loss: 0.6263\n",
      "2025-05-30 17:04:46,006 - INFO - Epoch [17/30] Batch [3970/4715] Loss: 0.9310\n",
      "2025-05-30 17:04:47,646 - INFO - Epoch [17/30] Batch [3980/4715] Loss: 0.8356\n",
      "2025-05-30 17:04:49,146 - INFO - Epoch [17/30] Batch [3990/4715] Loss: 0.7065\n",
      "2025-05-30 17:04:50,783 - INFO - Epoch [17/30] Batch [4000/4715] Loss: 0.7121\n",
      "2025-05-30 17:04:52,482 - INFO - Epoch [17/30] Batch [4010/4715] Loss: 0.5774\n",
      "2025-05-30 17:04:54,087 - INFO - Epoch [17/30] Batch [4020/4715] Loss: 0.7355\n",
      "2025-05-30 17:04:55,702 - INFO - Epoch [17/30] Batch [4030/4715] Loss: 0.6509\n",
      "2025-05-30 17:04:57,253 - INFO - Epoch [17/30] Batch [4040/4715] Loss: 0.8453\n",
      "2025-05-30 17:04:58,824 - INFO - Epoch [17/30] Batch [4050/4715] Loss: 0.8096\n",
      "2025-05-30 17:05:00,372 - INFO - Epoch [17/30] Batch [4060/4715] Loss: 0.8991\n",
      "2025-05-30 17:05:01,880 - INFO - Epoch [17/30] Batch [4070/4715] Loss: 1.0502\n",
      "2025-05-30 17:05:03,532 - INFO - Epoch [17/30] Batch [4080/4715] Loss: 0.6921\n",
      "2025-05-30 17:05:05,087 - INFO - Epoch [17/30] Batch [4090/4715] Loss: 0.8146\n",
      "2025-05-30 17:05:06,658 - INFO - Epoch [17/30] Batch [4100/4715] Loss: 0.6180\n",
      "2025-05-30 17:05:08,136 - INFO - Epoch [17/30] Batch [4110/4715] Loss: 0.6453\n",
      "2025-05-30 17:05:09,716 - INFO - Epoch [17/30] Batch [4120/4715] Loss: 0.6798\n",
      "2025-05-30 17:05:11,343 - INFO - Epoch [17/30] Batch [4130/4715] Loss: 0.7307\n",
      "2025-05-30 17:05:12,878 - INFO - Epoch [17/30] Batch [4140/4715] Loss: 0.7364\n",
      "2025-05-30 17:05:14,523 - INFO - Epoch [17/30] Batch [4150/4715] Loss: 0.6172\n",
      "2025-05-30 17:05:16,051 - INFO - Epoch [17/30] Batch [4160/4715] Loss: 0.8974\n",
      "2025-05-30 17:05:17,650 - INFO - Epoch [17/30] Batch [4170/4715] Loss: 0.6462\n",
      "2025-05-30 17:05:19,230 - INFO - Epoch [17/30] Batch [4180/4715] Loss: 0.7884\n",
      "2025-05-30 17:05:20,743 - INFO - Epoch [17/30] Batch [4190/4715] Loss: 1.1277\n",
      "2025-05-30 17:05:22,309 - INFO - Epoch [17/30] Batch [4200/4715] Loss: 0.8217\n",
      "2025-05-30 17:05:23,889 - INFO - Epoch [17/30] Batch [4210/4715] Loss: 0.8201\n",
      "2025-05-30 17:05:25,500 - INFO - Epoch [17/30] Batch [4220/4715] Loss: 0.9345\n",
      "2025-05-30 17:05:27,031 - INFO - Epoch [17/30] Batch [4230/4715] Loss: 0.5326\n",
      "2025-05-30 17:05:28,623 - INFO - Epoch [17/30] Batch [4240/4715] Loss: 1.1683\n",
      "2025-05-30 17:05:30,225 - INFO - Epoch [17/30] Batch [4250/4715] Loss: 0.9101\n",
      "2025-05-30 17:05:31,820 - INFO - Epoch [17/30] Batch [4260/4715] Loss: 0.5630\n",
      "2025-05-30 17:05:33,525 - INFO - Epoch [17/30] Batch [4270/4715] Loss: 0.7450\n",
      "2025-05-30 17:05:35,162 - INFO - Epoch [17/30] Batch [4280/4715] Loss: 0.6716\n",
      "2025-05-30 17:05:36,688 - INFO - Epoch [17/30] Batch [4290/4715] Loss: 0.8670\n",
      "2025-05-30 17:05:38,288 - INFO - Epoch [17/30] Batch [4300/4715] Loss: 0.7845\n",
      "2025-05-30 17:05:39,802 - INFO - Epoch [17/30] Batch [4310/4715] Loss: 0.7399\n",
      "2025-05-30 17:05:41,455 - INFO - Epoch [17/30] Batch [4320/4715] Loss: 1.0181\n",
      "2025-05-30 17:05:43,002 - INFO - Epoch [17/30] Batch [4330/4715] Loss: 0.8161\n",
      "2025-05-30 17:05:44,603 - INFO - Epoch [17/30] Batch [4340/4715] Loss: 1.0500\n",
      "2025-05-30 17:05:46,279 - INFO - Epoch [17/30] Batch [4350/4715] Loss: 0.6521\n",
      "2025-05-30 17:05:47,844 - INFO - Epoch [17/30] Batch [4360/4715] Loss: 0.6544\n",
      "2025-05-30 17:05:49,367 - INFO - Epoch [17/30] Batch [4370/4715] Loss: 0.6085\n",
      "2025-05-30 17:05:50,904 - INFO - Epoch [17/30] Batch [4380/4715] Loss: 0.7619\n",
      "2025-05-30 17:05:52,465 - INFO - Epoch [17/30] Batch [4390/4715] Loss: 0.6756\n",
      "2025-05-30 17:05:53,981 - INFO - Epoch [17/30] Batch [4400/4715] Loss: 0.9134\n",
      "2025-05-30 17:05:55,524 - INFO - Epoch [17/30] Batch [4410/4715] Loss: 0.9745\n",
      "2025-05-30 17:05:57,129 - INFO - Epoch [17/30] Batch [4420/4715] Loss: 0.7239\n",
      "2025-05-30 17:05:58,687 - INFO - Epoch [17/30] Batch [4430/4715] Loss: 0.8226\n",
      "2025-05-30 17:06:00,216 - INFO - Epoch [17/30] Batch [4440/4715] Loss: 0.9106\n",
      "2025-05-30 17:06:01,776 - INFO - Epoch [17/30] Batch [4450/4715] Loss: 0.7326\n",
      "2025-05-30 17:06:03,331 - INFO - Epoch [17/30] Batch [4460/4715] Loss: 0.7466\n",
      "2025-05-30 17:06:04,962 - INFO - Epoch [17/30] Batch [4470/4715] Loss: 0.8616\n",
      "2025-05-30 17:06:06,566 - INFO - Epoch [17/30] Batch [4480/4715] Loss: 0.9119\n",
      "2025-05-30 17:06:08,129 - INFO - Epoch [17/30] Batch [4490/4715] Loss: 0.5634\n",
      "2025-05-30 17:06:09,683 - INFO - Epoch [17/30] Batch [4500/4715] Loss: 0.7991\n",
      "2025-05-30 17:06:11,274 - INFO - Epoch [17/30] Batch [4510/4715] Loss: 0.7569\n",
      "2025-05-30 17:06:12,980 - INFO - Epoch [17/30] Batch [4520/4715] Loss: 0.5994\n",
      "2025-05-30 17:06:14,571 - INFO - Epoch [17/30] Batch [4530/4715] Loss: 0.9567\n",
      "2025-05-30 17:06:16,085 - INFO - Epoch [17/30] Batch [4540/4715] Loss: 0.7865\n",
      "2025-05-30 17:06:17,613 - INFO - Epoch [17/30] Batch [4550/4715] Loss: 0.8937\n",
      "2025-05-30 17:06:19,200 - INFO - Epoch [17/30] Batch [4560/4715] Loss: 0.6495\n",
      "2025-05-30 17:06:20,780 - INFO - Epoch [17/30] Batch [4570/4715] Loss: 0.9543\n",
      "2025-05-30 17:06:22,294 - INFO - Epoch [17/30] Batch [4580/4715] Loss: 0.8777\n",
      "2025-05-30 17:06:23,890 - INFO - Epoch [17/30] Batch [4590/4715] Loss: 0.8066\n",
      "2025-05-30 17:06:25,545 - INFO - Epoch [17/30] Batch [4600/4715] Loss: 0.9166\n",
      "2025-05-30 17:06:27,124 - INFO - Epoch [17/30] Batch [4610/4715] Loss: 0.9890\n",
      "2025-05-30 17:06:28,693 - INFO - Epoch [17/30] Batch [4620/4715] Loss: 0.8408\n",
      "2025-05-30 17:06:30,223 - INFO - Epoch [17/30] Batch [4630/4715] Loss: 0.6361\n",
      "2025-05-30 17:06:31,838 - INFO - Epoch [17/30] Batch [4640/4715] Loss: 0.8349\n",
      "2025-05-30 17:06:33,321 - INFO - Epoch [17/30] Batch [4650/4715] Loss: 0.5424\n",
      "2025-05-30 17:06:34,914 - INFO - Epoch [17/30] Batch [4660/4715] Loss: 0.8463\n",
      "2025-05-30 17:06:36,461 - INFO - Epoch [17/30] Batch [4670/4715] Loss: 0.7285\n",
      "2025-05-30 17:06:38,053 - INFO - Epoch [17/30] Batch [4680/4715] Loss: 0.7749\n",
      "2025-05-30 17:06:39,647 - INFO - Epoch [17/30] Batch [4690/4715] Loss: 0.8390\n",
      "2025-05-30 17:06:41,352 - INFO - Epoch [17/30] Batch [4700/4715] Loss: 0.7117\n",
      "2025-05-30 17:06:43,014 - INFO - Epoch [17/30] Batch [4710/4715] Loss: 0.4787\n",
      "2025-05-30 17:07:22,143 - INFO - \n",
      "Epoch [17/30] Time: 782.63s\n",
      "2025-05-30 17:07:22,144 - INFO - Train Loss: 0.7731, Valid Loss: 0.8154\n",
      "2025-05-30 17:07:22,145 - INFO - Valid AUC (macro): 0.7376, F1 (macro): 0.5712\n",
      "2025-05-30 17:07:22,679 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\last_checkpoint.pth\n",
      "2025-05-30 17:07:22,680 - INFO - Saved checkpoint at epoch 17\n",
      "2025-05-30 17:07:22,899 - INFO - Epoch [18/30] Batch [0/4715] Loss: 0.5329\n",
      "2025-05-30 17:07:24,834 - INFO - Epoch [18/30] Batch [10/4715] Loss: 0.5474\n",
      "2025-05-30 17:07:26,671 - INFO - Epoch [18/30] Batch [20/4715] Loss: 0.5621\n",
      "2025-05-30 17:07:28,312 - INFO - Epoch [18/30] Batch [30/4715] Loss: 0.6244\n",
      "2025-05-30 17:07:29,835 - INFO - Epoch [18/30] Batch [40/4715] Loss: 0.9528\n",
      "2025-05-30 17:07:31,416 - INFO - Epoch [18/30] Batch [50/4715] Loss: 0.8278\n",
      "2025-05-30 17:07:32,956 - INFO - Epoch [18/30] Batch [60/4715] Loss: 1.1396\n",
      "2025-05-30 17:07:34,476 - INFO - Epoch [18/30] Batch [70/4715] Loss: 0.7674\n",
      "2025-05-30 17:07:36,039 - INFO - Epoch [18/30] Batch [80/4715] Loss: 0.6505\n",
      "2025-05-30 17:07:37,641 - INFO - Epoch [18/30] Batch [90/4715] Loss: 0.7581\n",
      "2025-05-30 17:07:39,273 - INFO - Epoch [18/30] Batch [100/4715] Loss: 0.8029\n",
      "2025-05-30 17:07:40,821 - INFO - Epoch [18/30] Batch [110/4715] Loss: 0.7949\n",
      "2025-05-30 17:07:42,476 - INFO - Epoch [18/30] Batch [120/4715] Loss: 0.7915\n",
      "2025-05-30 17:07:44,012 - INFO - Epoch [18/30] Batch [130/4715] Loss: 0.7377\n",
      "2025-05-30 17:07:45,552 - INFO - Epoch [18/30] Batch [140/4715] Loss: 0.8366\n",
      "2025-05-30 17:07:47,113 - INFO - Epoch [18/30] Batch [150/4715] Loss: 0.7706\n",
      "2025-05-30 17:07:48,776 - INFO - Epoch [18/30] Batch [160/4715] Loss: 0.7822\n",
      "2025-05-30 17:07:50,418 - INFO - Epoch [18/30] Batch [170/4715] Loss: 0.8549\n",
      "2025-05-30 17:07:51,988 - INFO - Epoch [18/30] Batch [180/4715] Loss: 0.7991\n",
      "2025-05-30 17:07:53,516 - INFO - Epoch [18/30] Batch [190/4715] Loss: 0.9055\n",
      "2025-05-30 17:07:55,026 - INFO - Epoch [18/30] Batch [200/4715] Loss: 0.9598\n",
      "2025-05-30 17:07:56,580 - INFO - Epoch [18/30] Batch [210/4715] Loss: 0.7290\n",
      "2025-05-30 17:07:58,112 - INFO - Epoch [18/30] Batch [220/4715] Loss: 1.0145\n",
      "2025-05-30 17:07:59,675 - INFO - Epoch [18/30] Batch [230/4715] Loss: 0.9355\n",
      "2025-05-30 17:08:01,237 - INFO - Epoch [18/30] Batch [240/4715] Loss: 0.7555\n",
      "2025-05-30 17:08:02,831 - INFO - Epoch [18/30] Batch [250/4715] Loss: 0.7946\n",
      "2025-05-30 17:08:04,467 - INFO - Epoch [18/30] Batch [260/4715] Loss: 0.6558\n",
      "2025-05-30 17:08:06,064 - INFO - Epoch [18/30] Batch [270/4715] Loss: 0.8720\n",
      "2025-05-30 17:08:07,669 - INFO - Epoch [18/30] Batch [280/4715] Loss: 0.7005\n",
      "2025-05-30 17:08:09,195 - INFO - Epoch [18/30] Batch [290/4715] Loss: 0.8302\n",
      "2025-05-30 17:08:10,731 - INFO - Epoch [18/30] Batch [300/4715] Loss: 0.6311\n",
      "2025-05-30 17:08:12,304 - INFO - Epoch [18/30] Batch [310/4715] Loss: 0.9191\n",
      "2025-05-30 17:08:13,833 - INFO - Epoch [18/30] Batch [320/4715] Loss: 1.0568\n",
      "2025-05-30 17:08:15,445 - INFO - Epoch [18/30] Batch [330/4715] Loss: 0.6459\n",
      "2025-05-30 17:08:16,976 - INFO - Epoch [18/30] Batch [340/4715] Loss: 1.1516\n",
      "2025-05-30 17:08:18,598 - INFO - Epoch [18/30] Batch [350/4715] Loss: 0.7734\n",
      "2025-05-30 17:08:20,294 - INFO - Epoch [18/30] Batch [360/4715] Loss: 0.6689\n",
      "2025-05-30 17:08:21,830 - INFO - Epoch [18/30] Batch [370/4715] Loss: 0.8408\n",
      "2025-05-30 17:08:23,358 - INFO - Epoch [18/30] Batch [380/4715] Loss: 0.7307\n",
      "2025-05-30 17:08:24,886 - INFO - Epoch [18/30] Batch [390/4715] Loss: 0.6099\n",
      "2025-05-30 17:08:26,449 - INFO - Epoch [18/30] Batch [400/4715] Loss: 0.7389\n",
      "2025-05-30 17:08:28,057 - INFO - Epoch [18/30] Batch [410/4715] Loss: 0.8304\n",
      "2025-05-30 17:08:29,551 - INFO - Epoch [18/30] Batch [420/4715] Loss: 0.8028\n",
      "2025-05-30 17:08:31,184 - INFO - Epoch [18/30] Batch [430/4715] Loss: 0.9346\n",
      "2025-05-30 17:08:32,682 - INFO - Epoch [18/30] Batch [440/4715] Loss: 0.5740\n",
      "2025-05-30 17:08:34,258 - INFO - Epoch [18/30] Batch [450/4715] Loss: 0.8288\n",
      "2025-05-30 17:08:35,981 - INFO - Epoch [18/30] Batch [460/4715] Loss: 0.6608\n",
      "2025-05-30 17:08:37,536 - INFO - Epoch [18/30] Batch [470/4715] Loss: 0.7091\n",
      "2025-05-30 17:08:39,148 - INFO - Epoch [18/30] Batch [480/4715] Loss: 0.9034\n",
      "2025-05-30 17:08:40,741 - INFO - Epoch [18/30] Batch [490/4715] Loss: 0.7644\n",
      "2025-05-30 17:08:42,212 - INFO - Epoch [18/30] Batch [500/4715] Loss: 0.6415\n",
      "2025-05-30 17:08:43,734 - INFO - Epoch [18/30] Batch [510/4715] Loss: 0.7304\n",
      "2025-05-30 17:08:45,277 - INFO - Epoch [18/30] Batch [520/4715] Loss: 0.6702\n",
      "2025-05-30 17:08:46,782 - INFO - Epoch [18/30] Batch [530/4715] Loss: 0.6717\n",
      "2025-05-30 17:08:48,447 - INFO - Epoch [18/30] Batch [540/4715] Loss: 0.7652\n",
      "2025-05-30 17:08:50,017 - INFO - Epoch [18/30] Batch [550/4715] Loss: 0.6688\n",
      "2025-05-30 17:08:51,646 - INFO - Epoch [18/30] Batch [560/4715] Loss: 0.5994\n",
      "2025-05-30 17:08:53,366 - INFO - Epoch [18/30] Batch [570/4715] Loss: 0.9175\n",
      "2025-05-30 17:08:55,020 - INFO - Epoch [18/30] Batch [580/4715] Loss: 0.6643\n",
      "2025-05-30 17:08:56,528 - INFO - Epoch [18/30] Batch [590/4715] Loss: 0.5977\n",
      "2025-05-30 17:08:58,156 - INFO - Epoch [18/30] Batch [600/4715] Loss: 0.6187\n",
      "2025-05-30 17:08:59,699 - INFO - Epoch [18/30] Batch [610/4715] Loss: 0.5719\n",
      "2025-05-30 17:09:01,271 - INFO - Epoch [18/30] Batch [620/4715] Loss: 0.5646\n",
      "2025-05-30 17:09:02,874 - INFO - Epoch [18/30] Batch [630/4715] Loss: 0.7458\n",
      "2025-05-30 17:09:04,398 - INFO - Epoch [18/30] Batch [640/4715] Loss: 0.6874\n",
      "2025-05-30 17:09:05,914 - INFO - Epoch [18/30] Batch [650/4715] Loss: 0.6738\n",
      "2025-05-30 17:09:07,435 - INFO - Epoch [18/30] Batch [660/4715] Loss: 0.8674\n",
      "2025-05-30 17:09:09,017 - INFO - Epoch [18/30] Batch [670/4715] Loss: 0.6980\n",
      "2025-05-30 17:09:10,622 - INFO - Epoch [18/30] Batch [680/4715] Loss: 0.8428\n",
      "2025-05-30 17:09:12,220 - INFO - Epoch [18/30] Batch [690/4715] Loss: 0.9010\n",
      "2025-05-30 17:09:13,858 - INFO - Epoch [18/30] Batch [700/4715] Loss: 0.7224\n",
      "2025-05-30 17:09:15,412 - INFO - Epoch [18/30] Batch [710/4715] Loss: 0.5595\n",
      "2025-05-30 17:09:16,886 - INFO - Epoch [18/30] Batch [720/4715] Loss: 0.9624\n",
      "2025-05-30 17:09:18,448 - INFO - Epoch [18/30] Batch [730/4715] Loss: 1.0153\n",
      "2025-05-30 17:09:20,059 - INFO - Epoch [18/30] Batch [740/4715] Loss: 0.6679\n",
      "2025-05-30 17:09:21,559 - INFO - Epoch [18/30] Batch [750/4715] Loss: 0.8783\n",
      "2025-05-30 17:09:23,148 - INFO - Epoch [18/30] Batch [760/4715] Loss: 0.7756\n",
      "2025-05-30 17:09:24,705 - INFO - Epoch [18/30] Batch [770/4715] Loss: 0.7073\n",
      "2025-05-30 17:09:26,248 - INFO - Epoch [18/30] Batch [780/4715] Loss: 0.8802\n",
      "2025-05-30 17:09:27,822 - INFO - Epoch [18/30] Batch [790/4715] Loss: 0.9625\n",
      "2025-05-30 17:09:29,412 - INFO - Epoch [18/30] Batch [800/4715] Loss: 0.7860\n",
      "2025-05-30 17:09:31,099 - INFO - Epoch [18/30] Batch [810/4715] Loss: 1.1319\n",
      "2025-05-30 17:09:32,762 - INFO - Epoch [18/30] Batch [820/4715] Loss: 0.7530\n",
      "2025-05-30 17:09:34,308 - INFO - Epoch [18/30] Batch [830/4715] Loss: 0.7645\n",
      "2025-05-30 17:09:35,918 - INFO - Epoch [18/30] Batch [840/4715] Loss: 0.6584\n",
      "2025-05-30 17:09:37,465 - INFO - Epoch [18/30] Batch [850/4715] Loss: 0.8107\n",
      "2025-05-30 17:09:39,078 - INFO - Epoch [18/30] Batch [860/4715] Loss: 1.0127\n",
      "2025-05-30 17:09:40,716 - INFO - Epoch [18/30] Batch [870/4715] Loss: 0.7396\n",
      "2025-05-30 17:09:42,263 - INFO - Epoch [18/30] Batch [880/4715] Loss: 0.6878\n",
      "2025-05-30 17:09:43,833 - INFO - Epoch [18/30] Batch [890/4715] Loss: 0.3692\n",
      "2025-05-30 17:09:45,390 - INFO - Epoch [18/30] Batch [900/4715] Loss: 0.4520\n",
      "2025-05-30 17:09:47,033 - INFO - Epoch [18/30] Batch [910/4715] Loss: 1.1072\n",
      "2025-05-30 17:09:48,681 - INFO - Epoch [18/30] Batch [920/4715] Loss: 0.6447\n",
      "2025-05-30 17:09:50,265 - INFO - Epoch [18/30] Batch [930/4715] Loss: 0.8019\n",
      "2025-05-30 17:09:51,879 - INFO - Epoch [18/30] Batch [940/4715] Loss: 0.8978\n",
      "2025-05-30 17:09:53,425 - INFO - Epoch [18/30] Batch [950/4715] Loss: 0.4928\n",
      "2025-05-30 17:09:54,983 - INFO - Epoch [18/30] Batch [960/4715] Loss: 0.9257\n",
      "2025-05-30 17:09:56,583 - INFO - Epoch [18/30] Batch [970/4715] Loss: 0.8954\n",
      "2025-05-30 17:09:58,185 - INFO - Epoch [18/30] Batch [980/4715] Loss: 0.8796\n",
      "2025-05-30 17:09:59,760 - INFO - Epoch [18/30] Batch [990/4715] Loss: 0.6581\n",
      "2025-05-30 17:10:01,344 - INFO - Epoch [18/30] Batch [1000/4715] Loss: 0.6407\n",
      "2025-05-30 17:10:02,909 - INFO - Epoch [18/30] Batch [1010/4715] Loss: 0.5485\n",
      "2025-05-30 17:10:04,528 - INFO - Epoch [18/30] Batch [1020/4715] Loss: 0.6603\n",
      "2025-05-30 17:10:06,094 - INFO - Epoch [18/30] Batch [1030/4715] Loss: 0.6305\n",
      "2025-05-30 17:10:07,663 - INFO - Epoch [18/30] Batch [1040/4715] Loss: 0.9111\n",
      "2025-05-30 17:10:09,180 - INFO - Epoch [18/30] Batch [1050/4715] Loss: 0.8108\n",
      "2025-05-30 17:10:10,666 - INFO - Epoch [18/30] Batch [1060/4715] Loss: 0.8626\n",
      "2025-05-30 17:10:12,379 - INFO - Epoch [18/30] Batch [1070/4715] Loss: 0.9339\n",
      "2025-05-30 17:10:13,994 - INFO - Epoch [18/30] Batch [1080/4715] Loss: 0.7023\n",
      "2025-05-30 17:10:15,584 - INFO - Epoch [18/30] Batch [1090/4715] Loss: 0.8476\n",
      "2025-05-30 17:10:17,074 - INFO - Epoch [18/30] Batch [1100/4715] Loss: 0.8429\n",
      "2025-05-30 17:10:18,598 - INFO - Epoch [18/30] Batch [1110/4715] Loss: 0.7083\n",
      "2025-05-30 17:10:20,194 - INFO - Epoch [18/30] Batch [1120/4715] Loss: 0.9399\n",
      "2025-05-30 17:10:21,750 - INFO - Epoch [18/30] Batch [1130/4715] Loss: 0.5484\n",
      "2025-05-30 17:10:23,359 - INFO - Epoch [18/30] Batch [1140/4715] Loss: 0.9117\n",
      "2025-05-30 17:10:24,950 - INFO - Epoch [18/30] Batch [1150/4715] Loss: 0.6823\n",
      "2025-05-30 17:10:26,524 - INFO - Epoch [18/30] Batch [1160/4715] Loss: 0.6019\n",
      "2025-05-30 17:10:28,069 - INFO - Epoch [18/30] Batch [1170/4715] Loss: 0.6190\n",
      "2025-05-30 17:10:29,599 - INFO - Epoch [18/30] Batch [1180/4715] Loss: 0.6408\n",
      "2025-05-30 17:10:31,118 - INFO - Epoch [18/30] Batch [1190/4715] Loss: 1.0616\n",
      "2025-05-30 17:10:32,727 - INFO - Epoch [18/30] Batch [1200/4715] Loss: 0.6716\n",
      "2025-05-30 17:10:34,386 - INFO - Epoch [18/30] Batch [1210/4715] Loss: 0.8267\n",
      "2025-05-30 17:10:35,921 - INFO - Epoch [18/30] Batch [1220/4715] Loss: 0.5430\n",
      "2025-05-30 17:10:37,503 - INFO - Epoch [18/30] Batch [1230/4715] Loss: 0.7312\n",
      "2025-05-30 17:10:39,059 - INFO - Epoch [18/30] Batch [1240/4715] Loss: 0.7908\n",
      "2025-05-30 17:10:40,619 - INFO - Epoch [18/30] Batch [1250/4715] Loss: 0.6082\n",
      "2025-05-30 17:10:42,223 - INFO - Epoch [18/30] Batch [1260/4715] Loss: 0.9569\n",
      "2025-05-30 17:10:43,886 - INFO - Epoch [18/30] Batch [1270/4715] Loss: 0.7541\n",
      "2025-05-30 17:10:45,414 - INFO - Epoch [18/30] Batch [1280/4715] Loss: 0.6721\n",
      "2025-05-30 17:10:47,115 - INFO - Epoch [18/30] Batch [1290/4715] Loss: 0.7849\n",
      "2025-05-30 17:10:48,665 - INFO - Epoch [18/30] Batch [1300/4715] Loss: 0.6301\n",
      "2025-05-30 17:10:50,180 - INFO - Epoch [18/30] Batch [1310/4715] Loss: 0.7564\n",
      "2025-05-30 17:10:51,685 - INFO - Epoch [18/30] Batch [1320/4715] Loss: 0.8130\n",
      "2025-05-30 17:10:53,223 - INFO - Epoch [18/30] Batch [1330/4715] Loss: 0.6328\n",
      "2025-05-30 17:10:54,889 - INFO - Epoch [18/30] Batch [1340/4715] Loss: 0.6305\n",
      "2025-05-30 17:10:56,452 - INFO - Epoch [18/30] Batch [1350/4715] Loss: 0.5641\n",
      "2025-05-30 17:10:58,136 - INFO - Epoch [18/30] Batch [1360/4715] Loss: 0.7688\n",
      "2025-05-30 17:10:59,720 - INFO - Epoch [18/30] Batch [1370/4715] Loss: 0.8066\n",
      "2025-05-30 17:11:01,270 - INFO - Epoch [18/30] Batch [1380/4715] Loss: 0.5401\n",
      "2025-05-30 17:11:02,862 - INFO - Epoch [18/30] Batch [1390/4715] Loss: 0.8301\n",
      "2025-05-30 17:11:04,405 - INFO - Epoch [18/30] Batch [1400/4715] Loss: 0.8760\n",
      "2025-05-30 17:11:05,931 - INFO - Epoch [18/30] Batch [1410/4715] Loss: 0.6345\n",
      "2025-05-30 17:11:07,524 - INFO - Epoch [18/30] Batch [1420/4715] Loss: 0.7107\n",
      "2025-05-30 17:11:09,125 - INFO - Epoch [18/30] Batch [1430/4715] Loss: 0.9396\n",
      "2025-05-30 17:11:10,638 - INFO - Epoch [18/30] Batch [1440/4715] Loss: 0.7237\n",
      "2025-05-30 17:11:12,253 - INFO - Epoch [18/30] Batch [1450/4715] Loss: 0.8091\n",
      "2025-05-30 17:11:13,786 - INFO - Epoch [18/30] Batch [1460/4715] Loss: 0.8593\n",
      "2025-05-30 17:11:15,312 - INFO - Epoch [18/30] Batch [1470/4715] Loss: 0.7935\n",
      "2025-05-30 17:11:16,840 - INFO - Epoch [18/30] Batch [1480/4715] Loss: 0.6390\n",
      "2025-05-30 17:11:18,395 - INFO - Epoch [18/30] Batch [1490/4715] Loss: 0.7492\n",
      "2025-05-30 17:11:19,997 - INFO - Epoch [18/30] Batch [1500/4715] Loss: 1.0308\n",
      "2025-05-30 17:11:21,551 - INFO - Epoch [18/30] Batch [1510/4715] Loss: 0.9959\n",
      "2025-05-30 17:11:23,073 - INFO - Epoch [18/30] Batch [1520/4715] Loss: 0.8476\n",
      "2025-05-30 17:11:24,597 - INFO - Epoch [18/30] Batch [1530/4715] Loss: 0.4453\n",
      "2025-05-30 17:11:26,224 - INFO - Epoch [18/30] Batch [1540/4715] Loss: 0.7470\n",
      "2025-05-30 17:11:27,744 - INFO - Epoch [18/30] Batch [1550/4715] Loss: 0.8723\n",
      "2025-05-30 17:11:29,303 - INFO - Epoch [18/30] Batch [1560/4715] Loss: 0.6711\n",
      "2025-05-30 17:11:30,886 - INFO - Epoch [18/30] Batch [1570/4715] Loss: 0.8190\n",
      "2025-05-30 17:11:32,534 - INFO - Epoch [18/30] Batch [1580/4715] Loss: 0.9200\n",
      "2025-05-30 17:11:34,076 - INFO - Epoch [18/30] Batch [1590/4715] Loss: 0.6217\n",
      "2025-05-30 17:11:35,637 - INFO - Epoch [18/30] Batch [1600/4715] Loss: 0.8014\n",
      "2025-05-30 17:11:37,199 - INFO - Epoch [18/30] Batch [1610/4715] Loss: 1.0524\n",
      "2025-05-30 17:11:38,749 - INFO - Epoch [18/30] Batch [1620/4715] Loss: 0.6811\n",
      "2025-05-30 17:11:40,357 - INFO - Epoch [18/30] Batch [1630/4715] Loss: 0.9611\n",
      "2025-05-30 17:11:41,987 - INFO - Epoch [18/30] Batch [1640/4715] Loss: 0.7376\n",
      "2025-05-30 17:11:43,676 - INFO - Epoch [18/30] Batch [1650/4715] Loss: 0.8048\n",
      "2025-05-30 17:11:45,262 - INFO - Epoch [18/30] Batch [1660/4715] Loss: 0.7677\n",
      "2025-05-30 17:11:46,778 - INFO - Epoch [18/30] Batch [1670/4715] Loss: 0.8568\n",
      "2025-05-30 17:11:48,274 - INFO - Epoch [18/30] Batch [1680/4715] Loss: 0.6454\n",
      "2025-05-30 17:11:49,818 - INFO - Epoch [18/30] Batch [1690/4715] Loss: 1.0922\n",
      "2025-05-30 17:11:51,353 - INFO - Epoch [18/30] Batch [1700/4715] Loss: 0.6223\n",
      "2025-05-30 17:11:52,921 - INFO - Epoch [18/30] Batch [1710/4715] Loss: 0.7867\n",
      "2025-05-30 17:11:54,559 - INFO - Epoch [18/30] Batch [1720/4715] Loss: 0.8243\n",
      "2025-05-30 17:11:56,183 - INFO - Epoch [18/30] Batch [1730/4715] Loss: 0.7963\n",
      "2025-05-30 17:11:57,791 - INFO - Epoch [18/30] Batch [1740/4715] Loss: 0.6889\n",
      "2025-05-30 17:11:59,347 - INFO - Epoch [18/30] Batch [1750/4715] Loss: 0.7468\n",
      "2025-05-30 17:12:00,976 - INFO - Epoch [18/30] Batch [1760/4715] Loss: 0.7803\n",
      "2025-05-30 17:12:02,496 - INFO - Epoch [18/30] Batch [1770/4715] Loss: 0.9178\n",
      "2025-05-30 17:12:04,068 - INFO - Epoch [18/30] Batch [1780/4715] Loss: 0.8923\n",
      "2025-05-30 17:12:05,622 - INFO - Epoch [18/30] Batch [1790/4715] Loss: 0.6737\n",
      "2025-05-30 17:12:07,211 - INFO - Epoch [18/30] Batch [1800/4715] Loss: 0.6945\n",
      "2025-05-30 17:12:08,772 - INFO - Epoch [18/30] Batch [1810/4715] Loss: 0.8483\n",
      "2025-05-30 17:12:10,338 - INFO - Epoch [18/30] Batch [1820/4715] Loss: 0.7748\n",
      "2025-05-30 17:12:11,866 - INFO - Epoch [18/30] Batch [1830/4715] Loss: 0.9370\n",
      "2025-05-30 17:12:13,472 - INFO - Epoch [18/30] Batch [1840/4715] Loss: 0.7185\n",
      "2025-05-30 17:12:15,147 - INFO - Epoch [18/30] Batch [1850/4715] Loss: 0.7672\n",
      "2025-05-30 17:12:16,908 - INFO - Epoch [18/30] Batch [1860/4715] Loss: 0.8784\n",
      "2025-05-30 17:12:18,451 - INFO - Epoch [18/30] Batch [1870/4715] Loss: 0.6336\n",
      "2025-05-30 17:12:20,130 - INFO - Epoch [18/30] Batch [1880/4715] Loss: 0.7388\n",
      "2025-05-30 17:12:21,667 - INFO - Epoch [18/30] Batch [1890/4715] Loss: 0.7231\n",
      "2025-05-30 17:12:23,206 - INFO - Epoch [18/30] Batch [1900/4715] Loss: 0.6111\n",
      "2025-05-30 17:12:24,795 - INFO - Epoch [18/30] Batch [1910/4715] Loss: 0.6303\n",
      "2025-05-30 17:12:26,434 - INFO - Epoch [18/30] Batch [1920/4715] Loss: 1.1405\n",
      "2025-05-30 17:12:28,044 - INFO - Epoch [18/30] Batch [1930/4715] Loss: 0.7201\n",
      "2025-05-30 17:12:29,590 - INFO - Epoch [18/30] Batch [1940/4715] Loss: 0.4683\n",
      "2025-05-30 17:12:31,250 - INFO - Epoch [18/30] Batch [1950/4715] Loss: 0.7468\n",
      "2025-05-30 17:12:32,825 - INFO - Epoch [18/30] Batch [1960/4715] Loss: 0.6247\n",
      "2025-05-30 17:12:34,397 - INFO - Epoch [18/30] Batch [1970/4715] Loss: 0.8938\n",
      "2025-05-30 17:12:35,993 - INFO - Epoch [18/30] Batch [1980/4715] Loss: 0.6430\n",
      "2025-05-30 17:12:37,509 - INFO - Epoch [18/30] Batch [1990/4715] Loss: 0.8929\n",
      "2025-05-30 17:12:39,117 - INFO - Epoch [18/30] Batch [2000/4715] Loss: 0.5561\n",
      "2025-05-30 17:12:40,621 - INFO - Epoch [18/30] Batch [2010/4715] Loss: 0.7411\n",
      "2025-05-30 17:12:42,130 - INFO - Epoch [18/30] Batch [2020/4715] Loss: 0.7152\n",
      "2025-05-30 17:12:43,738 - INFO - Epoch [18/30] Batch [2030/4715] Loss: 0.9055\n",
      "2025-05-30 17:12:45,307 - INFO - Epoch [18/30] Batch [2040/4715] Loss: 0.6719\n",
      "2025-05-30 17:12:46,869 - INFO - Epoch [18/30] Batch [2050/4715] Loss: 0.6319\n",
      "2025-05-30 17:12:48,429 - INFO - Epoch [18/30] Batch [2060/4715] Loss: 0.7311\n",
      "2025-05-30 17:12:49,991 - INFO - Epoch [18/30] Batch [2070/4715] Loss: 0.7635\n",
      "2025-05-30 17:12:51,505 - INFO - Epoch [18/30] Batch [2080/4715] Loss: 0.8772\n",
      "2025-05-30 17:12:53,014 - INFO - Epoch [18/30] Batch [2090/4715] Loss: 0.8506\n",
      "2025-05-30 17:12:54,678 - INFO - Epoch [18/30] Batch [2100/4715] Loss: 0.8680\n",
      "2025-05-30 17:12:56,239 - INFO - Epoch [18/30] Batch [2110/4715] Loss: 0.7331\n",
      "2025-05-30 17:12:57,769 - INFO - Epoch [18/30] Batch [2120/4715] Loss: 0.7750\n",
      "2025-05-30 17:12:59,270 - INFO - Epoch [18/30] Batch [2130/4715] Loss: 0.7698\n",
      "2025-05-30 17:13:00,845 - INFO - Epoch [18/30] Batch [2140/4715] Loss: 0.9636\n",
      "2025-05-30 17:13:02,443 - INFO - Epoch [18/30] Batch [2150/4715] Loss: 0.6697\n",
      "2025-05-30 17:13:04,140 - INFO - Epoch [18/30] Batch [2160/4715] Loss: 0.8685\n",
      "2025-05-30 17:13:05,680 - INFO - Epoch [18/30] Batch [2170/4715] Loss: 0.7832\n",
      "2025-05-30 17:13:07,199 - INFO - Epoch [18/30] Batch [2180/4715] Loss: 0.9046\n",
      "2025-05-30 17:13:08,740 - INFO - Epoch [18/30] Batch [2190/4715] Loss: 0.5132\n",
      "2025-05-30 17:13:10,326 - INFO - Epoch [18/30] Batch [2200/4715] Loss: 0.8421\n",
      "2025-05-30 17:13:11,976 - INFO - Epoch [18/30] Batch [2210/4715] Loss: 0.6711\n",
      "2025-05-30 17:13:13,575 - INFO - Epoch [18/30] Batch [2220/4715] Loss: 0.8263\n",
      "2025-05-30 17:13:15,118 - INFO - Epoch [18/30] Batch [2230/4715] Loss: 0.6239\n",
      "2025-05-30 17:13:16,639 - INFO - Epoch [18/30] Batch [2240/4715] Loss: 0.8591\n",
      "2025-05-30 17:13:18,231 - INFO - Epoch [18/30] Batch [2250/4715] Loss: 0.7270\n",
      "2025-05-30 17:13:19,857 - INFO - Epoch [18/30] Batch [2260/4715] Loss: 0.8675\n",
      "2025-05-30 17:13:21,354 - INFO - Epoch [18/30] Batch [2270/4715] Loss: 0.7609\n",
      "2025-05-30 17:13:22,885 - INFO - Epoch [18/30] Batch [2280/4715] Loss: 0.5655\n",
      "2025-05-30 17:13:24,390 - INFO - Epoch [18/30] Batch [2290/4715] Loss: 0.5467\n",
      "2025-05-30 17:13:25,979 - INFO - Epoch [18/30] Batch [2300/4715] Loss: 0.8233\n",
      "2025-05-30 17:13:27,544 - INFO - Epoch [18/30] Batch [2310/4715] Loss: 0.8303\n",
      "2025-05-30 17:13:29,141 - INFO - Epoch [18/30] Batch [2320/4715] Loss: 0.8162\n",
      "2025-05-30 17:13:30,834 - INFO - Epoch [18/30] Batch [2330/4715] Loss: 0.5039\n",
      "2025-05-30 17:13:32,388 - INFO - Epoch [18/30] Batch [2340/4715] Loss: 0.7125\n",
      "2025-05-30 17:13:34,022 - INFO - Epoch [18/30] Batch [2350/4715] Loss: 0.7186\n",
      "2025-05-30 17:13:35,633 - INFO - Epoch [18/30] Batch [2360/4715] Loss: 0.7376\n",
      "2025-05-30 17:13:37,224 - INFO - Epoch [18/30] Batch [2370/4715] Loss: 1.0902\n",
      "2025-05-30 17:13:38,797 - INFO - Epoch [18/30] Batch [2380/4715] Loss: 0.7498\n",
      "2025-05-30 17:13:40,334 - INFO - Epoch [18/30] Batch [2390/4715] Loss: 0.8873\n",
      "2025-05-30 17:13:41,886 - INFO - Epoch [18/30] Batch [2400/4715] Loss: 0.8208\n",
      "2025-05-30 17:13:43,489 - INFO - Epoch [18/30] Batch [2410/4715] Loss: 0.8375\n",
      "2025-05-30 17:13:45,086 - INFO - Epoch [18/30] Batch [2420/4715] Loss: 0.6755\n",
      "2025-05-30 17:13:46,763 - INFO - Epoch [18/30] Batch [2430/4715] Loss: 0.8478\n",
      "2025-05-30 17:13:48,359 - INFO - Epoch [18/30] Batch [2440/4715] Loss: 0.9707\n",
      "2025-05-30 17:13:49,962 - INFO - Epoch [18/30] Batch [2450/4715] Loss: 0.9204\n",
      "2025-05-30 17:13:51,609 - INFO - Epoch [18/30] Batch [2460/4715] Loss: 0.7198\n",
      "2025-05-30 17:13:53,196 - INFO - Epoch [18/30] Batch [2470/4715] Loss: 0.8444\n",
      "2025-05-30 17:13:54,817 - INFO - Epoch [18/30] Batch [2480/4715] Loss: 0.8317\n",
      "2025-05-30 17:13:56,350 - INFO - Epoch [18/30] Batch [2490/4715] Loss: 0.5018\n",
      "2025-05-30 17:13:57,877 - INFO - Epoch [18/30] Batch [2500/4715] Loss: 0.6600\n",
      "2025-05-30 17:13:59,481 - INFO - Epoch [18/30] Batch [2510/4715] Loss: 0.6610\n",
      "2025-05-30 17:14:01,005 - INFO - Epoch [18/30] Batch [2520/4715] Loss: 0.8600\n",
      "2025-05-30 17:14:02,590 - INFO - Epoch [18/30] Batch [2530/4715] Loss: 0.6962\n",
      "2025-05-30 17:14:04,348 - INFO - Epoch [18/30] Batch [2540/4715] Loss: 0.6118\n",
      "2025-05-30 17:14:05,880 - INFO - Epoch [18/30] Batch [2550/4715] Loss: 0.5445\n",
      "2025-05-30 17:14:07,483 - INFO - Epoch [18/30] Batch [2560/4715] Loss: 0.8764\n",
      "2025-05-30 17:14:09,030 - INFO - Epoch [18/30] Batch [2570/4715] Loss: 0.7405\n",
      "2025-05-30 17:14:10,699 - INFO - Epoch [18/30] Batch [2580/4715] Loss: 0.8591\n",
      "2025-05-30 17:14:12,234 - INFO - Epoch [18/30] Batch [2590/4715] Loss: 0.7474\n",
      "2025-05-30 17:14:13,813 - INFO - Epoch [18/30] Batch [2600/4715] Loss: 0.7717\n",
      "2025-05-30 17:14:15,370 - INFO - Epoch [18/30] Batch [2610/4715] Loss: 0.9460\n",
      "2025-05-30 17:14:16,992 - INFO - Epoch [18/30] Batch [2620/4715] Loss: 0.8541\n",
      "2025-05-30 17:14:18,515 - INFO - Epoch [18/30] Batch [2630/4715] Loss: 0.6027\n",
      "2025-05-30 17:14:20,048 - INFO - Epoch [18/30] Batch [2640/4715] Loss: 1.1220\n",
      "2025-05-30 17:14:21,551 - INFO - Epoch [18/30] Batch [2650/4715] Loss: 0.9923\n",
      "2025-05-30 17:14:23,083 - INFO - Epoch [18/30] Batch [2660/4715] Loss: 0.7599\n",
      "2025-05-30 17:14:24,664 - INFO - Epoch [18/30] Batch [2670/4715] Loss: 1.2877\n",
      "2025-05-30 17:14:26,274 - INFO - Epoch [18/30] Batch [2680/4715] Loss: 0.7721\n",
      "2025-05-30 17:14:27,849 - INFO - Epoch [18/30] Batch [2690/4715] Loss: 0.7468\n",
      "2025-05-30 17:14:29,427 - INFO - Epoch [18/30] Batch [2700/4715] Loss: 0.7522\n",
      "2025-05-30 17:14:30,911 - INFO - Epoch [18/30] Batch [2710/4715] Loss: 0.9158\n",
      "2025-05-30 17:14:32,499 - INFO - Epoch [18/30] Batch [2720/4715] Loss: 0.8158\n",
      "2025-05-30 17:14:34,142 - INFO - Epoch [18/30] Batch [2730/4715] Loss: 0.9816\n",
      "2025-05-30 17:14:35,671 - INFO - Epoch [18/30] Batch [2740/4715] Loss: 0.6690\n",
      "2025-05-30 17:14:37,333 - INFO - Epoch [18/30] Batch [2750/4715] Loss: 0.7036\n",
      "2025-05-30 17:14:38,942 - INFO - Epoch [18/30] Batch [2760/4715] Loss: 0.6728\n",
      "2025-05-30 17:14:40,493 - INFO - Epoch [18/30] Batch [2770/4715] Loss: 0.6783\n",
      "2025-05-30 17:14:42,127 - INFO - Epoch [18/30] Batch [2780/4715] Loss: 0.7343\n",
      "2025-05-30 17:14:43,675 - INFO - Epoch [18/30] Batch [2790/4715] Loss: 0.9570\n",
      "2025-05-30 17:14:45,284 - INFO - Epoch [18/30] Batch [2800/4715] Loss: 0.7823\n",
      "2025-05-30 17:14:46,852 - INFO - Epoch [18/30] Batch [2810/4715] Loss: 0.5456\n",
      "2025-05-30 17:14:48,416 - INFO - Epoch [18/30] Batch [2820/4715] Loss: 0.7965\n",
      "2025-05-30 17:14:50,042 - INFO - Epoch [18/30] Batch [2830/4715] Loss: 0.9776\n",
      "2025-05-30 17:14:51,627 - INFO - Epoch [18/30] Batch [2840/4715] Loss: 1.0532\n",
      "2025-05-30 17:14:53,227 - INFO - Epoch [18/30] Batch [2850/4715] Loss: 0.5173\n",
      "2025-05-30 17:14:54,798 - INFO - Epoch [18/30] Batch [2860/4715] Loss: 0.8913\n",
      "2025-05-30 17:14:56,390 - INFO - Epoch [18/30] Batch [2870/4715] Loss: 0.9143\n",
      "2025-05-30 17:14:57,917 - INFO - Epoch [18/30] Batch [2880/4715] Loss: 0.7029\n",
      "2025-05-30 17:14:59,440 - INFO - Epoch [18/30] Batch [2890/4715] Loss: 0.6987\n",
      "2025-05-30 17:15:01,046 - INFO - Epoch [18/30] Batch [2900/4715] Loss: 0.6147\n",
      "2025-05-30 17:15:02,674 - INFO - Epoch [18/30] Batch [2910/4715] Loss: 0.9921\n",
      "2025-05-30 17:15:04,301 - INFO - Epoch [18/30] Batch [2920/4715] Loss: 0.6623\n",
      "2025-05-30 17:15:05,802 - INFO - Epoch [18/30] Batch [2930/4715] Loss: 0.8327\n",
      "2025-05-30 17:15:07,309 - INFO - Epoch [18/30] Batch [2940/4715] Loss: 0.7631\n",
      "2025-05-30 17:15:08,882 - INFO - Epoch [18/30] Batch [2950/4715] Loss: 0.5464\n",
      "2025-05-30 17:15:10,499 - INFO - Epoch [18/30] Batch [2960/4715] Loss: 0.4379\n",
      "2025-05-30 17:15:12,022 - INFO - Epoch [18/30] Batch [2970/4715] Loss: 1.2712\n",
      "2025-05-30 17:15:13,510 - INFO - Epoch [18/30] Batch [2980/4715] Loss: 0.8808\n",
      "2025-05-30 17:15:15,079 - INFO - Epoch [18/30] Batch [2990/4715] Loss: 0.6466\n",
      "2025-05-30 17:15:16,610 - INFO - Epoch [18/30] Batch [3000/4715] Loss: 0.9314\n",
      "2025-05-30 17:15:18,156 - INFO - Epoch [18/30] Batch [3010/4715] Loss: 0.7942\n",
      "2025-05-30 17:15:19,794 - INFO - Epoch [18/30] Batch [3020/4715] Loss: 0.7567\n",
      "2025-05-30 17:15:21,390 - INFO - Epoch [18/30] Batch [3030/4715] Loss: 0.7996\n",
      "2025-05-30 17:15:22,954 - INFO - Epoch [18/30] Batch [3040/4715] Loss: 0.6968\n",
      "2025-05-30 17:15:24,498 - INFO - Epoch [18/30] Batch [3050/4715] Loss: 0.9664\n",
      "2025-05-30 17:15:26,074 - INFO - Epoch [18/30] Batch [3060/4715] Loss: 0.9532\n",
      "2025-05-30 17:15:27,713 - INFO - Epoch [18/30] Batch [3070/4715] Loss: 0.7143\n",
      "2025-05-30 17:15:29,304 - INFO - Epoch [18/30] Batch [3080/4715] Loss: 0.7811\n",
      "2025-05-30 17:15:30,830 - INFO - Epoch [18/30] Batch [3090/4715] Loss: 0.9048\n",
      "2025-05-30 17:15:32,408 - INFO - Epoch [18/30] Batch [3100/4715] Loss: 0.8348\n",
      "2025-05-30 17:15:34,003 - INFO - Epoch [18/30] Batch [3110/4715] Loss: 1.0663\n",
      "2025-05-30 17:15:35,632 - INFO - Epoch [18/30] Batch [3120/4715] Loss: 0.7595\n",
      "2025-05-30 17:15:37,146 - INFO - Epoch [18/30] Batch [3130/4715] Loss: 0.6188\n",
      "2025-05-30 17:15:38,785 - INFO - Epoch [18/30] Batch [3140/4715] Loss: 0.6925\n",
      "2025-05-30 17:15:40,388 - INFO - Epoch [18/30] Batch [3150/4715] Loss: 0.8604\n",
      "2025-05-30 17:15:41,999 - INFO - Epoch [18/30] Batch [3160/4715] Loss: 0.8649\n",
      "2025-05-30 17:15:43,650 - INFO - Epoch [18/30] Batch [3170/4715] Loss: 0.6758\n",
      "2025-05-30 17:15:45,270 - INFO - Epoch [18/30] Batch [3180/4715] Loss: 0.9281\n",
      "2025-05-30 17:15:46,818 - INFO - Epoch [18/30] Batch [3190/4715] Loss: 0.7536\n",
      "2025-05-30 17:15:48,519 - INFO - Epoch [18/30] Batch [3200/4715] Loss: 0.6428\n",
      "2025-05-30 17:15:50,145 - INFO - Epoch [18/30] Batch [3210/4715] Loss: 0.9724\n",
      "2025-05-30 17:15:51,708 - INFO - Epoch [18/30] Batch [3220/4715] Loss: 0.8601\n",
      "2025-05-30 17:15:53,280 - INFO - Epoch [18/30] Batch [3230/4715] Loss: 0.6829\n",
      "2025-05-30 17:15:54,830 - INFO - Epoch [18/30] Batch [3240/4715] Loss: 0.9051\n",
      "2025-05-30 17:15:56,462 - INFO - Epoch [18/30] Batch [3250/4715] Loss: 0.6733\n",
      "2025-05-30 17:15:58,029 - INFO - Epoch [18/30] Batch [3260/4715] Loss: 0.9244\n",
      "2025-05-30 17:15:59,589 - INFO - Epoch [18/30] Batch [3270/4715] Loss: 0.8628\n",
      "2025-05-30 17:16:01,169 - INFO - Epoch [18/30] Batch [3280/4715] Loss: 0.8496\n",
      "2025-05-30 17:16:02,769 - INFO - Epoch [18/30] Batch [3290/4715] Loss: 0.7679\n",
      "2025-05-30 17:16:04,388 - INFO - Epoch [18/30] Batch [3300/4715] Loss: 0.7131\n",
      "2025-05-30 17:16:05,919 - INFO - Epoch [18/30] Batch [3310/4715] Loss: 0.7463\n",
      "2025-05-30 17:16:07,474 - INFO - Epoch [18/30] Batch [3320/4715] Loss: 0.5670\n",
      "2025-05-30 17:16:09,016 - INFO - Epoch [18/30] Batch [3330/4715] Loss: 0.6560\n",
      "2025-05-30 17:16:10,546 - INFO - Epoch [18/30] Batch [3340/4715] Loss: 0.6926\n",
      "2025-05-30 17:16:12,155 - INFO - Epoch [18/30] Batch [3350/4715] Loss: 0.7910\n",
      "2025-05-30 17:16:13,774 - INFO - Epoch [18/30] Batch [3360/4715] Loss: 0.6534\n",
      "2025-05-30 17:16:15,329 - INFO - Epoch [18/30] Batch [3370/4715] Loss: 0.7568\n",
      "2025-05-30 17:16:16,881 - INFO - Epoch [18/30] Batch [3380/4715] Loss: 0.5637\n",
      "2025-05-30 17:16:18,441 - INFO - Epoch [18/30] Batch [3390/4715] Loss: 0.6271\n",
      "2025-05-30 17:16:19,976 - INFO - Epoch [18/30] Batch [3400/4715] Loss: 0.7945\n",
      "2025-05-30 17:16:21,581 - INFO - Epoch [18/30] Batch [3410/4715] Loss: 0.8205\n",
      "2025-05-30 17:16:23,187 - INFO - Epoch [18/30] Batch [3420/4715] Loss: 0.8294\n",
      "2025-05-30 17:16:24,746 - INFO - Epoch [18/30] Batch [3430/4715] Loss: 0.5817\n",
      "2025-05-30 17:16:26,394 - INFO - Epoch [18/30] Batch [3440/4715] Loss: 0.4742\n",
      "2025-05-30 17:16:27,897 - INFO - Epoch [18/30] Batch [3450/4715] Loss: 0.7181\n",
      "2025-05-30 17:16:29,491 - INFO - Epoch [18/30] Batch [3460/4715] Loss: 0.5803\n",
      "2025-05-30 17:16:30,995 - INFO - Epoch [18/30] Batch [3470/4715] Loss: 0.7948\n",
      "2025-05-30 17:16:32,567 - INFO - Epoch [18/30] Batch [3480/4715] Loss: 0.7876\n",
      "2025-05-30 17:16:34,056 - INFO - Epoch [18/30] Batch [3490/4715] Loss: 0.5130\n",
      "2025-05-30 17:16:35,621 - INFO - Epoch [18/30] Batch [3500/4715] Loss: 0.7951\n",
      "2025-05-30 17:16:37,078 - INFO - Epoch [18/30] Batch [3510/4715] Loss: 0.7279\n",
      "2025-05-30 17:16:38,681 - INFO - Epoch [18/30] Batch [3520/4715] Loss: 0.8048\n",
      "2025-05-30 17:16:40,258 - INFO - Epoch [18/30] Batch [3530/4715] Loss: 0.6113\n",
      "2025-05-30 17:16:41,804 - INFO - Epoch [18/30] Batch [3540/4715] Loss: 0.6318\n",
      "2025-05-30 17:16:43,363 - INFO - Epoch [18/30] Batch [3550/4715] Loss: 0.7052\n",
      "2025-05-30 17:16:44,950 - INFO - Epoch [18/30] Batch [3560/4715] Loss: 0.8067\n",
      "2025-05-30 17:16:46,418 - INFO - Epoch [18/30] Batch [3570/4715] Loss: 0.5519\n",
      "2025-05-30 17:16:47,994 - INFO - Epoch [18/30] Batch [3580/4715] Loss: 0.8501\n",
      "2025-05-30 17:16:49,623 - INFO - Epoch [18/30] Batch [3590/4715] Loss: 0.7828\n",
      "2025-05-30 17:16:51,314 - INFO - Epoch [18/30] Batch [3600/4715] Loss: 0.7278\n",
      "2025-05-30 17:16:52,821 - INFO - Epoch [18/30] Batch [3610/4715] Loss: 0.8745\n",
      "2025-05-30 17:16:54,456 - INFO - Epoch [18/30] Batch [3620/4715] Loss: 0.8942\n",
      "2025-05-30 17:16:56,028 - INFO - Epoch [18/30] Batch [3630/4715] Loss: 0.7206\n",
      "2025-05-30 17:16:57,605 - INFO - Epoch [18/30] Batch [3640/4715] Loss: 0.7798\n",
      "2025-05-30 17:16:59,122 - INFO - Epoch [18/30] Batch [3650/4715] Loss: 0.8308\n",
      "2025-05-30 17:17:00,696 - INFO - Epoch [18/30] Batch [3660/4715] Loss: 0.6721\n",
      "2025-05-30 17:17:02,238 - INFO - Epoch [18/30] Batch [3670/4715] Loss: 0.9352\n",
      "2025-05-30 17:17:03,747 - INFO - Epoch [18/30] Batch [3680/4715] Loss: 0.7387\n",
      "2025-05-30 17:17:05,424 - INFO - Epoch [18/30] Batch [3690/4715] Loss: 0.9797\n",
      "2025-05-30 17:17:07,144 - INFO - Epoch [18/30] Batch [3700/4715] Loss: 0.8981\n",
      "2025-05-30 17:17:08,801 - INFO - Epoch [18/30] Batch [3710/4715] Loss: 0.7281\n",
      "2025-05-30 17:17:10,479 - INFO - Epoch [18/30] Batch [3720/4715] Loss: 0.6362\n",
      "2025-05-30 17:17:12,080 - INFO - Epoch [18/30] Batch [3730/4715] Loss: 0.9127\n",
      "2025-05-30 17:17:13,650 - INFO - Epoch [18/30] Batch [3740/4715] Loss: 0.8155\n",
      "2025-05-30 17:17:15,296 - INFO - Epoch [18/30] Batch [3750/4715] Loss: 0.9079\n",
      "2025-05-30 17:17:16,893 - INFO - Epoch [18/30] Batch [3760/4715] Loss: 0.7006\n",
      "2025-05-30 17:17:18,397 - INFO - Epoch [18/30] Batch [3770/4715] Loss: 0.8808\n",
      "2025-05-30 17:17:19,881 - INFO - Epoch [18/30] Batch [3780/4715] Loss: 0.6682\n",
      "2025-05-30 17:17:21,422 - INFO - Epoch [18/30] Batch [3790/4715] Loss: 1.0760\n",
      "2025-05-30 17:17:22,884 - INFO - Epoch [18/30] Batch [3800/4715] Loss: 0.7265\n",
      "2025-05-30 17:17:24,449 - INFO - Epoch [18/30] Batch [3810/4715] Loss: 1.0423\n",
      "2025-05-30 17:17:26,057 - INFO - Epoch [18/30] Batch [3820/4715] Loss: 0.8408\n",
      "2025-05-30 17:17:27,654 - INFO - Epoch [18/30] Batch [3830/4715] Loss: 0.5975\n",
      "2025-05-30 17:17:29,359 - INFO - Epoch [18/30] Batch [3840/4715] Loss: 0.3643\n",
      "2025-05-30 17:17:30,907 - INFO - Epoch [18/30] Batch [3850/4715] Loss: 0.7747\n",
      "2025-05-30 17:17:32,450 - INFO - Epoch [18/30] Batch [3860/4715] Loss: 0.8574\n",
      "2025-05-30 17:17:34,067 - INFO - Epoch [18/30] Batch [3870/4715] Loss: 1.0161\n",
      "2025-05-30 17:17:35,587 - INFO - Epoch [18/30] Batch [3880/4715] Loss: 0.5195\n",
      "2025-05-30 17:17:37,127 - INFO - Epoch [18/30] Batch [3890/4715] Loss: 0.5815\n",
      "2025-05-30 17:17:38,718 - INFO - Epoch [18/30] Batch [3900/4715] Loss: 0.7619\n",
      "2025-05-30 17:17:40,322 - INFO - Epoch [18/30] Batch [3910/4715] Loss: 0.7896\n",
      "2025-05-30 17:17:42,045 - INFO - Epoch [18/30] Batch [3920/4715] Loss: 0.5722\n",
      "2025-05-30 17:17:43,660 - INFO - Epoch [18/30] Batch [3930/4715] Loss: 0.8071\n",
      "2025-05-30 17:17:45,238 - INFO - Epoch [18/30] Batch [3940/4715] Loss: 0.9994\n",
      "2025-05-30 17:17:46,791 - INFO - Epoch [18/30] Batch [3950/4715] Loss: 0.6014\n",
      "2025-05-30 17:17:48,333 - INFO - Epoch [18/30] Batch [3960/4715] Loss: 0.7448\n",
      "2025-05-30 17:17:49,977 - INFO - Epoch [18/30] Batch [3970/4715] Loss: 0.7648\n",
      "2025-05-30 17:17:51,745 - INFO - Epoch [18/30] Batch [3980/4715] Loss: 0.5576\n",
      "2025-05-30 17:17:53,275 - INFO - Epoch [18/30] Batch [3990/4715] Loss: 0.7464\n",
      "2025-05-30 17:17:54,809 - INFO - Epoch [18/30] Batch [4000/4715] Loss: 0.8415\n",
      "2025-05-30 17:17:56,408 - INFO - Epoch [18/30] Batch [4010/4715] Loss: 0.7631\n",
      "2025-05-30 17:17:57,987 - INFO - Epoch [18/30] Batch [4020/4715] Loss: 0.6335\n",
      "2025-05-30 17:17:59,568 - INFO - Epoch [18/30] Batch [4030/4715] Loss: 0.8683\n",
      "2025-05-30 17:18:01,115 - INFO - Epoch [18/30] Batch [4040/4715] Loss: 0.8583\n",
      "2025-05-30 17:18:02,660 - INFO - Epoch [18/30] Batch [4050/4715] Loss: 0.7473\n",
      "2025-05-30 17:18:04,229 - INFO - Epoch [18/30] Batch [4060/4715] Loss: 0.7482\n",
      "2025-05-30 17:18:05,798 - INFO - Epoch [18/30] Batch [4070/4715] Loss: 0.6595\n",
      "2025-05-30 17:18:07,418 - INFO - Epoch [18/30] Batch [4080/4715] Loss: 0.8111\n",
      "2025-05-30 17:18:08,991 - INFO - Epoch [18/30] Batch [4090/4715] Loss: 0.7136\n",
      "2025-05-30 17:18:10,552 - INFO - Epoch [18/30] Batch [4100/4715] Loss: 0.7730\n",
      "2025-05-30 17:18:12,150 - INFO - Epoch [18/30] Batch [4110/4715] Loss: 0.8654\n",
      "2025-05-30 17:18:13,699 - INFO - Epoch [18/30] Batch [4120/4715] Loss: 0.6424\n",
      "2025-05-30 17:18:15,279 - INFO - Epoch [18/30] Batch [4130/4715] Loss: 0.7945\n",
      "2025-05-30 17:18:16,837 - INFO - Epoch [18/30] Batch [4140/4715] Loss: 0.6071\n",
      "2025-05-30 17:18:18,451 - INFO - Epoch [18/30] Batch [4150/4715] Loss: 0.7429\n",
      "2025-05-30 17:18:20,147 - INFO - Epoch [18/30] Batch [4160/4715] Loss: 0.3844\n",
      "2025-05-30 17:18:21,753 - INFO - Epoch [18/30] Batch [4170/4715] Loss: 0.8998\n",
      "2025-05-30 17:18:23,342 - INFO - Epoch [18/30] Batch [4180/4715] Loss: 0.7511\n",
      "2025-05-30 17:18:24,876 - INFO - Epoch [18/30] Batch [4190/4715] Loss: 0.7765\n",
      "2025-05-30 17:18:26,420 - INFO - Epoch [18/30] Batch [4200/4715] Loss: 0.8650\n",
      "2025-05-30 17:18:28,017 - INFO - Epoch [18/30] Batch [4210/4715] Loss: 0.7213\n",
      "2025-05-30 17:18:29,633 - INFO - Epoch [18/30] Batch [4220/4715] Loss: 0.8567\n",
      "2025-05-30 17:18:31,177 - INFO - Epoch [18/30] Batch [4230/4715] Loss: 0.7753\n",
      "2025-05-30 17:18:32,695 - INFO - Epoch [18/30] Batch [4240/4715] Loss: 0.7132\n",
      "2025-05-30 17:18:34,279 - INFO - Epoch [18/30] Batch [4250/4715] Loss: 1.1554\n",
      "2025-05-30 17:18:35,889 - INFO - Epoch [18/30] Batch [4260/4715] Loss: 0.7480\n",
      "2025-05-30 17:18:37,391 - INFO - Epoch [18/30] Batch [4270/4715] Loss: 0.8472\n",
      "2025-05-30 17:18:38,952 - INFO - Epoch [18/30] Batch [4280/4715] Loss: 0.8894\n",
      "2025-05-30 17:18:40,522 - INFO - Epoch [18/30] Batch [4290/4715] Loss: 0.7144\n",
      "2025-05-30 17:18:42,134 - INFO - Epoch [18/30] Batch [4300/4715] Loss: 0.8536\n",
      "2025-05-30 17:18:43,654 - INFO - Epoch [18/30] Batch [4310/4715] Loss: 0.9991\n",
      "2025-05-30 17:18:45,195 - INFO - Epoch [18/30] Batch [4320/4715] Loss: 1.0576\n",
      "2025-05-30 17:18:46,758 - INFO - Epoch [18/30] Batch [4330/4715] Loss: 0.8888\n",
      "2025-05-30 17:18:48,383 - INFO - Epoch [18/30] Batch [4340/4715] Loss: 0.8940\n",
      "2025-05-30 17:18:49,879 - INFO - Epoch [18/30] Batch [4350/4715] Loss: 1.0097\n",
      "2025-05-30 17:18:51,456 - INFO - Epoch [18/30] Batch [4360/4715] Loss: 0.8221\n",
      "2025-05-30 17:18:52,968 - INFO - Epoch [18/30] Batch [4370/4715] Loss: 0.8207\n",
      "2025-05-30 17:18:54,517 - INFO - Epoch [18/30] Batch [4380/4715] Loss: 0.7764\n",
      "2025-05-30 17:18:56,058 - INFO - Epoch [18/30] Batch [4390/4715] Loss: 0.5983\n",
      "2025-05-30 17:18:57,576 - INFO - Epoch [18/30] Batch [4400/4715] Loss: 0.8820\n",
      "2025-05-30 17:18:59,114 - INFO - Epoch [18/30] Batch [4410/4715] Loss: 0.7166\n",
      "2025-05-30 17:19:00,647 - INFO - Epoch [18/30] Batch [4420/4715] Loss: 0.9089\n",
      "2025-05-30 17:19:02,219 - INFO - Epoch [18/30] Batch [4430/4715] Loss: 0.7914\n",
      "2025-05-30 17:19:03,805 - INFO - Epoch [18/30] Batch [4440/4715] Loss: 0.9230\n",
      "2025-05-30 17:19:05,246 - INFO - Epoch [18/30] Batch [4450/4715] Loss: 0.7207\n",
      "2025-05-30 17:19:06,853 - INFO - Epoch [18/30] Batch [4460/4715] Loss: 0.8114\n",
      "2025-05-30 17:19:08,435 - INFO - Epoch [18/30] Batch [4470/4715] Loss: 0.6331\n",
      "2025-05-30 17:19:09,994 - INFO - Epoch [18/30] Batch [4480/4715] Loss: 0.8000\n",
      "2025-05-30 17:19:11,568 - INFO - Epoch [18/30] Batch [4490/4715] Loss: 0.8940\n",
      "2025-05-30 17:19:13,087 - INFO - Epoch [18/30] Batch [4500/4715] Loss: 1.0458\n",
      "2025-05-30 17:19:14,613 - INFO - Epoch [18/30] Batch [4510/4715] Loss: 0.9840\n",
      "2025-05-30 17:19:16,149 - INFO - Epoch [18/30] Batch [4520/4715] Loss: 0.6724\n",
      "2025-05-30 17:19:17,724 - INFO - Epoch [18/30] Batch [4530/4715] Loss: 0.5363\n",
      "2025-05-30 17:19:19,304 - INFO - Epoch [18/30] Batch [4540/4715] Loss: 0.9868\n",
      "2025-05-30 17:19:20,850 - INFO - Epoch [18/30] Batch [4550/4715] Loss: 0.7888\n",
      "2025-05-30 17:19:22,507 - INFO - Epoch [18/30] Batch [4560/4715] Loss: 0.6420\n",
      "2025-05-30 17:19:24,058 - INFO - Epoch [18/30] Batch [4570/4715] Loss: 0.7823\n",
      "2025-05-30 17:19:25,679 - INFO - Epoch [18/30] Batch [4580/4715] Loss: 0.8591\n",
      "2025-05-30 17:19:27,281 - INFO - Epoch [18/30] Batch [4590/4715] Loss: 0.7727\n",
      "2025-05-30 17:19:28,922 - INFO - Epoch [18/30] Batch [4600/4715] Loss: 0.6544\n",
      "2025-05-30 17:19:30,503 - INFO - Epoch [18/30] Batch [4610/4715] Loss: 0.7286\n",
      "2025-05-30 17:19:32,106 - INFO - Epoch [18/30] Batch [4620/4715] Loss: 0.5638\n",
      "2025-05-30 17:19:33,590 - INFO - Epoch [18/30] Batch [4630/4715] Loss: 0.6638\n",
      "2025-05-30 17:19:35,137 - INFO - Epoch [18/30] Batch [4640/4715] Loss: 0.6324\n",
      "2025-05-30 17:19:36,683 - INFO - Epoch [18/30] Batch [4650/4715] Loss: 0.8672\n",
      "2025-05-30 17:19:38,220 - INFO - Epoch [18/30] Batch [4660/4715] Loss: 0.8085\n",
      "2025-05-30 17:19:39,822 - INFO - Epoch [18/30] Batch [4670/4715] Loss: 0.7233\n",
      "2025-05-30 17:19:41,448 - INFO - Epoch [18/30] Batch [4680/4715] Loss: 0.9403\n",
      "2025-05-30 17:19:43,025 - INFO - Epoch [18/30] Batch [4690/4715] Loss: 0.6306\n",
      "2025-05-30 17:19:44,681 - INFO - Epoch [18/30] Batch [4700/4715] Loss: 0.6890\n",
      "2025-05-30 17:19:46,284 - INFO - Epoch [18/30] Batch [4710/4715] Loss: 0.8425\n",
      "2025-05-30 17:20:25,741 - INFO - \n",
      "Epoch [18/30] Time: 783.06s\n",
      "2025-05-30 17:20:25,742 - INFO - Train Loss: 0.7656, Valid Loss: 0.8116\n",
      "2025-05-30 17:20:25,743 - INFO - Valid AUC (macro): 0.7410, F1 (macro): 0.5786\n",
      "2025-05-30 17:20:25,751 - INFO - Early stopping triggered at epoch 18\n",
      "2025-05-30 17:20:26,286 - INFO - Checkpoint saved: E:\\ProyectoRN\\ct_3d_classifier_output\\final_model.pth\n",
      "2025-05-30 17:20:26,294 - INFO - \n",
      "Training completed!\n",
      "2025-05-30 17:20:26,295 - INFO - Best model: Epoch 15 with AUC 0.7411\n",
      "2025-05-30 17:20:26,296 - INFO - Generating final training report...\n",
      "2025-05-30 17:20:28,886 - INFO - Training report saved to: E:\\ProyectoRN\\ct_3d_classifier_output\\training_report.png\n",
      "2025-05-30 17:20:30,037 - INFO - Training report (PDF) saved to: E:\\ProyectoRN\\ct_3d_classifier_output\\training_report.pdf\n",
      "2025-05-30 17:20:30,045 - INFO - Detailed metrics CSV saved to: E:\\ProyectoRN\\ct_3d_classifier_output\\training_metrics_detailed.csv\n",
      "2025-05-30 17:20:30,046 - INFO - Training summary saved to: E:\\ProyectoRN\\ct_3d_classifier_output\\training_summary.json\n",
      "2025-05-30 17:20:30,046 - INFO - Training complete!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Agregar el directorio raíz al path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from config.config import Config\n",
    "from training.trainer import train_model\n",
    "from training.utils import find_latest_checkpoint\n",
    "from utils.logging_config import setup_logging\n",
    "\n",
    "def main():\n",
    "    # Setup logging\n",
    "    logger = setup_logging()\n",
    "    \n",
    "    # Initialize configuration\n",
    "    config = Config()\n",
    "    \n",
    "    # Find latest checkpoint if exists\n",
    "    latest_checkpoint = find_latest_checkpoint(config.OUTPUT_DIR)\n",
    "    if latest_checkpoint:\n",
    "        config.RESUME_FROM_CHECKPOINT = str(latest_checkpoint)\n",
    "        logger.info(f\"Found checkpoint: {latest_checkpoint}\")\n",
    "    \n",
    "    # Train model\n",
    "    model, history = train_model(config)\n",
    "    logger.info(\"Training complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Memoria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
